===> Loading train datasets
===> Epoch[1](100/2500): Loss: 0.9676
===> Epoch[1](200/2500): Loss: 0.5163
===> Epoch[1](300/2500): Loss: 0.4593
===> Epoch[1](400/2500): Loss: 0.5313
===> Epoch[1](500/2500): Loss: 0.5074
===> Epoch[1](600/2500): Loss: 0.4706
===> Epoch[1](700/2500): Loss: 0.4898
===> Epoch[1](800/2500): Loss: 0.4595
===> Epoch[1](900/2500): Loss: 0.4563
===> Epoch[1](1000/2500): Loss: 0.4634
===> Epoch[1](1100/2500): Loss: 0.4537
===> Epoch[1](1200/2500): Loss: 0.4409
===> Epoch[1](1300/2500): Loss: 0.4443
===> Epoch[1](1400/2500): Loss: 0.4585
===> Epoch[1](1500/2500): Loss: 0.4503
===> Epoch[1](1600/2500): Loss: 0.4373
===> Epoch[1](1700/2500): Loss: 0.4299
===> Epoch[1](1800/2500): Loss: 0.4214
===> Epoch[1](1900/2500): Loss: 0.4223
===> Epoch[1](2000/2500): Loss: 0.4607
===> Epoch[1](2100/2500): Loss: 0.4326
===> Epoch[1](2200/2500): Loss: 0.4261
===> Epoch[1](2300/2500): Loss: 0.4742
===> Epoch[1](2400/2500): Loss: 0.4154
===> Epoch[1](2500/2500): Loss: 0.3899
===> Epoch 1 Complete: Avg. Loss: 29.5391
===> Timestamp: [2025-08-03 15:25:30]
===> Loading train datasets
===> Loading train datasets
===> Epoch[2](100/2500): Loss: 0.4456
===> Epoch[2](200/2500): Loss: 0.4284
===> Epoch[2](300/2500): Loss: 0.4180
===> Epoch[2](400/2500): Loss: 0.4118
===> Epoch[2](500/2500): Loss: 0.4280
===> Epoch[2](600/2500): Loss: 0.4516
===> Epoch[2](700/2500): Loss: 0.4379
===> Epoch[2](800/2500): Loss: 0.4393
===> Epoch[2](900/2500): Loss: 0.4032
===> Epoch[2](1000/2500): Loss: 0.4108
===> Epoch[2](1100/2500): Loss: 0.4717
===> Epoch[2](1200/2500): Loss: 0.4228
===> Epoch[2](1300/2500): Loss: 0.3831
===> Epoch[2](1400/2500): Loss: 0.3787
===> Epoch[2](1500/2500): Loss: 0.4055
===> Epoch[2](1600/2500): Loss: 0.4497
===> Epoch[2](1700/2500): Loss: 0.4105
===> Epoch[2](1800/2500): Loss: 0.4085
===> Epoch[2](1900/2500): Loss: 0.4288
===> Epoch[2](2000/2500): Loss: 0.3914
===> Epoch[2](2100/2500): Loss: 0.4389
===> Epoch[2](2200/2500): Loss: 0.3983
===> Epoch[2](2300/2500): Loss: 0.4211
===> Epoch[2](2400/2500): Loss: 0.3962
===> Epoch[2](2500/2500): Loss: 0.4268
===> Epoch 2 Complete: Avg. Loss: 0.4177
===> Timestamp: [2025-08-03 15:30:04]
===> Loading train datasets
===> Epoch[2](100/2500): Loss: 0.4456
===> Epoch[2](200/2500): Loss: 0.4284
===> Epoch[2](300/2500): Loss: 0.4180
===> Epoch[2](400/2500): Loss: 0.4118
===> Epoch[2](500/2500): Loss: 0.4280
===> Epoch[2](600/2500): Loss: 0.4516
===> Epoch[2](700/2500): Loss: 0.4379
===> Epoch[2](800/2500): Loss: 0.4393
===> Epoch[2](900/2500): Loss: 0.4032
===> Epoch[2](1000/2500): Loss: 0.4108
===> Epoch[2](1100/2500): Loss: 0.4717
===> Epoch[2](1200/2500): Loss: 0.4228
===> Epoch[2](1300/2500): Loss: 0.3831
===> Epoch[2](1400/2500): Loss: 0.3787
===> Epoch[2](1500/2500): Loss: 0.4055
===> Epoch[2](1600/2500): Loss: 0.4497
===> Epoch[2](1700/2500): Loss: 0.4105
===> Epoch[2](1800/2500): Loss: 0.4085
===> Epoch[2](1900/2500): Loss: 0.4288
===> Epoch[2](2000/2500): Loss: 0.3914
===> Epoch[2](2100/2500): Loss: 0.4389
===> Epoch[2](2200/2500): Loss: 0.3983
===> Epoch[2](2300/2500): Loss: 0.4211
===> Epoch[2](2400/2500): Loss: 0.3962
===> Epoch[2](2500/2500): Loss: 0.4268
===> Epoch 2 Complete: Avg. Loss: 0.4177
===> Timestamp: [2025-08-03 15:30:04]
===> Loading train datasets
===> Loading train datasets
===> Epoch[3](100/2500): Loss: 0.3827
===> Epoch[3](200/2500): Loss: 0.3973
===> Epoch[3](300/2500): Loss: 0.3875
===> Epoch[3](400/2500): Loss: 0.4076
===> Epoch[3](500/2500): Loss: 0.4299
===> Epoch[3](600/2500): Loss: 0.4166
===> Epoch[3](700/2500): Loss: 0.3852
===> Epoch[3](800/2500): Loss: 0.3910
===> Epoch[3](900/2500): Loss: 0.4155
===> Epoch[3](1000/2500): Loss: 0.4014
===> Epoch[3](1100/2500): Loss: 0.3739
===> Epoch[3](1200/2500): Loss: 0.3732
===> Epoch[3](1300/2500): Loss: 0.3671
===> Epoch[3](1400/2500): Loss: 0.4140
===> Epoch[3](1500/2500): Loss: 0.3890
===> Epoch[3](1600/2500): Loss: 0.3636
===> Epoch[3](1700/2500): Loss: 0.3840
===> Epoch[3](1800/2500): Loss: 0.3810
===> Epoch[3](1900/2500): Loss: 0.3623
===> Epoch[3](2000/2500): Loss: 0.3753
===> Epoch[3](2100/2500): Loss: 0.3960
===> Epoch[3](2200/2500): Loss: 0.3612
===> Epoch[3](2300/2500): Loss: 0.3949
===> Epoch[3](2400/2500): Loss: 0.3781
===> Epoch[3](2500/2500): Loss: 0.3908
===> Epoch 3 Complete: Avg. Loss: 0.3934
===> Timestamp: [2025-08-03 15:34:38]
===> Loading train datasets
===> Epoch[3](100/2500): Loss: 0.3827
===> Epoch[3](200/2500): Loss: 0.3973
===> Epoch[3](300/2500): Loss: 0.3875
===> Epoch[3](400/2500): Loss: 0.4076
===> Epoch[3](500/2500): Loss: 0.4299
===> Epoch[3](600/2500): Loss: 0.4166
===> Epoch[3](700/2500): Loss: 0.3852
===> Epoch[3](800/2500): Loss: 0.3910
===> Epoch[3](900/2500): Loss: 0.4155
===> Epoch[3](1000/2500): Loss: 0.4014
===> Epoch[3](1100/2500): Loss: 0.3739
===> Epoch[3](1200/2500): Loss: 0.3732
===> Epoch[3](1300/2500): Loss: 0.3671
===> Epoch[3](1400/2500): Loss: 0.4140
===> Epoch[3](1500/2500): Loss: 0.3890
===> Epoch[3](1600/2500): Loss: 0.3636
===> Epoch[3](1700/2500): Loss: 0.3840
===> Epoch[3](1800/2500): Loss: 0.3810
===> Epoch[3](1900/2500): Loss: 0.3623
===> Epoch[3](2000/2500): Loss: 0.3753
===> Epoch[3](2100/2500): Loss: 0.3960
===> Epoch[3](2200/2500): Loss: 0.3612
===> Epoch[3](2300/2500): Loss: 0.3949
===> Epoch[3](2400/2500): Loss: 0.3781
===> Epoch[3](2500/2500): Loss: 0.3908
===> Epoch 3 Complete: Avg. Loss: 0.3934
===> Timestamp: [2025-08-03 15:34:38]
===> Loading train datasets
===> Epoch[3](100/2500): Loss: 0.3827
===> Epoch[3](200/2500): Loss: 0.3973
===> Epoch[3](300/2500): Loss: 0.3875
===> Epoch[3](400/2500): Loss: 0.4076
===> Epoch[3](500/2500): Loss: 0.4299
===> Epoch[3](600/2500): Loss: 0.4166
===> Epoch[3](700/2500): Loss: 0.3852
===> Epoch[3](800/2500): Loss: 0.3910
===> Epoch[3](900/2500): Loss: 0.4155
===> Epoch[3](1000/2500): Loss: 0.4014
===> Epoch[3](1100/2500): Loss: 0.3739
===> Epoch[3](1200/2500): Loss: 0.3732
===> Epoch[3](1300/2500): Loss: 0.3671
===> Epoch[3](1400/2500): Loss: 0.4140
===> Epoch[3](1500/2500): Loss: 0.3890
===> Epoch[3](1600/2500): Loss: 0.3636
===> Epoch[3](1700/2500): Loss: 0.3840
===> Epoch[3](1800/2500): Loss: 0.3810
===> Epoch[3](1900/2500): Loss: 0.3623
===> Epoch[3](2000/2500): Loss: 0.3753
===> Epoch[3](2100/2500): Loss: 0.3960
===> Epoch[3](2200/2500): Loss: 0.3612
===> Epoch[3](2300/2500): Loss: 0.3949
===> Epoch[3](2400/2500): Loss: 0.3781
===> Epoch[3](2500/2500): Loss: 0.3908
===> Epoch 3 Complete: Avg. Loss: 0.3934
===> Timestamp: [2025-08-03 15:34:38]
===> Loading train datasets
===> Loading train datasets
===> Epoch[4](100/2500): Loss: 0.3791
===> Epoch[4](200/2500): Loss: 0.3951
===> Epoch[4](300/2500): Loss: 0.3921
===> Epoch[4](400/2500): Loss: 0.3508
===> Epoch[4](500/2500): Loss: 0.3904
===> Epoch[4](600/2500): Loss: 0.3517
===> Epoch[4](700/2500): Loss: 0.3969
===> Epoch[4](800/2500): Loss: 0.3677
===> Epoch[4](900/2500): Loss: 0.3638
===> Epoch[4](1000/2500): Loss: 0.3766
===> Epoch[4](1100/2500): Loss: 0.3989
===> Epoch[4](1200/2500): Loss: 0.4008
===> Epoch[4](1300/2500): Loss: 0.3887
===> Epoch[4](1400/2500): Loss: 0.3615
===> Epoch[4](1500/2500): Loss: 0.3443
===> Epoch[4](1600/2500): Loss: 0.3750
===> Epoch[4](1700/2500): Loss: 0.3672
===> Epoch[4](1800/2500): Loss: 0.3415
===> Epoch[4](1900/2500): Loss: 0.3699
===> Epoch[4](2000/2500): Loss: 0.3542
===> Epoch[4](2100/2500): Loss: 0.3418
===> Epoch[4](2200/2500): Loss: 0.3862
===> Epoch[4](2300/2500): Loss: 0.3558
===> Epoch[4](2400/2500): Loss: 0.3677
===> Epoch[4](2500/2500): Loss: 0.3278
===> Epoch 4 Complete: Avg. Loss: 0.3750
===> Timestamp: [2025-08-03 15:39:12]
===> Loading train datasets
===> Epoch[4](100/2500): Loss: 0.3791
===> Epoch[4](200/2500): Loss: 0.3951
===> Epoch[4](300/2500): Loss: 0.3921
===> Epoch[4](400/2500): Loss: 0.3508
===> Epoch[4](500/2500): Loss: 0.3904
===> Epoch[4](600/2500): Loss: 0.3517
===> Epoch[4](700/2500): Loss: 0.3969
===> Epoch[4](800/2500): Loss: 0.3677
===> Epoch[4](900/2500): Loss: 0.3638
===> Epoch[4](1000/2500): Loss: 0.3766
===> Epoch[4](1100/2500): Loss: 0.3989
===> Epoch[4](1200/2500): Loss: 0.4008
===> Epoch[4](1300/2500): Loss: 0.3887
===> Epoch[4](1400/2500): Loss: 0.3615
===> Epoch[4](1500/2500): Loss: 0.3443
===> Epoch[4](1600/2500): Loss: 0.3750
===> Epoch[4](1700/2500): Loss: 0.3672
===> Epoch[4](1800/2500): Loss: 0.3415
===> Epoch[4](1900/2500): Loss: 0.3699
===> Epoch[4](2000/2500): Loss: 0.3542
===> Epoch[4](2100/2500): Loss: 0.3418
===> Epoch[4](2200/2500): Loss: 0.3862
===> Epoch[4](2300/2500): Loss: 0.3558
===> Epoch[4](2400/2500): Loss: 0.3677
===> Epoch[4](2500/2500): Loss: 0.3278
===> Epoch 4 Complete: Avg. Loss: 0.3750
===> Timestamp: [2025-08-03 15:39:12]
===> Loading train datasets
===> Epoch[4](100/2500): Loss: 0.3791
===> Epoch[4](200/2500): Loss: 0.3951
===> Epoch[4](300/2500): Loss: 0.3921
===> Epoch[4](400/2500): Loss: 0.3508
===> Epoch[4](500/2500): Loss: 0.3904
===> Epoch[4](600/2500): Loss: 0.3517
===> Epoch[4](700/2500): Loss: 0.3969
===> Epoch[4](800/2500): Loss: 0.3677
===> Epoch[4](900/2500): Loss: 0.3638
===> Epoch[4](1000/2500): Loss: 0.3766
===> Epoch[4](1100/2500): Loss: 0.3989
===> Epoch[4](1200/2500): Loss: 0.4008
===> Epoch[4](1300/2500): Loss: 0.3887
===> Epoch[4](1400/2500): Loss: 0.3615
===> Epoch[4](1500/2500): Loss: 0.3443
===> Epoch[4](1600/2500): Loss: 0.3750
===> Epoch[4](1700/2500): Loss: 0.3672
===> Epoch[4](1800/2500): Loss: 0.3415
===> Epoch[4](1900/2500): Loss: 0.3699
===> Epoch[4](2000/2500): Loss: 0.3542
===> Epoch[4](2100/2500): Loss: 0.3418
===> Epoch[4](2200/2500): Loss: 0.3862
===> Epoch[4](2300/2500): Loss: 0.3558
===> Epoch[4](2400/2500): Loss: 0.3677
===> Epoch[4](2500/2500): Loss: 0.3278
===> Epoch 4 Complete: Avg. Loss: 0.3750
===> Timestamp: [2025-08-03 15:39:12]
===> Loading train datasets
===> Epoch[4](100/2500): Loss: 0.3791
===> Epoch[4](200/2500): Loss: 0.3951
===> Epoch[4](300/2500): Loss: 0.3921
===> Epoch[4](400/2500): Loss: 0.3508
===> Epoch[4](500/2500): Loss: 0.3904
===> Epoch[4](600/2500): Loss: 0.3517
===> Epoch[4](700/2500): Loss: 0.3969
===> Epoch[4](800/2500): Loss: 0.3677
===> Epoch[4](900/2500): Loss: 0.3638
===> Epoch[4](1000/2500): Loss: 0.3766
===> Epoch[4](1100/2500): Loss: 0.3989
===> Epoch[4](1200/2500): Loss: 0.4008
===> Epoch[4](1300/2500): Loss: 0.3887
===> Epoch[4](1400/2500): Loss: 0.3615
===> Epoch[4](1500/2500): Loss: 0.3443
===> Epoch[4](1600/2500): Loss: 0.3750
===> Epoch[4](1700/2500): Loss: 0.3672
===> Epoch[4](1800/2500): Loss: 0.3415
===> Epoch[4](1900/2500): Loss: 0.3699
===> Epoch[4](2000/2500): Loss: 0.3542
===> Epoch[4](2100/2500): Loss: 0.3418
===> Epoch[4](2200/2500): Loss: 0.3862
===> Epoch[4](2300/2500): Loss: 0.3558
===> Epoch[4](2400/2500): Loss: 0.3677
===> Epoch[4](2500/2500): Loss: 0.3278
===> Epoch 4 Complete: Avg. Loss: 0.3750
===> Timestamp: [2025-08-03 15:39:12]
===> Loading train datasets
===> Loading train datasets
===> Epoch[5](100/2500): Loss: 0.3744
===> Epoch[5](200/2500): Loss: 0.3423
===> Epoch[5](300/2500): Loss: 0.3301
===> Epoch[5](400/2500): Loss: 0.3636
===> Epoch[5](500/2500): Loss: 0.3436
===> Epoch[5](600/2500): Loss: 0.3543
===> Epoch[5](700/2500): Loss: 0.3454
===> Epoch[5](800/2500): Loss: 0.3525
===> Epoch[5](900/2500): Loss: 0.3274
===> Epoch[5](1000/2500): Loss: 0.3674
===> Epoch[5](1100/2500): Loss: 0.3807
===> Epoch[5](1200/2500): Loss: 0.3881
===> Epoch[5](1300/2500): Loss: 0.3560
===> Epoch[5](1400/2500): Loss: 0.3619
===> Epoch[5](1500/2500): Loss: 0.3701
===> Epoch[5](1600/2500): Loss: 0.3345
===> Epoch[5](1700/2500): Loss: 0.3612
===> Epoch[5](1800/2500): Loss: 0.3157
===> Epoch[5](1900/2500): Loss: 0.3437
===> Epoch[5](2000/2500): Loss: 0.3454
===> Epoch[5](2100/2500): Loss: 0.3640
===> Epoch[5](2200/2500): Loss: 0.3533
===> Epoch[5](2300/2500): Loss: 0.3313
===> Epoch[5](2400/2500): Loss: 0.3189
===> Epoch[5](2500/2500): Loss: 0.3089
===> Epoch 5 Complete: Avg. Loss: 0.3570
===> Timestamp: [2025-08-03 15:43:46]
Checkpoint saved to TrainedNet/_epoch_5.pth
===> Loading train datasets
===> Epoch[5](100/2500): Loss: 0.3744
===> Epoch[5](200/2500): Loss: 0.3423
===> Epoch[5](300/2500): Loss: 0.3301
===> Epoch[5](400/2500): Loss: 0.3636
===> Epoch[5](500/2500): Loss: 0.3436
===> Epoch[5](600/2500): Loss: 0.3543
===> Epoch[5](700/2500): Loss: 0.3454
===> Epoch[5](800/2500): Loss: 0.3525
===> Epoch[5](900/2500): Loss: 0.3274
===> Epoch[5](1000/2500): Loss: 0.3674
===> Epoch[5](1100/2500): Loss: 0.3807
===> Epoch[5](1200/2500): Loss: 0.3881
===> Epoch[5](1300/2500): Loss: 0.3560
===> Epoch[5](1400/2500): Loss: 0.3619
===> Epoch[5](1500/2500): Loss: 0.3701
===> Epoch[5](1600/2500): Loss: 0.3345
===> Epoch[5](1700/2500): Loss: 0.3612
===> Epoch[5](1800/2500): Loss: 0.3157
===> Epoch[5](1900/2500): Loss: 0.3437
===> Epoch[5](2000/2500): Loss: 0.3454
===> Epoch[5](2100/2500): Loss: 0.3640
===> Epoch[5](2200/2500): Loss: 0.3533
===> Epoch[5](2300/2500): Loss: 0.3313
===> Epoch[5](2400/2500): Loss: 0.3189
===> Epoch[5](2500/2500): Loss: 0.3089
===> Epoch 5 Complete: Avg. Loss: 0.3570
===> Timestamp: [2025-08-03 15:43:46]
Checkpoint saved to TrainedNet/_epoch_5.pth
===> Loading train datasets
===> Epoch[5](100/2500): Loss: 0.3744
===> Epoch[5](200/2500): Loss: 0.3423
===> Epoch[5](300/2500): Loss: 0.3301
===> Epoch[5](400/2500): Loss: 0.3636
===> Epoch[5](500/2500): Loss: 0.3436
===> Epoch[5](600/2500): Loss: 0.3543
===> Epoch[5](700/2500): Loss: 0.3454
===> Epoch[5](800/2500): Loss: 0.3525
===> Epoch[5](900/2500): Loss: 0.3274
===> Epoch[5](1000/2500): Loss: 0.3674
===> Epoch[5](1100/2500): Loss: 0.3807
===> Epoch[5](1200/2500): Loss: 0.3881
===> Epoch[5](1300/2500): Loss: 0.3560
===> Epoch[5](1400/2500): Loss: 0.3619
===> Epoch[5](1500/2500): Loss: 0.3701
===> Epoch[5](1600/2500): Loss: 0.3345
===> Epoch[5](1700/2500): Loss: 0.3612
===> Epoch[5](1800/2500): Loss: 0.3157
===> Epoch[5](1900/2500): Loss: 0.3437
===> Epoch[5](2000/2500): Loss: 0.3454
===> Epoch[5](2100/2500): Loss: 0.3640
===> Epoch[5](2200/2500): Loss: 0.3533
===> Epoch[5](2300/2500): Loss: 0.3313
===> Epoch[5](2400/2500): Loss: 0.3189
===> Epoch[5](2500/2500): Loss: 0.3089
===> Epoch 5 Complete: Avg. Loss: 0.3570
===> Timestamp: [2025-08-03 15:43:46]
Checkpoint saved to TrainedNet/_epoch_5.pth
===> Loading train datasets
===> Epoch[5](100/2500): Loss: 0.3744
===> Epoch[5](200/2500): Loss: 0.3423
===> Epoch[5](300/2500): Loss: 0.3301
===> Epoch[5](400/2500): Loss: 0.3636
===> Epoch[5](500/2500): Loss: 0.3436
===> Epoch[5](600/2500): Loss: 0.3543
===> Epoch[5](700/2500): Loss: 0.3454
===> Epoch[5](800/2500): Loss: 0.3525
===> Epoch[5](900/2500): Loss: 0.3274
===> Epoch[5](1000/2500): Loss: 0.3674
===> Epoch[5](1100/2500): Loss: 0.3807
===> Epoch[5](1200/2500): Loss: 0.3881
===> Epoch[5](1300/2500): Loss: 0.3560
===> Epoch[5](1400/2500): Loss: 0.3619
===> Epoch[5](1500/2500): Loss: 0.3701
===> Epoch[5](1600/2500): Loss: 0.3345
===> Epoch[5](1700/2500): Loss: 0.3612
===> Epoch[5](1800/2500): Loss: 0.3157
===> Epoch[5](1900/2500): Loss: 0.3437
===> Epoch[5](2000/2500): Loss: 0.3454
===> Epoch[5](2100/2500): Loss: 0.3640
===> Epoch[5](2200/2500): Loss: 0.3533
===> Epoch[5](2300/2500): Loss: 0.3313
===> Epoch[5](2400/2500): Loss: 0.3189
===> Epoch[5](2500/2500): Loss: 0.3089
===> Epoch 5 Complete: Avg. Loss: 0.3570
===> Timestamp: [2025-08-03 15:43:46]
Checkpoint saved to TrainedNet/_epoch_5.pth
===> Loading train datasets
===> Epoch[5](100/2500): Loss: 0.3744
===> Epoch[5](200/2500): Loss: 0.3423
===> Epoch[5](300/2500): Loss: 0.3301
===> Epoch[5](400/2500): Loss: 0.3636
===> Epoch[5](500/2500): Loss: 0.3436
===> Epoch[5](600/2500): Loss: 0.3543
===> Epoch[5](700/2500): Loss: 0.3454
===> Epoch[5](800/2500): Loss: 0.3525
===> Epoch[5](900/2500): Loss: 0.3274
===> Epoch[5](1000/2500): Loss: 0.3674
===> Epoch[5](1100/2500): Loss: 0.3807
===> Epoch[5](1200/2500): Loss: 0.3881
===> Epoch[5](1300/2500): Loss: 0.3560
===> Epoch[5](1400/2500): Loss: 0.3619
===> Epoch[5](1500/2500): Loss: 0.3701
===> Epoch[5](1600/2500): Loss: 0.3345
===> Epoch[5](1700/2500): Loss: 0.3612
===> Epoch[5](1800/2500): Loss: 0.3157
===> Epoch[5](1900/2500): Loss: 0.3437
===> Epoch[5](2000/2500): Loss: 0.3454
===> Epoch[5](2100/2500): Loss: 0.3640
===> Epoch[5](2200/2500): Loss: 0.3533
===> Epoch[5](2300/2500): Loss: 0.3313
===> Epoch[5](2400/2500): Loss: 0.3189
===> Epoch[5](2500/2500): Loss: 0.3089
===> Epoch 5 Complete: Avg. Loss: 0.3570
===> Timestamp: [2025-08-03 15:43:46]
Checkpoint saved to TrainedNet/_epoch_5.pth
===> Loading train datasets
===> Loading train datasets
===> Epoch[6](100/2500): Loss: 0.3187
===> Epoch[6](200/2500): Loss: 0.3672
===> Epoch[6](300/2500): Loss: 0.3430
===> Epoch[6](400/2500): Loss: 0.3522
===> Epoch[6](500/2500): Loss: 0.3351
===> Epoch[6](600/2500): Loss: 0.3653
===> Epoch[6](700/2500): Loss: 0.3389
===> Epoch[6](800/2500): Loss: 0.3216
===> Epoch[6](900/2500): Loss: 0.3666
===> Epoch[6](1000/2500): Loss: 0.3547
===> Epoch[6](1100/2500): Loss: 0.3145
===> Epoch[6](1200/2500): Loss: 0.3379
===> Epoch[6](1300/2500): Loss: 0.3368
===> Epoch[6](1400/2500): Loss: 0.3541
===> Epoch[6](1500/2500): Loss: 0.3110
===> Epoch[6](1600/2500): Loss: 0.3175
===> Epoch[6](1700/2500): Loss: 0.3121
===> Epoch[6](1800/2500): Loss: 0.3068
===> Epoch[6](1900/2500): Loss: 0.3335
===> Epoch[6](2000/2500): Loss: 0.3162
===> Epoch[6](2100/2500): Loss: 0.3279
===> Epoch[6](2200/2500): Loss: 0.2966
===> Epoch[6](2300/2500): Loss: 0.3161
===> Epoch[6](2400/2500): Loss: 0.3216
===> Epoch[6](2500/2500): Loss: 0.3183
===> Epoch 6 Complete: Avg. Loss: 0.3357
===> Timestamp: [2025-08-03 15:48:19]
===> Loading train datasets
===> Epoch[6](100/2500): Loss: 0.3187
===> Epoch[6](200/2500): Loss: 0.3672
===> Epoch[6](300/2500): Loss: 0.3430
===> Epoch[6](400/2500): Loss: 0.3522
===> Epoch[6](500/2500): Loss: 0.3351
===> Epoch[6](600/2500): Loss: 0.3653
===> Epoch[6](700/2500): Loss: 0.3389
===> Epoch[6](800/2500): Loss: 0.3216
===> Epoch[6](900/2500): Loss: 0.3666
===> Epoch[6](1000/2500): Loss: 0.3547
===> Epoch[6](1100/2500): Loss: 0.3145
===> Epoch[6](1200/2500): Loss: 0.3379
===> Epoch[6](1300/2500): Loss: 0.3368
===> Epoch[6](1400/2500): Loss: 0.3541
===> Epoch[6](1500/2500): Loss: 0.3110
===> Epoch[6](1600/2500): Loss: 0.3175
===> Epoch[6](1700/2500): Loss: 0.3121
===> Epoch[6](1800/2500): Loss: 0.3068
===> Epoch[6](1900/2500): Loss: 0.3335
===> Epoch[6](2000/2500): Loss: 0.3162
===> Epoch[6](2100/2500): Loss: 0.3279
===> Epoch[6](2200/2500): Loss: 0.2966
===> Epoch[6](2300/2500): Loss: 0.3161
===> Epoch[6](2400/2500): Loss: 0.3216
===> Epoch[6](2500/2500): Loss: 0.3183
===> Epoch 6 Complete: Avg. Loss: 0.3357
===> Timestamp: [2025-08-03 15:48:19]
===> Loading train datasets
===> Epoch[6](100/2500): Loss: 0.3187
===> Epoch[6](200/2500): Loss: 0.3672
===> Epoch[6](300/2500): Loss: 0.3430
===> Epoch[6](400/2500): Loss: 0.3522
===> Epoch[6](500/2500): Loss: 0.3351
===> Epoch[6](600/2500): Loss: 0.3653
===> Epoch[6](700/2500): Loss: 0.3389
===> Epoch[6](800/2500): Loss: 0.3216
===> Epoch[6](900/2500): Loss: 0.3666
===> Epoch[6](1000/2500): Loss: 0.3547
===> Epoch[6](1100/2500): Loss: 0.3145
===> Epoch[6](1200/2500): Loss: 0.3379
===> Epoch[6](1300/2500): Loss: 0.3368
===> Epoch[6](1400/2500): Loss: 0.3541
===> Epoch[6](1500/2500): Loss: 0.3110
===> Epoch[6](1600/2500): Loss: 0.3175
===> Epoch[6](1700/2500): Loss: 0.3121
===> Epoch[6](1800/2500): Loss: 0.3068
===> Epoch[6](1900/2500): Loss: 0.3335
===> Epoch[6](2000/2500): Loss: 0.3162
===> Epoch[6](2100/2500): Loss: 0.3279
===> Epoch[6](2200/2500): Loss: 0.2966
===> Epoch[6](2300/2500): Loss: 0.3161
===> Epoch[6](2400/2500): Loss: 0.3216
===> Epoch[6](2500/2500): Loss: 0.3183
===> Epoch 6 Complete: Avg. Loss: 0.3357
===> Timestamp: [2025-08-03 15:48:19]
===> Loading train datasets
===> Epoch[6](100/2500): Loss: 0.3187
===> Epoch[6](200/2500): Loss: 0.3672
===> Epoch[6](300/2500): Loss: 0.3430
===> Epoch[6](400/2500): Loss: 0.3522
===> Epoch[6](500/2500): Loss: 0.3351
===> Epoch[6](600/2500): Loss: 0.3653
===> Epoch[6](700/2500): Loss: 0.3389
===> Epoch[6](800/2500): Loss: 0.3216
===> Epoch[6](900/2500): Loss: 0.3666
===> Epoch[6](1000/2500): Loss: 0.3547
===> Epoch[6](1100/2500): Loss: 0.3145
===> Epoch[6](1200/2500): Loss: 0.3379
===> Epoch[6](1300/2500): Loss: 0.3368
===> Epoch[6](1400/2500): Loss: 0.3541
===> Epoch[6](1500/2500): Loss: 0.3110
===> Epoch[6](1600/2500): Loss: 0.3175
===> Epoch[6](1700/2500): Loss: 0.3121
===> Epoch[6](1800/2500): Loss: 0.3068
===> Epoch[6](1900/2500): Loss: 0.3335
===> Epoch[6](2000/2500): Loss: 0.3162
===> Epoch[6](2100/2500): Loss: 0.3279
===> Epoch[6](2200/2500): Loss: 0.2966
===> Epoch[6](2300/2500): Loss: 0.3161
===> Epoch[6](2400/2500): Loss: 0.3216
===> Epoch[6](2500/2500): Loss: 0.3183
===> Epoch 6 Complete: Avg. Loss: 0.3357
===> Timestamp: [2025-08-03 15:48:19]
===> Loading train datasets
===> Epoch[6](100/2500): Loss: 0.3187
===> Epoch[6](200/2500): Loss: 0.3672
===> Epoch[6](300/2500): Loss: 0.3430
===> Epoch[6](400/2500): Loss: 0.3522
===> Epoch[6](500/2500): Loss: 0.3351
===> Epoch[6](600/2500): Loss: 0.3653
===> Epoch[6](700/2500): Loss: 0.3389
===> Epoch[6](800/2500): Loss: 0.3216
===> Epoch[6](900/2500): Loss: 0.3666
===> Epoch[6](1000/2500): Loss: 0.3547
===> Epoch[6](1100/2500): Loss: 0.3145
===> Epoch[6](1200/2500): Loss: 0.3379
===> Epoch[6](1300/2500): Loss: 0.3368
===> Epoch[6](1400/2500): Loss: 0.3541
===> Epoch[6](1500/2500): Loss: 0.3110
===> Epoch[6](1600/2500): Loss: 0.3175
===> Epoch[6](1700/2500): Loss: 0.3121
===> Epoch[6](1800/2500): Loss: 0.3068
===> Epoch[6](1900/2500): Loss: 0.3335
===> Epoch[6](2000/2500): Loss: 0.3162
===> Epoch[6](2100/2500): Loss: 0.3279
===> Epoch[6](2200/2500): Loss: 0.2966
===> Epoch[6](2300/2500): Loss: 0.3161
===> Epoch[6](2400/2500): Loss: 0.3216
===> Epoch[6](2500/2500): Loss: 0.3183
===> Epoch 6 Complete: Avg. Loss: 0.3357
===> Timestamp: [2025-08-03 15:48:19]
===> Loading train datasets
===> Epoch[6](100/2500): Loss: 0.3187
===> Epoch[6](200/2500): Loss: 0.3672
===> Epoch[6](300/2500): Loss: 0.3430
===> Epoch[6](400/2500): Loss: 0.3522
===> Epoch[6](500/2500): Loss: 0.3351
===> Epoch[6](600/2500): Loss: 0.3653
===> Epoch[6](700/2500): Loss: 0.3389
===> Epoch[6](800/2500): Loss: 0.3216
===> Epoch[6](900/2500): Loss: 0.3666
===> Epoch[6](1000/2500): Loss: 0.3547
===> Epoch[6](1100/2500): Loss: 0.3145
===> Epoch[6](1200/2500): Loss: 0.3379
===> Epoch[6](1300/2500): Loss: 0.3368
===> Epoch[6](1400/2500): Loss: 0.3541
===> Epoch[6](1500/2500): Loss: 0.3110
===> Epoch[6](1600/2500): Loss: 0.3175
===> Epoch[6](1700/2500): Loss: 0.3121
===> Epoch[6](1800/2500): Loss: 0.3068
===> Epoch[6](1900/2500): Loss: 0.3335
===> Epoch[6](2000/2500): Loss: 0.3162
===> Epoch[6](2100/2500): Loss: 0.3279
===> Epoch[6](2200/2500): Loss: 0.2966
===> Epoch[6](2300/2500): Loss: 0.3161
===> Epoch[6](2400/2500): Loss: 0.3216
===> Epoch[6](2500/2500): Loss: 0.3183
===> Epoch 6 Complete: Avg. Loss: 0.3357
===> Timestamp: [2025-08-03 15:48:19]
===> Loading train datasets
===> Loading train datasets
===> Epoch[7](100/2500): Loss: 0.2908
===> Epoch[7](200/2500): Loss: 0.3212
===> Epoch[7](300/2500): Loss: 0.3223
===> Epoch[7](400/2500): Loss: 0.3276
===> Epoch[7](500/2500): Loss: 0.3102
===> Epoch[7](600/2500): Loss: 0.3108
===> Epoch[7](700/2500): Loss: 0.2936
===> Epoch[7](800/2500): Loss: 0.3201
===> Epoch[7](900/2500): Loss: 0.3285
===> Epoch[7](1000/2500): Loss: 0.3332
===> Epoch[7](1100/2500): Loss: 0.3122
===> Epoch[7](1200/2500): Loss: 0.3062
===> Epoch[7](1300/2500): Loss: 0.3121
===> Epoch[7](1400/2500): Loss: 0.3202
===> Epoch[7](1500/2500): Loss: 0.2963
===> Epoch[7](1600/2500): Loss: 0.2990
===> Epoch[7](1700/2500): Loss: 0.2969
===> Epoch[7](1800/2500): Loss: 0.2940
===> Epoch[7](1900/2500): Loss: 0.3261
===> Epoch[7](2000/2500): Loss: 0.3296
===> Epoch[7](2100/2500): Loss: 0.2862
===> Epoch[7](2200/2500): Loss: 0.3128
===> Epoch[7](2300/2500): Loss: 0.3141
===> Epoch[7](2400/2500): Loss: 0.2983
===> Epoch[7](2500/2500): Loss: 0.3191
===> Epoch 7 Complete: Avg. Loss: 0.3170
===> Timestamp: [2025-08-03 15:52:53]
===> Loading train datasets
===> Epoch[7](100/2500): Loss: 0.2908
===> Epoch[7](200/2500): Loss: 0.3212
===> Epoch[7](300/2500): Loss: 0.3223
===> Epoch[7](400/2500): Loss: 0.3276
===> Epoch[7](500/2500): Loss: 0.3102
===> Epoch[7](600/2500): Loss: 0.3108
===> Epoch[7](700/2500): Loss: 0.2936
===> Epoch[7](800/2500): Loss: 0.3201
===> Epoch[7](900/2500): Loss: 0.3285
===> Epoch[7](1000/2500): Loss: 0.3332
===> Epoch[7](1100/2500): Loss: 0.3122
===> Epoch[7](1200/2500): Loss: 0.3062
===> Epoch[7](1300/2500): Loss: 0.3121
===> Epoch[7](1400/2500): Loss: 0.3202
===> Epoch[7](1500/2500): Loss: 0.2963
===> Epoch[7](1600/2500): Loss: 0.2990
===> Epoch[7](1700/2500): Loss: 0.2969
===> Epoch[7](1800/2500): Loss: 0.2940
===> Epoch[7](1900/2500): Loss: 0.3261
===> Epoch[7](2000/2500): Loss: 0.3296
===> Epoch[7](2100/2500): Loss: 0.2862
===> Epoch[7](2200/2500): Loss: 0.3128
===> Epoch[7](2300/2500): Loss: 0.3141
===> Epoch[7](2400/2500): Loss: 0.2983
===> Epoch[7](2500/2500): Loss: 0.3191
===> Epoch 7 Complete: Avg. Loss: 0.3170
===> Timestamp: [2025-08-03 15:52:53]
===> Loading train datasets
===> Epoch[7](100/2500): Loss: 0.2908
===> Epoch[7](200/2500): Loss: 0.3212
===> Epoch[7](300/2500): Loss: 0.3223
===> Epoch[7](400/2500): Loss: 0.3276
===> Epoch[7](500/2500): Loss: 0.3102
===> Epoch[7](600/2500): Loss: 0.3108
===> Epoch[7](700/2500): Loss: 0.2936
===> Epoch[7](800/2500): Loss: 0.3201
===> Epoch[7](900/2500): Loss: 0.3285
===> Epoch[7](1000/2500): Loss: 0.3332
===> Epoch[7](1100/2500): Loss: 0.3122
===> Epoch[7](1200/2500): Loss: 0.3062
===> Epoch[7](1300/2500): Loss: 0.3121
===> Epoch[7](1400/2500): Loss: 0.3202
===> Epoch[7](1500/2500): Loss: 0.2963
===> Epoch[7](1600/2500): Loss: 0.2990
===> Epoch[7](1700/2500): Loss: 0.2969
===> Epoch[7](1800/2500): Loss: 0.2940
===> Epoch[7](1900/2500): Loss: 0.3261
===> Epoch[7](2000/2500): Loss: 0.3296
===> Epoch[7](2100/2500): Loss: 0.2862
===> Epoch[7](2200/2500): Loss: 0.3128
===> Epoch[7](2300/2500): Loss: 0.3141
===> Epoch[7](2400/2500): Loss: 0.2983
===> Epoch[7](2500/2500): Loss: 0.3191
===> Epoch 7 Complete: Avg. Loss: 0.3170
===> Timestamp: [2025-08-03 15:52:53]
===> Loading train datasets
===> Epoch[7](100/2500): Loss: 0.2908
===> Epoch[7](200/2500): Loss: 0.3212
===> Epoch[7](300/2500): Loss: 0.3223
===> Epoch[7](400/2500): Loss: 0.3276
===> Epoch[7](500/2500): Loss: 0.3102
===> Epoch[7](600/2500): Loss: 0.3108
===> Epoch[7](700/2500): Loss: 0.2936
===> Epoch[7](800/2500): Loss: 0.3201
===> Epoch[7](900/2500): Loss: 0.3285
===> Epoch[7](1000/2500): Loss: 0.3332
===> Epoch[7](1100/2500): Loss: 0.3122
===> Epoch[7](1200/2500): Loss: 0.3062
===> Epoch[7](1300/2500): Loss: 0.3121
===> Epoch[7](1400/2500): Loss: 0.3202
===> Epoch[7](1500/2500): Loss: 0.2963
===> Epoch[7](1600/2500): Loss: 0.2990
===> Epoch[7](1700/2500): Loss: 0.2969
===> Epoch[7](1800/2500): Loss: 0.2940
===> Epoch[7](1900/2500): Loss: 0.3261
===> Epoch[7](2000/2500): Loss: 0.3296
===> Epoch[7](2100/2500): Loss: 0.2862
===> Epoch[7](2200/2500): Loss: 0.3128
===> Epoch[7](2300/2500): Loss: 0.3141
===> Epoch[7](2400/2500): Loss: 0.2983
===> Epoch[7](2500/2500): Loss: 0.3191
===> Epoch 7 Complete: Avg. Loss: 0.3170
===> Timestamp: [2025-08-03 15:52:53]
===> Loading train datasets
===> Epoch[7](100/2500): Loss: 0.2908
===> Epoch[7](200/2500): Loss: 0.3212
===> Epoch[7](300/2500): Loss: 0.3223
===> Epoch[7](400/2500): Loss: 0.3276
===> Epoch[7](500/2500): Loss: 0.3102
===> Epoch[7](600/2500): Loss: 0.3108
===> Epoch[7](700/2500): Loss: 0.2936
===> Epoch[7](800/2500): Loss: 0.3201
===> Epoch[7](900/2500): Loss: 0.3285
===> Epoch[7](1000/2500): Loss: 0.3332
===> Epoch[7](1100/2500): Loss: 0.3122
===> Epoch[7](1200/2500): Loss: 0.3062
===> Epoch[7](1300/2500): Loss: 0.3121
===> Epoch[7](1400/2500): Loss: 0.3202
===> Epoch[7](1500/2500): Loss: 0.2963
===> Epoch[7](1600/2500): Loss: 0.2990
===> Epoch[7](1700/2500): Loss: 0.2969
===> Epoch[7](1800/2500): Loss: 0.2940
===> Epoch[7](1900/2500): Loss: 0.3261
===> Epoch[7](2000/2500): Loss: 0.3296
===> Epoch[7](2100/2500): Loss: 0.2862
===> Epoch[7](2200/2500): Loss: 0.3128
===> Epoch[7](2300/2500): Loss: 0.3141
===> Epoch[7](2400/2500): Loss: 0.2983
===> Epoch[7](2500/2500): Loss: 0.3191
===> Epoch 7 Complete: Avg. Loss: 0.3170
===> Timestamp: [2025-08-03 15:52:53]
===> Loading train datasets
===> Epoch[7](100/2500): Loss: 0.2908
===> Epoch[7](200/2500): Loss: 0.3212
===> Epoch[7](300/2500): Loss: 0.3223
===> Epoch[7](400/2500): Loss: 0.3276
===> Epoch[7](500/2500): Loss: 0.3102
===> Epoch[7](600/2500): Loss: 0.3108
===> Epoch[7](700/2500): Loss: 0.2936
===> Epoch[7](800/2500): Loss: 0.3201
===> Epoch[7](900/2500): Loss: 0.3285
===> Epoch[7](1000/2500): Loss: 0.3332
===> Epoch[7](1100/2500): Loss: 0.3122
===> Epoch[7](1200/2500): Loss: 0.3062
===> Epoch[7](1300/2500): Loss: 0.3121
===> Epoch[7](1400/2500): Loss: 0.3202
===> Epoch[7](1500/2500): Loss: 0.2963
===> Epoch[7](1600/2500): Loss: 0.2990
===> Epoch[7](1700/2500): Loss: 0.2969
===> Epoch[7](1800/2500): Loss: 0.2940
===> Epoch[7](1900/2500): Loss: 0.3261
===> Epoch[7](2000/2500): Loss: 0.3296
===> Epoch[7](2100/2500): Loss: 0.2862
===> Epoch[7](2200/2500): Loss: 0.3128
===> Epoch[7](2300/2500): Loss: 0.3141
===> Epoch[7](2400/2500): Loss: 0.2983
===> Epoch[7](2500/2500): Loss: 0.3191
===> Epoch 7 Complete: Avg. Loss: 0.3170
===> Timestamp: [2025-08-03 15:52:53]
===> Loading train datasets
===> Epoch[7](100/2500): Loss: 0.2908
===> Epoch[7](200/2500): Loss: 0.3212
===> Epoch[7](300/2500): Loss: 0.3223
===> Epoch[7](400/2500): Loss: 0.3276
===> Epoch[7](500/2500): Loss: 0.3102
===> Epoch[7](600/2500): Loss: 0.3108
===> Epoch[7](700/2500): Loss: 0.2936
===> Epoch[7](800/2500): Loss: 0.3201
===> Epoch[7](900/2500): Loss: 0.3285
===> Epoch[7](1000/2500): Loss: 0.3332
===> Epoch[7](1100/2500): Loss: 0.3122
===> Epoch[7](1200/2500): Loss: 0.3062
===> Epoch[7](1300/2500): Loss: 0.3121
===> Epoch[7](1400/2500): Loss: 0.3202
===> Epoch[7](1500/2500): Loss: 0.2963
===> Epoch[7](1600/2500): Loss: 0.2990
===> Epoch[7](1700/2500): Loss: 0.2969
===> Epoch[7](1800/2500): Loss: 0.2940
===> Epoch[7](1900/2500): Loss: 0.3261
===> Epoch[7](2000/2500): Loss: 0.3296
===> Epoch[7](2100/2500): Loss: 0.2862
===> Epoch[7](2200/2500): Loss: 0.3128
===> Epoch[7](2300/2500): Loss: 0.3141
===> Epoch[7](2400/2500): Loss: 0.2983
===> Epoch[7](2500/2500): Loss: 0.3191
===> Epoch 7 Complete: Avg. Loss: 0.3170
===> Timestamp: [2025-08-03 15:52:53]
===> Loading train datasets
===> Loading train datasets
===> Epoch[8](100/2500): Loss: 0.3025
===> Epoch[8](200/2500): Loss: 0.2757
===> Epoch[8](300/2500): Loss: 0.3325
===> Epoch[8](400/2500): Loss: 0.3477
===> Epoch[8](500/2500): Loss: 0.3239
===> Epoch[8](600/2500): Loss: 0.3163
===> Epoch[8](700/2500): Loss: 0.3118
===> Epoch[8](800/2500): Loss: 0.2818
===> Epoch[8](900/2500): Loss: 0.2890
===> Epoch[8](1000/2500): Loss: 0.3093
===> Epoch[8](1100/2500): Loss: 0.3005
===> Epoch[8](1200/2500): Loss: 0.2912
===> Epoch[8](1300/2500): Loss: 0.2893
===> Epoch[8](1400/2500): Loss: 0.2987
===> Epoch[8](1500/2500): Loss: 0.2981
===> Epoch[8](1600/2500): Loss: 0.2933
===> Epoch[8](1700/2500): Loss: 0.2556
===> Epoch[8](1800/2500): Loss: 0.2861
===> Epoch[8](1900/2500): Loss: 0.2733
===> Epoch[8](2000/2500): Loss: 0.2603
===> Epoch[8](2100/2500): Loss: 0.2671
===> Epoch[8](2200/2500): Loss: 0.2750
===> Epoch[8](2300/2500): Loss: 0.2690
===> Epoch[8](2400/2500): Loss: 0.2643
===> Epoch[8](2500/2500): Loss: 0.2573
===> Epoch 8 Complete: Avg. Loss: 0.2906
===> Timestamp: [2025-08-03 15:57:27]
===> Loading train datasets
===> Epoch[8](100/2500): Loss: 0.3025
===> Epoch[8](200/2500): Loss: 0.2757
===> Epoch[8](300/2500): Loss: 0.3325
===> Epoch[8](400/2500): Loss: 0.3477
===> Epoch[8](500/2500): Loss: 0.3239
===> Epoch[8](600/2500): Loss: 0.3163
===> Epoch[8](700/2500): Loss: 0.3118
===> Epoch[8](800/2500): Loss: 0.2818
===> Epoch[8](900/2500): Loss: 0.2890
===> Epoch[8](1000/2500): Loss: 0.3093
===> Epoch[8](1100/2500): Loss: 0.3005
===> Epoch[8](1200/2500): Loss: 0.2912
===> Epoch[8](1300/2500): Loss: 0.2893
===> Epoch[8](1400/2500): Loss: 0.2987
===> Epoch[8](1500/2500): Loss: 0.2981
===> Epoch[8](1600/2500): Loss: 0.2933
===> Epoch[8](1700/2500): Loss: 0.2556
===> Epoch[8](1800/2500): Loss: 0.2861
===> Epoch[8](1900/2500): Loss: 0.2733
===> Epoch[8](2000/2500): Loss: 0.2603
===> Epoch[8](2100/2500): Loss: 0.2671
===> Epoch[8](2200/2500): Loss: 0.2750
===> Epoch[8](2300/2500): Loss: 0.2690
===> Epoch[8](2400/2500): Loss: 0.2643
===> Epoch[8](2500/2500): Loss: 0.2573
===> Epoch 8 Complete: Avg. Loss: 0.2906
===> Timestamp: [2025-08-03 15:57:27]
===> Loading train datasets
===> Epoch[8](100/2500): Loss: 0.3025
===> Epoch[8](200/2500): Loss: 0.2757
===> Epoch[8](300/2500): Loss: 0.3325
===> Epoch[8](400/2500): Loss: 0.3477
===> Epoch[8](500/2500): Loss: 0.3239
===> Epoch[8](600/2500): Loss: 0.3163
===> Epoch[8](700/2500): Loss: 0.3118
===> Epoch[8](800/2500): Loss: 0.2818
===> Epoch[8](900/2500): Loss: 0.2890
===> Epoch[8](1000/2500): Loss: 0.3093
===> Epoch[8](1100/2500): Loss: 0.3005
===> Epoch[8](1200/2500): Loss: 0.2912
===> Epoch[8](1300/2500): Loss: 0.2893
===> Epoch[8](1400/2500): Loss: 0.2987
===> Epoch[8](1500/2500): Loss: 0.2981
===> Epoch[8](1600/2500): Loss: 0.2933
===> Epoch[8](1700/2500): Loss: 0.2556
===> Epoch[8](1800/2500): Loss: 0.2861
===> Epoch[8](1900/2500): Loss: 0.2733
===> Epoch[8](2000/2500): Loss: 0.2603
===> Epoch[8](2100/2500): Loss: 0.2671
===> Epoch[8](2200/2500): Loss: 0.2750
===> Epoch[8](2300/2500): Loss: 0.2690
===> Epoch[8](2400/2500): Loss: 0.2643
===> Epoch[8](2500/2500): Loss: 0.2573
===> Epoch 8 Complete: Avg. Loss: 0.2906
===> Timestamp: [2025-08-03 15:57:27]
===> Loading train datasets
===> Epoch[8](100/2500): Loss: 0.3025
===> Epoch[8](200/2500): Loss: 0.2757
===> Epoch[8](300/2500): Loss: 0.3325
===> Epoch[8](400/2500): Loss: 0.3477
===> Epoch[8](500/2500): Loss: 0.3239
===> Epoch[8](600/2500): Loss: 0.3163
===> Epoch[8](700/2500): Loss: 0.3118
===> Epoch[8](800/2500): Loss: 0.2818
===> Epoch[8](900/2500): Loss: 0.2890
===> Epoch[8](1000/2500): Loss: 0.3093
===> Epoch[8](1100/2500): Loss: 0.3005
===> Epoch[8](1200/2500): Loss: 0.2912
===> Epoch[8](1300/2500): Loss: 0.2893
===> Epoch[8](1400/2500): Loss: 0.2987
===> Epoch[8](1500/2500): Loss: 0.2981
===> Epoch[8](1600/2500): Loss: 0.2933
===> Epoch[8](1700/2500): Loss: 0.2556
===> Epoch[8](1800/2500): Loss: 0.2861
===> Epoch[8](1900/2500): Loss: 0.2733
===> Epoch[8](2000/2500): Loss: 0.2603
===> Epoch[8](2100/2500): Loss: 0.2671
===> Epoch[8](2200/2500): Loss: 0.2750
===> Epoch[8](2300/2500): Loss: 0.2690
===> Epoch[8](2400/2500): Loss: 0.2643
===> Epoch[8](2500/2500): Loss: 0.2573
===> Epoch 8 Complete: Avg. Loss: 0.2906
===> Timestamp: [2025-08-03 15:57:27]
===> Loading train datasets
===> Epoch[8](100/2500): Loss: 0.3025
===> Epoch[8](200/2500): Loss: 0.2757
===> Epoch[8](300/2500): Loss: 0.3325
===> Epoch[8](400/2500): Loss: 0.3477
===> Epoch[8](500/2500): Loss: 0.3239
===> Epoch[8](600/2500): Loss: 0.3163
===> Epoch[8](700/2500): Loss: 0.3118
===> Epoch[8](800/2500): Loss: 0.2818
===> Epoch[8](900/2500): Loss: 0.2890
===> Epoch[8](1000/2500): Loss: 0.3093
===> Epoch[8](1100/2500): Loss: 0.3005
===> Epoch[8](1200/2500): Loss: 0.2912
===> Epoch[8](1300/2500): Loss: 0.2893
===> Epoch[8](1400/2500): Loss: 0.2987
===> Epoch[8](1500/2500): Loss: 0.2981
===> Epoch[8](1600/2500): Loss: 0.2933
===> Epoch[8](1700/2500): Loss: 0.2556
===> Epoch[8](1800/2500): Loss: 0.2861
===> Epoch[8](1900/2500): Loss: 0.2733
===> Epoch[8](2000/2500): Loss: 0.2603
===> Epoch[8](2100/2500): Loss: 0.2671
===> Epoch[8](2200/2500): Loss: 0.2750
===> Epoch[8](2300/2500): Loss: 0.2690
===> Epoch[8](2400/2500): Loss: 0.2643
===> Epoch[8](2500/2500): Loss: 0.2573
===> Epoch 8 Complete: Avg. Loss: 0.2906
===> Timestamp: [2025-08-03 15:57:27]
===> Loading train datasets
===> Epoch[8](100/2500): Loss: 0.3025
===> Epoch[8](200/2500): Loss: 0.2757
===> Epoch[8](300/2500): Loss: 0.3325
===> Epoch[8](400/2500): Loss: 0.3477
===> Epoch[8](500/2500): Loss: 0.3239
===> Epoch[8](600/2500): Loss: 0.3163
===> Epoch[8](700/2500): Loss: 0.3118
===> Epoch[8](800/2500): Loss: 0.2818
===> Epoch[8](900/2500): Loss: 0.2890
===> Epoch[8](1000/2500): Loss: 0.3093
===> Epoch[8](1100/2500): Loss: 0.3005
===> Epoch[8](1200/2500): Loss: 0.2912
===> Epoch[8](1300/2500): Loss: 0.2893
===> Epoch[8](1400/2500): Loss: 0.2987
===> Epoch[8](1500/2500): Loss: 0.2981
===> Epoch[8](1600/2500): Loss: 0.2933
===> Epoch[8](1700/2500): Loss: 0.2556
===> Epoch[8](1800/2500): Loss: 0.2861
===> Epoch[8](1900/2500): Loss: 0.2733
===> Epoch[8](2000/2500): Loss: 0.2603
===> Epoch[8](2100/2500): Loss: 0.2671
===> Epoch[8](2200/2500): Loss: 0.2750
===> Epoch[8](2300/2500): Loss: 0.2690
===> Epoch[8](2400/2500): Loss: 0.2643
===> Epoch[8](2500/2500): Loss: 0.2573
===> Epoch 8 Complete: Avg. Loss: 0.2906
===> Timestamp: [2025-08-03 15:57:27]
===> Loading train datasets
===> Epoch[8](100/2500): Loss: 0.3025
===> Epoch[8](200/2500): Loss: 0.2757
===> Epoch[8](300/2500): Loss: 0.3325
===> Epoch[8](400/2500): Loss: 0.3477
===> Epoch[8](500/2500): Loss: 0.3239
===> Epoch[8](600/2500): Loss: 0.3163
===> Epoch[8](700/2500): Loss: 0.3118
===> Epoch[8](800/2500): Loss: 0.2818
===> Epoch[8](900/2500): Loss: 0.2890
===> Epoch[8](1000/2500): Loss: 0.3093
===> Epoch[8](1100/2500): Loss: 0.3005
===> Epoch[8](1200/2500): Loss: 0.2912
===> Epoch[8](1300/2500): Loss: 0.2893
===> Epoch[8](1400/2500): Loss: 0.2987
===> Epoch[8](1500/2500): Loss: 0.2981
===> Epoch[8](1600/2500): Loss: 0.2933
===> Epoch[8](1700/2500): Loss: 0.2556
===> Epoch[8](1800/2500): Loss: 0.2861
===> Epoch[8](1900/2500): Loss: 0.2733
===> Epoch[8](2000/2500): Loss: 0.2603
===> Epoch[8](2100/2500): Loss: 0.2671
===> Epoch[8](2200/2500): Loss: 0.2750
===> Epoch[8](2300/2500): Loss: 0.2690
===> Epoch[8](2400/2500): Loss: 0.2643
===> Epoch[8](2500/2500): Loss: 0.2573
===> Epoch 8 Complete: Avg. Loss: 0.2906
===> Timestamp: [2025-08-03 15:57:27]
===> Loading train datasets
===> Epoch[8](100/2500): Loss: 0.3025
===> Epoch[8](200/2500): Loss: 0.2757
===> Epoch[8](300/2500): Loss: 0.3325
===> Epoch[8](400/2500): Loss: 0.3477
===> Epoch[8](500/2500): Loss: 0.3239
===> Epoch[8](600/2500): Loss: 0.3163
===> Epoch[8](700/2500): Loss: 0.3118
===> Epoch[8](800/2500): Loss: 0.2818
===> Epoch[8](900/2500): Loss: 0.2890
===> Epoch[8](1000/2500): Loss: 0.3093
===> Epoch[8](1100/2500): Loss: 0.3005
===> Epoch[8](1200/2500): Loss: 0.2912
===> Epoch[8](1300/2500): Loss: 0.2893
===> Epoch[8](1400/2500): Loss: 0.2987
===> Epoch[8](1500/2500): Loss: 0.2981
===> Epoch[8](1600/2500): Loss: 0.2933
===> Epoch[8](1700/2500): Loss: 0.2556
===> Epoch[8](1800/2500): Loss: 0.2861
===> Epoch[8](1900/2500): Loss: 0.2733
===> Epoch[8](2000/2500): Loss: 0.2603
===> Epoch[8](2100/2500): Loss: 0.2671
===> Epoch[8](2200/2500): Loss: 0.2750
===> Epoch[8](2300/2500): Loss: 0.2690
===> Epoch[8](2400/2500): Loss: 0.2643
===> Epoch[8](2500/2500): Loss: 0.2573
===> Epoch 8 Complete: Avg. Loss: 0.2906
===> Timestamp: [2025-08-03 15:57:27]
===> Loading train datasets
===> Loading train datasets
===> Epoch[9](100/2500): Loss: 0.2375
===> Epoch[9](200/2500): Loss: 0.2767
===> Epoch[9](300/2500): Loss: 0.2524
===> Epoch[9](400/2500): Loss: 0.2784
===> Epoch[9](500/2500): Loss: 0.2618
===> Epoch[9](600/2500): Loss: 0.2511
===> Epoch[9](700/2500): Loss: 0.2842
===> Epoch[9](800/2500): Loss: 0.2573
===> Epoch[9](900/2500): Loss: 0.2867
===> Epoch[9](1000/2500): Loss: 0.2548
===> Epoch[9](1100/2500): Loss: 0.2782
===> Epoch[9](1200/2500): Loss: 0.2584
===> Epoch[9](1300/2500): Loss: 0.2445
===> Epoch[9](1400/2500): Loss: 0.2692
===> Epoch[9](1500/2500): Loss: 0.2479
===> Epoch[9](1600/2500): Loss: 0.2931
===> Epoch[9](1700/2500): Loss: 0.2967
===> Epoch[9](1800/2500): Loss: 0.2689
===> Epoch[9](1900/2500): Loss: 0.2697
===> Epoch[9](2000/2500): Loss: 0.2570
===> Epoch[9](2100/2500): Loss: 0.2581
===> Epoch[9](2200/2500): Loss: 0.7067
===> Epoch[9](2300/2500): Loss: 0.3124
===> Epoch[9](2400/2500): Loss: 0.3021
===> Epoch[9](2500/2500): Loss: 0.2974
===> Epoch 9 Complete: Avg. Loss: 0.3193
===> Timestamp: [2025-08-03 16:02:01]
===> Loading train datasets
===> Epoch[9](100/2500): Loss: 0.2375
===> Epoch[9](200/2500): Loss: 0.2767
===> Epoch[9](300/2500): Loss: 0.2524
===> Epoch[9](400/2500): Loss: 0.2784
===> Epoch[9](500/2500): Loss: 0.2618
===> Epoch[9](600/2500): Loss: 0.2511
===> Epoch[9](700/2500): Loss: 0.2842
===> Epoch[9](800/2500): Loss: 0.2573
===> Epoch[9](900/2500): Loss: 0.2867
===> Epoch[9](1000/2500): Loss: 0.2548
===> Epoch[9](1100/2500): Loss: 0.2782
===> Epoch[9](1200/2500): Loss: 0.2584
===> Epoch[9](1300/2500): Loss: 0.2445
===> Epoch[9](1400/2500): Loss: 0.2692
===> Epoch[9](1500/2500): Loss: 0.2479
===> Epoch[9](1600/2500): Loss: 0.2931
===> Epoch[9](1700/2500): Loss: 0.2967
===> Epoch[9](1800/2500): Loss: 0.2689
===> Epoch[9](1900/2500): Loss: 0.2697
===> Epoch[9](2000/2500): Loss: 0.2570
===> Epoch[9](2100/2500): Loss: 0.2581
===> Epoch[9](2200/2500): Loss: 0.7067
===> Epoch[9](2300/2500): Loss: 0.3124
===> Epoch[9](2400/2500): Loss: 0.3021
===> Epoch[9](2500/2500): Loss: 0.2974
===> Epoch 9 Complete: Avg. Loss: 0.3193
===> Timestamp: [2025-08-03 16:02:01]
===> Loading train datasets
===> Epoch[9](100/2500): Loss: 0.2375
===> Epoch[9](200/2500): Loss: 0.2767
===> Epoch[9](300/2500): Loss: 0.2524
===> Epoch[9](400/2500): Loss: 0.2784
===> Epoch[9](500/2500): Loss: 0.2618
===> Epoch[9](600/2500): Loss: 0.2511
===> Epoch[9](700/2500): Loss: 0.2842
===> Epoch[9](800/2500): Loss: 0.2573
===> Epoch[9](900/2500): Loss: 0.2867
===> Epoch[9](1000/2500): Loss: 0.2548
===> Epoch[9](1100/2500): Loss: 0.2782
===> Epoch[9](1200/2500): Loss: 0.2584
===> Epoch[9](1300/2500): Loss: 0.2445
===> Epoch[9](1400/2500): Loss: 0.2692
===> Epoch[9](1500/2500): Loss: 0.2479
===> Epoch[9](1600/2500): Loss: 0.2931
===> Epoch[9](1700/2500): Loss: 0.2967
===> Epoch[9](1800/2500): Loss: 0.2689
===> Epoch[9](1900/2500): Loss: 0.2697
===> Epoch[9](2000/2500): Loss: 0.2570
===> Epoch[9](2100/2500): Loss: 0.2581
===> Epoch[9](2200/2500): Loss: 0.7067
===> Epoch[9](2300/2500): Loss: 0.3124
===> Epoch[9](2400/2500): Loss: 0.3021
===> Epoch[9](2500/2500): Loss: 0.2974
===> Epoch 9 Complete: Avg. Loss: 0.3193
===> Timestamp: [2025-08-03 16:02:01]
===> Loading train datasets
===> Epoch[9](100/2500): Loss: 0.2375
===> Epoch[9](200/2500): Loss: 0.2767
===> Epoch[9](300/2500): Loss: 0.2524
===> Epoch[9](400/2500): Loss: 0.2784
===> Epoch[9](500/2500): Loss: 0.2618
===> Epoch[9](600/2500): Loss: 0.2511
===> Epoch[9](700/2500): Loss: 0.2842
===> Epoch[9](800/2500): Loss: 0.2573
===> Epoch[9](900/2500): Loss: 0.2867
===> Epoch[9](1000/2500): Loss: 0.2548
===> Epoch[9](1100/2500): Loss: 0.2782
===> Epoch[9](1200/2500): Loss: 0.2584
===> Epoch[9](1300/2500): Loss: 0.2445
===> Epoch[9](1400/2500): Loss: 0.2692
===> Epoch[9](1500/2500): Loss: 0.2479
===> Epoch[9](1600/2500): Loss: 0.2931
===> Epoch[9](1700/2500): Loss: 0.2967
===> Epoch[9](1800/2500): Loss: 0.2689
===> Epoch[9](1900/2500): Loss: 0.2697
===> Epoch[9](2000/2500): Loss: 0.2570
===> Epoch[9](2100/2500): Loss: 0.2581
===> Epoch[9](2200/2500): Loss: 0.7067
===> Epoch[9](2300/2500): Loss: 0.3124
===> Epoch[9](2400/2500): Loss: 0.3021
===> Epoch[9](2500/2500): Loss: 0.2974
===> Epoch 9 Complete: Avg. Loss: 0.3193
===> Timestamp: [2025-08-03 16:02:01]
===> Loading train datasets
===> Epoch[9](100/2500): Loss: 0.2375
===> Epoch[9](200/2500): Loss: 0.2767
===> Epoch[9](300/2500): Loss: 0.2524
===> Epoch[9](400/2500): Loss: 0.2784
===> Epoch[9](500/2500): Loss: 0.2618
===> Epoch[9](600/2500): Loss: 0.2511
===> Epoch[9](700/2500): Loss: 0.2842
===> Epoch[9](800/2500): Loss: 0.2573
===> Epoch[9](900/2500): Loss: 0.2867
===> Epoch[9](1000/2500): Loss: 0.2548
===> Epoch[9](1100/2500): Loss: 0.2782
===> Epoch[9](1200/2500): Loss: 0.2584
===> Epoch[9](1300/2500): Loss: 0.2445
===> Epoch[9](1400/2500): Loss: 0.2692
===> Epoch[9](1500/2500): Loss: 0.2479
===> Epoch[9](1600/2500): Loss: 0.2931
===> Epoch[9](1700/2500): Loss: 0.2967
===> Epoch[9](1800/2500): Loss: 0.2689
===> Epoch[9](1900/2500): Loss: 0.2697
===> Epoch[9](2000/2500): Loss: 0.2570
===> Epoch[9](2100/2500): Loss: 0.2581
===> Epoch[9](2200/2500): Loss: 0.7067
===> Epoch[9](2300/2500): Loss: 0.3124
===> Epoch[9](2400/2500): Loss: 0.3021
===> Epoch[9](2500/2500): Loss: 0.2974
===> Epoch 9 Complete: Avg. Loss: 0.3193
===> Timestamp: [2025-08-03 16:02:01]
===> Loading train datasets
===> Epoch[9](100/2500): Loss: 0.2375
===> Epoch[9](200/2500): Loss: 0.2767
===> Epoch[9](300/2500): Loss: 0.2524
===> Epoch[9](400/2500): Loss: 0.2784
===> Epoch[9](500/2500): Loss: 0.2618
===> Epoch[9](600/2500): Loss: 0.2511
===> Epoch[9](700/2500): Loss: 0.2842
===> Epoch[9](800/2500): Loss: 0.2573
===> Epoch[9](900/2500): Loss: 0.2867
===> Epoch[9](1000/2500): Loss: 0.2548
===> Epoch[9](1100/2500): Loss: 0.2782
===> Epoch[9](1200/2500): Loss: 0.2584
===> Epoch[9](1300/2500): Loss: 0.2445
===> Epoch[9](1400/2500): Loss: 0.2692
===> Epoch[9](1500/2500): Loss: 0.2479
===> Epoch[9](1600/2500): Loss: 0.2931
===> Epoch[9](1700/2500): Loss: 0.2967
===> Epoch[9](1800/2500): Loss: 0.2689
===> Epoch[9](1900/2500): Loss: 0.2697
===> Epoch[9](2000/2500): Loss: 0.2570
===> Epoch[9](2100/2500): Loss: 0.2581
===> Epoch[9](2200/2500): Loss: 0.7067
===> Epoch[9](2300/2500): Loss: 0.3124
===> Epoch[9](2400/2500): Loss: 0.3021
===> Epoch[9](2500/2500): Loss: 0.2974
===> Epoch 9 Complete: Avg. Loss: 0.3193
===> Timestamp: [2025-08-03 16:02:01]
===> Loading train datasets
===> Epoch[9](100/2500): Loss: 0.2375
===> Epoch[9](200/2500): Loss: 0.2767
===> Epoch[9](300/2500): Loss: 0.2524
===> Epoch[9](400/2500): Loss: 0.2784
===> Epoch[9](500/2500): Loss: 0.2618
===> Epoch[9](600/2500): Loss: 0.2511
===> Epoch[9](700/2500): Loss: 0.2842
===> Epoch[9](800/2500): Loss: 0.2573
===> Epoch[9](900/2500): Loss: 0.2867
===> Epoch[9](1000/2500): Loss: 0.2548
===> Epoch[9](1100/2500): Loss: 0.2782
===> Epoch[9](1200/2500): Loss: 0.2584
===> Epoch[9](1300/2500): Loss: 0.2445
===> Epoch[9](1400/2500): Loss: 0.2692
===> Epoch[9](1500/2500): Loss: 0.2479
===> Epoch[9](1600/2500): Loss: 0.2931
===> Epoch[9](1700/2500): Loss: 0.2967
===> Epoch[9](1800/2500): Loss: 0.2689
===> Epoch[9](1900/2500): Loss: 0.2697
===> Epoch[9](2000/2500): Loss: 0.2570
===> Epoch[9](2100/2500): Loss: 0.2581
===> Epoch[9](2200/2500): Loss: 0.7067
===> Epoch[9](2300/2500): Loss: 0.3124
===> Epoch[9](2400/2500): Loss: 0.3021
===> Epoch[9](2500/2500): Loss: 0.2974
===> Epoch 9 Complete: Avg. Loss: 0.3193
===> Timestamp: [2025-08-03 16:02:01]
===> Loading train datasets
===> Epoch[9](100/2500): Loss: 0.2375
===> Epoch[9](200/2500): Loss: 0.2767
===> Epoch[9](300/2500): Loss: 0.2524
===> Epoch[9](400/2500): Loss: 0.2784
===> Epoch[9](500/2500): Loss: 0.2618
===> Epoch[9](600/2500): Loss: 0.2511
===> Epoch[9](700/2500): Loss: 0.2842
===> Epoch[9](800/2500): Loss: 0.2573
===> Epoch[9](900/2500): Loss: 0.2867
===> Epoch[9](1000/2500): Loss: 0.2548
===> Epoch[9](1100/2500): Loss: 0.2782
===> Epoch[9](1200/2500): Loss: 0.2584
===> Epoch[9](1300/2500): Loss: 0.2445
===> Epoch[9](1400/2500): Loss: 0.2692
===> Epoch[9](1500/2500): Loss: 0.2479
===> Epoch[9](1600/2500): Loss: 0.2931
===> Epoch[9](1700/2500): Loss: 0.2967
===> Epoch[9](1800/2500): Loss: 0.2689
===> Epoch[9](1900/2500): Loss: 0.2697
===> Epoch[9](2000/2500): Loss: 0.2570
===> Epoch[9](2100/2500): Loss: 0.2581
===> Epoch[9](2200/2500): Loss: 0.7067
===> Epoch[9](2300/2500): Loss: 0.3124
===> Epoch[9](2400/2500): Loss: 0.3021
===> Epoch[9](2500/2500): Loss: 0.2974
===> Epoch 9 Complete: Avg. Loss: 0.3193
===> Timestamp: [2025-08-03 16:02:01]
===> Loading train datasets
===> Epoch[9](100/2500): Loss: 0.2375
===> Epoch[9](200/2500): Loss: 0.2767
===> Epoch[9](300/2500): Loss: 0.2524
===> Epoch[9](400/2500): Loss: 0.2784
===> Epoch[9](500/2500): Loss: 0.2618
===> Epoch[9](600/2500): Loss: 0.2511
===> Epoch[9](700/2500): Loss: 0.2842
===> Epoch[9](800/2500): Loss: 0.2573
===> Epoch[9](900/2500): Loss: 0.2867
===> Epoch[9](1000/2500): Loss: 0.2548
===> Epoch[9](1100/2500): Loss: 0.2782
===> Epoch[9](1200/2500): Loss: 0.2584
===> Epoch[9](1300/2500): Loss: 0.2445
===> Epoch[9](1400/2500): Loss: 0.2692
===> Epoch[9](1500/2500): Loss: 0.2479
===> Epoch[9](1600/2500): Loss: 0.2931
===> Epoch[9](1700/2500): Loss: 0.2967
===> Epoch[9](1800/2500): Loss: 0.2689
===> Epoch[9](1900/2500): Loss: 0.2697
===> Epoch[9](2000/2500): Loss: 0.2570
===> Epoch[9](2100/2500): Loss: 0.2581
===> Epoch[9](2200/2500): Loss: 0.7067
===> Epoch[9](2300/2500): Loss: 0.3124
===> Epoch[9](2400/2500): Loss: 0.3021
===> Epoch[9](2500/2500): Loss: 0.2974
===> Epoch 9 Complete: Avg. Loss: 0.3193
===> Timestamp: [2025-08-03 16:02:01]
===> Loading train datasets
===> Loading train datasets
===> Epoch[10](100/2500): Loss: 0.2801
===> Epoch[10](200/2500): Loss: 0.2748
===> Epoch[10](300/2500): Loss: 0.2969
===> Epoch[10](400/2500): Loss: 0.2693
===> Epoch[10](500/2500): Loss: 0.2556
===> Epoch[10](600/2500): Loss: 0.2741
===> Epoch[10](700/2500): Loss: 0.2847
===> Epoch[10](800/2500): Loss: 0.2710
===> Epoch[10](900/2500): Loss: 0.3164
===> Epoch[10](1000/2500): Loss: 0.2682
===> Epoch[10](1100/2500): Loss: 0.2730
===> Epoch[10](1200/2500): Loss: 0.2755
===> Epoch[10](1300/2500): Loss: 0.2725
===> Epoch[10](1400/2500): Loss: 0.2519
===> Epoch[10](1500/2500): Loss: 0.2665
===> Epoch[10](1600/2500): Loss: 0.2637
===> Epoch[10](1700/2500): Loss: 0.2731
===> Epoch[10](1800/2500): Loss: 0.2713
===> Epoch[10](1900/2500): Loss: 0.2650
===> Epoch[10](2000/2500): Loss: 0.2754
===> Epoch[10](2100/2500): Loss: 0.2845
===> Epoch[10](2200/2500): Loss: 0.2578
===> Epoch[10](2300/2500): Loss: 0.2585
===> Epoch[10](2400/2500): Loss: 0.2481
===> Epoch[10](2500/2500): Loss: 0.2531
===> Epoch 10 Complete: Avg. Loss: 0.2753
===> Timestamp: [2025-08-03 16:06:34]
Checkpoint saved to TrainedNet/_epoch_10.pth
===> Loading train datasets
===> Epoch[10](100/2500): Loss: 0.2801
===> Epoch[10](200/2500): Loss: 0.2748
===> Epoch[10](300/2500): Loss: 0.2969
===> Epoch[10](400/2500): Loss: 0.2693
===> Epoch[10](500/2500): Loss: 0.2556
===> Epoch[10](600/2500): Loss: 0.2741
===> Epoch[10](700/2500): Loss: 0.2847
===> Epoch[10](800/2500): Loss: 0.2710
===> Epoch[10](900/2500): Loss: 0.3164
===> Epoch[10](1000/2500): Loss: 0.2682
===> Epoch[10](1100/2500): Loss: 0.2730
===> Epoch[10](1200/2500): Loss: 0.2755
===> Epoch[10](1300/2500): Loss: 0.2725
===> Epoch[10](1400/2500): Loss: 0.2519
===> Epoch[10](1500/2500): Loss: 0.2665
===> Epoch[10](1600/2500): Loss: 0.2637
===> Epoch[10](1700/2500): Loss: 0.2731
===> Epoch[10](1800/2500): Loss: 0.2713
===> Epoch[10](1900/2500): Loss: 0.2650
===> Epoch[10](2000/2500): Loss: 0.2754
===> Epoch[10](2100/2500): Loss: 0.2845
===> Epoch[10](2200/2500): Loss: 0.2578
===> Epoch[10](2300/2500): Loss: 0.2585
===> Epoch[10](2400/2500): Loss: 0.2481
===> Epoch[10](2500/2500): Loss: 0.2531
===> Epoch 10 Complete: Avg. Loss: 0.2753
===> Timestamp: [2025-08-03 16:06:34]
Checkpoint saved to TrainedNet/_epoch_10.pth
===> Loading train datasets
===> Epoch[10](100/2500): Loss: 0.2801
===> Epoch[10](200/2500): Loss: 0.2748
===> Epoch[10](300/2500): Loss: 0.2969
===> Epoch[10](400/2500): Loss: 0.2693
===> Epoch[10](500/2500): Loss: 0.2556
===> Epoch[10](600/2500): Loss: 0.2741
===> Epoch[10](700/2500): Loss: 0.2847
===> Epoch[10](800/2500): Loss: 0.2710
===> Epoch[10](900/2500): Loss: 0.3164
===> Epoch[10](1000/2500): Loss: 0.2682
===> Epoch[10](1100/2500): Loss: 0.2730
===> Epoch[10](1200/2500): Loss: 0.2755
===> Epoch[10](1300/2500): Loss: 0.2725
===> Epoch[10](1400/2500): Loss: 0.2519
===> Epoch[10](1500/2500): Loss: 0.2665
===> Epoch[10](1600/2500): Loss: 0.2637
===> Epoch[10](1700/2500): Loss: 0.2731
===> Epoch[10](1800/2500): Loss: 0.2713
===> Epoch[10](1900/2500): Loss: 0.2650
===> Epoch[10](2000/2500): Loss: 0.2754
===> Epoch[10](2100/2500): Loss: 0.2845
===> Epoch[10](2200/2500): Loss: 0.2578
===> Epoch[10](2300/2500): Loss: 0.2585
===> Epoch[10](2400/2500): Loss: 0.2481
===> Epoch[10](2500/2500): Loss: 0.2531
===> Epoch 10 Complete: Avg. Loss: 0.2753
===> Timestamp: [2025-08-03 16:06:34]
Checkpoint saved to TrainedNet/_epoch_10.pth
===> Loading train datasets
===> Epoch[10](100/2500): Loss: 0.2801
===> Epoch[10](200/2500): Loss: 0.2748
===> Epoch[10](300/2500): Loss: 0.2969
===> Epoch[10](400/2500): Loss: 0.2693
===> Epoch[10](500/2500): Loss: 0.2556
===> Epoch[10](600/2500): Loss: 0.2741
===> Epoch[10](700/2500): Loss: 0.2847
===> Epoch[10](800/2500): Loss: 0.2710
===> Epoch[10](900/2500): Loss: 0.3164
===> Epoch[10](1000/2500): Loss: 0.2682
===> Epoch[10](1100/2500): Loss: 0.2730
===> Epoch[10](1200/2500): Loss: 0.2755
===> Epoch[10](1300/2500): Loss: 0.2725
===> Epoch[10](1400/2500): Loss: 0.2519
===> Epoch[10](1500/2500): Loss: 0.2665
===> Epoch[10](1600/2500): Loss: 0.2637
===> Epoch[10](1700/2500): Loss: 0.2731
===> Epoch[10](1800/2500): Loss: 0.2713
===> Epoch[10](1900/2500): Loss: 0.2650
===> Epoch[10](2000/2500): Loss: 0.2754
===> Epoch[10](2100/2500): Loss: 0.2845
===> Epoch[10](2200/2500): Loss: 0.2578
===> Epoch[10](2300/2500): Loss: 0.2585
===> Epoch[10](2400/2500): Loss: 0.2481
===> Epoch[10](2500/2500): Loss: 0.2531
===> Epoch 10 Complete: Avg. Loss: 0.2753
===> Timestamp: [2025-08-03 16:06:34]
Checkpoint saved to TrainedNet/_epoch_10.pth
===> Loading train datasets
===> Epoch[10](100/2500): Loss: 0.2801
===> Epoch[10](200/2500): Loss: 0.2748
===> Epoch[10](300/2500): Loss: 0.2969
===> Epoch[10](400/2500): Loss: 0.2693
===> Epoch[10](500/2500): Loss: 0.2556
===> Epoch[10](600/2500): Loss: 0.2741
===> Epoch[10](700/2500): Loss: 0.2847
===> Epoch[10](800/2500): Loss: 0.2710
===> Epoch[10](900/2500): Loss: 0.3164
===> Epoch[10](1000/2500): Loss: 0.2682
===> Epoch[10](1100/2500): Loss: 0.2730
===> Epoch[10](1200/2500): Loss: 0.2755
===> Epoch[10](1300/2500): Loss: 0.2725
===> Epoch[10](1400/2500): Loss: 0.2519
===> Epoch[10](1500/2500): Loss: 0.2665
===> Epoch[10](1600/2500): Loss: 0.2637
===> Epoch[10](1700/2500): Loss: 0.2731
===> Epoch[10](1800/2500): Loss: 0.2713
===> Epoch[10](1900/2500): Loss: 0.2650
===> Epoch[10](2000/2500): Loss: 0.2754
===> Epoch[10](2100/2500): Loss: 0.2845
===> Epoch[10](2200/2500): Loss: 0.2578
===> Epoch[10](2300/2500): Loss: 0.2585
===> Epoch[10](2400/2500): Loss: 0.2481
===> Epoch[10](2500/2500): Loss: 0.2531
===> Epoch 10 Complete: Avg. Loss: 0.2753
===> Timestamp: [2025-08-03 16:06:34]
Checkpoint saved to TrainedNet/_epoch_10.pth
===> Loading train datasets
===> Epoch[10](100/2500): Loss: 0.2801
===> Epoch[10](200/2500): Loss: 0.2748
===> Epoch[10](300/2500): Loss: 0.2969
===> Epoch[10](400/2500): Loss: 0.2693
===> Epoch[10](500/2500): Loss: 0.2556
===> Epoch[10](600/2500): Loss: 0.2741
===> Epoch[10](700/2500): Loss: 0.2847
===> Epoch[10](800/2500): Loss: 0.2710
===> Epoch[10](900/2500): Loss: 0.3164
===> Epoch[10](1000/2500): Loss: 0.2682
===> Epoch[10](1100/2500): Loss: 0.2730
===> Epoch[10](1200/2500): Loss: 0.2755
===> Epoch[10](1300/2500): Loss: 0.2725
===> Epoch[10](1400/2500): Loss: 0.2519
===> Epoch[10](1500/2500): Loss: 0.2665
===> Epoch[10](1600/2500): Loss: 0.2637
===> Epoch[10](1700/2500): Loss: 0.2731
===> Epoch[10](1800/2500): Loss: 0.2713
===> Epoch[10](1900/2500): Loss: 0.2650
===> Epoch[10](2000/2500): Loss: 0.2754
===> Epoch[10](2100/2500): Loss: 0.2845
===> Epoch[10](2200/2500): Loss: 0.2578
===> Epoch[10](2300/2500): Loss: 0.2585
===> Epoch[10](2400/2500): Loss: 0.2481
===> Epoch[10](2500/2500): Loss: 0.2531
===> Epoch 10 Complete: Avg. Loss: 0.2753
===> Timestamp: [2025-08-03 16:06:34]
Checkpoint saved to TrainedNet/_epoch_10.pth
===> Loading train datasets
===> Epoch[10](100/2500): Loss: 0.2801
===> Epoch[10](200/2500): Loss: 0.2748
===> Epoch[10](300/2500): Loss: 0.2969
===> Epoch[10](400/2500): Loss: 0.2693
===> Epoch[10](500/2500): Loss: 0.2556
===> Epoch[10](600/2500): Loss: 0.2741
===> Epoch[10](700/2500): Loss: 0.2847
===> Epoch[10](800/2500): Loss: 0.2710
===> Epoch[10](900/2500): Loss: 0.3164
===> Epoch[10](1000/2500): Loss: 0.2682
===> Epoch[10](1100/2500): Loss: 0.2730
===> Epoch[10](1200/2500): Loss: 0.2755
===> Epoch[10](1300/2500): Loss: 0.2725
===> Epoch[10](1400/2500): Loss: 0.2519
===> Epoch[10](1500/2500): Loss: 0.2665
===> Epoch[10](1600/2500): Loss: 0.2637
===> Epoch[10](1700/2500): Loss: 0.2731
===> Epoch[10](1800/2500): Loss: 0.2713
===> Epoch[10](1900/2500): Loss: 0.2650
===> Epoch[10](2000/2500): Loss: 0.2754
===> Epoch[10](2100/2500): Loss: 0.2845
===> Epoch[10](2200/2500): Loss: 0.2578
===> Epoch[10](2300/2500): Loss: 0.2585
===> Epoch[10](2400/2500): Loss: 0.2481
===> Epoch[10](2500/2500): Loss: 0.2531
===> Epoch 10 Complete: Avg. Loss: 0.2753
===> Timestamp: [2025-08-03 16:06:34]
Checkpoint saved to TrainedNet/_epoch_10.pth
===> Loading train datasets
===> Epoch[10](100/2500): Loss: 0.2801
===> Epoch[10](200/2500): Loss: 0.2748
===> Epoch[10](300/2500): Loss: 0.2969
===> Epoch[10](400/2500): Loss: 0.2693
===> Epoch[10](500/2500): Loss: 0.2556
===> Epoch[10](600/2500): Loss: 0.2741
===> Epoch[10](700/2500): Loss: 0.2847
===> Epoch[10](800/2500): Loss: 0.2710
===> Epoch[10](900/2500): Loss: 0.3164
===> Epoch[10](1000/2500): Loss: 0.2682
===> Epoch[10](1100/2500): Loss: 0.2730
===> Epoch[10](1200/2500): Loss: 0.2755
===> Epoch[10](1300/2500): Loss: 0.2725
===> Epoch[10](1400/2500): Loss: 0.2519
===> Epoch[10](1500/2500): Loss: 0.2665
===> Epoch[10](1600/2500): Loss: 0.2637
===> Epoch[10](1700/2500): Loss: 0.2731
===> Epoch[10](1800/2500): Loss: 0.2713
===> Epoch[10](1900/2500): Loss: 0.2650
===> Epoch[10](2000/2500): Loss: 0.2754
===> Epoch[10](2100/2500): Loss: 0.2845
===> Epoch[10](2200/2500): Loss: 0.2578
===> Epoch[10](2300/2500): Loss: 0.2585
===> Epoch[10](2400/2500): Loss: 0.2481
===> Epoch[10](2500/2500): Loss: 0.2531
===> Epoch 10 Complete: Avg. Loss: 0.2753
===> Timestamp: [2025-08-03 16:06:34]
Checkpoint saved to TrainedNet/_epoch_10.pth
===> Loading train datasets
===> Epoch[10](100/2500): Loss: 0.2801
===> Epoch[10](200/2500): Loss: 0.2748
===> Epoch[10](300/2500): Loss: 0.2969
===> Epoch[10](400/2500): Loss: 0.2693
===> Epoch[10](500/2500): Loss: 0.2556
===> Epoch[10](600/2500): Loss: 0.2741
===> Epoch[10](700/2500): Loss: 0.2847
===> Epoch[10](800/2500): Loss: 0.2710
===> Epoch[10](900/2500): Loss: 0.3164
===> Epoch[10](1000/2500): Loss: 0.2682
===> Epoch[10](1100/2500): Loss: 0.2730
===> Epoch[10](1200/2500): Loss: 0.2755
===> Epoch[10](1300/2500): Loss: 0.2725
===> Epoch[10](1400/2500): Loss: 0.2519
===> Epoch[10](1500/2500): Loss: 0.2665
===> Epoch[10](1600/2500): Loss: 0.2637
===> Epoch[10](1700/2500): Loss: 0.2731
===> Epoch[10](1800/2500): Loss: 0.2713
===> Epoch[10](1900/2500): Loss: 0.2650
===> Epoch[10](2000/2500): Loss: 0.2754
===> Epoch[10](2100/2500): Loss: 0.2845
===> Epoch[10](2200/2500): Loss: 0.2578
===> Epoch[10](2300/2500): Loss: 0.2585
===> Epoch[10](2400/2500): Loss: 0.2481
===> Epoch[10](2500/2500): Loss: 0.2531
===> Epoch 10 Complete: Avg. Loss: 0.2753
===> Timestamp: [2025-08-03 16:06:34]
Checkpoint saved to TrainedNet/_epoch_10.pth
===> Loading train datasets
===> Epoch[10](100/2500): Loss: 0.2801
===> Epoch[10](200/2500): Loss: 0.2748
===> Epoch[10](300/2500): Loss: 0.2969
===> Epoch[10](400/2500): Loss: 0.2693
===> Epoch[10](500/2500): Loss: 0.2556
===> Epoch[10](600/2500): Loss: 0.2741
===> Epoch[10](700/2500): Loss: 0.2847
===> Epoch[10](800/2500): Loss: 0.2710
===> Epoch[10](900/2500): Loss: 0.3164
===> Epoch[10](1000/2500): Loss: 0.2682
===> Epoch[10](1100/2500): Loss: 0.2730
===> Epoch[10](1200/2500): Loss: 0.2755
===> Epoch[10](1300/2500): Loss: 0.2725
===> Epoch[10](1400/2500): Loss: 0.2519
===> Epoch[10](1500/2500): Loss: 0.2665
===> Epoch[10](1600/2500): Loss: 0.2637
===> Epoch[10](1700/2500): Loss: 0.2731
===> Epoch[10](1800/2500): Loss: 0.2713
===> Epoch[10](1900/2500): Loss: 0.2650
===> Epoch[10](2000/2500): Loss: 0.2754
===> Epoch[10](2100/2500): Loss: 0.2845
===> Epoch[10](2200/2500): Loss: 0.2578
===> Epoch[10](2300/2500): Loss: 0.2585
===> Epoch[10](2400/2500): Loss: 0.2481
===> Epoch[10](2500/2500): Loss: 0.2531
===> Epoch 10 Complete: Avg. Loss: 0.2753
===> Timestamp: [2025-08-03 16:06:34]
Checkpoint saved to TrainedNet/_epoch_10.pth
===> Loading train datasets
===> Loading train datasets
===> Epoch[11](100/2500): Loss: 0.2620
===> Epoch[11](200/2500): Loss: 0.2524
===> Epoch[11](300/2500): Loss: 0.2641
===> Epoch[11](400/2500): Loss: 0.2530
===> Epoch[11](500/2500): Loss: 0.2564
===> Epoch[11](600/2500): Loss: 0.2591
===> Epoch[11](700/2500): Loss: 0.2485
===> Epoch[11](800/2500): Loss: 0.2547
===> Epoch[11](900/2500): Loss: 0.2624
===> Epoch[11](1000/2500): Loss: 0.2525
===> Epoch[11](1100/2500): Loss: 0.2608
===> Epoch[11](1200/2500): Loss: 0.2548
===> Epoch[11](1300/2500): Loss: 0.2631
===> Epoch[11](1400/2500): Loss: 0.2779
===> Epoch[11](1500/2500): Loss: 0.2652
===> Epoch[11](1600/2500): Loss: 0.2391
===> Epoch[11](1700/2500): Loss: 0.2609
===> Epoch[11](1800/2500): Loss: 0.2854
===> Epoch[11](1900/2500): Loss: 0.2387
===> Epoch[11](2000/2500): Loss: 0.2454
===> Epoch[11](2100/2500): Loss: 0.2791
===> Epoch[11](2200/2500): Loss: 0.2555
===> Epoch[11](2300/2500): Loss: 0.2542
===> Epoch[11](2400/2500): Loss: 0.2469
===> Epoch[11](2500/2500): Loss: 0.2683
===> Epoch 11 Complete: Avg. Loss: 0.2611
===> Timestamp: [2025-08-03 16:11:08]
===> Loading train datasets
===> Epoch[11](100/2500): Loss: 0.2620
===> Epoch[11](200/2500): Loss: 0.2524
===> Epoch[11](300/2500): Loss: 0.2641
===> Epoch[11](400/2500): Loss: 0.2530
===> Epoch[11](500/2500): Loss: 0.2564
===> Epoch[11](600/2500): Loss: 0.2591
===> Epoch[11](700/2500): Loss: 0.2485
===> Epoch[11](800/2500): Loss: 0.2547
===> Epoch[11](900/2500): Loss: 0.2624
===> Epoch[11](1000/2500): Loss: 0.2525
===> Epoch[11](1100/2500): Loss: 0.2608
===> Epoch[11](1200/2500): Loss: 0.2548
===> Epoch[11](1300/2500): Loss: 0.2631
===> Epoch[11](1400/2500): Loss: 0.2779
===> Epoch[11](1500/2500): Loss: 0.2652
===> Epoch[11](1600/2500): Loss: 0.2391
===> Epoch[11](1700/2500): Loss: 0.2609
===> Epoch[11](1800/2500): Loss: 0.2854
===> Epoch[11](1900/2500): Loss: 0.2387
===> Epoch[11](2000/2500): Loss: 0.2454
===> Epoch[11](2100/2500): Loss: 0.2791
===> Epoch[11](2200/2500): Loss: 0.2555
===> Epoch[11](2300/2500): Loss: 0.2542
===> Epoch[11](2400/2500): Loss: 0.2469
===> Epoch[11](2500/2500): Loss: 0.2683
===> Epoch 11 Complete: Avg. Loss: 0.2611
===> Timestamp: [2025-08-03 16:11:08]
===> Loading train datasets
===> Epoch[11](100/2500): Loss: 0.2620
===> Epoch[11](200/2500): Loss: 0.2524
===> Epoch[11](300/2500): Loss: 0.2641
===> Epoch[11](400/2500): Loss: 0.2530
===> Epoch[11](500/2500): Loss: 0.2564
===> Epoch[11](600/2500): Loss: 0.2591
===> Epoch[11](700/2500): Loss: 0.2485
===> Epoch[11](800/2500): Loss: 0.2547
===> Epoch[11](900/2500): Loss: 0.2624
===> Epoch[11](1000/2500): Loss: 0.2525
===> Epoch[11](1100/2500): Loss: 0.2608
===> Epoch[11](1200/2500): Loss: 0.2548
===> Epoch[11](1300/2500): Loss: 0.2631
===> Epoch[11](1400/2500): Loss: 0.2779
===> Epoch[11](1500/2500): Loss: 0.2652
===> Epoch[11](1600/2500): Loss: 0.2391
===> Epoch[11](1700/2500): Loss: 0.2609
===> Epoch[11](1800/2500): Loss: 0.2854
===> Epoch[11](1900/2500): Loss: 0.2387
===> Epoch[11](2000/2500): Loss: 0.2454
===> Epoch[11](2100/2500): Loss: 0.2791
===> Epoch[11](2200/2500): Loss: 0.2555
===> Epoch[11](2300/2500): Loss: 0.2542
===> Epoch[11](2400/2500): Loss: 0.2469
===> Epoch[11](2500/2500): Loss: 0.2683
===> Epoch 11 Complete: Avg. Loss: 0.2611
===> Timestamp: [2025-08-03 16:11:08]
===> Loading train datasets
===> Epoch[11](100/2500): Loss: 0.2620
===> Epoch[11](200/2500): Loss: 0.2524
===> Epoch[11](300/2500): Loss: 0.2641
===> Epoch[11](400/2500): Loss: 0.2530
===> Epoch[11](500/2500): Loss: 0.2564
===> Epoch[11](600/2500): Loss: 0.2591
===> Epoch[11](700/2500): Loss: 0.2485
===> Epoch[11](800/2500): Loss: 0.2547
===> Epoch[11](900/2500): Loss: 0.2624
===> Epoch[11](1000/2500): Loss: 0.2525
===> Epoch[11](1100/2500): Loss: 0.2608
===> Epoch[11](1200/2500): Loss: 0.2548
===> Epoch[11](1300/2500): Loss: 0.2631
===> Epoch[11](1400/2500): Loss: 0.2779
===> Epoch[11](1500/2500): Loss: 0.2652
===> Epoch[11](1600/2500): Loss: 0.2391
===> Epoch[11](1700/2500): Loss: 0.2609
===> Epoch[11](1800/2500): Loss: 0.2854
===> Epoch[11](1900/2500): Loss: 0.2387
===> Epoch[11](2000/2500): Loss: 0.2454
===> Epoch[11](2100/2500): Loss: 0.2791
===> Epoch[11](2200/2500): Loss: 0.2555
===> Epoch[11](2300/2500): Loss: 0.2542
===> Epoch[11](2400/2500): Loss: 0.2469
===> Epoch[11](2500/2500): Loss: 0.2683
===> Epoch 11 Complete: Avg. Loss: 0.2611
===> Timestamp: [2025-08-03 16:11:08]
===> Loading train datasets
===> Epoch[11](100/2500): Loss: 0.2620
===> Epoch[11](200/2500): Loss: 0.2524
===> Epoch[11](300/2500): Loss: 0.2641
===> Epoch[11](400/2500): Loss: 0.2530
===> Epoch[11](500/2500): Loss: 0.2564
===> Epoch[11](600/2500): Loss: 0.2591
===> Epoch[11](700/2500): Loss: 0.2485
===> Epoch[11](800/2500): Loss: 0.2547
===> Epoch[11](900/2500): Loss: 0.2624
===> Epoch[11](1000/2500): Loss: 0.2525
===> Epoch[11](1100/2500): Loss: 0.2608
===> Epoch[11](1200/2500): Loss: 0.2548
===> Epoch[11](1300/2500): Loss: 0.2631
===> Epoch[11](1400/2500): Loss: 0.2779
===> Epoch[11](1500/2500): Loss: 0.2652
===> Epoch[11](1600/2500): Loss: 0.2391
===> Epoch[11](1700/2500): Loss: 0.2609
===> Epoch[11](1800/2500): Loss: 0.2854
===> Epoch[11](1900/2500): Loss: 0.2387
===> Epoch[11](2000/2500): Loss: 0.2454
===> Epoch[11](2100/2500): Loss: 0.2791
===> Epoch[11](2200/2500): Loss: 0.2555
===> Epoch[11](2300/2500): Loss: 0.2542
===> Epoch[11](2400/2500): Loss: 0.2469
===> Epoch[11](2500/2500): Loss: 0.2683
===> Epoch 11 Complete: Avg. Loss: 0.2611
===> Timestamp: [2025-08-03 16:11:08]
===> Loading train datasets
===> Epoch[11](100/2500): Loss: 0.2620
===> Epoch[11](200/2500): Loss: 0.2524
===> Epoch[11](300/2500): Loss: 0.2641
===> Epoch[11](400/2500): Loss: 0.2530
===> Epoch[11](500/2500): Loss: 0.2564
===> Epoch[11](600/2500): Loss: 0.2591
===> Epoch[11](700/2500): Loss: 0.2485
===> Epoch[11](800/2500): Loss: 0.2547
===> Epoch[11](900/2500): Loss: 0.2624
===> Epoch[11](1000/2500): Loss: 0.2525
===> Epoch[11](1100/2500): Loss: 0.2608
===> Epoch[11](1200/2500): Loss: 0.2548
===> Epoch[11](1300/2500): Loss: 0.2631
===> Epoch[11](1400/2500): Loss: 0.2779
===> Epoch[11](1500/2500): Loss: 0.2652
===> Epoch[11](1600/2500): Loss: 0.2391
===> Epoch[11](1700/2500): Loss: 0.2609
===> Epoch[11](1800/2500): Loss: 0.2854
===> Epoch[11](1900/2500): Loss: 0.2387
===> Epoch[11](2000/2500): Loss: 0.2454
===> Epoch[11](2100/2500): Loss: 0.2791
===> Epoch[11](2200/2500): Loss: 0.2555
===> Epoch[11](2300/2500): Loss: 0.2542
===> Epoch[11](2400/2500): Loss: 0.2469
===> Epoch[11](2500/2500): Loss: 0.2683
===> Epoch 11 Complete: Avg. Loss: 0.2611
===> Timestamp: [2025-08-03 16:11:08]
===> Loading train datasets
===> Epoch[11](100/2500): Loss: 0.2620
===> Epoch[11](200/2500): Loss: 0.2524
===> Epoch[11](300/2500): Loss: 0.2641
===> Epoch[11](400/2500): Loss: 0.2530
===> Epoch[11](500/2500): Loss: 0.2564
===> Epoch[11](600/2500): Loss: 0.2591
===> Epoch[11](700/2500): Loss: 0.2485
===> Epoch[11](800/2500): Loss: 0.2547
===> Epoch[11](900/2500): Loss: 0.2624
===> Epoch[11](1000/2500): Loss: 0.2525
===> Epoch[11](1100/2500): Loss: 0.2608
===> Epoch[11](1200/2500): Loss: 0.2548
===> Epoch[11](1300/2500): Loss: 0.2631
===> Epoch[11](1400/2500): Loss: 0.2779
===> Epoch[11](1500/2500): Loss: 0.2652
===> Epoch[11](1600/2500): Loss: 0.2391
===> Epoch[11](1700/2500): Loss: 0.2609
===> Epoch[11](1800/2500): Loss: 0.2854
===> Epoch[11](1900/2500): Loss: 0.2387
===> Epoch[11](2000/2500): Loss: 0.2454
===> Epoch[11](2100/2500): Loss: 0.2791
===> Epoch[11](2200/2500): Loss: 0.2555
===> Epoch[11](2300/2500): Loss: 0.2542
===> Epoch[11](2400/2500): Loss: 0.2469
===> Epoch[11](2500/2500): Loss: 0.2683
===> Epoch 11 Complete: Avg. Loss: 0.2611
===> Timestamp: [2025-08-03 16:11:08]
===> Loading train datasets
===> Epoch[11](100/2500): Loss: 0.2620
===> Epoch[11](200/2500): Loss: 0.2524
===> Epoch[11](300/2500): Loss: 0.2641
===> Epoch[11](400/2500): Loss: 0.2530
===> Epoch[11](500/2500): Loss: 0.2564
===> Epoch[11](600/2500): Loss: 0.2591
===> Epoch[11](700/2500): Loss: 0.2485
===> Epoch[11](800/2500): Loss: 0.2547
===> Epoch[11](900/2500): Loss: 0.2624
===> Epoch[11](1000/2500): Loss: 0.2525
===> Epoch[11](1100/2500): Loss: 0.2608
===> Epoch[11](1200/2500): Loss: 0.2548
===> Epoch[11](1300/2500): Loss: 0.2631
===> Epoch[11](1400/2500): Loss: 0.2779
===> Epoch[11](1500/2500): Loss: 0.2652
===> Epoch[11](1600/2500): Loss: 0.2391
===> Epoch[11](1700/2500): Loss: 0.2609
===> Epoch[11](1800/2500): Loss: 0.2854
===> Epoch[11](1900/2500): Loss: 0.2387
===> Epoch[11](2000/2500): Loss: 0.2454
===> Epoch[11](2100/2500): Loss: 0.2791
===> Epoch[11](2200/2500): Loss: 0.2555
===> Epoch[11](2300/2500): Loss: 0.2542
===> Epoch[11](2400/2500): Loss: 0.2469
===> Epoch[11](2500/2500): Loss: 0.2683
===> Epoch 11 Complete: Avg. Loss: 0.2611
===> Timestamp: [2025-08-03 16:11:08]
===> Loading train datasets
===> Epoch[11](100/2500): Loss: 0.2620
===> Epoch[11](200/2500): Loss: 0.2524
===> Epoch[11](300/2500): Loss: 0.2641
===> Epoch[11](400/2500): Loss: 0.2530
===> Epoch[11](500/2500): Loss: 0.2564
===> Epoch[11](600/2500): Loss: 0.2591
===> Epoch[11](700/2500): Loss: 0.2485
===> Epoch[11](800/2500): Loss: 0.2547
===> Epoch[11](900/2500): Loss: 0.2624
===> Epoch[11](1000/2500): Loss: 0.2525
===> Epoch[11](1100/2500): Loss: 0.2608
===> Epoch[11](1200/2500): Loss: 0.2548
===> Epoch[11](1300/2500): Loss: 0.2631
===> Epoch[11](1400/2500): Loss: 0.2779
===> Epoch[11](1500/2500): Loss: 0.2652
===> Epoch[11](1600/2500): Loss: 0.2391
===> Epoch[11](1700/2500): Loss: 0.2609
===> Epoch[11](1800/2500): Loss: 0.2854
===> Epoch[11](1900/2500): Loss: 0.2387
===> Epoch[11](2000/2500): Loss: 0.2454
===> Epoch[11](2100/2500): Loss: 0.2791
===> Epoch[11](2200/2500): Loss: 0.2555
===> Epoch[11](2300/2500): Loss: 0.2542
===> Epoch[11](2400/2500): Loss: 0.2469
===> Epoch[11](2500/2500): Loss: 0.2683
===> Epoch 11 Complete: Avg. Loss: 0.2611
===> Timestamp: [2025-08-03 16:11:08]
===> Loading train datasets
===> Epoch[11](100/2500): Loss: 0.2620
===> Epoch[11](200/2500): Loss: 0.2524
===> Epoch[11](300/2500): Loss: 0.2641
===> Epoch[11](400/2500): Loss: 0.2530
===> Epoch[11](500/2500): Loss: 0.2564
===> Epoch[11](600/2500): Loss: 0.2591
===> Epoch[11](700/2500): Loss: 0.2485
===> Epoch[11](800/2500): Loss: 0.2547
===> Epoch[11](900/2500): Loss: 0.2624
===> Epoch[11](1000/2500): Loss: 0.2525
===> Epoch[11](1100/2500): Loss: 0.2608
===> Epoch[11](1200/2500): Loss: 0.2548
===> Epoch[11](1300/2500): Loss: 0.2631
===> Epoch[11](1400/2500): Loss: 0.2779
===> Epoch[11](1500/2500): Loss: 0.2652
===> Epoch[11](1600/2500): Loss: 0.2391
===> Epoch[11](1700/2500): Loss: 0.2609
===> Epoch[11](1800/2500): Loss: 0.2854
===> Epoch[11](1900/2500): Loss: 0.2387
===> Epoch[11](2000/2500): Loss: 0.2454
===> Epoch[11](2100/2500): Loss: 0.2791
===> Epoch[11](2200/2500): Loss: 0.2555
===> Epoch[11](2300/2500): Loss: 0.2542
===> Epoch[11](2400/2500): Loss: 0.2469
===> Epoch[11](2500/2500): Loss: 0.2683
===> Epoch 11 Complete: Avg. Loss: 0.2611
===> Timestamp: [2025-08-03 16:11:08]
===> Loading train datasets
===> Epoch[11](100/2500): Loss: 0.2620
===> Epoch[11](200/2500): Loss: 0.2524
===> Epoch[11](300/2500): Loss: 0.2641
===> Epoch[11](400/2500): Loss: 0.2530
===> Epoch[11](500/2500): Loss: 0.2564
===> Epoch[11](600/2500): Loss: 0.2591
===> Epoch[11](700/2500): Loss: 0.2485
===> Epoch[11](800/2500): Loss: 0.2547
===> Epoch[11](900/2500): Loss: 0.2624
===> Epoch[11](1000/2500): Loss: 0.2525
===> Epoch[11](1100/2500): Loss: 0.2608
===> Epoch[11](1200/2500): Loss: 0.2548
===> Epoch[11](1300/2500): Loss: 0.2631
===> Epoch[11](1400/2500): Loss: 0.2779
===> Epoch[11](1500/2500): Loss: 0.2652
===> Epoch[11](1600/2500): Loss: 0.2391
===> Epoch[11](1700/2500): Loss: 0.2609
===> Epoch[11](1800/2500): Loss: 0.2854
===> Epoch[11](1900/2500): Loss: 0.2387
===> Epoch[11](2000/2500): Loss: 0.2454
===> Epoch[11](2100/2500): Loss: 0.2791
===> Epoch[11](2200/2500): Loss: 0.2555
===> Epoch[11](2300/2500): Loss: 0.2542
===> Epoch[11](2400/2500): Loss: 0.2469
===> Epoch[11](2500/2500): Loss: 0.2683
===> Epoch 11 Complete: Avg. Loss: 0.2611
===> Timestamp: [2025-08-03 16:11:08]
===> Loading train datasets
===> Loading train datasets
===> Epoch[12](100/2500): Loss: 0.2765
===> Epoch[12](200/2500): Loss: 0.2680
===> Epoch[12](300/2500): Loss: 0.2840
===> Epoch[12](400/2500): Loss: 0.2614
===> Epoch[12](500/2500): Loss: 0.2718
===> Epoch[12](600/2500): Loss: 0.2412
===> Epoch[12](700/2500): Loss: 0.2348
===> Epoch[12](800/2500): Loss: 0.2419
===> Epoch[12](900/2500): Loss: 0.2478
===> Epoch[12](1000/2500): Loss: 0.2434
===> Epoch[12](1100/2500): Loss: 0.2806
===> Epoch[12](1200/2500): Loss: 0.2282
===> Epoch[12](1300/2500): Loss: 0.2656
===> Epoch[12](1400/2500): Loss: 0.2503
===> Epoch[12](1500/2500): Loss: 0.2607
===> Epoch[12](1600/2500): Loss: 0.2529
===> Epoch[12](1700/2500): Loss: 0.2393
===> Epoch[12](1800/2500): Loss: 0.2777
===> Epoch[12](1900/2500): Loss: 0.2421
===> Epoch[12](2000/2500): Loss: 0.2746
===> Epoch[12](2100/2500): Loss: 0.2741
===> Epoch[12](2200/2500): Loss: 0.2743
===> Epoch[12](2300/2500): Loss: 0.2439
===> Epoch[12](2400/2500): Loss: 0.2638
===> Epoch[12](2500/2500): Loss: 0.2568
===> Epoch 12 Complete: Avg. Loss: 0.2537
===> Timestamp: [2025-08-03 16:15:42]
===> Loading train datasets
===> Epoch[12](100/2500): Loss: 0.2765
===> Epoch[12](200/2500): Loss: 0.2680
===> Epoch[12](300/2500): Loss: 0.2840
===> Epoch[12](400/2500): Loss: 0.2614
===> Epoch[12](500/2500): Loss: 0.2718
===> Epoch[12](600/2500): Loss: 0.2412
===> Epoch[12](700/2500): Loss: 0.2348
===> Epoch[12](800/2500): Loss: 0.2419
===> Epoch[12](900/2500): Loss: 0.2478
===> Epoch[12](1000/2500): Loss: 0.2434
===> Epoch[12](1100/2500): Loss: 0.2806
===> Epoch[12](1200/2500): Loss: 0.2282
===> Epoch[12](1300/2500): Loss: 0.2656
===> Epoch[12](1400/2500): Loss: 0.2503
===> Epoch[12](1500/2500): Loss: 0.2607
===> Epoch[12](1600/2500): Loss: 0.2529
===> Epoch[12](1700/2500): Loss: 0.2393
===> Epoch[12](1800/2500): Loss: 0.2777
===> Epoch[12](1900/2500): Loss: 0.2421
===> Epoch[12](2000/2500): Loss: 0.2746
===> Epoch[12](2100/2500): Loss: 0.2741
===> Epoch[12](2200/2500): Loss: 0.2743
===> Epoch[12](2300/2500): Loss: 0.2439
===> Epoch[12](2400/2500): Loss: 0.2638
===> Epoch[12](2500/2500): Loss: 0.2568
===> Epoch 12 Complete: Avg. Loss: 0.2537
===> Timestamp: [2025-08-03 16:15:42]
===> Loading train datasets
===> Epoch[12](100/2500): Loss: 0.2765
===> Epoch[12](200/2500): Loss: 0.2680
===> Epoch[12](300/2500): Loss: 0.2840
===> Epoch[12](400/2500): Loss: 0.2614
===> Epoch[12](500/2500): Loss: 0.2718
===> Epoch[12](600/2500): Loss: 0.2412
===> Epoch[12](700/2500): Loss: 0.2348
===> Epoch[12](800/2500): Loss: 0.2419
===> Epoch[12](900/2500): Loss: 0.2478
===> Epoch[12](1000/2500): Loss: 0.2434
===> Epoch[12](1100/2500): Loss: 0.2806
===> Epoch[12](1200/2500): Loss: 0.2282
===> Epoch[12](1300/2500): Loss: 0.2656
===> Epoch[12](1400/2500): Loss: 0.2503
===> Epoch[12](1500/2500): Loss: 0.2607
===> Epoch[12](1600/2500): Loss: 0.2529
===> Epoch[12](1700/2500): Loss: 0.2393
===> Epoch[12](1800/2500): Loss: 0.2777
===> Epoch[12](1900/2500): Loss: 0.2421
===> Epoch[12](2000/2500): Loss: 0.2746
===> Epoch[12](2100/2500): Loss: 0.2741
===> Epoch[12](2200/2500): Loss: 0.2743
===> Epoch[12](2300/2500): Loss: 0.2439
===> Epoch[12](2400/2500): Loss: 0.2638
===> Epoch[12](2500/2500): Loss: 0.2568
===> Epoch 12 Complete: Avg. Loss: 0.2537
===> Timestamp: [2025-08-03 16:15:42]
===> Loading train datasets
===> Epoch[12](100/2500): Loss: 0.2765
===> Epoch[12](200/2500): Loss: 0.2680
===> Epoch[12](300/2500): Loss: 0.2840
===> Epoch[12](400/2500): Loss: 0.2614
===> Epoch[12](500/2500): Loss: 0.2718
===> Epoch[12](600/2500): Loss: 0.2412
===> Epoch[12](700/2500): Loss: 0.2348
===> Epoch[12](800/2500): Loss: 0.2419
===> Epoch[12](900/2500): Loss: 0.2478
===> Epoch[12](1000/2500): Loss: 0.2434
===> Epoch[12](1100/2500): Loss: 0.2806
===> Epoch[12](1200/2500): Loss: 0.2282
===> Epoch[12](1300/2500): Loss: 0.2656
===> Epoch[12](1400/2500): Loss: 0.2503
===> Epoch[12](1500/2500): Loss: 0.2607
===> Epoch[12](1600/2500): Loss: 0.2529
===> Epoch[12](1700/2500): Loss: 0.2393
===> Epoch[12](1800/2500): Loss: 0.2777
===> Epoch[12](1900/2500): Loss: 0.2421
===> Epoch[12](2000/2500): Loss: 0.2746
===> Epoch[12](2100/2500): Loss: 0.2741
===> Epoch[12](2200/2500): Loss: 0.2743
===> Epoch[12](2300/2500): Loss: 0.2439
===> Epoch[12](2400/2500): Loss: 0.2638
===> Epoch[12](2500/2500): Loss: 0.2568
===> Epoch 12 Complete: Avg. Loss: 0.2537
===> Timestamp: [2025-08-03 16:15:42]
===> Loading train datasets
===> Epoch[12](100/2500): Loss: 0.2765
===> Epoch[12](200/2500): Loss: 0.2680
===> Epoch[12](300/2500): Loss: 0.2840
===> Epoch[12](400/2500): Loss: 0.2614
===> Epoch[12](500/2500): Loss: 0.2718
===> Epoch[12](600/2500): Loss: 0.2412
===> Epoch[12](700/2500): Loss: 0.2348
===> Epoch[12](800/2500): Loss: 0.2419
===> Epoch[12](900/2500): Loss: 0.2478
===> Epoch[12](1000/2500): Loss: 0.2434
===> Epoch[12](1100/2500): Loss: 0.2806
===> Epoch[12](1200/2500): Loss: 0.2282
===> Epoch[12](1300/2500): Loss: 0.2656
===> Epoch[12](1400/2500): Loss: 0.2503
===> Epoch[12](1500/2500): Loss: 0.2607
===> Epoch[12](1600/2500): Loss: 0.2529
===> Epoch[12](1700/2500): Loss: 0.2393
===> Epoch[12](1800/2500): Loss: 0.2777
===> Epoch[12](1900/2500): Loss: 0.2421
===> Epoch[12](2000/2500): Loss: 0.2746
===> Epoch[12](2100/2500): Loss: 0.2741
===> Epoch[12](2200/2500): Loss: 0.2743
===> Epoch[12](2300/2500): Loss: 0.2439
===> Epoch[12](2400/2500): Loss: 0.2638
===> Epoch[12](2500/2500): Loss: 0.2568
===> Epoch 12 Complete: Avg. Loss: 0.2537
===> Timestamp: [2025-08-03 16:15:42]
===> Loading train datasets
===> Epoch[12](100/2500): Loss: 0.2765
===> Epoch[12](200/2500): Loss: 0.2680
===> Epoch[12](300/2500): Loss: 0.2840
===> Epoch[12](400/2500): Loss: 0.2614
===> Epoch[12](500/2500): Loss: 0.2718
===> Epoch[12](600/2500): Loss: 0.2412
===> Epoch[12](700/2500): Loss: 0.2348
===> Epoch[12](800/2500): Loss: 0.2419
===> Epoch[12](900/2500): Loss: 0.2478
===> Epoch[12](1000/2500): Loss: 0.2434
===> Epoch[12](1100/2500): Loss: 0.2806
===> Epoch[12](1200/2500): Loss: 0.2282
===> Epoch[12](1300/2500): Loss: 0.2656
===> Epoch[12](1400/2500): Loss: 0.2503
===> Epoch[12](1500/2500): Loss: 0.2607
===> Epoch[12](1600/2500): Loss: 0.2529
===> Epoch[12](1700/2500): Loss: 0.2393
===> Epoch[12](1800/2500): Loss: 0.2777
===> Epoch[12](1900/2500): Loss: 0.2421
===> Epoch[12](2000/2500): Loss: 0.2746
===> Epoch[12](2100/2500): Loss: 0.2741
===> Epoch[12](2200/2500): Loss: 0.2743
===> Epoch[12](2300/2500): Loss: 0.2439
===> Epoch[12](2400/2500): Loss: 0.2638
===> Epoch[12](2500/2500): Loss: 0.2568
===> Epoch 12 Complete: Avg. Loss: 0.2537
===> Timestamp: [2025-08-03 16:15:42]
===> Loading train datasets
===> Epoch[12](100/2500): Loss: 0.2765
===> Epoch[12](200/2500): Loss: 0.2680
===> Epoch[12](300/2500): Loss: 0.2840
===> Epoch[12](400/2500): Loss: 0.2614
===> Epoch[12](500/2500): Loss: 0.2718
===> Epoch[12](600/2500): Loss: 0.2412
===> Epoch[12](700/2500): Loss: 0.2348
===> Epoch[12](800/2500): Loss: 0.2419
===> Epoch[12](900/2500): Loss: 0.2478
===> Epoch[12](1000/2500): Loss: 0.2434
===> Epoch[12](1100/2500): Loss: 0.2806
===> Epoch[12](1200/2500): Loss: 0.2282
===> Epoch[12](1300/2500): Loss: 0.2656
===> Epoch[12](1400/2500): Loss: 0.2503
===> Epoch[12](1500/2500): Loss: 0.2607
===> Epoch[12](1600/2500): Loss: 0.2529
===> Epoch[12](1700/2500): Loss: 0.2393
===> Epoch[12](1800/2500): Loss: 0.2777
===> Epoch[12](1900/2500): Loss: 0.2421
===> Epoch[12](2000/2500): Loss: 0.2746
===> Epoch[12](2100/2500): Loss: 0.2741
===> Epoch[12](2200/2500): Loss: 0.2743
===> Epoch[12](2300/2500): Loss: 0.2439
===> Epoch[12](2400/2500): Loss: 0.2638
===> Epoch[12](2500/2500): Loss: 0.2568
===> Epoch 12 Complete: Avg. Loss: 0.2537
===> Timestamp: [2025-08-03 16:15:42]
===> Loading train datasets
===> Epoch[12](100/2500): Loss: 0.2765
===> Epoch[12](200/2500): Loss: 0.2680
===> Epoch[12](300/2500): Loss: 0.2840
===> Epoch[12](400/2500): Loss: 0.2614
===> Epoch[12](500/2500): Loss: 0.2718
===> Epoch[12](600/2500): Loss: 0.2412
===> Epoch[12](700/2500): Loss: 0.2348
===> Epoch[12](800/2500): Loss: 0.2419
===> Epoch[12](900/2500): Loss: 0.2478
===> Epoch[12](1000/2500): Loss: 0.2434
===> Epoch[12](1100/2500): Loss: 0.2806
===> Epoch[12](1200/2500): Loss: 0.2282
===> Epoch[12](1300/2500): Loss: 0.2656
===> Epoch[12](1400/2500): Loss: 0.2503
===> Epoch[12](1500/2500): Loss: 0.2607
===> Epoch[12](1600/2500): Loss: 0.2529
===> Epoch[12](1700/2500): Loss: 0.2393
===> Epoch[12](1800/2500): Loss: 0.2777
===> Epoch[12](1900/2500): Loss: 0.2421
===> Epoch[12](2000/2500): Loss: 0.2746
===> Epoch[12](2100/2500): Loss: 0.2741
===> Epoch[12](2200/2500): Loss: 0.2743
===> Epoch[12](2300/2500): Loss: 0.2439
===> Epoch[12](2400/2500): Loss: 0.2638
===> Epoch[12](2500/2500): Loss: 0.2568
===> Epoch 12 Complete: Avg. Loss: 0.2537
===> Timestamp: [2025-08-03 16:15:42]
===> Loading train datasets
===> Epoch[12](100/2500): Loss: 0.2765
===> Epoch[12](200/2500): Loss: 0.2680
===> Epoch[12](300/2500): Loss: 0.2840
===> Epoch[12](400/2500): Loss: 0.2614
===> Epoch[12](500/2500): Loss: 0.2718
===> Epoch[12](600/2500): Loss: 0.2412
===> Epoch[12](700/2500): Loss: 0.2348
===> Epoch[12](800/2500): Loss: 0.2419
===> Epoch[12](900/2500): Loss: 0.2478
===> Epoch[12](1000/2500): Loss: 0.2434
===> Epoch[12](1100/2500): Loss: 0.2806
===> Epoch[12](1200/2500): Loss: 0.2282
===> Epoch[12](1300/2500): Loss: 0.2656
===> Epoch[12](1400/2500): Loss: 0.2503
===> Epoch[12](1500/2500): Loss: 0.2607
===> Epoch[12](1600/2500): Loss: 0.2529
===> Epoch[12](1700/2500): Loss: 0.2393
===> Epoch[12](1800/2500): Loss: 0.2777
===> Epoch[12](1900/2500): Loss: 0.2421
===> Epoch[12](2000/2500): Loss: 0.2746
===> Epoch[12](2100/2500): Loss: 0.2741
===> Epoch[12](2200/2500): Loss: 0.2743
===> Epoch[12](2300/2500): Loss: 0.2439
===> Epoch[12](2400/2500): Loss: 0.2638
===> Epoch[12](2500/2500): Loss: 0.2568
===> Epoch 12 Complete: Avg. Loss: 0.2537
===> Timestamp: [2025-08-03 16:15:42]
===> Loading train datasets
===> Epoch[12](100/2500): Loss: 0.2765
===> Epoch[12](200/2500): Loss: 0.2680
===> Epoch[12](300/2500): Loss: 0.2840
===> Epoch[12](400/2500): Loss: 0.2614
===> Epoch[12](500/2500): Loss: 0.2718
===> Epoch[12](600/2500): Loss: 0.2412
===> Epoch[12](700/2500): Loss: 0.2348
===> Epoch[12](800/2500): Loss: 0.2419
===> Epoch[12](900/2500): Loss: 0.2478
===> Epoch[12](1000/2500): Loss: 0.2434
===> Epoch[12](1100/2500): Loss: 0.2806
===> Epoch[12](1200/2500): Loss: 0.2282
===> Epoch[12](1300/2500): Loss: 0.2656
===> Epoch[12](1400/2500): Loss: 0.2503
===> Epoch[12](1500/2500): Loss: 0.2607
===> Epoch[12](1600/2500): Loss: 0.2529
===> Epoch[12](1700/2500): Loss: 0.2393
===> Epoch[12](1800/2500): Loss: 0.2777
===> Epoch[12](1900/2500): Loss: 0.2421
===> Epoch[12](2000/2500): Loss: 0.2746
===> Epoch[12](2100/2500): Loss: 0.2741
===> Epoch[12](2200/2500): Loss: 0.2743
===> Epoch[12](2300/2500): Loss: 0.2439
===> Epoch[12](2400/2500): Loss: 0.2638
===> Epoch[12](2500/2500): Loss: 0.2568
===> Epoch 12 Complete: Avg. Loss: 0.2537
===> Timestamp: [2025-08-03 16:15:42]
===> Loading train datasets
===> Epoch[12](100/2500): Loss: 0.2765
===> Epoch[12](200/2500): Loss: 0.2680
===> Epoch[12](300/2500): Loss: 0.2840
===> Epoch[12](400/2500): Loss: 0.2614
===> Epoch[12](500/2500): Loss: 0.2718
===> Epoch[12](600/2500): Loss: 0.2412
===> Epoch[12](700/2500): Loss: 0.2348
===> Epoch[12](800/2500): Loss: 0.2419
===> Epoch[12](900/2500): Loss: 0.2478
===> Epoch[12](1000/2500): Loss: 0.2434
===> Epoch[12](1100/2500): Loss: 0.2806
===> Epoch[12](1200/2500): Loss: 0.2282
===> Epoch[12](1300/2500): Loss: 0.2656
===> Epoch[12](1400/2500): Loss: 0.2503
===> Epoch[12](1500/2500): Loss: 0.2607
===> Epoch[12](1600/2500): Loss: 0.2529
===> Epoch[12](1700/2500): Loss: 0.2393
===> Epoch[12](1800/2500): Loss: 0.2777
===> Epoch[12](1900/2500): Loss: 0.2421
===> Epoch[12](2000/2500): Loss: 0.2746
===> Epoch[12](2100/2500): Loss: 0.2741
===> Epoch[12](2200/2500): Loss: 0.2743
===> Epoch[12](2300/2500): Loss: 0.2439
===> Epoch[12](2400/2500): Loss: 0.2638
===> Epoch[12](2500/2500): Loss: 0.2568
===> Epoch 12 Complete: Avg. Loss: 0.2537
===> Timestamp: [2025-08-03 16:15:42]
===> Loading train datasets
===> Epoch[12](100/2500): Loss: 0.2765
===> Epoch[12](200/2500): Loss: 0.2680
===> Epoch[12](300/2500): Loss: 0.2840
===> Epoch[12](400/2500): Loss: 0.2614
===> Epoch[12](500/2500): Loss: 0.2718
===> Epoch[12](600/2500): Loss: 0.2412
===> Epoch[12](700/2500): Loss: 0.2348
===> Epoch[12](800/2500): Loss: 0.2419
===> Epoch[12](900/2500): Loss: 0.2478
===> Epoch[12](1000/2500): Loss: 0.2434
===> Epoch[12](1100/2500): Loss: 0.2806
===> Epoch[12](1200/2500): Loss: 0.2282
===> Epoch[12](1300/2500): Loss: 0.2656
===> Epoch[12](1400/2500): Loss: 0.2503
===> Epoch[12](1500/2500): Loss: 0.2607
===> Epoch[12](1600/2500): Loss: 0.2529
===> Epoch[12](1700/2500): Loss: 0.2393
===> Epoch[12](1800/2500): Loss: 0.2777
===> Epoch[12](1900/2500): Loss: 0.2421
===> Epoch[12](2000/2500): Loss: 0.2746
===> Epoch[12](2100/2500): Loss: 0.2741
===> Epoch[12](2200/2500): Loss: 0.2743
===> Epoch[12](2300/2500): Loss: 0.2439
===> Epoch[12](2400/2500): Loss: 0.2638
===> Epoch[12](2500/2500): Loss: 0.2568
===> Epoch 12 Complete: Avg. Loss: 0.2537
===> Timestamp: [2025-08-03 16:15:42]
===> Loading train datasets
===> Loading train datasets
===> Epoch[13](100/2500): Loss: 0.2606
===> Epoch[13](200/2500): Loss: 0.2746
===> Epoch[13](300/2500): Loss: 0.2603
===> Epoch[13](400/2500): Loss: 0.2568
===> Epoch[13](500/2500): Loss: 0.2318
===> Epoch[13](600/2500): Loss: 0.2556
===> Epoch[13](700/2500): Loss: 0.2625
===> Epoch[13](800/2500): Loss: 0.2366
===> Epoch[13](900/2500): Loss: 0.2465
===> Epoch[13](1000/2500): Loss: 0.2645
===> Epoch[13](1100/2500): Loss: 0.2572
===> Epoch[13](1200/2500): Loss: 0.2504
===> Epoch[13](1300/2500): Loss: 0.2368
===> Epoch[13](1400/2500): Loss: 0.2454
===> Epoch[13](1500/2500): Loss: 0.2119
===> Epoch[13](1600/2500): Loss: 0.2570
===> Epoch[13](1700/2500): Loss: 0.2391
===> Epoch[13](1800/2500): Loss: 0.2400
===> Epoch[13](1900/2500): Loss: 0.2522
===> Epoch[13](2000/2500): Loss: 0.2404
===> Epoch[13](2100/2500): Loss: 0.2308
===> Epoch[13](2200/2500): Loss: 0.2547
===> Epoch[13](2300/2500): Loss: 0.2539
===> Epoch[13](2400/2500): Loss: 0.2607
===> Epoch[13](2500/2500): Loss: 0.2434
===> Epoch 13 Complete: Avg. Loss: 0.2476
===> Timestamp: [2025-08-03 16:20:16]
===> Loading train datasets
===> Epoch[13](100/2500): Loss: 0.2606
===> Epoch[13](200/2500): Loss: 0.2746
===> Epoch[13](300/2500): Loss: 0.2603
===> Epoch[13](400/2500): Loss: 0.2568
===> Epoch[13](500/2500): Loss: 0.2318
===> Epoch[13](600/2500): Loss: 0.2556
===> Epoch[13](700/2500): Loss: 0.2625
===> Epoch[13](800/2500): Loss: 0.2366
===> Epoch[13](900/2500): Loss: 0.2465
===> Epoch[13](1000/2500): Loss: 0.2645
===> Epoch[13](1100/2500): Loss: 0.2572
===> Epoch[13](1200/2500): Loss: 0.2504
===> Epoch[13](1300/2500): Loss: 0.2368
===> Epoch[13](1400/2500): Loss: 0.2454
===> Epoch[13](1500/2500): Loss: 0.2119
===> Epoch[13](1600/2500): Loss: 0.2570
===> Epoch[13](1700/2500): Loss: 0.2391
===> Epoch[13](1800/2500): Loss: 0.2400
===> Epoch[13](1900/2500): Loss: 0.2522
===> Epoch[13](2000/2500): Loss: 0.2404
===> Epoch[13](2100/2500): Loss: 0.2308
===> Epoch[13](2200/2500): Loss: 0.2547
===> Epoch[13](2300/2500): Loss: 0.2539
===> Epoch[13](2400/2500): Loss: 0.2607
===> Epoch[13](2500/2500): Loss: 0.2434
===> Epoch 13 Complete: Avg. Loss: 0.2476
===> Timestamp: [2025-08-03 16:20:16]
===> Loading train datasets
===> Epoch[13](100/2500): Loss: 0.2606
===> Epoch[13](200/2500): Loss: 0.2746
===> Epoch[13](300/2500): Loss: 0.2603
===> Epoch[13](400/2500): Loss: 0.2568
===> Epoch[13](500/2500): Loss: 0.2318
===> Epoch[13](600/2500): Loss: 0.2556
===> Epoch[13](700/2500): Loss: 0.2625
===> Epoch[13](800/2500): Loss: 0.2366
===> Epoch[13](900/2500): Loss: 0.2465
===> Epoch[13](1000/2500): Loss: 0.2645
===> Epoch[13](1100/2500): Loss: 0.2572
===> Epoch[13](1200/2500): Loss: 0.2504
===> Epoch[13](1300/2500): Loss: 0.2368
===> Epoch[13](1400/2500): Loss: 0.2454
===> Epoch[13](1500/2500): Loss: 0.2119
===> Epoch[13](1600/2500): Loss: 0.2570
===> Epoch[13](1700/2500): Loss: 0.2391
===> Epoch[13](1800/2500): Loss: 0.2400
===> Epoch[13](1900/2500): Loss: 0.2522
===> Epoch[13](2000/2500): Loss: 0.2404
===> Epoch[13](2100/2500): Loss: 0.2308
===> Epoch[13](2200/2500): Loss: 0.2547
===> Epoch[13](2300/2500): Loss: 0.2539
===> Epoch[13](2400/2500): Loss: 0.2607
===> Epoch[13](2500/2500): Loss: 0.2434
===> Epoch 13 Complete: Avg. Loss: 0.2476
===> Timestamp: [2025-08-03 16:20:16]
===> Loading train datasets
===> Epoch[13](100/2500): Loss: 0.2606
===> Epoch[13](200/2500): Loss: 0.2746
===> Epoch[13](300/2500): Loss: 0.2603
===> Epoch[13](400/2500): Loss: 0.2568
===> Epoch[13](500/2500): Loss: 0.2318
===> Epoch[13](600/2500): Loss: 0.2556
===> Epoch[13](700/2500): Loss: 0.2625
===> Epoch[13](800/2500): Loss: 0.2366
===> Epoch[13](900/2500): Loss: 0.2465
===> Epoch[13](1000/2500): Loss: 0.2645
===> Epoch[13](1100/2500): Loss: 0.2572
===> Epoch[13](1200/2500): Loss: 0.2504
===> Epoch[13](1300/2500): Loss: 0.2368
===> Epoch[13](1400/2500): Loss: 0.2454
===> Epoch[13](1500/2500): Loss: 0.2119
===> Epoch[13](1600/2500): Loss: 0.2570
===> Epoch[13](1700/2500): Loss: 0.2391
===> Epoch[13](1800/2500): Loss: 0.2400
===> Epoch[13](1900/2500): Loss: 0.2522
===> Epoch[13](2000/2500): Loss: 0.2404
===> Epoch[13](2100/2500): Loss: 0.2308
===> Epoch[13](2200/2500): Loss: 0.2547
===> Epoch[13](2300/2500): Loss: 0.2539
===> Epoch[13](2400/2500): Loss: 0.2607
===> Epoch[13](2500/2500): Loss: 0.2434
===> Epoch 13 Complete: Avg. Loss: 0.2476
===> Timestamp: [2025-08-03 16:20:16]
===> Loading train datasets
===> Epoch[13](100/2500): Loss: 0.2606
===> Epoch[13](200/2500): Loss: 0.2746
===> Epoch[13](300/2500): Loss: 0.2603
===> Epoch[13](400/2500): Loss: 0.2568
===> Epoch[13](500/2500): Loss: 0.2318
===> Epoch[13](600/2500): Loss: 0.2556
===> Epoch[13](700/2500): Loss: 0.2625
===> Epoch[13](800/2500): Loss: 0.2366
===> Epoch[13](900/2500): Loss: 0.2465
===> Epoch[13](1000/2500): Loss: 0.2645
===> Epoch[13](1100/2500): Loss: 0.2572
===> Epoch[13](1200/2500): Loss: 0.2504
===> Epoch[13](1300/2500): Loss: 0.2368
===> Epoch[13](1400/2500): Loss: 0.2454
===> Epoch[13](1500/2500): Loss: 0.2119
===> Epoch[13](1600/2500): Loss: 0.2570
===> Epoch[13](1700/2500): Loss: 0.2391
===> Epoch[13](1800/2500): Loss: 0.2400
===> Epoch[13](1900/2500): Loss: 0.2522
===> Epoch[13](2000/2500): Loss: 0.2404
===> Epoch[13](2100/2500): Loss: 0.2308
===> Epoch[13](2200/2500): Loss: 0.2547
===> Epoch[13](2300/2500): Loss: 0.2539
===> Epoch[13](2400/2500): Loss: 0.2607
===> Epoch[13](2500/2500): Loss: 0.2434
===> Epoch 13 Complete: Avg. Loss: 0.2476
===> Timestamp: [2025-08-03 16:20:16]
===> Loading train datasets
===> Epoch[13](100/2500): Loss: 0.2606
===> Epoch[13](200/2500): Loss: 0.2746
===> Epoch[13](300/2500): Loss: 0.2603
===> Epoch[13](400/2500): Loss: 0.2568
===> Epoch[13](500/2500): Loss: 0.2318
===> Epoch[13](600/2500): Loss: 0.2556
===> Epoch[13](700/2500): Loss: 0.2625
===> Epoch[13](800/2500): Loss: 0.2366
===> Epoch[13](900/2500): Loss: 0.2465
===> Epoch[13](1000/2500): Loss: 0.2645
===> Epoch[13](1100/2500): Loss: 0.2572
===> Epoch[13](1200/2500): Loss: 0.2504
===> Epoch[13](1300/2500): Loss: 0.2368
===> Epoch[13](1400/2500): Loss: 0.2454
===> Epoch[13](1500/2500): Loss: 0.2119
===> Epoch[13](1600/2500): Loss: 0.2570
===> Epoch[13](1700/2500): Loss: 0.2391
===> Epoch[13](1800/2500): Loss: 0.2400
===> Epoch[13](1900/2500): Loss: 0.2522
===> Epoch[13](2000/2500): Loss: 0.2404
===> Epoch[13](2100/2500): Loss: 0.2308
===> Epoch[13](2200/2500): Loss: 0.2547
===> Epoch[13](2300/2500): Loss: 0.2539
===> Epoch[13](2400/2500): Loss: 0.2607
===> Epoch[13](2500/2500): Loss: 0.2434
===> Epoch 13 Complete: Avg. Loss: 0.2476
===> Timestamp: [2025-08-03 16:20:16]
===> Loading train datasets
===> Epoch[13](100/2500): Loss: 0.2606
===> Epoch[13](200/2500): Loss: 0.2746
===> Epoch[13](300/2500): Loss: 0.2603
===> Epoch[13](400/2500): Loss: 0.2568
===> Epoch[13](500/2500): Loss: 0.2318
===> Epoch[13](600/2500): Loss: 0.2556
===> Epoch[13](700/2500): Loss: 0.2625
===> Epoch[13](800/2500): Loss: 0.2366
===> Epoch[13](900/2500): Loss: 0.2465
===> Epoch[13](1000/2500): Loss: 0.2645
===> Epoch[13](1100/2500): Loss: 0.2572
===> Epoch[13](1200/2500): Loss: 0.2504
===> Epoch[13](1300/2500): Loss: 0.2368
===> Epoch[13](1400/2500): Loss: 0.2454
===> Epoch[13](1500/2500): Loss: 0.2119
===> Epoch[13](1600/2500): Loss: 0.2570
===> Epoch[13](1700/2500): Loss: 0.2391
===> Epoch[13](1800/2500): Loss: 0.2400
===> Epoch[13](1900/2500): Loss: 0.2522
===> Epoch[13](2000/2500): Loss: 0.2404
===> Epoch[13](2100/2500): Loss: 0.2308
===> Epoch[13](2200/2500): Loss: 0.2547
===> Epoch[13](2300/2500): Loss: 0.2539
===> Epoch[13](2400/2500): Loss: 0.2607
===> Epoch[13](2500/2500): Loss: 0.2434
===> Epoch 13 Complete: Avg. Loss: 0.2476
===> Timestamp: [2025-08-03 16:20:16]
===> Loading train datasets
===> Epoch[13](100/2500): Loss: 0.2606
===> Epoch[13](200/2500): Loss: 0.2746
===> Epoch[13](300/2500): Loss: 0.2603
===> Epoch[13](400/2500): Loss: 0.2568
===> Epoch[13](500/2500): Loss: 0.2318
===> Epoch[13](600/2500): Loss: 0.2556
===> Epoch[13](700/2500): Loss: 0.2625
===> Epoch[13](800/2500): Loss: 0.2366
===> Epoch[13](900/2500): Loss: 0.2465
===> Epoch[13](1000/2500): Loss: 0.2645
===> Epoch[13](1100/2500): Loss: 0.2572
===> Epoch[13](1200/2500): Loss: 0.2504
===> Epoch[13](1300/2500): Loss: 0.2368
===> Epoch[13](1400/2500): Loss: 0.2454
===> Epoch[13](1500/2500): Loss: 0.2119
===> Epoch[13](1600/2500): Loss: 0.2570
===> Epoch[13](1700/2500): Loss: 0.2391
===> Epoch[13](1800/2500): Loss: 0.2400
===> Epoch[13](1900/2500): Loss: 0.2522
===> Epoch[13](2000/2500): Loss: 0.2404
===> Epoch[13](2100/2500): Loss: 0.2308
===> Epoch[13](2200/2500): Loss: 0.2547
===> Epoch[13](2300/2500): Loss: 0.2539
===> Epoch[13](2400/2500): Loss: 0.2607
===> Epoch[13](2500/2500): Loss: 0.2434
===> Epoch 13 Complete: Avg. Loss: 0.2476
===> Timestamp: [2025-08-03 16:20:16]
===> Loading train datasets
===> Epoch[13](100/2500): Loss: 0.2606
===> Epoch[13](200/2500): Loss: 0.2746
===> Epoch[13](300/2500): Loss: 0.2603
===> Epoch[13](400/2500): Loss: 0.2568
===> Epoch[13](500/2500): Loss: 0.2318
===> Epoch[13](600/2500): Loss: 0.2556
===> Epoch[13](700/2500): Loss: 0.2625
===> Epoch[13](800/2500): Loss: 0.2366
===> Epoch[13](900/2500): Loss: 0.2465
===> Epoch[13](1000/2500): Loss: 0.2645
===> Epoch[13](1100/2500): Loss: 0.2572
===> Epoch[13](1200/2500): Loss: 0.2504
===> Epoch[13](1300/2500): Loss: 0.2368
===> Epoch[13](1400/2500): Loss: 0.2454
===> Epoch[13](1500/2500): Loss: 0.2119
===> Epoch[13](1600/2500): Loss: 0.2570
===> Epoch[13](1700/2500): Loss: 0.2391
===> Epoch[13](1800/2500): Loss: 0.2400
===> Epoch[13](1900/2500): Loss: 0.2522
===> Epoch[13](2000/2500): Loss: 0.2404
===> Epoch[13](2100/2500): Loss: 0.2308
===> Epoch[13](2200/2500): Loss: 0.2547
===> Epoch[13](2300/2500): Loss: 0.2539
===> Epoch[13](2400/2500): Loss: 0.2607
===> Epoch[13](2500/2500): Loss: 0.2434
===> Epoch 13 Complete: Avg. Loss: 0.2476
===> Timestamp: [2025-08-03 16:20:16]
===> Loading train datasets
===> Epoch[13](100/2500): Loss: 0.2606
===> Epoch[13](200/2500): Loss: 0.2746
===> Epoch[13](300/2500): Loss: 0.2603
===> Epoch[13](400/2500): Loss: 0.2568
===> Epoch[13](500/2500): Loss: 0.2318
===> Epoch[13](600/2500): Loss: 0.2556
===> Epoch[13](700/2500): Loss: 0.2625
===> Epoch[13](800/2500): Loss: 0.2366
===> Epoch[13](900/2500): Loss: 0.2465
===> Epoch[13](1000/2500): Loss: 0.2645
===> Epoch[13](1100/2500): Loss: 0.2572
===> Epoch[13](1200/2500): Loss: 0.2504
===> Epoch[13](1300/2500): Loss: 0.2368
===> Epoch[13](1400/2500): Loss: 0.2454
===> Epoch[13](1500/2500): Loss: 0.2119
===> Epoch[13](1600/2500): Loss: 0.2570
===> Epoch[13](1700/2500): Loss: 0.2391
===> Epoch[13](1800/2500): Loss: 0.2400
===> Epoch[13](1900/2500): Loss: 0.2522
===> Epoch[13](2000/2500): Loss: 0.2404
===> Epoch[13](2100/2500): Loss: 0.2308
===> Epoch[13](2200/2500): Loss: 0.2547
===> Epoch[13](2300/2500): Loss: 0.2539
===> Epoch[13](2400/2500): Loss: 0.2607
===> Epoch[13](2500/2500): Loss: 0.2434
===> Epoch 13 Complete: Avg. Loss: 0.2476
===> Timestamp: [2025-08-03 16:20:16]
===> Loading train datasets
===> Epoch[13](100/2500): Loss: 0.2606
===> Epoch[13](200/2500): Loss: 0.2746
===> Epoch[13](300/2500): Loss: 0.2603
===> Epoch[13](400/2500): Loss: 0.2568
===> Epoch[13](500/2500): Loss: 0.2318
===> Epoch[13](600/2500): Loss: 0.2556
===> Epoch[13](700/2500): Loss: 0.2625
===> Epoch[13](800/2500): Loss: 0.2366
===> Epoch[13](900/2500): Loss: 0.2465
===> Epoch[13](1000/2500): Loss: 0.2645
===> Epoch[13](1100/2500): Loss: 0.2572
===> Epoch[13](1200/2500): Loss: 0.2504
===> Epoch[13](1300/2500): Loss: 0.2368
===> Epoch[13](1400/2500): Loss: 0.2454
===> Epoch[13](1500/2500): Loss: 0.2119
===> Epoch[13](1600/2500): Loss: 0.2570
===> Epoch[13](1700/2500): Loss: 0.2391
===> Epoch[13](1800/2500): Loss: 0.2400
===> Epoch[13](1900/2500): Loss: 0.2522
===> Epoch[13](2000/2500): Loss: 0.2404
===> Epoch[13](2100/2500): Loss: 0.2308
===> Epoch[13](2200/2500): Loss: 0.2547
===> Epoch[13](2300/2500): Loss: 0.2539
===> Epoch[13](2400/2500): Loss: 0.2607
===> Epoch[13](2500/2500): Loss: 0.2434
===> Epoch 13 Complete: Avg. Loss: 0.2476
===> Timestamp: [2025-08-03 16:20:16]
===> Loading train datasets
===> Epoch[13](100/2500): Loss: 0.2606
===> Epoch[13](200/2500): Loss: 0.2746
===> Epoch[13](300/2500): Loss: 0.2603
===> Epoch[13](400/2500): Loss: 0.2568
===> Epoch[13](500/2500): Loss: 0.2318
===> Epoch[13](600/2500): Loss: 0.2556
===> Epoch[13](700/2500): Loss: 0.2625
===> Epoch[13](800/2500): Loss: 0.2366
===> Epoch[13](900/2500): Loss: 0.2465
===> Epoch[13](1000/2500): Loss: 0.2645
===> Epoch[13](1100/2500): Loss: 0.2572
===> Epoch[13](1200/2500): Loss: 0.2504
===> Epoch[13](1300/2500): Loss: 0.2368
===> Epoch[13](1400/2500): Loss: 0.2454
===> Epoch[13](1500/2500): Loss: 0.2119
===> Epoch[13](1600/2500): Loss: 0.2570
===> Epoch[13](1700/2500): Loss: 0.2391
===> Epoch[13](1800/2500): Loss: 0.2400
===> Epoch[13](1900/2500): Loss: 0.2522
===> Epoch[13](2000/2500): Loss: 0.2404
===> Epoch[13](2100/2500): Loss: 0.2308
===> Epoch[13](2200/2500): Loss: 0.2547
===> Epoch[13](2300/2500): Loss: 0.2539
===> Epoch[13](2400/2500): Loss: 0.2607
===> Epoch[13](2500/2500): Loss: 0.2434
===> Epoch 13 Complete: Avg. Loss: 0.2476
===> Timestamp: [2025-08-03 16:20:16]
===> Loading train datasets
===> Epoch[13](100/2500): Loss: 0.2606
===> Epoch[13](200/2500): Loss: 0.2746
===> Epoch[13](300/2500): Loss: 0.2603
===> Epoch[13](400/2500): Loss: 0.2568
===> Epoch[13](500/2500): Loss: 0.2318
===> Epoch[13](600/2500): Loss: 0.2556
===> Epoch[13](700/2500): Loss: 0.2625
===> Epoch[13](800/2500): Loss: 0.2366
===> Epoch[13](900/2500): Loss: 0.2465
===> Epoch[13](1000/2500): Loss: 0.2645
===> Epoch[13](1100/2500): Loss: 0.2572
===> Epoch[13](1200/2500): Loss: 0.2504
===> Epoch[13](1300/2500): Loss: 0.2368
===> Epoch[13](1400/2500): Loss: 0.2454
===> Epoch[13](1500/2500): Loss: 0.2119
===> Epoch[13](1600/2500): Loss: 0.2570
===> Epoch[13](1700/2500): Loss: 0.2391
===> Epoch[13](1800/2500): Loss: 0.2400
===> Epoch[13](1900/2500): Loss: 0.2522
===> Epoch[13](2000/2500): Loss: 0.2404
===> Epoch[13](2100/2500): Loss: 0.2308
===> Epoch[13](2200/2500): Loss: 0.2547
===> Epoch[13](2300/2500): Loss: 0.2539
===> Epoch[13](2400/2500): Loss: 0.2607
===> Epoch[13](2500/2500): Loss: 0.2434
===> Epoch 13 Complete: Avg. Loss: 0.2476
===> Timestamp: [2025-08-03 16:20:16]
===> Loading train datasets
===> Loading train datasets
===> Epoch[14](100/2500): Loss: 0.2308
===> Epoch[14](200/2500): Loss: 0.2599
===> Epoch[14](300/2500): Loss: 0.2275
===> Epoch[14](400/2500): Loss: 0.2434
===> Epoch[14](500/2500): Loss: 0.2357
===> Epoch[14](600/2500): Loss: 0.2320
===> Epoch[14](700/2500): Loss: 0.2257
===> Epoch[14](800/2500): Loss: 0.2492
===> Epoch[14](900/2500): Loss: 0.2274
===> Epoch[14](1000/2500): Loss: 0.2419
===> Epoch[14](1100/2500): Loss: 0.2315
===> Epoch[14](1200/2500): Loss: 0.2530
===> Epoch[14](1300/2500): Loss: 0.2374
===> Epoch[14](1400/2500): Loss: 0.2492
===> Epoch[14](1500/2500): Loss: 0.2583
===> Epoch[14](1600/2500): Loss: 0.2561
===> Epoch[14](1700/2500): Loss: 0.2448
===> Epoch[14](1800/2500): Loss: 0.2267
===> Epoch[14](1900/2500): Loss: 0.2355
===> Epoch[14](2000/2500): Loss: 0.2617
===> Epoch[14](2100/2500): Loss: 0.2379
===> Epoch[14](2200/2500): Loss: 0.2176
===> Epoch[14](2300/2500): Loss: 0.2383
===> Epoch[14](2400/2500): Loss: 0.2596
===> Epoch[14](2500/2500): Loss: 0.2321
===> Epoch 14 Complete: Avg. Loss: 0.2411
===> Timestamp: [2025-08-03 16:24:49]
===> Loading train datasets
===> Epoch[14](100/2500): Loss: 0.2308
===> Epoch[14](200/2500): Loss: 0.2599
===> Epoch[14](300/2500): Loss: 0.2275
===> Epoch[14](400/2500): Loss: 0.2434
===> Epoch[14](500/2500): Loss: 0.2357
===> Epoch[14](600/2500): Loss: 0.2320
===> Epoch[14](700/2500): Loss: 0.2257
===> Epoch[14](800/2500): Loss: 0.2492
===> Epoch[14](900/2500): Loss: 0.2274
===> Epoch[14](1000/2500): Loss: 0.2419
===> Epoch[14](1100/2500): Loss: 0.2315
===> Epoch[14](1200/2500): Loss: 0.2530
===> Epoch[14](1300/2500): Loss: 0.2374
===> Epoch[14](1400/2500): Loss: 0.2492
===> Epoch[14](1500/2500): Loss: 0.2583
===> Epoch[14](1600/2500): Loss: 0.2561
===> Epoch[14](1700/2500): Loss: 0.2448
===> Epoch[14](1800/2500): Loss: 0.2267
===> Epoch[14](1900/2500): Loss: 0.2355
===> Epoch[14](2000/2500): Loss: 0.2617
===> Epoch[14](2100/2500): Loss: 0.2379
===> Epoch[14](2200/2500): Loss: 0.2176
===> Epoch[14](2300/2500): Loss: 0.2383
===> Epoch[14](2400/2500): Loss: 0.2596
===> Epoch[14](2500/2500): Loss: 0.2321
===> Epoch 14 Complete: Avg. Loss: 0.2411
===> Timestamp: [2025-08-03 16:24:49]
===> Loading train datasets
===> Epoch[14](100/2500): Loss: 0.2308
===> Epoch[14](200/2500): Loss: 0.2599
===> Epoch[14](300/2500): Loss: 0.2275
===> Epoch[14](400/2500): Loss: 0.2434
===> Epoch[14](500/2500): Loss: 0.2357
===> Epoch[14](600/2500): Loss: 0.2320
===> Epoch[14](700/2500): Loss: 0.2257
===> Epoch[14](800/2500): Loss: 0.2492
===> Epoch[14](900/2500): Loss: 0.2274
===> Epoch[14](1000/2500): Loss: 0.2419
===> Epoch[14](1100/2500): Loss: 0.2315
===> Epoch[14](1200/2500): Loss: 0.2530
===> Epoch[14](1300/2500): Loss: 0.2374
===> Epoch[14](1400/2500): Loss: 0.2492
===> Epoch[14](1500/2500): Loss: 0.2583
===> Epoch[14](1600/2500): Loss: 0.2561
===> Epoch[14](1700/2500): Loss: 0.2448
===> Epoch[14](1800/2500): Loss: 0.2267
===> Epoch[14](1900/2500): Loss: 0.2355
===> Epoch[14](2000/2500): Loss: 0.2617
===> Epoch[14](2100/2500): Loss: 0.2379
===> Epoch[14](2200/2500): Loss: 0.2176
===> Epoch[14](2300/2500): Loss: 0.2383
===> Epoch[14](2400/2500): Loss: 0.2596
===> Epoch[14](2500/2500): Loss: 0.2321
===> Epoch 14 Complete: Avg. Loss: 0.2411
===> Timestamp: [2025-08-03 16:24:49]
===> Loading train datasets
===> Epoch[14](100/2500): Loss: 0.2308
===> Epoch[14](200/2500): Loss: 0.2599
===> Epoch[14](300/2500): Loss: 0.2275
===> Epoch[14](400/2500): Loss: 0.2434
===> Epoch[14](500/2500): Loss: 0.2357
===> Epoch[14](600/2500): Loss: 0.2320
===> Epoch[14](700/2500): Loss: 0.2257
===> Epoch[14](800/2500): Loss: 0.2492
===> Epoch[14](900/2500): Loss: 0.2274
===> Epoch[14](1000/2500): Loss: 0.2419
===> Epoch[14](1100/2500): Loss: 0.2315
===> Epoch[14](1200/2500): Loss: 0.2530
===> Epoch[14](1300/2500): Loss: 0.2374
===> Epoch[14](1400/2500): Loss: 0.2492
===> Epoch[14](1500/2500): Loss: 0.2583
===> Epoch[14](1600/2500): Loss: 0.2561
===> Epoch[14](1700/2500): Loss: 0.2448
===> Epoch[14](1800/2500): Loss: 0.2267
===> Epoch[14](1900/2500): Loss: 0.2355
===> Epoch[14](2000/2500): Loss: 0.2617
===> Epoch[14](2100/2500): Loss: 0.2379
===> Epoch[14](2200/2500): Loss: 0.2176
===> Epoch[14](2300/2500): Loss: 0.2383
===> Epoch[14](2400/2500): Loss: 0.2596
===> Epoch[14](2500/2500): Loss: 0.2321
===> Epoch 14 Complete: Avg. Loss: 0.2411
===> Timestamp: [2025-08-03 16:24:49]
===> Loading train datasets
===> Epoch[14](100/2500): Loss: 0.2308
===> Epoch[14](200/2500): Loss: 0.2599
===> Epoch[14](300/2500): Loss: 0.2275
===> Epoch[14](400/2500): Loss: 0.2434
===> Epoch[14](500/2500): Loss: 0.2357
===> Epoch[14](600/2500): Loss: 0.2320
===> Epoch[14](700/2500): Loss: 0.2257
===> Epoch[14](800/2500): Loss: 0.2492
===> Epoch[14](900/2500): Loss: 0.2274
===> Epoch[14](1000/2500): Loss: 0.2419
===> Epoch[14](1100/2500): Loss: 0.2315
===> Epoch[14](1200/2500): Loss: 0.2530
===> Epoch[14](1300/2500): Loss: 0.2374
===> Epoch[14](1400/2500): Loss: 0.2492
===> Epoch[14](1500/2500): Loss: 0.2583
===> Epoch[14](1600/2500): Loss: 0.2561
===> Epoch[14](1700/2500): Loss: 0.2448
===> Epoch[14](1800/2500): Loss: 0.2267
===> Epoch[14](1900/2500): Loss: 0.2355
===> Epoch[14](2000/2500): Loss: 0.2617
===> Epoch[14](2100/2500): Loss: 0.2379
===> Epoch[14](2200/2500): Loss: 0.2176
===> Epoch[14](2300/2500): Loss: 0.2383
===> Epoch[14](2400/2500): Loss: 0.2596
===> Epoch[14](2500/2500): Loss: 0.2321
===> Epoch 14 Complete: Avg. Loss: 0.2411
===> Timestamp: [2025-08-03 16:24:49]
===> Loading train datasets
===> Epoch[14](100/2500): Loss: 0.2308
===> Epoch[14](200/2500): Loss: 0.2599
===> Epoch[14](300/2500): Loss: 0.2275
===> Epoch[14](400/2500): Loss: 0.2434
===> Epoch[14](500/2500): Loss: 0.2357
===> Epoch[14](600/2500): Loss: 0.2320
===> Epoch[14](700/2500): Loss: 0.2257
===> Epoch[14](800/2500): Loss: 0.2492
===> Epoch[14](900/2500): Loss: 0.2274
===> Epoch[14](1000/2500): Loss: 0.2419
===> Epoch[14](1100/2500): Loss: 0.2315
===> Epoch[14](1200/2500): Loss: 0.2530
===> Epoch[14](1300/2500): Loss: 0.2374
===> Epoch[14](1400/2500): Loss: 0.2492
===> Epoch[14](1500/2500): Loss: 0.2583
===> Epoch[14](1600/2500): Loss: 0.2561
===> Epoch[14](1700/2500): Loss: 0.2448
===> Epoch[14](1800/2500): Loss: 0.2267
===> Epoch[14](1900/2500): Loss: 0.2355
===> Epoch[14](2000/2500): Loss: 0.2617
===> Epoch[14](2100/2500): Loss: 0.2379
===> Epoch[14](2200/2500): Loss: 0.2176
===> Epoch[14](2300/2500): Loss: 0.2383
===> Epoch[14](2400/2500): Loss: 0.2596
===> Epoch[14](2500/2500): Loss: 0.2321
===> Epoch 14 Complete: Avg. Loss: 0.2411
===> Timestamp: [2025-08-03 16:24:49]
===> Loading train datasets
===> Epoch[14](100/2500): Loss: 0.2308
===> Epoch[14](200/2500): Loss: 0.2599
===> Epoch[14](300/2500): Loss: 0.2275
===> Epoch[14](400/2500): Loss: 0.2434
===> Epoch[14](500/2500): Loss: 0.2357
===> Epoch[14](600/2500): Loss: 0.2320
===> Epoch[14](700/2500): Loss: 0.2257
===> Epoch[14](800/2500): Loss: 0.2492
===> Epoch[14](900/2500): Loss: 0.2274
===> Epoch[14](1000/2500): Loss: 0.2419
===> Epoch[14](1100/2500): Loss: 0.2315
===> Epoch[14](1200/2500): Loss: 0.2530
===> Epoch[14](1300/2500): Loss: 0.2374
===> Epoch[14](1400/2500): Loss: 0.2492
===> Epoch[14](1500/2500): Loss: 0.2583
===> Epoch[14](1600/2500): Loss: 0.2561
===> Epoch[14](1700/2500): Loss: 0.2448
===> Epoch[14](1800/2500): Loss: 0.2267
===> Epoch[14](1900/2500): Loss: 0.2355
===> Epoch[14](2000/2500): Loss: 0.2617
===> Epoch[14](2100/2500): Loss: 0.2379
===> Epoch[14](2200/2500): Loss: 0.2176
===> Epoch[14](2300/2500): Loss: 0.2383
===> Epoch[14](2400/2500): Loss: 0.2596
===> Epoch[14](2500/2500): Loss: 0.2321
===> Epoch 14 Complete: Avg. Loss: 0.2411
===> Timestamp: [2025-08-03 16:24:49]
===> Loading train datasets
===> Epoch[14](100/2500): Loss: 0.2308
===> Epoch[14](200/2500): Loss: 0.2599
===> Epoch[14](300/2500): Loss: 0.2275
===> Epoch[14](400/2500): Loss: 0.2434
===> Epoch[14](500/2500): Loss: 0.2357
===> Epoch[14](600/2500): Loss: 0.2320
===> Epoch[14](700/2500): Loss: 0.2257
===> Epoch[14](800/2500): Loss: 0.2492
===> Epoch[14](900/2500): Loss: 0.2274
===> Epoch[14](1000/2500): Loss: 0.2419
===> Epoch[14](1100/2500): Loss: 0.2315
===> Epoch[14](1200/2500): Loss: 0.2530
===> Epoch[14](1300/2500): Loss: 0.2374
===> Epoch[14](1400/2500): Loss: 0.2492
===> Epoch[14](1500/2500): Loss: 0.2583
===> Epoch[14](1600/2500): Loss: 0.2561
===> Epoch[14](1700/2500): Loss: 0.2448
===> Epoch[14](1800/2500): Loss: 0.2267
===> Epoch[14](1900/2500): Loss: 0.2355
===> Epoch[14](2000/2500): Loss: 0.2617
===> Epoch[14](2100/2500): Loss: 0.2379
===> Epoch[14](2200/2500): Loss: 0.2176
===> Epoch[14](2300/2500): Loss: 0.2383
===> Epoch[14](2400/2500): Loss: 0.2596
===> Epoch[14](2500/2500): Loss: 0.2321
===> Epoch 14 Complete: Avg. Loss: 0.2411
===> Timestamp: [2025-08-03 16:24:49]
===> Loading train datasets
===> Epoch[14](100/2500): Loss: 0.2308
===> Epoch[14](200/2500): Loss: 0.2599
===> Epoch[14](300/2500): Loss: 0.2275
===> Epoch[14](400/2500): Loss: 0.2434
===> Epoch[14](500/2500): Loss: 0.2357
===> Epoch[14](600/2500): Loss: 0.2320
===> Epoch[14](700/2500): Loss: 0.2257
===> Epoch[14](800/2500): Loss: 0.2492
===> Epoch[14](900/2500): Loss: 0.2274
===> Epoch[14](1000/2500): Loss: 0.2419
===> Epoch[14](1100/2500): Loss: 0.2315
===> Epoch[14](1200/2500): Loss: 0.2530
===> Epoch[14](1300/2500): Loss: 0.2374
===> Epoch[14](1400/2500): Loss: 0.2492
===> Epoch[14](1500/2500): Loss: 0.2583
===> Epoch[14](1600/2500): Loss: 0.2561
===> Epoch[14](1700/2500): Loss: 0.2448
===> Epoch[14](1800/2500): Loss: 0.2267
===> Epoch[14](1900/2500): Loss: 0.2355
===> Epoch[14](2000/2500): Loss: 0.2617
===> Epoch[14](2100/2500): Loss: 0.2379
===> Epoch[14](2200/2500): Loss: 0.2176
===> Epoch[14](2300/2500): Loss: 0.2383
===> Epoch[14](2400/2500): Loss: 0.2596
===> Epoch[14](2500/2500): Loss: 0.2321
===> Epoch 14 Complete: Avg. Loss: 0.2411
===> Timestamp: [2025-08-03 16:24:49]
===> Loading train datasets
===> Epoch[14](100/2500): Loss: 0.2308
===> Epoch[14](200/2500): Loss: 0.2599
===> Epoch[14](300/2500): Loss: 0.2275
===> Epoch[14](400/2500): Loss: 0.2434
===> Epoch[14](500/2500): Loss: 0.2357
===> Epoch[14](600/2500): Loss: 0.2320
===> Epoch[14](700/2500): Loss: 0.2257
===> Epoch[14](800/2500): Loss: 0.2492
===> Epoch[14](900/2500): Loss: 0.2274
===> Epoch[14](1000/2500): Loss: 0.2419
===> Epoch[14](1100/2500): Loss: 0.2315
===> Epoch[14](1200/2500): Loss: 0.2530
===> Epoch[14](1300/2500): Loss: 0.2374
===> Epoch[14](1400/2500): Loss: 0.2492
===> Epoch[14](1500/2500): Loss: 0.2583
===> Epoch[14](1600/2500): Loss: 0.2561
===> Epoch[14](1700/2500): Loss: 0.2448
===> Epoch[14](1800/2500): Loss: 0.2267
===> Epoch[14](1900/2500): Loss: 0.2355
===> Epoch[14](2000/2500): Loss: 0.2617
===> Epoch[14](2100/2500): Loss: 0.2379
===> Epoch[14](2200/2500): Loss: 0.2176
===> Epoch[14](2300/2500): Loss: 0.2383
===> Epoch[14](2400/2500): Loss: 0.2596
===> Epoch[14](2500/2500): Loss: 0.2321
===> Epoch 14 Complete: Avg. Loss: 0.2411
===> Timestamp: [2025-08-03 16:24:49]
===> Loading train datasets
===> Epoch[14](100/2500): Loss: 0.2308
===> Epoch[14](200/2500): Loss: 0.2599
===> Epoch[14](300/2500): Loss: 0.2275
===> Epoch[14](400/2500): Loss: 0.2434
===> Epoch[14](500/2500): Loss: 0.2357
===> Epoch[14](600/2500): Loss: 0.2320
===> Epoch[14](700/2500): Loss: 0.2257
===> Epoch[14](800/2500): Loss: 0.2492
===> Epoch[14](900/2500): Loss: 0.2274
===> Epoch[14](1000/2500): Loss: 0.2419
===> Epoch[14](1100/2500): Loss: 0.2315
===> Epoch[14](1200/2500): Loss: 0.2530
===> Epoch[14](1300/2500): Loss: 0.2374
===> Epoch[14](1400/2500): Loss: 0.2492
===> Epoch[14](1500/2500): Loss: 0.2583
===> Epoch[14](1600/2500): Loss: 0.2561
===> Epoch[14](1700/2500): Loss: 0.2448
===> Epoch[14](1800/2500): Loss: 0.2267
===> Epoch[14](1900/2500): Loss: 0.2355
===> Epoch[14](2000/2500): Loss: 0.2617
===> Epoch[14](2100/2500): Loss: 0.2379
===> Epoch[14](2200/2500): Loss: 0.2176
===> Epoch[14](2300/2500): Loss: 0.2383
===> Epoch[14](2400/2500): Loss: 0.2596
===> Epoch[14](2500/2500): Loss: 0.2321
===> Epoch 14 Complete: Avg. Loss: 0.2411
===> Timestamp: [2025-08-03 16:24:49]
===> Loading train datasets
===> Epoch[14](100/2500): Loss: 0.2308
===> Epoch[14](200/2500): Loss: 0.2599
===> Epoch[14](300/2500): Loss: 0.2275
===> Epoch[14](400/2500): Loss: 0.2434
===> Epoch[14](500/2500): Loss: 0.2357
===> Epoch[14](600/2500): Loss: 0.2320
===> Epoch[14](700/2500): Loss: 0.2257
===> Epoch[14](800/2500): Loss: 0.2492
===> Epoch[14](900/2500): Loss: 0.2274
===> Epoch[14](1000/2500): Loss: 0.2419
===> Epoch[14](1100/2500): Loss: 0.2315
===> Epoch[14](1200/2500): Loss: 0.2530
===> Epoch[14](1300/2500): Loss: 0.2374
===> Epoch[14](1400/2500): Loss: 0.2492
===> Epoch[14](1500/2500): Loss: 0.2583
===> Epoch[14](1600/2500): Loss: 0.2561
===> Epoch[14](1700/2500): Loss: 0.2448
===> Epoch[14](1800/2500): Loss: 0.2267
===> Epoch[14](1900/2500): Loss: 0.2355
===> Epoch[14](2000/2500): Loss: 0.2617
===> Epoch[14](2100/2500): Loss: 0.2379
===> Epoch[14](2200/2500): Loss: 0.2176
===> Epoch[14](2300/2500): Loss: 0.2383
===> Epoch[14](2400/2500): Loss: 0.2596
===> Epoch[14](2500/2500): Loss: 0.2321
===> Epoch 14 Complete: Avg. Loss: 0.2411
===> Timestamp: [2025-08-03 16:24:49]
===> Loading train datasets
===> Epoch[14](100/2500): Loss: 0.2308
===> Epoch[14](200/2500): Loss: 0.2599
===> Epoch[14](300/2500): Loss: 0.2275
===> Epoch[14](400/2500): Loss: 0.2434
===> Epoch[14](500/2500): Loss: 0.2357
===> Epoch[14](600/2500): Loss: 0.2320
===> Epoch[14](700/2500): Loss: 0.2257
===> Epoch[14](800/2500): Loss: 0.2492
===> Epoch[14](900/2500): Loss: 0.2274
===> Epoch[14](1000/2500): Loss: 0.2419
===> Epoch[14](1100/2500): Loss: 0.2315
===> Epoch[14](1200/2500): Loss: 0.2530
===> Epoch[14](1300/2500): Loss: 0.2374
===> Epoch[14](1400/2500): Loss: 0.2492
===> Epoch[14](1500/2500): Loss: 0.2583
===> Epoch[14](1600/2500): Loss: 0.2561
===> Epoch[14](1700/2500): Loss: 0.2448
===> Epoch[14](1800/2500): Loss: 0.2267
===> Epoch[14](1900/2500): Loss: 0.2355
===> Epoch[14](2000/2500): Loss: 0.2617
===> Epoch[14](2100/2500): Loss: 0.2379
===> Epoch[14](2200/2500): Loss: 0.2176
===> Epoch[14](2300/2500): Loss: 0.2383
===> Epoch[14](2400/2500): Loss: 0.2596
===> Epoch[14](2500/2500): Loss: 0.2321
===> Epoch 14 Complete: Avg. Loss: 0.2411
===> Timestamp: [2025-08-03 16:24:49]
===> Loading train datasets
===> Epoch[14](100/2500): Loss: 0.2308
===> Epoch[14](200/2500): Loss: 0.2599
===> Epoch[14](300/2500): Loss: 0.2275
===> Epoch[14](400/2500): Loss: 0.2434
===> Epoch[14](500/2500): Loss: 0.2357
===> Epoch[14](600/2500): Loss: 0.2320
===> Epoch[14](700/2500): Loss: 0.2257
===> Epoch[14](800/2500): Loss: 0.2492
===> Epoch[14](900/2500): Loss: 0.2274
===> Epoch[14](1000/2500): Loss: 0.2419
===> Epoch[14](1100/2500): Loss: 0.2315
===> Epoch[14](1200/2500): Loss: 0.2530
===> Epoch[14](1300/2500): Loss: 0.2374
===> Epoch[14](1400/2500): Loss: 0.2492
===> Epoch[14](1500/2500): Loss: 0.2583
===> Epoch[14](1600/2500): Loss: 0.2561
===> Epoch[14](1700/2500): Loss: 0.2448
===> Epoch[14](1800/2500): Loss: 0.2267
===> Epoch[14](1900/2500): Loss: 0.2355
===> Epoch[14](2000/2500): Loss: 0.2617
===> Epoch[14](2100/2500): Loss: 0.2379
===> Epoch[14](2200/2500): Loss: 0.2176
===> Epoch[14](2300/2500): Loss: 0.2383
===> Epoch[14](2400/2500): Loss: 0.2596
===> Epoch[14](2500/2500): Loss: 0.2321
===> Epoch 14 Complete: Avg. Loss: 0.2411
===> Timestamp: [2025-08-03 16:24:49]
===> Loading train datasets
===> Loading train datasets
===> Epoch[15](100/2500): Loss: 0.2424
===> Epoch[15](200/2500): Loss: 0.2399
===> Epoch[15](300/2500): Loss: 0.2550
===> Epoch[15](400/2500): Loss: 0.2506
===> Epoch[15](500/2500): Loss: 0.2314
===> Epoch[15](600/2500): Loss: 0.2339
===> Epoch[15](700/2500): Loss: 0.2443
===> Epoch[15](800/2500): Loss: 0.2438
===> Epoch[15](900/2500): Loss: 0.2479
===> Epoch[15](1000/2500): Loss: 0.2239
===> Epoch[15](1100/2500): Loss: 0.2394
===> Epoch[15](1200/2500): Loss: 0.2344
===> Epoch[15](1300/2500): Loss: 0.2672
===> Epoch[15](1400/2500): Loss: 0.2266
===> Epoch[15](1500/2500): Loss: 0.2406
===> Epoch[15](1600/2500): Loss: 0.2411
===> Epoch[15](1700/2500): Loss: 0.2314
===> Epoch[15](1800/2500): Loss: 0.2366
===> Epoch[15](1900/2500): Loss: 0.2208
===> Epoch[15](2000/2500): Loss: 0.2499
===> Epoch[15](2100/2500): Loss: 0.2453
===> Epoch[15](2200/2500): Loss: 0.2607
===> Epoch[15](2300/2500): Loss: 0.2362
===> Epoch[15](2400/2500): Loss: 0.2316
===> Epoch[15](2500/2500): Loss: 0.2352
===> Epoch 15 Complete: Avg. Loss: 0.2396
===> Timestamp: [2025-08-03 16:29:23]
Checkpoint saved to TrainedNet/_epoch_15.pth
===> Loading train datasets
===> Epoch[15](100/2500): Loss: 0.2424
===> Epoch[15](200/2500): Loss: 0.2399
===> Epoch[15](300/2500): Loss: 0.2550
===> Epoch[15](400/2500): Loss: 0.2506
===> Epoch[15](500/2500): Loss: 0.2314
===> Epoch[15](600/2500): Loss: 0.2339
===> Epoch[15](700/2500): Loss: 0.2443
===> Epoch[15](800/2500): Loss: 0.2438
===> Epoch[15](900/2500): Loss: 0.2479
===> Epoch[15](1000/2500): Loss: 0.2239
===> Epoch[15](1100/2500): Loss: 0.2394
===> Epoch[15](1200/2500): Loss: 0.2344
===> Epoch[15](1300/2500): Loss: 0.2672
===> Epoch[15](1400/2500): Loss: 0.2266
===> Epoch[15](1500/2500): Loss: 0.2406
===> Epoch[15](1600/2500): Loss: 0.2411
===> Epoch[15](1700/2500): Loss: 0.2314
===> Epoch[15](1800/2500): Loss: 0.2366
===> Epoch[15](1900/2500): Loss: 0.2208
===> Epoch[15](2000/2500): Loss: 0.2499
===> Epoch[15](2100/2500): Loss: 0.2453
===> Epoch[15](2200/2500): Loss: 0.2607
===> Epoch[15](2300/2500): Loss: 0.2362
===> Epoch[15](2400/2500): Loss: 0.2316
===> Epoch[15](2500/2500): Loss: 0.2352
===> Epoch 15 Complete: Avg. Loss: 0.2396
===> Timestamp: [2025-08-03 16:29:23]
Checkpoint saved to TrainedNet/_epoch_15.pth
===> Loading train datasets
===> Epoch[15](100/2500): Loss: 0.2424
===> Epoch[15](200/2500): Loss: 0.2399
===> Epoch[15](300/2500): Loss: 0.2550
===> Epoch[15](400/2500): Loss: 0.2506
===> Epoch[15](500/2500): Loss: 0.2314
===> Epoch[15](600/2500): Loss: 0.2339
===> Epoch[15](700/2500): Loss: 0.2443
===> Epoch[15](800/2500): Loss: 0.2438
===> Epoch[15](900/2500): Loss: 0.2479
===> Epoch[15](1000/2500): Loss: 0.2239
===> Epoch[15](1100/2500): Loss: 0.2394
===> Epoch[15](1200/2500): Loss: 0.2344
===> Epoch[15](1300/2500): Loss: 0.2672
===> Epoch[15](1400/2500): Loss: 0.2266
===> Epoch[15](1500/2500): Loss: 0.2406
===> Epoch[15](1600/2500): Loss: 0.2411
===> Epoch[15](1700/2500): Loss: 0.2314
===> Epoch[15](1800/2500): Loss: 0.2366
===> Epoch[15](1900/2500): Loss: 0.2208
===> Epoch[15](2000/2500): Loss: 0.2499
===> Epoch[15](2100/2500): Loss: 0.2453
===> Epoch[15](2200/2500): Loss: 0.2607
===> Epoch[15](2300/2500): Loss: 0.2362
===> Epoch[15](2400/2500): Loss: 0.2316
===> Epoch[15](2500/2500): Loss: 0.2352
===> Epoch 15 Complete: Avg. Loss: 0.2396
===> Timestamp: [2025-08-03 16:29:23]
Checkpoint saved to TrainedNet/_epoch_15.pth
===> Loading train datasets
===> Epoch[15](100/2500): Loss: 0.2424
===> Epoch[15](200/2500): Loss: 0.2399
===> Epoch[15](300/2500): Loss: 0.2550
===> Epoch[15](400/2500): Loss: 0.2506
===> Epoch[15](500/2500): Loss: 0.2314
===> Epoch[15](600/2500): Loss: 0.2339
===> Epoch[15](700/2500): Loss: 0.2443
===> Epoch[15](800/2500): Loss: 0.2438
===> Epoch[15](900/2500): Loss: 0.2479
===> Epoch[15](1000/2500): Loss: 0.2239
===> Epoch[15](1100/2500): Loss: 0.2394
===> Epoch[15](1200/2500): Loss: 0.2344
===> Epoch[15](1300/2500): Loss: 0.2672
===> Epoch[15](1400/2500): Loss: 0.2266
===> Epoch[15](1500/2500): Loss: 0.2406
===> Epoch[15](1600/2500): Loss: 0.2411
===> Epoch[15](1700/2500): Loss: 0.2314
===> Epoch[15](1800/2500): Loss: 0.2366
===> Epoch[15](1900/2500): Loss: 0.2208
===> Epoch[15](2000/2500): Loss: 0.2499
===> Epoch[15](2100/2500): Loss: 0.2453
===> Epoch[15](2200/2500): Loss: 0.2607
===> Epoch[15](2300/2500): Loss: 0.2362
===> Epoch[15](2400/2500): Loss: 0.2316
===> Epoch[15](2500/2500): Loss: 0.2352
===> Epoch 15 Complete: Avg. Loss: 0.2396
===> Timestamp: [2025-08-03 16:29:23]
Checkpoint saved to TrainedNet/_epoch_15.pth
===> Loading train datasets
===> Epoch[15](100/2500): Loss: 0.2424
===> Epoch[15](200/2500): Loss: 0.2399
===> Epoch[15](300/2500): Loss: 0.2550
===> Epoch[15](400/2500): Loss: 0.2506
===> Epoch[15](500/2500): Loss: 0.2314
===> Epoch[15](600/2500): Loss: 0.2339
===> Epoch[15](700/2500): Loss: 0.2443
===> Epoch[15](800/2500): Loss: 0.2438
===> Epoch[15](900/2500): Loss: 0.2479
===> Epoch[15](1000/2500): Loss: 0.2239
===> Epoch[15](1100/2500): Loss: 0.2394
===> Epoch[15](1200/2500): Loss: 0.2344
===> Epoch[15](1300/2500): Loss: 0.2672
===> Epoch[15](1400/2500): Loss: 0.2266
===> Epoch[15](1500/2500): Loss: 0.2406
===> Epoch[15](1600/2500): Loss: 0.2411
===> Epoch[15](1700/2500): Loss: 0.2314
===> Epoch[15](1800/2500): Loss: 0.2366
===> Epoch[15](1900/2500): Loss: 0.2208
===> Epoch[15](2000/2500): Loss: 0.2499
===> Epoch[15](2100/2500): Loss: 0.2453
===> Epoch[15](2200/2500): Loss: 0.2607
===> Epoch[15](2300/2500): Loss: 0.2362
===> Epoch[15](2400/2500): Loss: 0.2316
===> Epoch[15](2500/2500): Loss: 0.2352
===> Epoch 15 Complete: Avg. Loss: 0.2396
===> Timestamp: [2025-08-03 16:29:23]
Checkpoint saved to TrainedNet/_epoch_15.pth
===> Loading train datasets
===> Epoch[15](100/2500): Loss: 0.2424
===> Epoch[15](200/2500): Loss: 0.2399
===> Epoch[15](300/2500): Loss: 0.2550
===> Epoch[15](400/2500): Loss: 0.2506
===> Epoch[15](500/2500): Loss: 0.2314
===> Epoch[15](600/2500): Loss: 0.2339
===> Epoch[15](700/2500): Loss: 0.2443
===> Epoch[15](800/2500): Loss: 0.2438
===> Epoch[15](900/2500): Loss: 0.2479
===> Epoch[15](1000/2500): Loss: 0.2239
===> Epoch[15](1100/2500): Loss: 0.2394
===> Epoch[15](1200/2500): Loss: 0.2344
===> Epoch[15](1300/2500): Loss: 0.2672
===> Epoch[15](1400/2500): Loss: 0.2266
===> Epoch[15](1500/2500): Loss: 0.2406
===> Epoch[15](1600/2500): Loss: 0.2411
===> Epoch[15](1700/2500): Loss: 0.2314
===> Epoch[15](1800/2500): Loss: 0.2366
===> Epoch[15](1900/2500): Loss: 0.2208
===> Epoch[15](2000/2500): Loss: 0.2499
===> Epoch[15](2100/2500): Loss: 0.2453
===> Epoch[15](2200/2500): Loss: 0.2607
===> Epoch[15](2300/2500): Loss: 0.2362
===> Epoch[15](2400/2500): Loss: 0.2316
===> Epoch[15](2500/2500): Loss: 0.2352
===> Epoch 15 Complete: Avg. Loss: 0.2396
===> Timestamp: [2025-08-03 16:29:23]
Checkpoint saved to TrainedNet/_epoch_15.pth
===> Loading train datasets
===> Epoch[15](100/2500): Loss: 0.2424
===> Epoch[15](200/2500): Loss: 0.2399
===> Epoch[15](300/2500): Loss: 0.2550
===> Epoch[15](400/2500): Loss: 0.2506
===> Epoch[15](500/2500): Loss: 0.2314
===> Epoch[15](600/2500): Loss: 0.2339
===> Epoch[15](700/2500): Loss: 0.2443
===> Epoch[15](800/2500): Loss: 0.2438
===> Epoch[15](900/2500): Loss: 0.2479
===> Epoch[15](1000/2500): Loss: 0.2239
===> Epoch[15](1100/2500): Loss: 0.2394
===> Epoch[15](1200/2500): Loss: 0.2344
===> Epoch[15](1300/2500): Loss: 0.2672
===> Epoch[15](1400/2500): Loss: 0.2266
===> Epoch[15](1500/2500): Loss: 0.2406
===> Epoch[15](1600/2500): Loss: 0.2411
===> Epoch[15](1700/2500): Loss: 0.2314
===> Epoch[15](1800/2500): Loss: 0.2366
===> Epoch[15](1900/2500): Loss: 0.2208
===> Epoch[15](2000/2500): Loss: 0.2499
===> Epoch[15](2100/2500): Loss: 0.2453
===> Epoch[15](2200/2500): Loss: 0.2607
===> Epoch[15](2300/2500): Loss: 0.2362
===> Epoch[15](2400/2500): Loss: 0.2316
===> Epoch[15](2500/2500): Loss: 0.2352
===> Epoch 15 Complete: Avg. Loss: 0.2396
===> Timestamp: [2025-08-03 16:29:23]
Checkpoint saved to TrainedNet/_epoch_15.pth
===> Loading train datasets
===> Epoch[15](100/2500): Loss: 0.2424
===> Epoch[15](200/2500): Loss: 0.2399
===> Epoch[15](300/2500): Loss: 0.2550
===> Epoch[15](400/2500): Loss: 0.2506
===> Epoch[15](500/2500): Loss: 0.2314
===> Epoch[15](600/2500): Loss: 0.2339
===> Epoch[15](700/2500): Loss: 0.2443
===> Epoch[15](800/2500): Loss: 0.2438
===> Epoch[15](900/2500): Loss: 0.2479
===> Epoch[15](1000/2500): Loss: 0.2239
===> Epoch[15](1100/2500): Loss: 0.2394
===> Epoch[15](1200/2500): Loss: 0.2344
===> Epoch[15](1300/2500): Loss: 0.2672
===> Epoch[15](1400/2500): Loss: 0.2266
===> Epoch[15](1500/2500): Loss: 0.2406
===> Epoch[15](1600/2500): Loss: 0.2411
===> Epoch[15](1700/2500): Loss: 0.2314
===> Epoch[15](1800/2500): Loss: 0.2366
===> Epoch[15](1900/2500): Loss: 0.2208
===> Epoch[15](2000/2500): Loss: 0.2499
===> Epoch[15](2100/2500): Loss: 0.2453
===> Epoch[15](2200/2500): Loss: 0.2607
===> Epoch[15](2300/2500): Loss: 0.2362
===> Epoch[15](2400/2500): Loss: 0.2316
===> Epoch[15](2500/2500): Loss: 0.2352
===> Epoch 15 Complete: Avg. Loss: 0.2396
===> Timestamp: [2025-08-03 16:29:23]
Checkpoint saved to TrainedNet/_epoch_15.pth
===> Loading train datasets
===> Epoch[15](100/2500): Loss: 0.2424
===> Epoch[15](200/2500): Loss: 0.2399
===> Epoch[15](300/2500): Loss: 0.2550
===> Epoch[15](400/2500): Loss: 0.2506
===> Epoch[15](500/2500): Loss: 0.2314
===> Epoch[15](600/2500): Loss: 0.2339
===> Epoch[15](700/2500): Loss: 0.2443
===> Epoch[15](800/2500): Loss: 0.2438
===> Epoch[15](900/2500): Loss: 0.2479
===> Epoch[15](1000/2500): Loss: 0.2239
===> Epoch[15](1100/2500): Loss: 0.2394
===> Epoch[15](1200/2500): Loss: 0.2344
===> Epoch[15](1300/2500): Loss: 0.2672
===> Epoch[15](1400/2500): Loss: 0.2266
===> Epoch[15](1500/2500): Loss: 0.2406
===> Epoch[15](1600/2500): Loss: 0.2411
===> Epoch[15](1700/2500): Loss: 0.2314
===> Epoch[15](1800/2500): Loss: 0.2366
===> Epoch[15](1900/2500): Loss: 0.2208
===> Epoch[15](2000/2500): Loss: 0.2499
===> Epoch[15](2100/2500): Loss: 0.2453
===> Epoch[15](2200/2500): Loss: 0.2607
===> Epoch[15](2300/2500): Loss: 0.2362
===> Epoch[15](2400/2500): Loss: 0.2316
===> Epoch[15](2500/2500): Loss: 0.2352
===> Epoch 15 Complete: Avg. Loss: 0.2396
===> Timestamp: [2025-08-03 16:29:23]
Checkpoint saved to TrainedNet/_epoch_15.pth
===> Loading train datasets
===> Epoch[15](100/2500): Loss: 0.2424
===> Epoch[15](200/2500): Loss: 0.2399
===> Epoch[15](300/2500): Loss: 0.2550
===> Epoch[15](400/2500): Loss: 0.2506
===> Epoch[15](500/2500): Loss: 0.2314
===> Epoch[15](600/2500): Loss: 0.2339
===> Epoch[15](700/2500): Loss: 0.2443
===> Epoch[15](800/2500): Loss: 0.2438
===> Epoch[15](900/2500): Loss: 0.2479
===> Epoch[15](1000/2500): Loss: 0.2239
===> Epoch[15](1100/2500): Loss: 0.2394
===> Epoch[15](1200/2500): Loss: 0.2344
===> Epoch[15](1300/2500): Loss: 0.2672
===> Epoch[15](1400/2500): Loss: 0.2266
===> Epoch[15](1500/2500): Loss: 0.2406
===> Epoch[15](1600/2500): Loss: 0.2411
===> Epoch[15](1700/2500): Loss: 0.2314
===> Epoch[15](1800/2500): Loss: 0.2366
===> Epoch[15](1900/2500): Loss: 0.2208
===> Epoch[15](2000/2500): Loss: 0.2499
===> Epoch[15](2100/2500): Loss: 0.2453
===> Epoch[15](2200/2500): Loss: 0.2607
===> Epoch[15](2300/2500): Loss: 0.2362
===> Epoch[15](2400/2500): Loss: 0.2316
===> Epoch[15](2500/2500): Loss: 0.2352
===> Epoch 15 Complete: Avg. Loss: 0.2396
===> Timestamp: [2025-08-03 16:29:23]
Checkpoint saved to TrainedNet/_epoch_15.pth
===> Loading train datasets
===> Epoch[15](100/2500): Loss: 0.2424
===> Epoch[15](200/2500): Loss: 0.2399
===> Epoch[15](300/2500): Loss: 0.2550
===> Epoch[15](400/2500): Loss: 0.2506
===> Epoch[15](500/2500): Loss: 0.2314
===> Epoch[15](600/2500): Loss: 0.2339
===> Epoch[15](700/2500): Loss: 0.2443
===> Epoch[15](800/2500): Loss: 0.2438
===> Epoch[15](900/2500): Loss: 0.2479
===> Epoch[15](1000/2500): Loss: 0.2239
===> Epoch[15](1100/2500): Loss: 0.2394
===> Epoch[15](1200/2500): Loss: 0.2344
===> Epoch[15](1300/2500): Loss: 0.2672
===> Epoch[15](1400/2500): Loss: 0.2266
===> Epoch[15](1500/2500): Loss: 0.2406
===> Epoch[15](1600/2500): Loss: 0.2411
===> Epoch[15](1700/2500): Loss: 0.2314
===> Epoch[15](1800/2500): Loss: 0.2366
===> Epoch[15](1900/2500): Loss: 0.2208
===> Epoch[15](2000/2500): Loss: 0.2499
===> Epoch[15](2100/2500): Loss: 0.2453
===> Epoch[15](2200/2500): Loss: 0.2607
===> Epoch[15](2300/2500): Loss: 0.2362
===> Epoch[15](2400/2500): Loss: 0.2316
===> Epoch[15](2500/2500): Loss: 0.2352
===> Epoch 15 Complete: Avg. Loss: 0.2396
===> Timestamp: [2025-08-03 16:29:23]
Checkpoint saved to TrainedNet/_epoch_15.pth
===> Loading train datasets
===> Epoch[15](100/2500): Loss: 0.2424
===> Epoch[15](200/2500): Loss: 0.2399
===> Epoch[15](300/2500): Loss: 0.2550
===> Epoch[15](400/2500): Loss: 0.2506
===> Epoch[15](500/2500): Loss: 0.2314
===> Epoch[15](600/2500): Loss: 0.2339
===> Epoch[15](700/2500): Loss: 0.2443
===> Epoch[15](800/2500): Loss: 0.2438
===> Epoch[15](900/2500): Loss: 0.2479
===> Epoch[15](1000/2500): Loss: 0.2239
===> Epoch[15](1100/2500): Loss: 0.2394
===> Epoch[15](1200/2500): Loss: 0.2344
===> Epoch[15](1300/2500): Loss: 0.2672
===> Epoch[15](1400/2500): Loss: 0.2266
===> Epoch[15](1500/2500): Loss: 0.2406
===> Epoch[15](1600/2500): Loss: 0.2411
===> Epoch[15](1700/2500): Loss: 0.2314
===> Epoch[15](1800/2500): Loss: 0.2366
===> Epoch[15](1900/2500): Loss: 0.2208
===> Epoch[15](2000/2500): Loss: 0.2499
===> Epoch[15](2100/2500): Loss: 0.2453
===> Epoch[15](2200/2500): Loss: 0.2607
===> Epoch[15](2300/2500): Loss: 0.2362
===> Epoch[15](2400/2500): Loss: 0.2316
===> Epoch[15](2500/2500): Loss: 0.2352
===> Epoch 15 Complete: Avg. Loss: 0.2396
===> Timestamp: [2025-08-03 16:29:23]
Checkpoint saved to TrainedNet/_epoch_15.pth
===> Loading train datasets
===> Epoch[15](100/2500): Loss: 0.2424
===> Epoch[15](200/2500): Loss: 0.2399
===> Epoch[15](300/2500): Loss: 0.2550
===> Epoch[15](400/2500): Loss: 0.2506
===> Epoch[15](500/2500): Loss: 0.2314
===> Epoch[15](600/2500): Loss: 0.2339
===> Epoch[15](700/2500): Loss: 0.2443
===> Epoch[15](800/2500): Loss: 0.2438
===> Epoch[15](900/2500): Loss: 0.2479
===> Epoch[15](1000/2500): Loss: 0.2239
===> Epoch[15](1100/2500): Loss: 0.2394
===> Epoch[15](1200/2500): Loss: 0.2344
===> Epoch[15](1300/2500): Loss: 0.2672
===> Epoch[15](1400/2500): Loss: 0.2266
===> Epoch[15](1500/2500): Loss: 0.2406
===> Epoch[15](1600/2500): Loss: 0.2411
===> Epoch[15](1700/2500): Loss: 0.2314
===> Epoch[15](1800/2500): Loss: 0.2366
===> Epoch[15](1900/2500): Loss: 0.2208
===> Epoch[15](2000/2500): Loss: 0.2499
===> Epoch[15](2100/2500): Loss: 0.2453
===> Epoch[15](2200/2500): Loss: 0.2607
===> Epoch[15](2300/2500): Loss: 0.2362
===> Epoch[15](2400/2500): Loss: 0.2316
===> Epoch[15](2500/2500): Loss: 0.2352
===> Epoch 15 Complete: Avg. Loss: 0.2396
===> Timestamp: [2025-08-03 16:29:23]
Checkpoint saved to TrainedNet/_epoch_15.pth
===> Loading train datasets
===> Epoch[15](100/2500): Loss: 0.2424
===> Epoch[15](200/2500): Loss: 0.2399
===> Epoch[15](300/2500): Loss: 0.2550
===> Epoch[15](400/2500): Loss: 0.2506
===> Epoch[15](500/2500): Loss: 0.2314
===> Epoch[15](600/2500): Loss: 0.2339
===> Epoch[15](700/2500): Loss: 0.2443
===> Epoch[15](800/2500): Loss: 0.2438
===> Epoch[15](900/2500): Loss: 0.2479
===> Epoch[15](1000/2500): Loss: 0.2239
===> Epoch[15](1100/2500): Loss: 0.2394
===> Epoch[15](1200/2500): Loss: 0.2344
===> Epoch[15](1300/2500): Loss: 0.2672
===> Epoch[15](1400/2500): Loss: 0.2266
===> Epoch[15](1500/2500): Loss: 0.2406
===> Epoch[15](1600/2500): Loss: 0.2411
===> Epoch[15](1700/2500): Loss: 0.2314
===> Epoch[15](1800/2500): Loss: 0.2366
===> Epoch[15](1900/2500): Loss: 0.2208
===> Epoch[15](2000/2500): Loss: 0.2499
===> Epoch[15](2100/2500): Loss: 0.2453
===> Epoch[15](2200/2500): Loss: 0.2607
===> Epoch[15](2300/2500): Loss: 0.2362
===> Epoch[15](2400/2500): Loss: 0.2316
===> Epoch[15](2500/2500): Loss: 0.2352
===> Epoch 15 Complete: Avg. Loss: 0.2396
===> Timestamp: [2025-08-03 16:29:23]
Checkpoint saved to TrainedNet/_epoch_15.pth
===> Loading train datasets
===> Epoch[15](100/2500): Loss: 0.2424
===> Epoch[15](200/2500): Loss: 0.2399
===> Epoch[15](300/2500): Loss: 0.2550
===> Epoch[15](400/2500): Loss: 0.2506
===> Epoch[15](500/2500): Loss: 0.2314
===> Epoch[15](600/2500): Loss: 0.2339
===> Epoch[15](700/2500): Loss: 0.2443
===> Epoch[15](800/2500): Loss: 0.2438
===> Epoch[15](900/2500): Loss: 0.2479
===> Epoch[15](1000/2500): Loss: 0.2239
===> Epoch[15](1100/2500): Loss: 0.2394
===> Epoch[15](1200/2500): Loss: 0.2344
===> Epoch[15](1300/2500): Loss: 0.2672
===> Epoch[15](1400/2500): Loss: 0.2266
===> Epoch[15](1500/2500): Loss: 0.2406
===> Epoch[15](1600/2500): Loss: 0.2411
===> Epoch[15](1700/2500): Loss: 0.2314
===> Epoch[15](1800/2500): Loss: 0.2366
===> Epoch[15](1900/2500): Loss: 0.2208
===> Epoch[15](2000/2500): Loss: 0.2499
===> Epoch[15](2100/2500): Loss: 0.2453
===> Epoch[15](2200/2500): Loss: 0.2607
===> Epoch[15](2300/2500): Loss: 0.2362
===> Epoch[15](2400/2500): Loss: 0.2316
===> Epoch[15](2500/2500): Loss: 0.2352
===> Epoch 15 Complete: Avg. Loss: 0.2396
===> Timestamp: [2025-08-03 16:29:23]
Checkpoint saved to TrainedNet/_epoch_15.pth
===> Loading train datasets
===> Loading train datasets
===> Epoch[16](100/2500): Loss: 0.2560
===> Epoch[16](200/2500): Loss: 0.2455
===> Epoch[16](300/2500): Loss: 0.2316
===> Epoch[16](400/2500): Loss: 0.2449
===> Epoch[16](500/2500): Loss: 0.2204
===> Epoch[16](600/2500): Loss: 0.2291
===> Epoch[16](700/2500): Loss: 0.2611
===> Epoch[16](800/2500): Loss: 0.2372
===> Epoch[16](900/2500): Loss: 0.2441
===> Epoch[16](1000/2500): Loss: 0.2177
===> Epoch[16](1100/2500): Loss: 0.2349
===> Epoch[16](1200/2500): Loss: 0.2217
===> Epoch[16](1300/2500): Loss: 0.2349
===> Epoch[16](1400/2500): Loss: 0.2490
===> Epoch[16](1500/2500): Loss: 0.2412
===> Epoch[16](1600/2500): Loss: 0.2245
===> Epoch[16](1700/2500): Loss: 0.2540
===> Epoch[16](1800/2500): Loss: 0.2245
===> Epoch[16](1900/2500): Loss: 0.2370
===> Epoch[16](2000/2500): Loss: 0.2364
===> Epoch[16](2100/2500): Loss: 0.2357
===> Epoch[16](2200/2500): Loss: 0.2259
===> Epoch[16](2300/2500): Loss: 0.2325
===> Epoch[16](2400/2500): Loss: 0.2376
===> Epoch[16](2500/2500): Loss: 0.2195
===> Epoch 16 Complete: Avg. Loss: 0.2367
===> Timestamp: [2025-08-03 16:33:57]
===> Loading train datasets
===> Epoch[16](100/2500): Loss: 0.2560
===> Epoch[16](200/2500): Loss: 0.2455
===> Epoch[16](300/2500): Loss: 0.2316
===> Epoch[16](400/2500): Loss: 0.2449
===> Epoch[16](500/2500): Loss: 0.2204
===> Epoch[16](600/2500): Loss: 0.2291
===> Epoch[16](700/2500): Loss: 0.2611
===> Epoch[16](800/2500): Loss: 0.2372
===> Epoch[16](900/2500): Loss: 0.2441
===> Epoch[16](1000/2500): Loss: 0.2177
===> Epoch[16](1100/2500): Loss: 0.2349
===> Epoch[16](1200/2500): Loss: 0.2217
===> Epoch[16](1300/2500): Loss: 0.2349
===> Epoch[16](1400/2500): Loss: 0.2490
===> Epoch[16](1500/2500): Loss: 0.2412
===> Epoch[16](1600/2500): Loss: 0.2245
===> Epoch[16](1700/2500): Loss: 0.2540
===> Epoch[16](1800/2500): Loss: 0.2245
===> Epoch[16](1900/2500): Loss: 0.2370
===> Epoch[16](2000/2500): Loss: 0.2364
===> Epoch[16](2100/2500): Loss: 0.2357
===> Epoch[16](2200/2500): Loss: 0.2259
===> Epoch[16](2300/2500): Loss: 0.2325
===> Epoch[16](2400/2500): Loss: 0.2376
===> Epoch[16](2500/2500): Loss: 0.2195
===> Epoch 16 Complete: Avg. Loss: 0.2367
===> Timestamp: [2025-08-03 16:33:57]
===> Loading train datasets
===> Epoch[16](100/2500): Loss: 0.2560
===> Epoch[16](200/2500): Loss: 0.2455
===> Epoch[16](300/2500): Loss: 0.2316
===> Epoch[16](400/2500): Loss: 0.2449
===> Epoch[16](500/2500): Loss: 0.2204
===> Epoch[16](600/2500): Loss: 0.2291
===> Epoch[16](700/2500): Loss: 0.2611
===> Epoch[16](800/2500): Loss: 0.2372
===> Epoch[16](900/2500): Loss: 0.2441
===> Epoch[16](1000/2500): Loss: 0.2177
===> Epoch[16](1100/2500): Loss: 0.2349
===> Epoch[16](1200/2500): Loss: 0.2217
===> Epoch[16](1300/2500): Loss: 0.2349
===> Epoch[16](1400/2500): Loss: 0.2490
===> Epoch[16](1500/2500): Loss: 0.2412
===> Epoch[16](1600/2500): Loss: 0.2245
===> Epoch[16](1700/2500): Loss: 0.2540
===> Epoch[16](1800/2500): Loss: 0.2245
===> Epoch[16](1900/2500): Loss: 0.2370
===> Epoch[16](2000/2500): Loss: 0.2364
===> Epoch[16](2100/2500): Loss: 0.2357
===> Epoch[16](2200/2500): Loss: 0.2259
===> Epoch[16](2300/2500): Loss: 0.2325
===> Epoch[16](2400/2500): Loss: 0.2376
===> Epoch[16](2500/2500): Loss: 0.2195
===> Epoch 16 Complete: Avg. Loss: 0.2367
===> Timestamp: [2025-08-03 16:33:57]
===> Loading train datasets
===> Epoch[16](100/2500): Loss: 0.2560
===> Epoch[16](200/2500): Loss: 0.2455
===> Epoch[16](300/2500): Loss: 0.2316
===> Epoch[16](400/2500): Loss: 0.2449
===> Epoch[16](500/2500): Loss: 0.2204
===> Epoch[16](600/2500): Loss: 0.2291
===> Epoch[16](700/2500): Loss: 0.2611
===> Epoch[16](800/2500): Loss: 0.2372
===> Epoch[16](900/2500): Loss: 0.2441
===> Epoch[16](1000/2500): Loss: 0.2177
===> Epoch[16](1100/2500): Loss: 0.2349
===> Epoch[16](1200/2500): Loss: 0.2217
===> Epoch[16](1300/2500): Loss: 0.2349
===> Epoch[16](1400/2500): Loss: 0.2490
===> Epoch[16](1500/2500): Loss: 0.2412
===> Epoch[16](1600/2500): Loss: 0.2245
===> Epoch[16](1700/2500): Loss: 0.2540
===> Epoch[16](1800/2500): Loss: 0.2245
===> Epoch[16](1900/2500): Loss: 0.2370
===> Epoch[16](2000/2500): Loss: 0.2364
===> Epoch[16](2100/2500): Loss: 0.2357
===> Epoch[16](2200/2500): Loss: 0.2259
===> Epoch[16](2300/2500): Loss: 0.2325
===> Epoch[16](2400/2500): Loss: 0.2376
===> Epoch[16](2500/2500): Loss: 0.2195
===> Epoch 16 Complete: Avg. Loss: 0.2367
===> Timestamp: [2025-08-03 16:33:57]
===> Loading train datasets
===> Epoch[16](100/2500): Loss: 0.2560
===> Epoch[16](200/2500): Loss: 0.2455
===> Epoch[16](300/2500): Loss: 0.2316
===> Epoch[16](400/2500): Loss: 0.2449
===> Epoch[16](500/2500): Loss: 0.2204
===> Epoch[16](600/2500): Loss: 0.2291
===> Epoch[16](700/2500): Loss: 0.2611
===> Epoch[16](800/2500): Loss: 0.2372
===> Epoch[16](900/2500): Loss: 0.2441
===> Epoch[16](1000/2500): Loss: 0.2177
===> Epoch[16](1100/2500): Loss: 0.2349
===> Epoch[16](1200/2500): Loss: 0.2217
===> Epoch[16](1300/2500): Loss: 0.2349
===> Epoch[16](1400/2500): Loss: 0.2490
===> Epoch[16](1500/2500): Loss: 0.2412
===> Epoch[16](1600/2500): Loss: 0.2245
===> Epoch[16](1700/2500): Loss: 0.2540
===> Epoch[16](1800/2500): Loss: 0.2245
===> Epoch[16](1900/2500): Loss: 0.2370
===> Epoch[16](2000/2500): Loss: 0.2364
===> Epoch[16](2100/2500): Loss: 0.2357
===> Epoch[16](2200/2500): Loss: 0.2259
===> Epoch[16](2300/2500): Loss: 0.2325
===> Epoch[16](2400/2500): Loss: 0.2376
===> Epoch[16](2500/2500): Loss: 0.2195
===> Epoch 16 Complete: Avg. Loss: 0.2367
===> Timestamp: [2025-08-03 16:33:57]
===> Loading train datasets
===> Epoch[16](100/2500): Loss: 0.2560
===> Epoch[16](200/2500): Loss: 0.2455
===> Epoch[16](300/2500): Loss: 0.2316
===> Epoch[16](400/2500): Loss: 0.2449
===> Epoch[16](500/2500): Loss: 0.2204
===> Epoch[16](600/2500): Loss: 0.2291
===> Epoch[16](700/2500): Loss: 0.2611
===> Epoch[16](800/2500): Loss: 0.2372
===> Epoch[16](900/2500): Loss: 0.2441
===> Epoch[16](1000/2500): Loss: 0.2177
===> Epoch[16](1100/2500): Loss: 0.2349
===> Epoch[16](1200/2500): Loss: 0.2217
===> Epoch[16](1300/2500): Loss: 0.2349
===> Epoch[16](1400/2500): Loss: 0.2490
===> Epoch[16](1500/2500): Loss: 0.2412
===> Epoch[16](1600/2500): Loss: 0.2245
===> Epoch[16](1700/2500): Loss: 0.2540
===> Epoch[16](1800/2500): Loss: 0.2245
===> Epoch[16](1900/2500): Loss: 0.2370
===> Epoch[16](2000/2500): Loss: 0.2364
===> Epoch[16](2100/2500): Loss: 0.2357
===> Epoch[16](2200/2500): Loss: 0.2259
===> Epoch[16](2300/2500): Loss: 0.2325
===> Epoch[16](2400/2500): Loss: 0.2376
===> Epoch[16](2500/2500): Loss: 0.2195
===> Epoch 16 Complete: Avg. Loss: 0.2367
===> Timestamp: [2025-08-03 16:33:57]
===> Loading train datasets
===> Epoch[16](100/2500): Loss: 0.2560
===> Epoch[16](200/2500): Loss: 0.2455
===> Epoch[16](300/2500): Loss: 0.2316
===> Epoch[16](400/2500): Loss: 0.2449
===> Epoch[16](500/2500): Loss: 0.2204
===> Epoch[16](600/2500): Loss: 0.2291
===> Epoch[16](700/2500): Loss: 0.2611
===> Epoch[16](800/2500): Loss: 0.2372
===> Epoch[16](900/2500): Loss: 0.2441
===> Epoch[16](1000/2500): Loss: 0.2177
===> Epoch[16](1100/2500): Loss: 0.2349
===> Epoch[16](1200/2500): Loss: 0.2217
===> Epoch[16](1300/2500): Loss: 0.2349
===> Epoch[16](1400/2500): Loss: 0.2490
===> Epoch[16](1500/2500): Loss: 0.2412
===> Epoch[16](1600/2500): Loss: 0.2245
===> Epoch[16](1700/2500): Loss: 0.2540
===> Epoch[16](1800/2500): Loss: 0.2245
===> Epoch[16](1900/2500): Loss: 0.2370
===> Epoch[16](2000/2500): Loss: 0.2364
===> Epoch[16](2100/2500): Loss: 0.2357
===> Epoch[16](2200/2500): Loss: 0.2259
===> Epoch[16](2300/2500): Loss: 0.2325
===> Epoch[16](2400/2500): Loss: 0.2376
===> Epoch[16](2500/2500): Loss: 0.2195
===> Epoch 16 Complete: Avg. Loss: 0.2367
===> Timestamp: [2025-08-03 16:33:57]
===> Loading train datasets
===> Epoch[16](100/2500): Loss: 0.2560
===> Epoch[16](200/2500): Loss: 0.2455
===> Epoch[16](300/2500): Loss: 0.2316
===> Epoch[16](400/2500): Loss: 0.2449
===> Epoch[16](500/2500): Loss: 0.2204
===> Epoch[16](600/2500): Loss: 0.2291
===> Epoch[16](700/2500): Loss: 0.2611
===> Epoch[16](800/2500): Loss: 0.2372
===> Epoch[16](900/2500): Loss: 0.2441
===> Epoch[16](1000/2500): Loss: 0.2177
===> Epoch[16](1100/2500): Loss: 0.2349
===> Epoch[16](1200/2500): Loss: 0.2217
===> Epoch[16](1300/2500): Loss: 0.2349
===> Epoch[16](1400/2500): Loss: 0.2490
===> Epoch[16](1500/2500): Loss: 0.2412
===> Epoch[16](1600/2500): Loss: 0.2245
===> Epoch[16](1700/2500): Loss: 0.2540
===> Epoch[16](1800/2500): Loss: 0.2245
===> Epoch[16](1900/2500): Loss: 0.2370
===> Epoch[16](2000/2500): Loss: 0.2364
===> Epoch[16](2100/2500): Loss: 0.2357
===> Epoch[16](2200/2500): Loss: 0.2259
===> Epoch[16](2300/2500): Loss: 0.2325
===> Epoch[16](2400/2500): Loss: 0.2376
===> Epoch[16](2500/2500): Loss: 0.2195
===> Epoch 16 Complete: Avg. Loss: 0.2367
===> Timestamp: [2025-08-03 16:33:57]
===> Loading train datasets
===> Epoch[16](100/2500): Loss: 0.2560
===> Epoch[16](200/2500): Loss: 0.2455
===> Epoch[16](300/2500): Loss: 0.2316
===> Epoch[16](400/2500): Loss: 0.2449
===> Epoch[16](500/2500): Loss: 0.2204
===> Epoch[16](600/2500): Loss: 0.2291
===> Epoch[16](700/2500): Loss: 0.2611
===> Epoch[16](800/2500): Loss: 0.2372
===> Epoch[16](900/2500): Loss: 0.2441
===> Epoch[16](1000/2500): Loss: 0.2177
===> Epoch[16](1100/2500): Loss: 0.2349
===> Epoch[16](1200/2500): Loss: 0.2217
===> Epoch[16](1300/2500): Loss: 0.2349
===> Epoch[16](1400/2500): Loss: 0.2490
===> Epoch[16](1500/2500): Loss: 0.2412
===> Epoch[16](1600/2500): Loss: 0.2245
===> Epoch[16](1700/2500): Loss: 0.2540
===> Epoch[16](1800/2500): Loss: 0.2245
===> Epoch[16](1900/2500): Loss: 0.2370
===> Epoch[16](2000/2500): Loss: 0.2364
===> Epoch[16](2100/2500): Loss: 0.2357
===> Epoch[16](2200/2500): Loss: 0.2259
===> Epoch[16](2300/2500): Loss: 0.2325
===> Epoch[16](2400/2500): Loss: 0.2376
===> Epoch[16](2500/2500): Loss: 0.2195
===> Epoch 16 Complete: Avg. Loss: 0.2367
===> Timestamp: [2025-08-03 16:33:57]
===> Loading train datasets
===> Epoch[16](100/2500): Loss: 0.2560
===> Epoch[16](200/2500): Loss: 0.2455
===> Epoch[16](300/2500): Loss: 0.2316
===> Epoch[16](400/2500): Loss: 0.2449
===> Epoch[16](500/2500): Loss: 0.2204
===> Epoch[16](600/2500): Loss: 0.2291
===> Epoch[16](700/2500): Loss: 0.2611
===> Epoch[16](800/2500): Loss: 0.2372
===> Epoch[16](900/2500): Loss: 0.2441
===> Epoch[16](1000/2500): Loss: 0.2177
===> Epoch[16](1100/2500): Loss: 0.2349
===> Epoch[16](1200/2500): Loss: 0.2217
===> Epoch[16](1300/2500): Loss: 0.2349
===> Epoch[16](1400/2500): Loss: 0.2490
===> Epoch[16](1500/2500): Loss: 0.2412
===> Epoch[16](1600/2500): Loss: 0.2245
===> Epoch[16](1700/2500): Loss: 0.2540
===> Epoch[16](1800/2500): Loss: 0.2245
===> Epoch[16](1900/2500): Loss: 0.2370
===> Epoch[16](2000/2500): Loss: 0.2364
===> Epoch[16](2100/2500): Loss: 0.2357
===> Epoch[16](2200/2500): Loss: 0.2259
===> Epoch[16](2300/2500): Loss: 0.2325
===> Epoch[16](2400/2500): Loss: 0.2376
===> Epoch[16](2500/2500): Loss: 0.2195
===> Epoch 16 Complete: Avg. Loss: 0.2367
===> Timestamp: [2025-08-03 16:33:57]
===> Loading train datasets
===> Epoch[16](100/2500): Loss: 0.2560
===> Epoch[16](200/2500): Loss: 0.2455
===> Epoch[16](300/2500): Loss: 0.2316
===> Epoch[16](400/2500): Loss: 0.2449
===> Epoch[16](500/2500): Loss: 0.2204
===> Epoch[16](600/2500): Loss: 0.2291
===> Epoch[16](700/2500): Loss: 0.2611
===> Epoch[16](800/2500): Loss: 0.2372
===> Epoch[16](900/2500): Loss: 0.2441
===> Epoch[16](1000/2500): Loss: 0.2177
===> Epoch[16](1100/2500): Loss: 0.2349
===> Epoch[16](1200/2500): Loss: 0.2217
===> Epoch[16](1300/2500): Loss: 0.2349
===> Epoch[16](1400/2500): Loss: 0.2490
===> Epoch[16](1500/2500): Loss: 0.2412
===> Epoch[16](1600/2500): Loss: 0.2245
===> Epoch[16](1700/2500): Loss: 0.2540
===> Epoch[16](1800/2500): Loss: 0.2245
===> Epoch[16](1900/2500): Loss: 0.2370
===> Epoch[16](2000/2500): Loss: 0.2364
===> Epoch[16](2100/2500): Loss: 0.2357
===> Epoch[16](2200/2500): Loss: 0.2259
===> Epoch[16](2300/2500): Loss: 0.2325
===> Epoch[16](2400/2500): Loss: 0.2376
===> Epoch[16](2500/2500): Loss: 0.2195
===> Epoch 16 Complete: Avg. Loss: 0.2367
===> Timestamp: [2025-08-03 16:33:57]
===> Loading train datasets
===> Epoch[16](100/2500): Loss: 0.2560
===> Epoch[16](200/2500): Loss: 0.2455
===> Epoch[16](300/2500): Loss: 0.2316
===> Epoch[16](400/2500): Loss: 0.2449
===> Epoch[16](500/2500): Loss: 0.2204
===> Epoch[16](600/2500): Loss: 0.2291
===> Epoch[16](700/2500): Loss: 0.2611
===> Epoch[16](800/2500): Loss: 0.2372
===> Epoch[16](900/2500): Loss: 0.2441
===> Epoch[16](1000/2500): Loss: 0.2177
===> Epoch[16](1100/2500): Loss: 0.2349
===> Epoch[16](1200/2500): Loss: 0.2217
===> Epoch[16](1300/2500): Loss: 0.2349
===> Epoch[16](1400/2500): Loss: 0.2490
===> Epoch[16](1500/2500): Loss: 0.2412
===> Epoch[16](1600/2500): Loss: 0.2245
===> Epoch[16](1700/2500): Loss: 0.2540
===> Epoch[16](1800/2500): Loss: 0.2245
===> Epoch[16](1900/2500): Loss: 0.2370
===> Epoch[16](2000/2500): Loss: 0.2364
===> Epoch[16](2100/2500): Loss: 0.2357
===> Epoch[16](2200/2500): Loss: 0.2259
===> Epoch[16](2300/2500): Loss: 0.2325
===> Epoch[16](2400/2500): Loss: 0.2376
===> Epoch[16](2500/2500): Loss: 0.2195
===> Epoch 16 Complete: Avg. Loss: 0.2367
===> Timestamp: [2025-08-03 16:33:57]
===> Loading train datasets
===> Epoch[16](100/2500): Loss: 0.2560
===> Epoch[16](200/2500): Loss: 0.2455
===> Epoch[16](300/2500): Loss: 0.2316
===> Epoch[16](400/2500): Loss: 0.2449
===> Epoch[16](500/2500): Loss: 0.2204
===> Epoch[16](600/2500): Loss: 0.2291
===> Epoch[16](700/2500): Loss: 0.2611
===> Epoch[16](800/2500): Loss: 0.2372
===> Epoch[16](900/2500): Loss: 0.2441
===> Epoch[16](1000/2500): Loss: 0.2177
===> Epoch[16](1100/2500): Loss: 0.2349
===> Epoch[16](1200/2500): Loss: 0.2217
===> Epoch[16](1300/2500): Loss: 0.2349
===> Epoch[16](1400/2500): Loss: 0.2490
===> Epoch[16](1500/2500): Loss: 0.2412
===> Epoch[16](1600/2500): Loss: 0.2245
===> Epoch[16](1700/2500): Loss: 0.2540
===> Epoch[16](1800/2500): Loss: 0.2245
===> Epoch[16](1900/2500): Loss: 0.2370
===> Epoch[16](2000/2500): Loss: 0.2364
===> Epoch[16](2100/2500): Loss: 0.2357
===> Epoch[16](2200/2500): Loss: 0.2259
===> Epoch[16](2300/2500): Loss: 0.2325
===> Epoch[16](2400/2500): Loss: 0.2376
===> Epoch[16](2500/2500): Loss: 0.2195
===> Epoch 16 Complete: Avg. Loss: 0.2367
===> Timestamp: [2025-08-03 16:33:57]
===> Loading train datasets
===> Epoch[16](100/2500): Loss: 0.2560
===> Epoch[16](200/2500): Loss: 0.2455
===> Epoch[16](300/2500): Loss: 0.2316
===> Epoch[16](400/2500): Loss: 0.2449
===> Epoch[16](500/2500): Loss: 0.2204
===> Epoch[16](600/2500): Loss: 0.2291
===> Epoch[16](700/2500): Loss: 0.2611
===> Epoch[16](800/2500): Loss: 0.2372
===> Epoch[16](900/2500): Loss: 0.2441
===> Epoch[16](1000/2500): Loss: 0.2177
===> Epoch[16](1100/2500): Loss: 0.2349
===> Epoch[16](1200/2500): Loss: 0.2217
===> Epoch[16](1300/2500): Loss: 0.2349
===> Epoch[16](1400/2500): Loss: 0.2490
===> Epoch[16](1500/2500): Loss: 0.2412
===> Epoch[16](1600/2500): Loss: 0.2245
===> Epoch[16](1700/2500): Loss: 0.2540
===> Epoch[16](1800/2500): Loss: 0.2245
===> Epoch[16](1900/2500): Loss: 0.2370
===> Epoch[16](2000/2500): Loss: 0.2364
===> Epoch[16](2100/2500): Loss: 0.2357
===> Epoch[16](2200/2500): Loss: 0.2259
===> Epoch[16](2300/2500): Loss: 0.2325
===> Epoch[16](2400/2500): Loss: 0.2376
===> Epoch[16](2500/2500): Loss: 0.2195
===> Epoch 16 Complete: Avg. Loss: 0.2367
===> Timestamp: [2025-08-03 16:33:57]
===> Loading train datasets
===> Epoch[16](100/2500): Loss: 0.2560
===> Epoch[16](200/2500): Loss: 0.2455
===> Epoch[16](300/2500): Loss: 0.2316
===> Epoch[16](400/2500): Loss: 0.2449
===> Epoch[16](500/2500): Loss: 0.2204
===> Epoch[16](600/2500): Loss: 0.2291
===> Epoch[16](700/2500): Loss: 0.2611
===> Epoch[16](800/2500): Loss: 0.2372
===> Epoch[16](900/2500): Loss: 0.2441
===> Epoch[16](1000/2500): Loss: 0.2177
===> Epoch[16](1100/2500): Loss: 0.2349
===> Epoch[16](1200/2500): Loss: 0.2217
===> Epoch[16](1300/2500): Loss: 0.2349
===> Epoch[16](1400/2500): Loss: 0.2490
===> Epoch[16](1500/2500): Loss: 0.2412
===> Epoch[16](1600/2500): Loss: 0.2245
===> Epoch[16](1700/2500): Loss: 0.2540
===> Epoch[16](1800/2500): Loss: 0.2245
===> Epoch[16](1900/2500): Loss: 0.2370
===> Epoch[16](2000/2500): Loss: 0.2364
===> Epoch[16](2100/2500): Loss: 0.2357
===> Epoch[16](2200/2500): Loss: 0.2259
===> Epoch[16](2300/2500): Loss: 0.2325
===> Epoch[16](2400/2500): Loss: 0.2376
===> Epoch[16](2500/2500): Loss: 0.2195
===> Epoch 16 Complete: Avg. Loss: 0.2367
===> Timestamp: [2025-08-03 16:33:57]
===> Loading train datasets
===> Epoch[16](100/2500): Loss: 0.2560
===> Epoch[16](200/2500): Loss: 0.2455
===> Epoch[16](300/2500): Loss: 0.2316
===> Epoch[16](400/2500): Loss: 0.2449
===> Epoch[16](500/2500): Loss: 0.2204
===> Epoch[16](600/2500): Loss: 0.2291
===> Epoch[16](700/2500): Loss: 0.2611
===> Epoch[16](800/2500): Loss: 0.2372
===> Epoch[16](900/2500): Loss: 0.2441
===> Epoch[16](1000/2500): Loss: 0.2177
===> Epoch[16](1100/2500): Loss: 0.2349
===> Epoch[16](1200/2500): Loss: 0.2217
===> Epoch[16](1300/2500): Loss: 0.2349
===> Epoch[16](1400/2500): Loss: 0.2490
===> Epoch[16](1500/2500): Loss: 0.2412
===> Epoch[16](1600/2500): Loss: 0.2245
===> Epoch[16](1700/2500): Loss: 0.2540
===> Epoch[16](1800/2500): Loss: 0.2245
===> Epoch[16](1900/2500): Loss: 0.2370
===> Epoch[16](2000/2500): Loss: 0.2364
===> Epoch[16](2100/2500): Loss: 0.2357
===> Epoch[16](2200/2500): Loss: 0.2259
===> Epoch[16](2300/2500): Loss: 0.2325
===> Epoch[16](2400/2500): Loss: 0.2376
===> Epoch[16](2500/2500): Loss: 0.2195
===> Epoch 16 Complete: Avg. Loss: 0.2367
===> Timestamp: [2025-08-03 16:33:57]
===> Loading train datasets
===> Loading train datasets
===> Epoch[17](100/2500): Loss: 0.2596
===> Epoch[17](200/2500): Loss: 0.2332
===> Epoch[17](300/2500): Loss: 0.2355
===> Epoch[17](400/2500): Loss: 0.2396
===> Epoch[17](500/2500): Loss: 0.2665
===> Epoch[17](600/2500): Loss: 0.2332
===> Epoch[17](700/2500): Loss: 0.2491
===> Epoch[17](800/2500): Loss: 0.2297
===> Epoch[17](900/2500): Loss: 0.2224
===> Epoch[17](1000/2500): Loss: 0.2506
===> Epoch[17](1100/2500): Loss: 0.2426
===> Epoch[17](1200/2500): Loss: 0.2322
===> Epoch[17](1300/2500): Loss: 0.2359
===> Epoch[17](1400/2500): Loss: 0.2348
===> Epoch[17](1500/2500): Loss: 0.2222
===> Epoch[17](1600/2500): Loss: 0.2318
===> Epoch[17](1700/2500): Loss: 0.2289
===> Epoch[17](1800/2500): Loss: 0.2252
===> Epoch[17](1900/2500): Loss: 0.2486
===> Epoch[17](2000/2500): Loss: 0.2452
===> Epoch[17](2100/2500): Loss: 0.2469
===> Epoch[17](2200/2500): Loss: 0.2114
===> Epoch[17](2300/2500): Loss: 0.2215
===> Epoch[17](2400/2500): Loss: 0.2392
===> Epoch[17](2500/2500): Loss: 0.2219
===> Epoch 17 Complete: Avg. Loss: 0.2347
===> Timestamp: [2025-08-03 16:38:31]
===> Loading train datasets
===> Epoch[17](100/2500): Loss: 0.2596
===> Epoch[17](200/2500): Loss: 0.2332
===> Epoch[17](300/2500): Loss: 0.2355
===> Epoch[17](400/2500): Loss: 0.2396
===> Epoch[17](500/2500): Loss: 0.2665
===> Epoch[17](600/2500): Loss: 0.2332
===> Epoch[17](700/2500): Loss: 0.2491
===> Epoch[17](800/2500): Loss: 0.2297
===> Epoch[17](900/2500): Loss: 0.2224
===> Epoch[17](1000/2500): Loss: 0.2506
===> Epoch[17](1100/2500): Loss: 0.2426
===> Epoch[17](1200/2500): Loss: 0.2322
===> Epoch[17](1300/2500): Loss: 0.2359
===> Epoch[17](1400/2500): Loss: 0.2348
===> Epoch[17](1500/2500): Loss: 0.2222
===> Epoch[17](1600/2500): Loss: 0.2318
===> Epoch[17](1700/2500): Loss: 0.2289
===> Epoch[17](1800/2500): Loss: 0.2252
===> Epoch[17](1900/2500): Loss: 0.2486
===> Epoch[17](2000/2500): Loss: 0.2452
===> Epoch[17](2100/2500): Loss: 0.2469
===> Epoch[17](2200/2500): Loss: 0.2114
===> Epoch[17](2300/2500): Loss: 0.2215
===> Epoch[17](2400/2500): Loss: 0.2392
===> Epoch[17](2500/2500): Loss: 0.2219
===> Epoch 17 Complete: Avg. Loss: 0.2347
===> Timestamp: [2025-08-03 16:38:31]
===> Loading train datasets
===> Epoch[17](100/2500): Loss: 0.2596
===> Epoch[17](200/2500): Loss: 0.2332
===> Epoch[17](300/2500): Loss: 0.2355
===> Epoch[17](400/2500): Loss: 0.2396
===> Epoch[17](500/2500): Loss: 0.2665
===> Epoch[17](600/2500): Loss: 0.2332
===> Epoch[17](700/2500): Loss: 0.2491
===> Epoch[17](800/2500): Loss: 0.2297
===> Epoch[17](900/2500): Loss: 0.2224
===> Epoch[17](1000/2500): Loss: 0.2506
===> Epoch[17](1100/2500): Loss: 0.2426
===> Epoch[17](1200/2500): Loss: 0.2322
===> Epoch[17](1300/2500): Loss: 0.2359
===> Epoch[17](1400/2500): Loss: 0.2348
===> Epoch[17](1500/2500): Loss: 0.2222
===> Epoch[17](1600/2500): Loss: 0.2318
===> Epoch[17](1700/2500): Loss: 0.2289
===> Epoch[17](1800/2500): Loss: 0.2252
===> Epoch[17](1900/2500): Loss: 0.2486
===> Epoch[17](2000/2500): Loss: 0.2452
===> Epoch[17](2100/2500): Loss: 0.2469
===> Epoch[17](2200/2500): Loss: 0.2114
===> Epoch[17](2300/2500): Loss: 0.2215
===> Epoch[17](2400/2500): Loss: 0.2392
===> Epoch[17](2500/2500): Loss: 0.2219
===> Epoch 17 Complete: Avg. Loss: 0.2347
===> Timestamp: [2025-08-03 16:38:31]
===> Loading train datasets
===> Epoch[17](100/2500): Loss: 0.2596
===> Epoch[17](200/2500): Loss: 0.2332
===> Epoch[17](300/2500): Loss: 0.2355
===> Epoch[17](400/2500): Loss: 0.2396
===> Epoch[17](500/2500): Loss: 0.2665
===> Epoch[17](600/2500): Loss: 0.2332
===> Epoch[17](700/2500): Loss: 0.2491
===> Epoch[17](800/2500): Loss: 0.2297
===> Epoch[17](900/2500): Loss: 0.2224
===> Epoch[17](1000/2500): Loss: 0.2506
===> Epoch[17](1100/2500): Loss: 0.2426
===> Epoch[17](1200/2500): Loss: 0.2322
===> Epoch[17](1300/2500): Loss: 0.2359
===> Epoch[17](1400/2500): Loss: 0.2348
===> Epoch[17](1500/2500): Loss: 0.2222
===> Epoch[17](1600/2500): Loss: 0.2318
===> Epoch[17](1700/2500): Loss: 0.2289
===> Epoch[17](1800/2500): Loss: 0.2252
===> Epoch[17](1900/2500): Loss: 0.2486
===> Epoch[17](2000/2500): Loss: 0.2452
===> Epoch[17](2100/2500): Loss: 0.2469
===> Epoch[17](2200/2500): Loss: 0.2114
===> Epoch[17](2300/2500): Loss: 0.2215
===> Epoch[17](2400/2500): Loss: 0.2392
===> Epoch[17](2500/2500): Loss: 0.2219
===> Epoch 17 Complete: Avg. Loss: 0.2347
===> Timestamp: [2025-08-03 16:38:31]
===> Loading train datasets
===> Epoch[17](100/2500): Loss: 0.2596
===> Epoch[17](200/2500): Loss: 0.2332
===> Epoch[17](300/2500): Loss: 0.2355
===> Epoch[17](400/2500): Loss: 0.2396
===> Epoch[17](500/2500): Loss: 0.2665
===> Epoch[17](600/2500): Loss: 0.2332
===> Epoch[17](700/2500): Loss: 0.2491
===> Epoch[17](800/2500): Loss: 0.2297
===> Epoch[17](900/2500): Loss: 0.2224
===> Epoch[17](1000/2500): Loss: 0.2506
===> Epoch[17](1100/2500): Loss: 0.2426
===> Epoch[17](1200/2500): Loss: 0.2322
===> Epoch[17](1300/2500): Loss: 0.2359
===> Epoch[17](1400/2500): Loss: 0.2348
===> Epoch[17](1500/2500): Loss: 0.2222
===> Epoch[17](1600/2500): Loss: 0.2318
===> Epoch[17](1700/2500): Loss: 0.2289
===> Epoch[17](1800/2500): Loss: 0.2252
===> Epoch[17](1900/2500): Loss: 0.2486
===> Epoch[17](2000/2500): Loss: 0.2452
===> Epoch[17](2100/2500): Loss: 0.2469
===> Epoch[17](2200/2500): Loss: 0.2114
===> Epoch[17](2300/2500): Loss: 0.2215
===> Epoch[17](2400/2500): Loss: 0.2392
===> Epoch[17](2500/2500): Loss: 0.2219
===> Epoch 17 Complete: Avg. Loss: 0.2347
===> Timestamp: [2025-08-03 16:38:31]
===> Loading train datasets
===> Epoch[17](100/2500): Loss: 0.2596
===> Epoch[17](200/2500): Loss: 0.2332
===> Epoch[17](300/2500): Loss: 0.2355
===> Epoch[17](400/2500): Loss: 0.2396
===> Epoch[17](500/2500): Loss: 0.2665
===> Epoch[17](600/2500): Loss: 0.2332
===> Epoch[17](700/2500): Loss: 0.2491
===> Epoch[17](800/2500): Loss: 0.2297
===> Epoch[17](900/2500): Loss: 0.2224
===> Epoch[17](1000/2500): Loss: 0.2506
===> Epoch[17](1100/2500): Loss: 0.2426
===> Epoch[17](1200/2500): Loss: 0.2322
===> Epoch[17](1300/2500): Loss: 0.2359
===> Epoch[17](1400/2500): Loss: 0.2348
===> Epoch[17](1500/2500): Loss: 0.2222
===> Epoch[17](1600/2500): Loss: 0.2318
===> Epoch[17](1700/2500): Loss: 0.2289
===> Epoch[17](1800/2500): Loss: 0.2252
===> Epoch[17](1900/2500): Loss: 0.2486
===> Epoch[17](2000/2500): Loss: 0.2452
===> Epoch[17](2100/2500): Loss: 0.2469
===> Epoch[17](2200/2500): Loss: 0.2114
===> Epoch[17](2300/2500): Loss: 0.2215
===> Epoch[17](2400/2500): Loss: 0.2392
===> Epoch[17](2500/2500): Loss: 0.2219
===> Epoch 17 Complete: Avg. Loss: 0.2347
===> Timestamp: [2025-08-03 16:38:31]
===> Loading train datasets
===> Epoch[17](100/2500): Loss: 0.2596
===> Epoch[17](200/2500): Loss: 0.2332
===> Epoch[17](300/2500): Loss: 0.2355
===> Epoch[17](400/2500): Loss: 0.2396
===> Epoch[17](500/2500): Loss: 0.2665
===> Epoch[17](600/2500): Loss: 0.2332
===> Epoch[17](700/2500): Loss: 0.2491
===> Epoch[17](800/2500): Loss: 0.2297
===> Epoch[17](900/2500): Loss: 0.2224
===> Epoch[17](1000/2500): Loss: 0.2506
===> Epoch[17](1100/2500): Loss: 0.2426
===> Epoch[17](1200/2500): Loss: 0.2322
===> Epoch[17](1300/2500): Loss: 0.2359
===> Epoch[17](1400/2500): Loss: 0.2348
===> Epoch[17](1500/2500): Loss: 0.2222
===> Epoch[17](1600/2500): Loss: 0.2318
===> Epoch[17](1700/2500): Loss: 0.2289
===> Epoch[17](1800/2500): Loss: 0.2252
===> Epoch[17](1900/2500): Loss: 0.2486
===> Epoch[17](2000/2500): Loss: 0.2452
===> Epoch[17](2100/2500): Loss: 0.2469
===> Epoch[17](2200/2500): Loss: 0.2114
===> Epoch[17](2300/2500): Loss: 0.2215
===> Epoch[17](2400/2500): Loss: 0.2392
===> Epoch[17](2500/2500): Loss: 0.2219
===> Epoch 17 Complete: Avg. Loss: 0.2347
===> Timestamp: [2025-08-03 16:38:31]
===> Loading train datasets
===> Epoch[17](100/2500): Loss: 0.2596
===> Epoch[17](200/2500): Loss: 0.2332
===> Epoch[17](300/2500): Loss: 0.2355
===> Epoch[17](400/2500): Loss: 0.2396
===> Epoch[17](500/2500): Loss: 0.2665
===> Epoch[17](600/2500): Loss: 0.2332
===> Epoch[17](700/2500): Loss: 0.2491
===> Epoch[17](800/2500): Loss: 0.2297
===> Epoch[17](900/2500): Loss: 0.2224
===> Epoch[17](1000/2500): Loss: 0.2506
===> Epoch[17](1100/2500): Loss: 0.2426
===> Epoch[17](1200/2500): Loss: 0.2322
===> Epoch[17](1300/2500): Loss: 0.2359
===> Epoch[17](1400/2500): Loss: 0.2348
===> Epoch[17](1500/2500): Loss: 0.2222
===> Epoch[17](1600/2500): Loss: 0.2318
===> Epoch[17](1700/2500): Loss: 0.2289
===> Epoch[17](1800/2500): Loss: 0.2252
===> Epoch[17](1900/2500): Loss: 0.2486
===> Epoch[17](2000/2500): Loss: 0.2452
===> Epoch[17](2100/2500): Loss: 0.2469
===> Epoch[17](2200/2500): Loss: 0.2114
===> Epoch[17](2300/2500): Loss: 0.2215
===> Epoch[17](2400/2500): Loss: 0.2392
===> Epoch[17](2500/2500): Loss: 0.2219
===> Epoch 17 Complete: Avg. Loss: 0.2347
===> Timestamp: [2025-08-03 16:38:31]
===> Loading train datasets
===> Epoch[17](100/2500): Loss: 0.2596
===> Epoch[17](200/2500): Loss: 0.2332
===> Epoch[17](300/2500): Loss: 0.2355
===> Epoch[17](400/2500): Loss: 0.2396
===> Epoch[17](500/2500): Loss: 0.2665
===> Epoch[17](600/2500): Loss: 0.2332
===> Epoch[17](700/2500): Loss: 0.2491
===> Epoch[17](800/2500): Loss: 0.2297
===> Epoch[17](900/2500): Loss: 0.2224
===> Epoch[17](1000/2500): Loss: 0.2506
===> Epoch[17](1100/2500): Loss: 0.2426
===> Epoch[17](1200/2500): Loss: 0.2322
===> Epoch[17](1300/2500): Loss: 0.2359
===> Epoch[17](1400/2500): Loss: 0.2348
===> Epoch[17](1500/2500): Loss: 0.2222
===> Epoch[17](1600/2500): Loss: 0.2318
===> Epoch[17](1700/2500): Loss: 0.2289
===> Epoch[17](1800/2500): Loss: 0.2252
===> Epoch[17](1900/2500): Loss: 0.2486
===> Epoch[17](2000/2500): Loss: 0.2452
===> Epoch[17](2100/2500): Loss: 0.2469
===> Epoch[17](2200/2500): Loss: 0.2114
===> Epoch[17](2300/2500): Loss: 0.2215
===> Epoch[17](2400/2500): Loss: 0.2392
===> Epoch[17](2500/2500): Loss: 0.2219
===> Epoch 17 Complete: Avg. Loss: 0.2347
===> Timestamp: [2025-08-03 16:38:31]
===> Loading train datasets
===> Epoch[17](100/2500): Loss: 0.2596
===> Epoch[17](200/2500): Loss: 0.2332
===> Epoch[17](300/2500): Loss: 0.2355
===> Epoch[17](400/2500): Loss: 0.2396
===> Epoch[17](500/2500): Loss: 0.2665
===> Epoch[17](600/2500): Loss: 0.2332
===> Epoch[17](700/2500): Loss: 0.2491
===> Epoch[17](800/2500): Loss: 0.2297
===> Epoch[17](900/2500): Loss: 0.2224
===> Epoch[17](1000/2500): Loss: 0.2506
===> Epoch[17](1100/2500): Loss: 0.2426
===> Epoch[17](1200/2500): Loss: 0.2322
===> Epoch[17](1300/2500): Loss: 0.2359
===> Epoch[17](1400/2500): Loss: 0.2348
===> Epoch[17](1500/2500): Loss: 0.2222
===> Epoch[17](1600/2500): Loss: 0.2318
===> Epoch[17](1700/2500): Loss: 0.2289
===> Epoch[17](1800/2500): Loss: 0.2252
===> Epoch[17](1900/2500): Loss: 0.2486
===> Epoch[17](2000/2500): Loss: 0.2452
===> Epoch[17](2100/2500): Loss: 0.2469
===> Epoch[17](2200/2500): Loss: 0.2114
===> Epoch[17](2300/2500): Loss: 0.2215
===> Epoch[17](2400/2500): Loss: 0.2392
===> Epoch[17](2500/2500): Loss: 0.2219
===> Epoch 17 Complete: Avg. Loss: 0.2347
===> Timestamp: [2025-08-03 16:38:31]
===> Loading train datasets
===> Epoch[17](100/2500): Loss: 0.2596
===> Epoch[17](200/2500): Loss: 0.2332
===> Epoch[17](300/2500): Loss: 0.2355
===> Epoch[17](400/2500): Loss: 0.2396
===> Epoch[17](500/2500): Loss: 0.2665
===> Epoch[17](600/2500): Loss: 0.2332
===> Epoch[17](700/2500): Loss: 0.2491
===> Epoch[17](800/2500): Loss: 0.2297
===> Epoch[17](900/2500): Loss: 0.2224
===> Epoch[17](1000/2500): Loss: 0.2506
===> Epoch[17](1100/2500): Loss: 0.2426
===> Epoch[17](1200/2500): Loss: 0.2322
===> Epoch[17](1300/2500): Loss: 0.2359
===> Epoch[17](1400/2500): Loss: 0.2348
===> Epoch[17](1500/2500): Loss: 0.2222
===> Epoch[17](1600/2500): Loss: 0.2318
===> Epoch[17](1700/2500): Loss: 0.2289
===> Epoch[17](1800/2500): Loss: 0.2252
===> Epoch[17](1900/2500): Loss: 0.2486
===> Epoch[17](2000/2500): Loss: 0.2452
===> Epoch[17](2100/2500): Loss: 0.2469
===> Epoch[17](2200/2500): Loss: 0.2114
===> Epoch[17](2300/2500): Loss: 0.2215
===> Epoch[17](2400/2500): Loss: 0.2392
===> Epoch[17](2500/2500): Loss: 0.2219
===> Epoch 17 Complete: Avg. Loss: 0.2347
===> Timestamp: [2025-08-03 16:38:31]
===> Loading train datasets
===> Epoch[17](100/2500): Loss: 0.2596
===> Epoch[17](200/2500): Loss: 0.2332
===> Epoch[17](300/2500): Loss: 0.2355
===> Epoch[17](400/2500): Loss: 0.2396
===> Epoch[17](500/2500): Loss: 0.2665
===> Epoch[17](600/2500): Loss: 0.2332
===> Epoch[17](700/2500): Loss: 0.2491
===> Epoch[17](800/2500): Loss: 0.2297
===> Epoch[17](900/2500): Loss: 0.2224
===> Epoch[17](1000/2500): Loss: 0.2506
===> Epoch[17](1100/2500): Loss: 0.2426
===> Epoch[17](1200/2500): Loss: 0.2322
===> Epoch[17](1300/2500): Loss: 0.2359
===> Epoch[17](1400/2500): Loss: 0.2348
===> Epoch[17](1500/2500): Loss: 0.2222
===> Epoch[17](1600/2500): Loss: 0.2318
===> Epoch[17](1700/2500): Loss: 0.2289
===> Epoch[17](1800/2500): Loss: 0.2252
===> Epoch[17](1900/2500): Loss: 0.2486
===> Epoch[17](2000/2500): Loss: 0.2452
===> Epoch[17](2100/2500): Loss: 0.2469
===> Epoch[17](2200/2500): Loss: 0.2114
===> Epoch[17](2300/2500): Loss: 0.2215
===> Epoch[17](2400/2500): Loss: 0.2392
===> Epoch[17](2500/2500): Loss: 0.2219
===> Epoch 17 Complete: Avg. Loss: 0.2347
===> Timestamp: [2025-08-03 16:38:31]
===> Loading train datasets
===> Epoch[17](100/2500): Loss: 0.2596
===> Epoch[17](200/2500): Loss: 0.2332
===> Epoch[17](300/2500): Loss: 0.2355
===> Epoch[17](400/2500): Loss: 0.2396
===> Epoch[17](500/2500): Loss: 0.2665
===> Epoch[17](600/2500): Loss: 0.2332
===> Epoch[17](700/2500): Loss: 0.2491
===> Epoch[17](800/2500): Loss: 0.2297
===> Epoch[17](900/2500): Loss: 0.2224
===> Epoch[17](1000/2500): Loss: 0.2506
===> Epoch[17](1100/2500): Loss: 0.2426
===> Epoch[17](1200/2500): Loss: 0.2322
===> Epoch[17](1300/2500): Loss: 0.2359
===> Epoch[17](1400/2500): Loss: 0.2348
===> Epoch[17](1500/2500): Loss: 0.2222
===> Epoch[17](1600/2500): Loss: 0.2318
===> Epoch[17](1700/2500): Loss: 0.2289
===> Epoch[17](1800/2500): Loss: 0.2252
===> Epoch[17](1900/2500): Loss: 0.2486
===> Epoch[17](2000/2500): Loss: 0.2452
===> Epoch[17](2100/2500): Loss: 0.2469
===> Epoch[17](2200/2500): Loss: 0.2114
===> Epoch[17](2300/2500): Loss: 0.2215
===> Epoch[17](2400/2500): Loss: 0.2392
===> Epoch[17](2500/2500): Loss: 0.2219
===> Epoch 17 Complete: Avg. Loss: 0.2347
===> Timestamp: [2025-08-03 16:38:31]
===> Loading train datasets
===> Epoch[17](100/2500): Loss: 0.2596
===> Epoch[17](200/2500): Loss: 0.2332
===> Epoch[17](300/2500): Loss: 0.2355
===> Epoch[17](400/2500): Loss: 0.2396
===> Epoch[17](500/2500): Loss: 0.2665
===> Epoch[17](600/2500): Loss: 0.2332
===> Epoch[17](700/2500): Loss: 0.2491
===> Epoch[17](800/2500): Loss: 0.2297
===> Epoch[17](900/2500): Loss: 0.2224
===> Epoch[17](1000/2500): Loss: 0.2506
===> Epoch[17](1100/2500): Loss: 0.2426
===> Epoch[17](1200/2500): Loss: 0.2322
===> Epoch[17](1300/2500): Loss: 0.2359
===> Epoch[17](1400/2500): Loss: 0.2348
===> Epoch[17](1500/2500): Loss: 0.2222
===> Epoch[17](1600/2500): Loss: 0.2318
===> Epoch[17](1700/2500): Loss: 0.2289
===> Epoch[17](1800/2500): Loss: 0.2252
===> Epoch[17](1900/2500): Loss: 0.2486
===> Epoch[17](2000/2500): Loss: 0.2452
===> Epoch[17](2100/2500): Loss: 0.2469
===> Epoch[17](2200/2500): Loss: 0.2114
===> Epoch[17](2300/2500): Loss: 0.2215
===> Epoch[17](2400/2500): Loss: 0.2392
===> Epoch[17](2500/2500): Loss: 0.2219
===> Epoch 17 Complete: Avg. Loss: 0.2347
===> Timestamp: [2025-08-03 16:38:31]
===> Loading train datasets
===> Epoch[17](100/2500): Loss: 0.2596
===> Epoch[17](200/2500): Loss: 0.2332
===> Epoch[17](300/2500): Loss: 0.2355
===> Epoch[17](400/2500): Loss: 0.2396
===> Epoch[17](500/2500): Loss: 0.2665
===> Epoch[17](600/2500): Loss: 0.2332
===> Epoch[17](700/2500): Loss: 0.2491
===> Epoch[17](800/2500): Loss: 0.2297
===> Epoch[17](900/2500): Loss: 0.2224
===> Epoch[17](1000/2500): Loss: 0.2506
===> Epoch[17](1100/2500): Loss: 0.2426
===> Epoch[17](1200/2500): Loss: 0.2322
===> Epoch[17](1300/2500): Loss: 0.2359
===> Epoch[17](1400/2500): Loss: 0.2348
===> Epoch[17](1500/2500): Loss: 0.2222
===> Epoch[17](1600/2500): Loss: 0.2318
===> Epoch[17](1700/2500): Loss: 0.2289
===> Epoch[17](1800/2500): Loss: 0.2252
===> Epoch[17](1900/2500): Loss: 0.2486
===> Epoch[17](2000/2500): Loss: 0.2452
===> Epoch[17](2100/2500): Loss: 0.2469
===> Epoch[17](2200/2500): Loss: 0.2114
===> Epoch[17](2300/2500): Loss: 0.2215
===> Epoch[17](2400/2500): Loss: 0.2392
===> Epoch[17](2500/2500): Loss: 0.2219
===> Epoch 17 Complete: Avg. Loss: 0.2347
===> Timestamp: [2025-08-03 16:38:31]
===> Loading train datasets
===> Epoch[17](100/2500): Loss: 0.2596
===> Epoch[17](200/2500): Loss: 0.2332
===> Epoch[17](300/2500): Loss: 0.2355
===> Epoch[17](400/2500): Loss: 0.2396
===> Epoch[17](500/2500): Loss: 0.2665
===> Epoch[17](600/2500): Loss: 0.2332
===> Epoch[17](700/2500): Loss: 0.2491
===> Epoch[17](800/2500): Loss: 0.2297
===> Epoch[17](900/2500): Loss: 0.2224
===> Epoch[17](1000/2500): Loss: 0.2506
===> Epoch[17](1100/2500): Loss: 0.2426
===> Epoch[17](1200/2500): Loss: 0.2322
===> Epoch[17](1300/2500): Loss: 0.2359
===> Epoch[17](1400/2500): Loss: 0.2348
===> Epoch[17](1500/2500): Loss: 0.2222
===> Epoch[17](1600/2500): Loss: 0.2318
===> Epoch[17](1700/2500): Loss: 0.2289
===> Epoch[17](1800/2500): Loss: 0.2252
===> Epoch[17](1900/2500): Loss: 0.2486
===> Epoch[17](2000/2500): Loss: 0.2452
===> Epoch[17](2100/2500): Loss: 0.2469
===> Epoch[17](2200/2500): Loss: 0.2114
===> Epoch[17](2300/2500): Loss: 0.2215
===> Epoch[17](2400/2500): Loss: 0.2392
===> Epoch[17](2500/2500): Loss: 0.2219
===> Epoch 17 Complete: Avg. Loss: 0.2347
===> Timestamp: [2025-08-03 16:38:31]
===> Loading train datasets
===> Epoch[17](100/2500): Loss: 0.2596
===> Epoch[17](200/2500): Loss: 0.2332
===> Epoch[17](300/2500): Loss: 0.2355
===> Epoch[17](400/2500): Loss: 0.2396
===> Epoch[17](500/2500): Loss: 0.2665
===> Epoch[17](600/2500): Loss: 0.2332
===> Epoch[17](700/2500): Loss: 0.2491
===> Epoch[17](800/2500): Loss: 0.2297
===> Epoch[17](900/2500): Loss: 0.2224
===> Epoch[17](1000/2500): Loss: 0.2506
===> Epoch[17](1100/2500): Loss: 0.2426
===> Epoch[17](1200/2500): Loss: 0.2322
===> Epoch[17](1300/2500): Loss: 0.2359
===> Epoch[17](1400/2500): Loss: 0.2348
===> Epoch[17](1500/2500): Loss: 0.2222
===> Epoch[17](1600/2500): Loss: 0.2318
===> Epoch[17](1700/2500): Loss: 0.2289
===> Epoch[17](1800/2500): Loss: 0.2252
===> Epoch[17](1900/2500): Loss: 0.2486
===> Epoch[17](2000/2500): Loss: 0.2452
===> Epoch[17](2100/2500): Loss: 0.2469
===> Epoch[17](2200/2500): Loss: 0.2114
===> Epoch[17](2300/2500): Loss: 0.2215
===> Epoch[17](2400/2500): Loss: 0.2392
===> Epoch[17](2500/2500): Loss: 0.2219
===> Epoch 17 Complete: Avg. Loss: 0.2347
===> Timestamp: [2025-08-03 16:38:31]
===> Loading train datasets
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2219
===> Epoch[18](200/2500): Loss: 0.2279
===> Epoch[18](300/2500): Loss: 0.2377
===> Epoch[18](400/2500): Loss: 0.2160
===> Epoch[18](500/2500): Loss: 0.2342
===> Epoch[18](600/2500): Loss: 0.2553
===> Epoch[18](700/2500): Loss: 0.2464
===> Epoch[18](800/2500): Loss: 0.2384
===> Epoch[18](900/2500): Loss: 0.2248
===> Epoch[18](1000/2500): Loss: 0.2380
===> Epoch[18](1100/2500): Loss: 0.2505
===> Epoch[18](1200/2500): Loss: 0.2110
===> Epoch[18](1300/2500): Loss: 0.2492
===> Epoch[18](1400/2500): Loss: 0.2484
===> Epoch[18](1500/2500): Loss: 0.2449
===> Epoch[18](1600/2500): Loss: 0.2240
===> Epoch[18](1700/2500): Loss: 0.2423
===> Epoch[18](1800/2500): Loss: 0.2228
===> Epoch[18](1900/2500): Loss: 0.2411
===> Epoch[18](2000/2500): Loss: 0.2546
===> Epoch[18](2100/2500): Loss: 0.2512
===> Epoch[18](2200/2500): Loss: 0.2362
===> Epoch[18](2300/2500): Loss: 0.2227
===> Epoch[18](2400/2500): Loss: 0.2283
===> Epoch[18](2500/2500): Loss: 0.2278
===> Epoch 18 Complete: Avg. Loss: 0.2343
===> Timestamp: [2025-08-03 16:43:04]
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2219
===> Epoch[18](200/2500): Loss: 0.2279
===> Epoch[18](300/2500): Loss: 0.2377
===> Epoch[18](400/2500): Loss: 0.2160
===> Epoch[18](500/2500): Loss: 0.2342
===> Epoch[18](600/2500): Loss: 0.2553
===> Epoch[18](700/2500): Loss: 0.2464
===> Epoch[18](800/2500): Loss: 0.2384
===> Epoch[18](900/2500): Loss: 0.2248
===> Epoch[18](1000/2500): Loss: 0.2380
===> Epoch[18](1100/2500): Loss: 0.2505
===> Epoch[18](1200/2500): Loss: 0.2110
===> Epoch[18](1300/2500): Loss: 0.2492
===> Epoch[18](1400/2500): Loss: 0.2484
===> Epoch[18](1500/2500): Loss: 0.2449
===> Epoch[18](1600/2500): Loss: 0.2240
===> Epoch[18](1700/2500): Loss: 0.2423
===> Epoch[18](1800/2500): Loss: 0.2228
===> Epoch[18](1900/2500): Loss: 0.2411
===> Epoch[18](2000/2500): Loss: 0.2546
===> Epoch[18](2100/2500): Loss: 0.2512
===> Epoch[18](2200/2500): Loss: 0.2362
===> Epoch[18](2300/2500): Loss: 0.2227
===> Epoch[18](2400/2500): Loss: 0.2283
===> Epoch[18](2500/2500): Loss: 0.2278
===> Epoch 18 Complete: Avg. Loss: 0.2343
===> Timestamp: [2025-08-03 16:43:04]
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2219
===> Epoch[18](200/2500): Loss: 0.2279
===> Epoch[18](300/2500): Loss: 0.2377
===> Epoch[18](400/2500): Loss: 0.2160
===> Epoch[18](500/2500): Loss: 0.2342
===> Epoch[18](600/2500): Loss: 0.2553
===> Epoch[18](700/2500): Loss: 0.2464
===> Epoch[18](800/2500): Loss: 0.2384
===> Epoch[18](900/2500): Loss: 0.2248
===> Epoch[18](1000/2500): Loss: 0.2380
===> Epoch[18](1100/2500): Loss: 0.2505
===> Epoch[18](1200/2500): Loss: 0.2110
===> Epoch[18](1300/2500): Loss: 0.2492
===> Epoch[18](1400/2500): Loss: 0.2484
===> Epoch[18](1500/2500): Loss: 0.2449
===> Epoch[18](1600/2500): Loss: 0.2240
===> Epoch[18](1700/2500): Loss: 0.2423
===> Epoch[18](1800/2500): Loss: 0.2228
===> Epoch[18](1900/2500): Loss: 0.2411
===> Epoch[18](2000/2500): Loss: 0.2546
===> Epoch[18](2100/2500): Loss: 0.2512
===> Epoch[18](2200/2500): Loss: 0.2362
===> Epoch[18](2300/2500): Loss: 0.2227
===> Epoch[18](2400/2500): Loss: 0.2283
===> Epoch[18](2500/2500): Loss: 0.2278
===> Epoch 18 Complete: Avg. Loss: 0.2343
===> Timestamp: [2025-08-03 16:43:04]
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2219
===> Epoch[18](200/2500): Loss: 0.2279
===> Epoch[18](300/2500): Loss: 0.2377
===> Epoch[18](400/2500): Loss: 0.2160
===> Epoch[18](500/2500): Loss: 0.2342
===> Epoch[18](600/2500): Loss: 0.2553
===> Epoch[18](700/2500): Loss: 0.2464
===> Epoch[18](800/2500): Loss: 0.2384
===> Epoch[18](900/2500): Loss: 0.2248
===> Epoch[18](1000/2500): Loss: 0.2380
===> Epoch[18](1100/2500): Loss: 0.2505
===> Epoch[18](1200/2500): Loss: 0.2110
===> Epoch[18](1300/2500): Loss: 0.2492
===> Epoch[18](1400/2500): Loss: 0.2484
===> Epoch[18](1500/2500): Loss: 0.2449
===> Epoch[18](1600/2500): Loss: 0.2240
===> Epoch[18](1700/2500): Loss: 0.2423
===> Epoch[18](1800/2500): Loss: 0.2228
===> Epoch[18](1900/2500): Loss: 0.2411
===> Epoch[18](2000/2500): Loss: 0.2546
===> Epoch[18](2100/2500): Loss: 0.2512
===> Epoch[18](2200/2500): Loss: 0.2362
===> Epoch[18](2300/2500): Loss: 0.2227
===> Epoch[18](2400/2500): Loss: 0.2283
===> Epoch[18](2500/2500): Loss: 0.2278
===> Epoch 18 Complete: Avg. Loss: 0.2343
===> Timestamp: [2025-08-03 16:43:04]
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2219
===> Epoch[18](200/2500): Loss: 0.2279
===> Epoch[18](300/2500): Loss: 0.2377
===> Epoch[18](400/2500): Loss: 0.2160
===> Epoch[18](500/2500): Loss: 0.2342
===> Epoch[18](600/2500): Loss: 0.2553
===> Epoch[18](700/2500): Loss: 0.2464
===> Epoch[18](800/2500): Loss: 0.2384
===> Epoch[18](900/2500): Loss: 0.2248
===> Epoch[18](1000/2500): Loss: 0.2380
===> Epoch[18](1100/2500): Loss: 0.2505
===> Epoch[18](1200/2500): Loss: 0.2110
===> Epoch[18](1300/2500): Loss: 0.2492
===> Epoch[18](1400/2500): Loss: 0.2484
===> Epoch[18](1500/2500): Loss: 0.2449
===> Epoch[18](1600/2500): Loss: 0.2240
===> Epoch[18](1700/2500): Loss: 0.2423
===> Epoch[18](1800/2500): Loss: 0.2228
===> Epoch[18](1900/2500): Loss: 0.2411
===> Epoch[18](2000/2500): Loss: 0.2546
===> Epoch[18](2100/2500): Loss: 0.2512
===> Epoch[18](2200/2500): Loss: 0.2362
===> Epoch[18](2300/2500): Loss: 0.2227
===> Epoch[18](2400/2500): Loss: 0.2283
===> Epoch[18](2500/2500): Loss: 0.2278
===> Epoch 18 Complete: Avg. Loss: 0.2343
===> Timestamp: [2025-08-03 16:43:04]
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2219
===> Epoch[18](200/2500): Loss: 0.2279
===> Epoch[18](300/2500): Loss: 0.2377
===> Epoch[18](400/2500): Loss: 0.2160
===> Epoch[18](500/2500): Loss: 0.2342
===> Epoch[18](600/2500): Loss: 0.2553
===> Epoch[18](700/2500): Loss: 0.2464
===> Epoch[18](800/2500): Loss: 0.2384
===> Epoch[18](900/2500): Loss: 0.2248
===> Epoch[18](1000/2500): Loss: 0.2380
===> Epoch[18](1100/2500): Loss: 0.2505
===> Epoch[18](1200/2500): Loss: 0.2110
===> Epoch[18](1300/2500): Loss: 0.2492
===> Epoch[18](1400/2500): Loss: 0.2484
===> Epoch[18](1500/2500): Loss: 0.2449
===> Epoch[18](1600/2500): Loss: 0.2240
===> Epoch[18](1700/2500): Loss: 0.2423
===> Epoch[18](1800/2500): Loss: 0.2228
===> Epoch[18](1900/2500): Loss: 0.2411
===> Epoch[18](2000/2500): Loss: 0.2546
===> Epoch[18](2100/2500): Loss: 0.2512
===> Epoch[18](2200/2500): Loss: 0.2362
===> Epoch[18](2300/2500): Loss: 0.2227
===> Epoch[18](2400/2500): Loss: 0.2283
===> Epoch[18](2500/2500): Loss: 0.2278
===> Epoch 18 Complete: Avg. Loss: 0.2343
===> Timestamp: [2025-08-03 16:43:04]
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2219
===> Epoch[18](200/2500): Loss: 0.2279
===> Epoch[18](300/2500): Loss: 0.2377
===> Epoch[18](400/2500): Loss: 0.2160
===> Epoch[18](500/2500): Loss: 0.2342
===> Epoch[18](600/2500): Loss: 0.2553
===> Epoch[18](700/2500): Loss: 0.2464
===> Epoch[18](800/2500): Loss: 0.2384
===> Epoch[18](900/2500): Loss: 0.2248
===> Epoch[18](1000/2500): Loss: 0.2380
===> Epoch[18](1100/2500): Loss: 0.2505
===> Epoch[18](1200/2500): Loss: 0.2110
===> Epoch[18](1300/2500): Loss: 0.2492
===> Epoch[18](1400/2500): Loss: 0.2484
===> Epoch[18](1500/2500): Loss: 0.2449
===> Epoch[18](1600/2500): Loss: 0.2240
===> Epoch[18](1700/2500): Loss: 0.2423
===> Epoch[18](1800/2500): Loss: 0.2228
===> Epoch[18](1900/2500): Loss: 0.2411
===> Epoch[18](2000/2500): Loss: 0.2546
===> Epoch[18](2100/2500): Loss: 0.2512
===> Epoch[18](2200/2500): Loss: 0.2362
===> Epoch[18](2300/2500): Loss: 0.2227
===> Epoch[18](2400/2500): Loss: 0.2283
===> Epoch[18](2500/2500): Loss: 0.2278
===> Epoch 18 Complete: Avg. Loss: 0.2343
===> Timestamp: [2025-08-03 16:43:04]
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2219
===> Epoch[18](200/2500): Loss: 0.2279
===> Epoch[18](300/2500): Loss: 0.2377
===> Epoch[18](400/2500): Loss: 0.2160
===> Epoch[18](500/2500): Loss: 0.2342
===> Epoch[18](600/2500): Loss: 0.2553
===> Epoch[18](700/2500): Loss: 0.2464
===> Epoch[18](800/2500): Loss: 0.2384
===> Epoch[18](900/2500): Loss: 0.2248
===> Epoch[18](1000/2500): Loss: 0.2380
===> Epoch[18](1100/2500): Loss: 0.2505
===> Epoch[18](1200/2500): Loss: 0.2110
===> Epoch[18](1300/2500): Loss: 0.2492
===> Epoch[18](1400/2500): Loss: 0.2484
===> Epoch[18](1500/2500): Loss: 0.2449
===> Epoch[18](1600/2500): Loss: 0.2240
===> Epoch[18](1700/2500): Loss: 0.2423
===> Epoch[18](1800/2500): Loss: 0.2228
===> Epoch[18](1900/2500): Loss: 0.2411
===> Epoch[18](2000/2500): Loss: 0.2546
===> Epoch[18](2100/2500): Loss: 0.2512
===> Epoch[18](2200/2500): Loss: 0.2362
===> Epoch[18](2300/2500): Loss: 0.2227
===> Epoch[18](2400/2500): Loss: 0.2283
===> Epoch[18](2500/2500): Loss: 0.2278
===> Epoch 18 Complete: Avg. Loss: 0.2343
===> Timestamp: [2025-08-03 16:43:04]
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2219
===> Epoch[18](200/2500): Loss: 0.2279
===> Epoch[18](300/2500): Loss: 0.2377
===> Epoch[18](400/2500): Loss: 0.2160
===> Epoch[18](500/2500): Loss: 0.2342
===> Epoch[18](600/2500): Loss: 0.2553
===> Epoch[18](700/2500): Loss: 0.2464
===> Epoch[18](800/2500): Loss: 0.2384
===> Epoch[18](900/2500): Loss: 0.2248
===> Epoch[18](1000/2500): Loss: 0.2380
===> Epoch[18](1100/2500): Loss: 0.2505
===> Epoch[18](1200/2500): Loss: 0.2110
===> Epoch[18](1300/2500): Loss: 0.2492
===> Epoch[18](1400/2500): Loss: 0.2484
===> Epoch[18](1500/2500): Loss: 0.2449
===> Epoch[18](1600/2500): Loss: 0.2240
===> Epoch[18](1700/2500): Loss: 0.2423
===> Epoch[18](1800/2500): Loss: 0.2228
===> Epoch[18](1900/2500): Loss: 0.2411
===> Epoch[18](2000/2500): Loss: 0.2546
===> Epoch[18](2100/2500): Loss: 0.2512
===> Epoch[18](2200/2500): Loss: 0.2362
===> Epoch[18](2300/2500): Loss: 0.2227
===> Epoch[18](2400/2500): Loss: 0.2283
===> Epoch[18](2500/2500): Loss: 0.2278
===> Epoch 18 Complete: Avg. Loss: 0.2343
===> Timestamp: [2025-08-03 16:43:04]
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2219
===> Epoch[18](200/2500): Loss: 0.2279
===> Epoch[18](300/2500): Loss: 0.2377
===> Epoch[18](400/2500): Loss: 0.2160
===> Epoch[18](500/2500): Loss: 0.2342
===> Epoch[18](600/2500): Loss: 0.2553
===> Epoch[18](700/2500): Loss: 0.2464
===> Epoch[18](800/2500): Loss: 0.2384
===> Epoch[18](900/2500): Loss: 0.2248
===> Epoch[18](1000/2500): Loss: 0.2380
===> Epoch[18](1100/2500): Loss: 0.2505
===> Epoch[18](1200/2500): Loss: 0.2110
===> Epoch[18](1300/2500): Loss: 0.2492
===> Epoch[18](1400/2500): Loss: 0.2484
===> Epoch[18](1500/2500): Loss: 0.2449
===> Epoch[18](1600/2500): Loss: 0.2240
===> Epoch[18](1700/2500): Loss: 0.2423
===> Epoch[18](1800/2500): Loss: 0.2228
===> Epoch[18](1900/2500): Loss: 0.2411
===> Epoch[18](2000/2500): Loss: 0.2546
===> Epoch[18](2100/2500): Loss: 0.2512
===> Epoch[18](2200/2500): Loss: 0.2362
===> Epoch[18](2300/2500): Loss: 0.2227
===> Epoch[18](2400/2500): Loss: 0.2283
===> Epoch[18](2500/2500): Loss: 0.2278
===> Epoch 18 Complete: Avg. Loss: 0.2343
===> Timestamp: [2025-08-03 16:43:04]
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2219
===> Epoch[18](200/2500): Loss: 0.2279
===> Epoch[18](300/2500): Loss: 0.2377
===> Epoch[18](400/2500): Loss: 0.2160
===> Epoch[18](500/2500): Loss: 0.2342
===> Epoch[18](600/2500): Loss: 0.2553
===> Epoch[18](700/2500): Loss: 0.2464
===> Epoch[18](800/2500): Loss: 0.2384
===> Epoch[18](900/2500): Loss: 0.2248
===> Epoch[18](1000/2500): Loss: 0.2380
===> Epoch[18](1100/2500): Loss: 0.2505
===> Epoch[18](1200/2500): Loss: 0.2110
===> Epoch[18](1300/2500): Loss: 0.2492
===> Epoch[18](1400/2500): Loss: 0.2484
===> Epoch[18](1500/2500): Loss: 0.2449
===> Epoch[18](1600/2500): Loss: 0.2240
===> Epoch[18](1700/2500): Loss: 0.2423
===> Epoch[18](1800/2500): Loss: 0.2228
===> Epoch[18](1900/2500): Loss: 0.2411
===> Epoch[18](2000/2500): Loss: 0.2546
===> Epoch[18](2100/2500): Loss: 0.2512
===> Epoch[18](2200/2500): Loss: 0.2362
===> Epoch[18](2300/2500): Loss: 0.2227
===> Epoch[18](2400/2500): Loss: 0.2283
===> Epoch[18](2500/2500): Loss: 0.2278
===> Epoch 18 Complete: Avg. Loss: 0.2343
===> Timestamp: [2025-08-03 16:43:04]
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2219
===> Epoch[18](200/2500): Loss: 0.2279
===> Epoch[18](300/2500): Loss: 0.2377
===> Epoch[18](400/2500): Loss: 0.2160
===> Epoch[18](500/2500): Loss: 0.2342
===> Epoch[18](600/2500): Loss: 0.2553
===> Epoch[18](700/2500): Loss: 0.2464
===> Epoch[18](800/2500): Loss: 0.2384
===> Epoch[18](900/2500): Loss: 0.2248
===> Epoch[18](1000/2500): Loss: 0.2380
===> Epoch[18](1100/2500): Loss: 0.2505
===> Epoch[18](1200/2500): Loss: 0.2110
===> Epoch[18](1300/2500): Loss: 0.2492
===> Epoch[18](1400/2500): Loss: 0.2484
===> Epoch[18](1500/2500): Loss: 0.2449
===> Epoch[18](1600/2500): Loss: 0.2240
===> Epoch[18](1700/2500): Loss: 0.2423
===> Epoch[18](1800/2500): Loss: 0.2228
===> Epoch[18](1900/2500): Loss: 0.2411
===> Epoch[18](2000/2500): Loss: 0.2546
===> Epoch[18](2100/2500): Loss: 0.2512
===> Epoch[18](2200/2500): Loss: 0.2362
===> Epoch[18](2300/2500): Loss: 0.2227
===> Epoch[18](2400/2500): Loss: 0.2283
===> Epoch[18](2500/2500): Loss: 0.2278
===> Epoch 18 Complete: Avg. Loss: 0.2343
===> Timestamp: [2025-08-03 16:43:04]
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2219
===> Epoch[18](200/2500): Loss: 0.2279
===> Epoch[18](300/2500): Loss: 0.2377
===> Epoch[18](400/2500): Loss: 0.2160
===> Epoch[18](500/2500): Loss: 0.2342
===> Epoch[18](600/2500): Loss: 0.2553
===> Epoch[18](700/2500): Loss: 0.2464
===> Epoch[18](800/2500): Loss: 0.2384
===> Epoch[18](900/2500): Loss: 0.2248
===> Epoch[18](1000/2500): Loss: 0.2380
===> Epoch[18](1100/2500): Loss: 0.2505
===> Epoch[18](1200/2500): Loss: 0.2110
===> Epoch[18](1300/2500): Loss: 0.2492
===> Epoch[18](1400/2500): Loss: 0.2484
===> Epoch[18](1500/2500): Loss: 0.2449
===> Epoch[18](1600/2500): Loss: 0.2240
===> Epoch[18](1700/2500): Loss: 0.2423
===> Epoch[18](1800/2500): Loss: 0.2228
===> Epoch[18](1900/2500): Loss: 0.2411
===> Epoch[18](2000/2500): Loss: 0.2546
===> Epoch[18](2100/2500): Loss: 0.2512
===> Epoch[18](2200/2500): Loss: 0.2362
===> Epoch[18](2300/2500): Loss: 0.2227
===> Epoch[18](2400/2500): Loss: 0.2283
===> Epoch[18](2500/2500): Loss: 0.2278
===> Epoch 18 Complete: Avg. Loss: 0.2343
===> Timestamp: [2025-08-03 16:43:04]
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2219
===> Epoch[18](200/2500): Loss: 0.2279
===> Epoch[18](300/2500): Loss: 0.2377
===> Epoch[18](400/2500): Loss: 0.2160
===> Epoch[18](500/2500): Loss: 0.2342
===> Epoch[18](600/2500): Loss: 0.2553
===> Epoch[18](700/2500): Loss: 0.2464
===> Epoch[18](800/2500): Loss: 0.2384
===> Epoch[18](900/2500): Loss: 0.2248
===> Epoch[18](1000/2500): Loss: 0.2380
===> Epoch[18](1100/2500): Loss: 0.2505
===> Epoch[18](1200/2500): Loss: 0.2110
===> Epoch[18](1300/2500): Loss: 0.2492
===> Epoch[18](1400/2500): Loss: 0.2484
===> Epoch[18](1500/2500): Loss: 0.2449
===> Epoch[18](1600/2500): Loss: 0.2240
===> Epoch[18](1700/2500): Loss: 0.2423
===> Epoch[18](1800/2500): Loss: 0.2228
===> Epoch[18](1900/2500): Loss: 0.2411
===> Epoch[18](2000/2500): Loss: 0.2546
===> Epoch[18](2100/2500): Loss: 0.2512
===> Epoch[18](2200/2500): Loss: 0.2362
===> Epoch[18](2300/2500): Loss: 0.2227
===> Epoch[18](2400/2500): Loss: 0.2283
===> Epoch[18](2500/2500): Loss: 0.2278
===> Epoch 18 Complete: Avg. Loss: 0.2343
===> Timestamp: [2025-08-03 16:43:04]
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2219
===> Epoch[18](200/2500): Loss: 0.2279
===> Epoch[18](300/2500): Loss: 0.2377
===> Epoch[18](400/2500): Loss: 0.2160
===> Epoch[18](500/2500): Loss: 0.2342
===> Epoch[18](600/2500): Loss: 0.2553
===> Epoch[18](700/2500): Loss: 0.2464
===> Epoch[18](800/2500): Loss: 0.2384
===> Epoch[18](900/2500): Loss: 0.2248
===> Epoch[18](1000/2500): Loss: 0.2380
===> Epoch[18](1100/2500): Loss: 0.2505
===> Epoch[18](1200/2500): Loss: 0.2110
===> Epoch[18](1300/2500): Loss: 0.2492
===> Epoch[18](1400/2500): Loss: 0.2484
===> Epoch[18](1500/2500): Loss: 0.2449
===> Epoch[18](1600/2500): Loss: 0.2240
===> Epoch[18](1700/2500): Loss: 0.2423
===> Epoch[18](1800/2500): Loss: 0.2228
===> Epoch[18](1900/2500): Loss: 0.2411
===> Epoch[18](2000/2500): Loss: 0.2546
===> Epoch[18](2100/2500): Loss: 0.2512
===> Epoch[18](2200/2500): Loss: 0.2362
===> Epoch[18](2300/2500): Loss: 0.2227
===> Epoch[18](2400/2500): Loss: 0.2283
===> Epoch[18](2500/2500): Loss: 0.2278
===> Epoch 18 Complete: Avg. Loss: 0.2343
===> Timestamp: [2025-08-03 16:43:04]
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2219
===> Epoch[18](200/2500): Loss: 0.2279
===> Epoch[18](300/2500): Loss: 0.2377
===> Epoch[18](400/2500): Loss: 0.2160
===> Epoch[18](500/2500): Loss: 0.2342
===> Epoch[18](600/2500): Loss: 0.2553
===> Epoch[18](700/2500): Loss: 0.2464
===> Epoch[18](800/2500): Loss: 0.2384
===> Epoch[18](900/2500): Loss: 0.2248
===> Epoch[18](1000/2500): Loss: 0.2380
===> Epoch[18](1100/2500): Loss: 0.2505
===> Epoch[18](1200/2500): Loss: 0.2110
===> Epoch[18](1300/2500): Loss: 0.2492
===> Epoch[18](1400/2500): Loss: 0.2484
===> Epoch[18](1500/2500): Loss: 0.2449
===> Epoch[18](1600/2500): Loss: 0.2240
===> Epoch[18](1700/2500): Loss: 0.2423
===> Epoch[18](1800/2500): Loss: 0.2228
===> Epoch[18](1900/2500): Loss: 0.2411
===> Epoch[18](2000/2500): Loss: 0.2546
===> Epoch[18](2100/2500): Loss: 0.2512
===> Epoch[18](2200/2500): Loss: 0.2362
===> Epoch[18](2300/2500): Loss: 0.2227
===> Epoch[18](2400/2500): Loss: 0.2283
===> Epoch[18](2500/2500): Loss: 0.2278
===> Epoch 18 Complete: Avg. Loss: 0.2343
===> Timestamp: [2025-08-03 16:43:04]
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2219
===> Epoch[18](200/2500): Loss: 0.2279
===> Epoch[18](300/2500): Loss: 0.2377
===> Epoch[18](400/2500): Loss: 0.2160
===> Epoch[18](500/2500): Loss: 0.2342
===> Epoch[18](600/2500): Loss: 0.2553
===> Epoch[18](700/2500): Loss: 0.2464
===> Epoch[18](800/2500): Loss: 0.2384
===> Epoch[18](900/2500): Loss: 0.2248
===> Epoch[18](1000/2500): Loss: 0.2380
===> Epoch[18](1100/2500): Loss: 0.2505
===> Epoch[18](1200/2500): Loss: 0.2110
===> Epoch[18](1300/2500): Loss: 0.2492
===> Epoch[18](1400/2500): Loss: 0.2484
===> Epoch[18](1500/2500): Loss: 0.2449
===> Epoch[18](1600/2500): Loss: 0.2240
===> Epoch[18](1700/2500): Loss: 0.2423
===> Epoch[18](1800/2500): Loss: 0.2228
===> Epoch[18](1900/2500): Loss: 0.2411
===> Epoch[18](2000/2500): Loss: 0.2546
===> Epoch[18](2100/2500): Loss: 0.2512
===> Epoch[18](2200/2500): Loss: 0.2362
===> Epoch[18](2300/2500): Loss: 0.2227
===> Epoch[18](2400/2500): Loss: 0.2283
===> Epoch[18](2500/2500): Loss: 0.2278
===> Epoch 18 Complete: Avg. Loss: 0.2343
===> Timestamp: [2025-08-03 16:43:04]
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2219
===> Epoch[18](200/2500): Loss: 0.2279
===> Epoch[18](300/2500): Loss: 0.2377
===> Epoch[18](400/2500): Loss: 0.2160
===> Epoch[18](500/2500): Loss: 0.2342
===> Epoch[18](600/2500): Loss: 0.2553
===> Epoch[18](700/2500): Loss: 0.2464
===> Epoch[18](800/2500): Loss: 0.2384
===> Epoch[18](900/2500): Loss: 0.2248
===> Epoch[18](1000/2500): Loss: 0.2380
===> Epoch[18](1100/2500): Loss: 0.2505
===> Epoch[18](1200/2500): Loss: 0.2110
===> Epoch[18](1300/2500): Loss: 0.2492
===> Epoch[18](1400/2500): Loss: 0.2484
===> Epoch[18](1500/2500): Loss: 0.2449
===> Epoch[18](1600/2500): Loss: 0.2240
===> Epoch[18](1700/2500): Loss: 0.2423
===> Epoch[18](1800/2500): Loss: 0.2228
===> Epoch[18](1900/2500): Loss: 0.2411
===> Epoch[18](2000/2500): Loss: 0.2546
===> Epoch[18](2100/2500): Loss: 0.2512
===> Epoch[18](2200/2500): Loss: 0.2362
===> Epoch[18](2300/2500): Loss: 0.2227
===> Epoch[18](2400/2500): Loss: 0.2283
===> Epoch[18](2500/2500): Loss: 0.2278
===> Epoch 18 Complete: Avg. Loss: 0.2343
===> Timestamp: [2025-08-03 16:43:04]
===> Loading train datasets
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.2378
===> Epoch[19](200/2500): Loss: 0.2641
===> Epoch[19](300/2500): Loss: 0.2158
===> Epoch[19](400/2500): Loss: 0.2360
===> Epoch[19](500/2500): Loss: 0.2478
===> Epoch[19](600/2500): Loss: 0.2306
===> Epoch[19](700/2500): Loss: 0.2216
===> Epoch[19](800/2500): Loss: 0.2481
===> Epoch[19](900/2500): Loss: 0.2415
===> Epoch[19](1000/2500): Loss: 0.2441
===> Epoch[19](1100/2500): Loss: 0.2147
===> Epoch[19](1200/2500): Loss: 0.2469
===> Epoch[19](1300/2500): Loss: 0.2245
===> Epoch[19](1400/2500): Loss: 0.2505
===> Epoch[19](1500/2500): Loss: 0.2347
===> Epoch[19](1600/2500): Loss: 0.2336
===> Epoch[19](1700/2500): Loss: 0.2536
===> Epoch[19](1800/2500): Loss: 0.2206
===> Epoch[19](1900/2500): Loss: 0.2332
===> Epoch[19](2000/2500): Loss: 0.2398
===> Epoch[19](2100/2500): Loss: 0.2339
===> Epoch[19](2200/2500): Loss: 0.2672
===> Epoch[19](2300/2500): Loss: 0.2242
===> Epoch[19](2400/2500): Loss: 0.2436
===> Epoch[19](2500/2500): Loss: 0.2337
===> Epoch 19 Complete: Avg. Loss: 0.2331
===> Timestamp: [2025-08-03 16:47:38]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.2378
===> Epoch[19](200/2500): Loss: 0.2641
===> Epoch[19](300/2500): Loss: 0.2158
===> Epoch[19](400/2500): Loss: 0.2360
===> Epoch[19](500/2500): Loss: 0.2478
===> Epoch[19](600/2500): Loss: 0.2306
===> Epoch[19](700/2500): Loss: 0.2216
===> Epoch[19](800/2500): Loss: 0.2481
===> Epoch[19](900/2500): Loss: 0.2415
===> Epoch[19](1000/2500): Loss: 0.2441
===> Epoch[19](1100/2500): Loss: 0.2147
===> Epoch[19](1200/2500): Loss: 0.2469
===> Epoch[19](1300/2500): Loss: 0.2245
===> Epoch[19](1400/2500): Loss: 0.2505
===> Epoch[19](1500/2500): Loss: 0.2347
===> Epoch[19](1600/2500): Loss: 0.2336
===> Epoch[19](1700/2500): Loss: 0.2536
===> Epoch[19](1800/2500): Loss: 0.2206
===> Epoch[19](1900/2500): Loss: 0.2332
===> Epoch[19](2000/2500): Loss: 0.2398
===> Epoch[19](2100/2500): Loss: 0.2339
===> Epoch[19](2200/2500): Loss: 0.2672
===> Epoch[19](2300/2500): Loss: 0.2242
===> Epoch[19](2400/2500): Loss: 0.2436
===> Epoch[19](2500/2500): Loss: 0.2337
===> Epoch 19 Complete: Avg. Loss: 0.2331
===> Timestamp: [2025-08-03 16:47:38]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.2378
===> Epoch[19](200/2500): Loss: 0.2641
===> Epoch[19](300/2500): Loss: 0.2158
===> Epoch[19](400/2500): Loss: 0.2360
===> Epoch[19](500/2500): Loss: 0.2478
===> Epoch[19](600/2500): Loss: 0.2306
===> Epoch[19](700/2500): Loss: 0.2216
===> Epoch[19](800/2500): Loss: 0.2481
===> Epoch[19](900/2500): Loss: 0.2415
===> Epoch[19](1000/2500): Loss: 0.2441
===> Epoch[19](1100/2500): Loss: 0.2147
===> Epoch[19](1200/2500): Loss: 0.2469
===> Epoch[19](1300/2500): Loss: 0.2245
===> Epoch[19](1400/2500): Loss: 0.2505
===> Epoch[19](1500/2500): Loss: 0.2347
===> Epoch[19](1600/2500): Loss: 0.2336
===> Epoch[19](1700/2500): Loss: 0.2536
===> Epoch[19](1800/2500): Loss: 0.2206
===> Epoch[19](1900/2500): Loss: 0.2332
===> Epoch[19](2000/2500): Loss: 0.2398
===> Epoch[19](2100/2500): Loss: 0.2339
===> Epoch[19](2200/2500): Loss: 0.2672
===> Epoch[19](2300/2500): Loss: 0.2242
===> Epoch[19](2400/2500): Loss: 0.2436
===> Epoch[19](2500/2500): Loss: 0.2337
===> Epoch 19 Complete: Avg. Loss: 0.2331
===> Timestamp: [2025-08-03 16:47:38]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.2378
===> Epoch[19](200/2500): Loss: 0.2641
===> Epoch[19](300/2500): Loss: 0.2158
===> Epoch[19](400/2500): Loss: 0.2360
===> Epoch[19](500/2500): Loss: 0.2478
===> Epoch[19](600/2500): Loss: 0.2306
===> Epoch[19](700/2500): Loss: 0.2216
===> Epoch[19](800/2500): Loss: 0.2481
===> Epoch[19](900/2500): Loss: 0.2415
===> Epoch[19](1000/2500): Loss: 0.2441
===> Epoch[19](1100/2500): Loss: 0.2147
===> Epoch[19](1200/2500): Loss: 0.2469
===> Epoch[19](1300/2500): Loss: 0.2245
===> Epoch[19](1400/2500): Loss: 0.2505
===> Epoch[19](1500/2500): Loss: 0.2347
===> Epoch[19](1600/2500): Loss: 0.2336
===> Epoch[19](1700/2500): Loss: 0.2536
===> Epoch[19](1800/2500): Loss: 0.2206
===> Epoch[19](1900/2500): Loss: 0.2332
===> Epoch[19](2000/2500): Loss: 0.2398
===> Epoch[19](2100/2500): Loss: 0.2339
===> Epoch[19](2200/2500): Loss: 0.2672
===> Epoch[19](2300/2500): Loss: 0.2242
===> Epoch[19](2400/2500): Loss: 0.2436
===> Epoch[19](2500/2500): Loss: 0.2337
===> Epoch 19 Complete: Avg. Loss: 0.2331
===> Timestamp: [2025-08-03 16:47:38]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.2378
===> Epoch[19](200/2500): Loss: 0.2641
===> Epoch[19](300/2500): Loss: 0.2158
===> Epoch[19](400/2500): Loss: 0.2360
===> Epoch[19](500/2500): Loss: 0.2478
===> Epoch[19](600/2500): Loss: 0.2306
===> Epoch[19](700/2500): Loss: 0.2216
===> Epoch[19](800/2500): Loss: 0.2481
===> Epoch[19](900/2500): Loss: 0.2415
===> Epoch[19](1000/2500): Loss: 0.2441
===> Epoch[19](1100/2500): Loss: 0.2147
===> Epoch[19](1200/2500): Loss: 0.2469
===> Epoch[19](1300/2500): Loss: 0.2245
===> Epoch[19](1400/2500): Loss: 0.2505
===> Epoch[19](1500/2500): Loss: 0.2347
===> Epoch[19](1600/2500): Loss: 0.2336
===> Epoch[19](1700/2500): Loss: 0.2536
===> Epoch[19](1800/2500): Loss: 0.2206
===> Epoch[19](1900/2500): Loss: 0.2332
===> Epoch[19](2000/2500): Loss: 0.2398
===> Epoch[19](2100/2500): Loss: 0.2339
===> Epoch[19](2200/2500): Loss: 0.2672
===> Epoch[19](2300/2500): Loss: 0.2242
===> Epoch[19](2400/2500): Loss: 0.2436
===> Epoch[19](2500/2500): Loss: 0.2337
===> Epoch 19 Complete: Avg. Loss: 0.2331
===> Timestamp: [2025-08-03 16:47:38]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.2378
===> Epoch[19](200/2500): Loss: 0.2641
===> Epoch[19](300/2500): Loss: 0.2158
===> Epoch[19](400/2500): Loss: 0.2360
===> Epoch[19](500/2500): Loss: 0.2478
===> Epoch[19](600/2500): Loss: 0.2306
===> Epoch[19](700/2500): Loss: 0.2216
===> Epoch[19](800/2500): Loss: 0.2481
===> Epoch[19](900/2500): Loss: 0.2415
===> Epoch[19](1000/2500): Loss: 0.2441
===> Epoch[19](1100/2500): Loss: 0.2147
===> Epoch[19](1200/2500): Loss: 0.2469
===> Epoch[19](1300/2500): Loss: 0.2245
===> Epoch[19](1400/2500): Loss: 0.2505
===> Epoch[19](1500/2500): Loss: 0.2347
===> Epoch[19](1600/2500): Loss: 0.2336
===> Epoch[19](1700/2500): Loss: 0.2536
===> Epoch[19](1800/2500): Loss: 0.2206
===> Epoch[19](1900/2500): Loss: 0.2332
===> Epoch[19](2000/2500): Loss: 0.2398
===> Epoch[19](2100/2500): Loss: 0.2339
===> Epoch[19](2200/2500): Loss: 0.2672
===> Epoch[19](2300/2500): Loss: 0.2242
===> Epoch[19](2400/2500): Loss: 0.2436
===> Epoch[19](2500/2500): Loss: 0.2337
===> Epoch 19 Complete: Avg. Loss: 0.2331
===> Timestamp: [2025-08-03 16:47:38]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.2378
===> Epoch[19](200/2500): Loss: 0.2641
===> Epoch[19](300/2500): Loss: 0.2158
===> Epoch[19](400/2500): Loss: 0.2360
===> Epoch[19](500/2500): Loss: 0.2478
===> Epoch[19](600/2500): Loss: 0.2306
===> Epoch[19](700/2500): Loss: 0.2216
===> Epoch[19](800/2500): Loss: 0.2481
===> Epoch[19](900/2500): Loss: 0.2415
===> Epoch[19](1000/2500): Loss: 0.2441
===> Epoch[19](1100/2500): Loss: 0.2147
===> Epoch[19](1200/2500): Loss: 0.2469
===> Epoch[19](1300/2500): Loss: 0.2245
===> Epoch[19](1400/2500): Loss: 0.2505
===> Epoch[19](1500/2500): Loss: 0.2347
===> Epoch[19](1600/2500): Loss: 0.2336
===> Epoch[19](1700/2500): Loss: 0.2536
===> Epoch[19](1800/2500): Loss: 0.2206
===> Epoch[19](1900/2500): Loss: 0.2332
===> Epoch[19](2000/2500): Loss: 0.2398
===> Epoch[19](2100/2500): Loss: 0.2339
===> Epoch[19](2200/2500): Loss: 0.2672
===> Epoch[19](2300/2500): Loss: 0.2242
===> Epoch[19](2400/2500): Loss: 0.2436
===> Epoch[19](2500/2500): Loss: 0.2337
===> Epoch 19 Complete: Avg. Loss: 0.2331
===> Timestamp: [2025-08-03 16:47:38]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.2378
===> Epoch[19](200/2500): Loss: 0.2641
===> Epoch[19](300/2500): Loss: 0.2158
===> Epoch[19](400/2500): Loss: 0.2360
===> Epoch[19](500/2500): Loss: 0.2478
===> Epoch[19](600/2500): Loss: 0.2306
===> Epoch[19](700/2500): Loss: 0.2216
===> Epoch[19](800/2500): Loss: 0.2481
===> Epoch[19](900/2500): Loss: 0.2415
===> Epoch[19](1000/2500): Loss: 0.2441
===> Epoch[19](1100/2500): Loss: 0.2147
===> Epoch[19](1200/2500): Loss: 0.2469
===> Epoch[19](1300/2500): Loss: 0.2245
===> Epoch[19](1400/2500): Loss: 0.2505
===> Epoch[19](1500/2500): Loss: 0.2347
===> Epoch[19](1600/2500): Loss: 0.2336
===> Epoch[19](1700/2500): Loss: 0.2536
===> Epoch[19](1800/2500): Loss: 0.2206
===> Epoch[19](1900/2500): Loss: 0.2332
===> Epoch[19](2000/2500): Loss: 0.2398
===> Epoch[19](2100/2500): Loss: 0.2339
===> Epoch[19](2200/2500): Loss: 0.2672
===> Epoch[19](2300/2500): Loss: 0.2242
===> Epoch[19](2400/2500): Loss: 0.2436
===> Epoch[19](2500/2500): Loss: 0.2337
===> Epoch 19 Complete: Avg. Loss: 0.2331
===> Timestamp: [2025-08-03 16:47:38]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.2378
===> Epoch[19](200/2500): Loss: 0.2641
===> Epoch[19](300/2500): Loss: 0.2158
===> Epoch[19](400/2500): Loss: 0.2360
===> Epoch[19](500/2500): Loss: 0.2478
===> Epoch[19](600/2500): Loss: 0.2306
===> Epoch[19](700/2500): Loss: 0.2216
===> Epoch[19](800/2500): Loss: 0.2481
===> Epoch[19](900/2500): Loss: 0.2415
===> Epoch[19](1000/2500): Loss: 0.2441
===> Epoch[19](1100/2500): Loss: 0.2147
===> Epoch[19](1200/2500): Loss: 0.2469
===> Epoch[19](1300/2500): Loss: 0.2245
===> Epoch[19](1400/2500): Loss: 0.2505
===> Epoch[19](1500/2500): Loss: 0.2347
===> Epoch[19](1600/2500): Loss: 0.2336
===> Epoch[19](1700/2500): Loss: 0.2536
===> Epoch[19](1800/2500): Loss: 0.2206
===> Epoch[19](1900/2500): Loss: 0.2332
===> Epoch[19](2000/2500): Loss: 0.2398
===> Epoch[19](2100/2500): Loss: 0.2339
===> Epoch[19](2200/2500): Loss: 0.2672
===> Epoch[19](2300/2500): Loss: 0.2242
===> Epoch[19](2400/2500): Loss: 0.2436
===> Epoch[19](2500/2500): Loss: 0.2337
===> Epoch 19 Complete: Avg. Loss: 0.2331
===> Timestamp: [2025-08-03 16:47:38]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.2378
===> Epoch[19](200/2500): Loss: 0.2641
===> Epoch[19](300/2500): Loss: 0.2158
===> Epoch[19](400/2500): Loss: 0.2360
===> Epoch[19](500/2500): Loss: 0.2478
===> Epoch[19](600/2500): Loss: 0.2306
===> Epoch[19](700/2500): Loss: 0.2216
===> Epoch[19](800/2500): Loss: 0.2481
===> Epoch[19](900/2500): Loss: 0.2415
===> Epoch[19](1000/2500): Loss: 0.2441
===> Epoch[19](1100/2500): Loss: 0.2147
===> Epoch[19](1200/2500): Loss: 0.2469
===> Epoch[19](1300/2500): Loss: 0.2245
===> Epoch[19](1400/2500): Loss: 0.2505
===> Epoch[19](1500/2500): Loss: 0.2347
===> Epoch[19](1600/2500): Loss: 0.2336
===> Epoch[19](1700/2500): Loss: 0.2536
===> Epoch[19](1800/2500): Loss: 0.2206
===> Epoch[19](1900/2500): Loss: 0.2332
===> Epoch[19](2000/2500): Loss: 0.2398
===> Epoch[19](2100/2500): Loss: 0.2339
===> Epoch[19](2200/2500): Loss: 0.2672
===> Epoch[19](2300/2500): Loss: 0.2242
===> Epoch[19](2400/2500): Loss: 0.2436
===> Epoch[19](2500/2500): Loss: 0.2337
===> Epoch 19 Complete: Avg. Loss: 0.2331
===> Timestamp: [2025-08-03 16:47:38]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.2378
===> Epoch[19](200/2500): Loss: 0.2641
===> Epoch[19](300/2500): Loss: 0.2158
===> Epoch[19](400/2500): Loss: 0.2360
===> Epoch[19](500/2500): Loss: 0.2478
===> Epoch[19](600/2500): Loss: 0.2306
===> Epoch[19](700/2500): Loss: 0.2216
===> Epoch[19](800/2500): Loss: 0.2481
===> Epoch[19](900/2500): Loss: 0.2415
===> Epoch[19](1000/2500): Loss: 0.2441
===> Epoch[19](1100/2500): Loss: 0.2147
===> Epoch[19](1200/2500): Loss: 0.2469
===> Epoch[19](1300/2500): Loss: 0.2245
===> Epoch[19](1400/2500): Loss: 0.2505
===> Epoch[19](1500/2500): Loss: 0.2347
===> Epoch[19](1600/2500): Loss: 0.2336
===> Epoch[19](1700/2500): Loss: 0.2536
===> Epoch[19](1800/2500): Loss: 0.2206
===> Epoch[19](1900/2500): Loss: 0.2332
===> Epoch[19](2000/2500): Loss: 0.2398
===> Epoch[19](2100/2500): Loss: 0.2339
===> Epoch[19](2200/2500): Loss: 0.2672
===> Epoch[19](2300/2500): Loss: 0.2242
===> Epoch[19](2400/2500): Loss: 0.2436
===> Epoch[19](2500/2500): Loss: 0.2337
===> Epoch 19 Complete: Avg. Loss: 0.2331
===> Timestamp: [2025-08-03 16:47:38]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.2378
===> Epoch[19](200/2500): Loss: 0.2641
===> Epoch[19](300/2500): Loss: 0.2158
===> Epoch[19](400/2500): Loss: 0.2360
===> Epoch[19](500/2500): Loss: 0.2478
===> Epoch[19](600/2500): Loss: 0.2306
===> Epoch[19](700/2500): Loss: 0.2216
===> Epoch[19](800/2500): Loss: 0.2481
===> Epoch[19](900/2500): Loss: 0.2415
===> Epoch[19](1000/2500): Loss: 0.2441
===> Epoch[19](1100/2500): Loss: 0.2147
===> Epoch[19](1200/2500): Loss: 0.2469
===> Epoch[19](1300/2500): Loss: 0.2245
===> Epoch[19](1400/2500): Loss: 0.2505
===> Epoch[19](1500/2500): Loss: 0.2347
===> Epoch[19](1600/2500): Loss: 0.2336
===> Epoch[19](1700/2500): Loss: 0.2536
===> Epoch[19](1800/2500): Loss: 0.2206
===> Epoch[19](1900/2500): Loss: 0.2332
===> Epoch[19](2000/2500): Loss: 0.2398
===> Epoch[19](2100/2500): Loss: 0.2339
===> Epoch[19](2200/2500): Loss: 0.2672
===> Epoch[19](2300/2500): Loss: 0.2242
===> Epoch[19](2400/2500): Loss: 0.2436
===> Epoch[19](2500/2500): Loss: 0.2337
===> Epoch 19 Complete: Avg. Loss: 0.2331
===> Timestamp: [2025-08-03 16:47:38]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.2378
===> Epoch[19](200/2500): Loss: 0.2641
===> Epoch[19](300/2500): Loss: 0.2158
===> Epoch[19](400/2500): Loss: 0.2360
===> Epoch[19](500/2500): Loss: 0.2478
===> Epoch[19](600/2500): Loss: 0.2306
===> Epoch[19](700/2500): Loss: 0.2216
===> Epoch[19](800/2500): Loss: 0.2481
===> Epoch[19](900/2500): Loss: 0.2415
===> Epoch[19](1000/2500): Loss: 0.2441
===> Epoch[19](1100/2500): Loss: 0.2147
===> Epoch[19](1200/2500): Loss: 0.2469
===> Epoch[19](1300/2500): Loss: 0.2245
===> Epoch[19](1400/2500): Loss: 0.2505
===> Epoch[19](1500/2500): Loss: 0.2347
===> Epoch[19](1600/2500): Loss: 0.2336
===> Epoch[19](1700/2500): Loss: 0.2536
===> Epoch[19](1800/2500): Loss: 0.2206
===> Epoch[19](1900/2500): Loss: 0.2332
===> Epoch[19](2000/2500): Loss: 0.2398
===> Epoch[19](2100/2500): Loss: 0.2339
===> Epoch[19](2200/2500): Loss: 0.2672
===> Epoch[19](2300/2500): Loss: 0.2242
===> Epoch[19](2400/2500): Loss: 0.2436
===> Epoch[19](2500/2500): Loss: 0.2337
===> Epoch 19 Complete: Avg. Loss: 0.2331
===> Timestamp: [2025-08-03 16:47:38]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.2378
===> Epoch[19](200/2500): Loss: 0.2641
===> Epoch[19](300/2500): Loss: 0.2158
===> Epoch[19](400/2500): Loss: 0.2360
===> Epoch[19](500/2500): Loss: 0.2478
===> Epoch[19](600/2500): Loss: 0.2306
===> Epoch[19](700/2500): Loss: 0.2216
===> Epoch[19](800/2500): Loss: 0.2481
===> Epoch[19](900/2500): Loss: 0.2415
===> Epoch[19](1000/2500): Loss: 0.2441
===> Epoch[19](1100/2500): Loss: 0.2147
===> Epoch[19](1200/2500): Loss: 0.2469
===> Epoch[19](1300/2500): Loss: 0.2245
===> Epoch[19](1400/2500): Loss: 0.2505
===> Epoch[19](1500/2500): Loss: 0.2347
===> Epoch[19](1600/2500): Loss: 0.2336
===> Epoch[19](1700/2500): Loss: 0.2536
===> Epoch[19](1800/2500): Loss: 0.2206
===> Epoch[19](1900/2500): Loss: 0.2332
===> Epoch[19](2000/2500): Loss: 0.2398
===> Epoch[19](2100/2500): Loss: 0.2339
===> Epoch[19](2200/2500): Loss: 0.2672
===> Epoch[19](2300/2500): Loss: 0.2242
===> Epoch[19](2400/2500): Loss: 0.2436
===> Epoch[19](2500/2500): Loss: 0.2337
===> Epoch 19 Complete: Avg. Loss: 0.2331
===> Timestamp: [2025-08-03 16:47:38]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.2378
===> Epoch[19](200/2500): Loss: 0.2641
===> Epoch[19](300/2500): Loss: 0.2158
===> Epoch[19](400/2500): Loss: 0.2360
===> Epoch[19](500/2500): Loss: 0.2478
===> Epoch[19](600/2500): Loss: 0.2306
===> Epoch[19](700/2500): Loss: 0.2216
===> Epoch[19](800/2500): Loss: 0.2481
===> Epoch[19](900/2500): Loss: 0.2415
===> Epoch[19](1000/2500): Loss: 0.2441
===> Epoch[19](1100/2500): Loss: 0.2147
===> Epoch[19](1200/2500): Loss: 0.2469
===> Epoch[19](1300/2500): Loss: 0.2245
===> Epoch[19](1400/2500): Loss: 0.2505
===> Epoch[19](1500/2500): Loss: 0.2347
===> Epoch[19](1600/2500): Loss: 0.2336
===> Epoch[19](1700/2500): Loss: 0.2536
===> Epoch[19](1800/2500): Loss: 0.2206
===> Epoch[19](1900/2500): Loss: 0.2332
===> Epoch[19](2000/2500): Loss: 0.2398
===> Epoch[19](2100/2500): Loss: 0.2339
===> Epoch[19](2200/2500): Loss: 0.2672
===> Epoch[19](2300/2500): Loss: 0.2242
===> Epoch[19](2400/2500): Loss: 0.2436
===> Epoch[19](2500/2500): Loss: 0.2337
===> Epoch 19 Complete: Avg. Loss: 0.2331
===> Timestamp: [2025-08-03 16:47:38]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.2378
===> Epoch[19](200/2500): Loss: 0.2641
===> Epoch[19](300/2500): Loss: 0.2158
===> Epoch[19](400/2500): Loss: 0.2360
===> Epoch[19](500/2500): Loss: 0.2478
===> Epoch[19](600/2500): Loss: 0.2306
===> Epoch[19](700/2500): Loss: 0.2216
===> Epoch[19](800/2500): Loss: 0.2481
===> Epoch[19](900/2500): Loss: 0.2415
===> Epoch[19](1000/2500): Loss: 0.2441
===> Epoch[19](1100/2500): Loss: 0.2147
===> Epoch[19](1200/2500): Loss: 0.2469
===> Epoch[19](1300/2500): Loss: 0.2245
===> Epoch[19](1400/2500): Loss: 0.2505
===> Epoch[19](1500/2500): Loss: 0.2347
===> Epoch[19](1600/2500): Loss: 0.2336
===> Epoch[19](1700/2500): Loss: 0.2536
===> Epoch[19](1800/2500): Loss: 0.2206
===> Epoch[19](1900/2500): Loss: 0.2332
===> Epoch[19](2000/2500): Loss: 0.2398
===> Epoch[19](2100/2500): Loss: 0.2339
===> Epoch[19](2200/2500): Loss: 0.2672
===> Epoch[19](2300/2500): Loss: 0.2242
===> Epoch[19](2400/2500): Loss: 0.2436
===> Epoch[19](2500/2500): Loss: 0.2337
===> Epoch 19 Complete: Avg. Loss: 0.2331
===> Timestamp: [2025-08-03 16:47:38]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.2378
===> Epoch[19](200/2500): Loss: 0.2641
===> Epoch[19](300/2500): Loss: 0.2158
===> Epoch[19](400/2500): Loss: 0.2360
===> Epoch[19](500/2500): Loss: 0.2478
===> Epoch[19](600/2500): Loss: 0.2306
===> Epoch[19](700/2500): Loss: 0.2216
===> Epoch[19](800/2500): Loss: 0.2481
===> Epoch[19](900/2500): Loss: 0.2415
===> Epoch[19](1000/2500): Loss: 0.2441
===> Epoch[19](1100/2500): Loss: 0.2147
===> Epoch[19](1200/2500): Loss: 0.2469
===> Epoch[19](1300/2500): Loss: 0.2245
===> Epoch[19](1400/2500): Loss: 0.2505
===> Epoch[19](1500/2500): Loss: 0.2347
===> Epoch[19](1600/2500): Loss: 0.2336
===> Epoch[19](1700/2500): Loss: 0.2536
===> Epoch[19](1800/2500): Loss: 0.2206
===> Epoch[19](1900/2500): Loss: 0.2332
===> Epoch[19](2000/2500): Loss: 0.2398
===> Epoch[19](2100/2500): Loss: 0.2339
===> Epoch[19](2200/2500): Loss: 0.2672
===> Epoch[19](2300/2500): Loss: 0.2242
===> Epoch[19](2400/2500): Loss: 0.2436
===> Epoch[19](2500/2500): Loss: 0.2337
===> Epoch 19 Complete: Avg. Loss: 0.2331
===> Timestamp: [2025-08-03 16:47:38]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.2378
===> Epoch[19](200/2500): Loss: 0.2641
===> Epoch[19](300/2500): Loss: 0.2158
===> Epoch[19](400/2500): Loss: 0.2360
===> Epoch[19](500/2500): Loss: 0.2478
===> Epoch[19](600/2500): Loss: 0.2306
===> Epoch[19](700/2500): Loss: 0.2216
===> Epoch[19](800/2500): Loss: 0.2481
===> Epoch[19](900/2500): Loss: 0.2415
===> Epoch[19](1000/2500): Loss: 0.2441
===> Epoch[19](1100/2500): Loss: 0.2147
===> Epoch[19](1200/2500): Loss: 0.2469
===> Epoch[19](1300/2500): Loss: 0.2245
===> Epoch[19](1400/2500): Loss: 0.2505
===> Epoch[19](1500/2500): Loss: 0.2347
===> Epoch[19](1600/2500): Loss: 0.2336
===> Epoch[19](1700/2500): Loss: 0.2536
===> Epoch[19](1800/2500): Loss: 0.2206
===> Epoch[19](1900/2500): Loss: 0.2332
===> Epoch[19](2000/2500): Loss: 0.2398
===> Epoch[19](2100/2500): Loss: 0.2339
===> Epoch[19](2200/2500): Loss: 0.2672
===> Epoch[19](2300/2500): Loss: 0.2242
===> Epoch[19](2400/2500): Loss: 0.2436
===> Epoch[19](2500/2500): Loss: 0.2337
===> Epoch 19 Complete: Avg. Loss: 0.2331
===> Timestamp: [2025-08-03 16:47:38]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.2378
===> Epoch[19](200/2500): Loss: 0.2641
===> Epoch[19](300/2500): Loss: 0.2158
===> Epoch[19](400/2500): Loss: 0.2360
===> Epoch[19](500/2500): Loss: 0.2478
===> Epoch[19](600/2500): Loss: 0.2306
===> Epoch[19](700/2500): Loss: 0.2216
===> Epoch[19](800/2500): Loss: 0.2481
===> Epoch[19](900/2500): Loss: 0.2415
===> Epoch[19](1000/2500): Loss: 0.2441
===> Epoch[19](1100/2500): Loss: 0.2147
===> Epoch[19](1200/2500): Loss: 0.2469
===> Epoch[19](1300/2500): Loss: 0.2245
===> Epoch[19](1400/2500): Loss: 0.2505
===> Epoch[19](1500/2500): Loss: 0.2347
===> Epoch[19](1600/2500): Loss: 0.2336
===> Epoch[19](1700/2500): Loss: 0.2536
===> Epoch[19](1800/2500): Loss: 0.2206
===> Epoch[19](1900/2500): Loss: 0.2332
===> Epoch[19](2000/2500): Loss: 0.2398
===> Epoch[19](2100/2500): Loss: 0.2339
===> Epoch[19](2200/2500): Loss: 0.2672
===> Epoch[19](2300/2500): Loss: 0.2242
===> Epoch[19](2400/2500): Loss: 0.2436
===> Epoch[19](2500/2500): Loss: 0.2337
===> Epoch 19 Complete: Avg. Loss: 0.2331
===> Timestamp: [2025-08-03 16:47:38]
===> Loading train datasets
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2270
===> Epoch[20](200/2500): Loss: 0.2391
===> Epoch[20](300/2500): Loss: 0.2502
===> Epoch[20](400/2500): Loss: 0.2395
===> Epoch[20](500/2500): Loss: 0.2472
===> Epoch[20](600/2500): Loss: 0.2269
===> Epoch[20](700/2500): Loss: 0.2227
===> Epoch[20](800/2500): Loss: 0.2259
===> Epoch[20](900/2500): Loss: 0.2315
===> Epoch[20](1000/2500): Loss: 0.2235
===> Epoch[20](1100/2500): Loss: 0.2104
===> Epoch[20](1200/2500): Loss: 0.2334
===> Epoch[20](1300/2500): Loss: 0.2248
===> Epoch[20](1400/2500): Loss: 0.2367
===> Epoch[20](1500/2500): Loss: 0.2268
===> Epoch[20](1600/2500): Loss: 0.2258
===> Epoch[20](1700/2500): Loss: 0.2234
===> Epoch[20](1800/2500): Loss: 0.2198
===> Epoch[20](1900/2500): Loss: 0.2336
===> Epoch[20](2000/2500): Loss: 0.2094
===> Epoch[20](2100/2500): Loss: 0.2390
===> Epoch[20](2200/2500): Loss: 0.2159
===> Epoch[20](2300/2500): Loss: 0.2268
===> Epoch[20](2400/2500): Loss: 0.2387
===> Epoch[20](2500/2500): Loss: 0.2276
===> Epoch 20 Complete: Avg. Loss: 0.2322
===> Timestamp: [2025-08-03 16:52:12]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2270
===> Epoch[20](200/2500): Loss: 0.2391
===> Epoch[20](300/2500): Loss: 0.2502
===> Epoch[20](400/2500): Loss: 0.2395
===> Epoch[20](500/2500): Loss: 0.2472
===> Epoch[20](600/2500): Loss: 0.2269
===> Epoch[20](700/2500): Loss: 0.2227
===> Epoch[20](800/2500): Loss: 0.2259
===> Epoch[20](900/2500): Loss: 0.2315
===> Epoch[20](1000/2500): Loss: 0.2235
===> Epoch[20](1100/2500): Loss: 0.2104
===> Epoch[20](1200/2500): Loss: 0.2334
===> Epoch[20](1300/2500): Loss: 0.2248
===> Epoch[20](1400/2500): Loss: 0.2367
===> Epoch[20](1500/2500): Loss: 0.2268
===> Epoch[20](1600/2500): Loss: 0.2258
===> Epoch[20](1700/2500): Loss: 0.2234
===> Epoch[20](1800/2500): Loss: 0.2198
===> Epoch[20](1900/2500): Loss: 0.2336
===> Epoch[20](2000/2500): Loss: 0.2094
===> Epoch[20](2100/2500): Loss: 0.2390
===> Epoch[20](2200/2500): Loss: 0.2159
===> Epoch[20](2300/2500): Loss: 0.2268
===> Epoch[20](2400/2500): Loss: 0.2387
===> Epoch[20](2500/2500): Loss: 0.2276
===> Epoch 20 Complete: Avg. Loss: 0.2322
===> Timestamp: [2025-08-03 16:52:12]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2270
===> Epoch[20](200/2500): Loss: 0.2391
===> Epoch[20](300/2500): Loss: 0.2502
===> Epoch[20](400/2500): Loss: 0.2395
===> Epoch[20](500/2500): Loss: 0.2472
===> Epoch[20](600/2500): Loss: 0.2269
===> Epoch[20](700/2500): Loss: 0.2227
===> Epoch[20](800/2500): Loss: 0.2259
===> Epoch[20](900/2500): Loss: 0.2315
===> Epoch[20](1000/2500): Loss: 0.2235
===> Epoch[20](1100/2500): Loss: 0.2104
===> Epoch[20](1200/2500): Loss: 0.2334
===> Epoch[20](1300/2500): Loss: 0.2248
===> Epoch[20](1400/2500): Loss: 0.2367
===> Epoch[20](1500/2500): Loss: 0.2268
===> Epoch[20](1600/2500): Loss: 0.2258
===> Epoch[20](1700/2500): Loss: 0.2234
===> Epoch[20](1800/2500): Loss: 0.2198
===> Epoch[20](1900/2500): Loss: 0.2336
===> Epoch[20](2000/2500): Loss: 0.2094
===> Epoch[20](2100/2500): Loss: 0.2390
===> Epoch[20](2200/2500): Loss: 0.2159
===> Epoch[20](2300/2500): Loss: 0.2268
===> Epoch[20](2400/2500): Loss: 0.2387
===> Epoch[20](2500/2500): Loss: 0.2276
===> Epoch 20 Complete: Avg. Loss: 0.2322
===> Timestamp: [2025-08-03 16:52:12]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2270
===> Epoch[20](200/2500): Loss: 0.2391
===> Epoch[20](300/2500): Loss: 0.2502
===> Epoch[20](400/2500): Loss: 0.2395
===> Epoch[20](500/2500): Loss: 0.2472
===> Epoch[20](600/2500): Loss: 0.2269
===> Epoch[20](700/2500): Loss: 0.2227
===> Epoch[20](800/2500): Loss: 0.2259
===> Epoch[20](900/2500): Loss: 0.2315
===> Epoch[20](1000/2500): Loss: 0.2235
===> Epoch[20](1100/2500): Loss: 0.2104
===> Epoch[20](1200/2500): Loss: 0.2334
===> Epoch[20](1300/2500): Loss: 0.2248
===> Epoch[20](1400/2500): Loss: 0.2367
===> Epoch[20](1500/2500): Loss: 0.2268
===> Epoch[20](1600/2500): Loss: 0.2258
===> Epoch[20](1700/2500): Loss: 0.2234
===> Epoch[20](1800/2500): Loss: 0.2198
===> Epoch[20](1900/2500): Loss: 0.2336
===> Epoch[20](2000/2500): Loss: 0.2094
===> Epoch[20](2100/2500): Loss: 0.2390
===> Epoch[20](2200/2500): Loss: 0.2159
===> Epoch[20](2300/2500): Loss: 0.2268
===> Epoch[20](2400/2500): Loss: 0.2387
===> Epoch[20](2500/2500): Loss: 0.2276
===> Epoch 20 Complete: Avg. Loss: 0.2322
===> Timestamp: [2025-08-03 16:52:12]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2270
===> Epoch[20](200/2500): Loss: 0.2391
===> Epoch[20](300/2500): Loss: 0.2502
===> Epoch[20](400/2500): Loss: 0.2395
===> Epoch[20](500/2500): Loss: 0.2472
===> Epoch[20](600/2500): Loss: 0.2269
===> Epoch[20](700/2500): Loss: 0.2227
===> Epoch[20](800/2500): Loss: 0.2259
===> Epoch[20](900/2500): Loss: 0.2315
===> Epoch[20](1000/2500): Loss: 0.2235
===> Epoch[20](1100/2500): Loss: 0.2104
===> Epoch[20](1200/2500): Loss: 0.2334
===> Epoch[20](1300/2500): Loss: 0.2248
===> Epoch[20](1400/2500): Loss: 0.2367
===> Epoch[20](1500/2500): Loss: 0.2268
===> Epoch[20](1600/2500): Loss: 0.2258
===> Epoch[20](1700/2500): Loss: 0.2234
===> Epoch[20](1800/2500): Loss: 0.2198
===> Epoch[20](1900/2500): Loss: 0.2336
===> Epoch[20](2000/2500): Loss: 0.2094
===> Epoch[20](2100/2500): Loss: 0.2390
===> Epoch[20](2200/2500): Loss: 0.2159
===> Epoch[20](2300/2500): Loss: 0.2268
===> Epoch[20](2400/2500): Loss: 0.2387
===> Epoch[20](2500/2500): Loss: 0.2276
===> Epoch 20 Complete: Avg. Loss: 0.2322
===> Timestamp: [2025-08-03 16:52:12]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2270
===> Epoch[20](200/2500): Loss: 0.2391
===> Epoch[20](300/2500): Loss: 0.2502
===> Epoch[20](400/2500): Loss: 0.2395
===> Epoch[20](500/2500): Loss: 0.2472
===> Epoch[20](600/2500): Loss: 0.2269
===> Epoch[20](700/2500): Loss: 0.2227
===> Epoch[20](800/2500): Loss: 0.2259
===> Epoch[20](900/2500): Loss: 0.2315
===> Epoch[20](1000/2500): Loss: 0.2235
===> Epoch[20](1100/2500): Loss: 0.2104
===> Epoch[20](1200/2500): Loss: 0.2334
===> Epoch[20](1300/2500): Loss: 0.2248
===> Epoch[20](1400/2500): Loss: 0.2367
===> Epoch[20](1500/2500): Loss: 0.2268
===> Epoch[20](1600/2500): Loss: 0.2258
===> Epoch[20](1700/2500): Loss: 0.2234
===> Epoch[20](1800/2500): Loss: 0.2198
===> Epoch[20](1900/2500): Loss: 0.2336
===> Epoch[20](2000/2500): Loss: 0.2094
===> Epoch[20](2100/2500): Loss: 0.2390
===> Epoch[20](2200/2500): Loss: 0.2159
===> Epoch[20](2300/2500): Loss: 0.2268
===> Epoch[20](2400/2500): Loss: 0.2387
===> Epoch[20](2500/2500): Loss: 0.2276
===> Epoch 20 Complete: Avg. Loss: 0.2322
===> Timestamp: [2025-08-03 16:52:12]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2270
===> Epoch[20](200/2500): Loss: 0.2391
===> Epoch[20](300/2500): Loss: 0.2502
===> Epoch[20](400/2500): Loss: 0.2395
===> Epoch[20](500/2500): Loss: 0.2472
===> Epoch[20](600/2500): Loss: 0.2269
===> Epoch[20](700/2500): Loss: 0.2227
===> Epoch[20](800/2500): Loss: 0.2259
===> Epoch[20](900/2500): Loss: 0.2315
===> Epoch[20](1000/2500): Loss: 0.2235
===> Epoch[20](1100/2500): Loss: 0.2104
===> Epoch[20](1200/2500): Loss: 0.2334
===> Epoch[20](1300/2500): Loss: 0.2248
===> Epoch[20](1400/2500): Loss: 0.2367
===> Epoch[20](1500/2500): Loss: 0.2268
===> Epoch[20](1600/2500): Loss: 0.2258
===> Epoch[20](1700/2500): Loss: 0.2234
===> Epoch[20](1800/2500): Loss: 0.2198
===> Epoch[20](1900/2500): Loss: 0.2336
===> Epoch[20](2000/2500): Loss: 0.2094
===> Epoch[20](2100/2500): Loss: 0.2390
===> Epoch[20](2200/2500): Loss: 0.2159
===> Epoch[20](2300/2500): Loss: 0.2268
===> Epoch[20](2400/2500): Loss: 0.2387
===> Epoch[20](2500/2500): Loss: 0.2276
===> Epoch 20 Complete: Avg. Loss: 0.2322
===> Timestamp: [2025-08-03 16:52:12]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2270
===> Epoch[20](200/2500): Loss: 0.2391
===> Epoch[20](300/2500): Loss: 0.2502
===> Epoch[20](400/2500): Loss: 0.2395
===> Epoch[20](500/2500): Loss: 0.2472
===> Epoch[20](600/2500): Loss: 0.2269
===> Epoch[20](700/2500): Loss: 0.2227
===> Epoch[20](800/2500): Loss: 0.2259
===> Epoch[20](900/2500): Loss: 0.2315
===> Epoch[20](1000/2500): Loss: 0.2235
===> Epoch[20](1100/2500): Loss: 0.2104
===> Epoch[20](1200/2500): Loss: 0.2334
===> Epoch[20](1300/2500): Loss: 0.2248
===> Epoch[20](1400/2500): Loss: 0.2367
===> Epoch[20](1500/2500): Loss: 0.2268
===> Epoch[20](1600/2500): Loss: 0.2258
===> Epoch[20](1700/2500): Loss: 0.2234
===> Epoch[20](1800/2500): Loss: 0.2198
===> Epoch[20](1900/2500): Loss: 0.2336
===> Epoch[20](2000/2500): Loss: 0.2094
===> Epoch[20](2100/2500): Loss: 0.2390
===> Epoch[20](2200/2500): Loss: 0.2159
===> Epoch[20](2300/2500): Loss: 0.2268
===> Epoch[20](2400/2500): Loss: 0.2387
===> Epoch[20](2500/2500): Loss: 0.2276
===> Epoch 20 Complete: Avg. Loss: 0.2322
===> Timestamp: [2025-08-03 16:52:12]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2270
===> Epoch[20](200/2500): Loss: 0.2391
===> Epoch[20](300/2500): Loss: 0.2502
===> Epoch[20](400/2500): Loss: 0.2395
===> Epoch[20](500/2500): Loss: 0.2472
===> Epoch[20](600/2500): Loss: 0.2269
===> Epoch[20](700/2500): Loss: 0.2227
===> Epoch[20](800/2500): Loss: 0.2259
===> Epoch[20](900/2500): Loss: 0.2315
===> Epoch[20](1000/2500): Loss: 0.2235
===> Epoch[20](1100/2500): Loss: 0.2104
===> Epoch[20](1200/2500): Loss: 0.2334
===> Epoch[20](1300/2500): Loss: 0.2248
===> Epoch[20](1400/2500): Loss: 0.2367
===> Epoch[20](1500/2500): Loss: 0.2268
===> Epoch[20](1600/2500): Loss: 0.2258
===> Epoch[20](1700/2500): Loss: 0.2234
===> Epoch[20](1800/2500): Loss: 0.2198
===> Epoch[20](1900/2500): Loss: 0.2336
===> Epoch[20](2000/2500): Loss: 0.2094
===> Epoch[20](2100/2500): Loss: 0.2390
===> Epoch[20](2200/2500): Loss: 0.2159
===> Epoch[20](2300/2500): Loss: 0.2268
===> Epoch[20](2400/2500): Loss: 0.2387
===> Epoch[20](2500/2500): Loss: 0.2276
===> Epoch 20 Complete: Avg. Loss: 0.2322
===> Timestamp: [2025-08-03 16:52:12]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2270
===> Epoch[20](200/2500): Loss: 0.2391
===> Epoch[20](300/2500): Loss: 0.2502
===> Epoch[20](400/2500): Loss: 0.2395
===> Epoch[20](500/2500): Loss: 0.2472
===> Epoch[20](600/2500): Loss: 0.2269
===> Epoch[20](700/2500): Loss: 0.2227
===> Epoch[20](800/2500): Loss: 0.2259
===> Epoch[20](900/2500): Loss: 0.2315
===> Epoch[20](1000/2500): Loss: 0.2235
===> Epoch[20](1100/2500): Loss: 0.2104
===> Epoch[20](1200/2500): Loss: 0.2334
===> Epoch[20](1300/2500): Loss: 0.2248
===> Epoch[20](1400/2500): Loss: 0.2367
===> Epoch[20](1500/2500): Loss: 0.2268
===> Epoch[20](1600/2500): Loss: 0.2258
===> Epoch[20](1700/2500): Loss: 0.2234
===> Epoch[20](1800/2500): Loss: 0.2198
===> Epoch[20](1900/2500): Loss: 0.2336
===> Epoch[20](2000/2500): Loss: 0.2094
===> Epoch[20](2100/2500): Loss: 0.2390
===> Epoch[20](2200/2500): Loss: 0.2159
===> Epoch[20](2300/2500): Loss: 0.2268
===> Epoch[20](2400/2500): Loss: 0.2387
===> Epoch[20](2500/2500): Loss: 0.2276
===> Epoch 20 Complete: Avg. Loss: 0.2322
===> Timestamp: [2025-08-03 16:52:12]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2270
===> Epoch[20](200/2500): Loss: 0.2391
===> Epoch[20](300/2500): Loss: 0.2502
===> Epoch[20](400/2500): Loss: 0.2395
===> Epoch[20](500/2500): Loss: 0.2472
===> Epoch[20](600/2500): Loss: 0.2269
===> Epoch[20](700/2500): Loss: 0.2227
===> Epoch[20](800/2500): Loss: 0.2259
===> Epoch[20](900/2500): Loss: 0.2315
===> Epoch[20](1000/2500): Loss: 0.2235
===> Epoch[20](1100/2500): Loss: 0.2104
===> Epoch[20](1200/2500): Loss: 0.2334
===> Epoch[20](1300/2500): Loss: 0.2248
===> Epoch[20](1400/2500): Loss: 0.2367
===> Epoch[20](1500/2500): Loss: 0.2268
===> Epoch[20](1600/2500): Loss: 0.2258
===> Epoch[20](1700/2500): Loss: 0.2234
===> Epoch[20](1800/2500): Loss: 0.2198
===> Epoch[20](1900/2500): Loss: 0.2336
===> Epoch[20](2000/2500): Loss: 0.2094
===> Epoch[20](2100/2500): Loss: 0.2390
===> Epoch[20](2200/2500): Loss: 0.2159
===> Epoch[20](2300/2500): Loss: 0.2268
===> Epoch[20](2400/2500): Loss: 0.2387
===> Epoch[20](2500/2500): Loss: 0.2276
===> Epoch 20 Complete: Avg. Loss: 0.2322
===> Timestamp: [2025-08-03 16:52:12]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2270
===> Epoch[20](200/2500): Loss: 0.2391
===> Epoch[20](300/2500): Loss: 0.2502
===> Epoch[20](400/2500): Loss: 0.2395
===> Epoch[20](500/2500): Loss: 0.2472
===> Epoch[20](600/2500): Loss: 0.2269
===> Epoch[20](700/2500): Loss: 0.2227
===> Epoch[20](800/2500): Loss: 0.2259
===> Epoch[20](900/2500): Loss: 0.2315
===> Epoch[20](1000/2500): Loss: 0.2235
===> Epoch[20](1100/2500): Loss: 0.2104
===> Epoch[20](1200/2500): Loss: 0.2334
===> Epoch[20](1300/2500): Loss: 0.2248
===> Epoch[20](1400/2500): Loss: 0.2367
===> Epoch[20](1500/2500): Loss: 0.2268
===> Epoch[20](1600/2500): Loss: 0.2258
===> Epoch[20](1700/2500): Loss: 0.2234
===> Epoch[20](1800/2500): Loss: 0.2198
===> Epoch[20](1900/2500): Loss: 0.2336
===> Epoch[20](2000/2500): Loss: 0.2094
===> Epoch[20](2100/2500): Loss: 0.2390
===> Epoch[20](2200/2500): Loss: 0.2159
===> Epoch[20](2300/2500): Loss: 0.2268
===> Epoch[20](2400/2500): Loss: 0.2387
===> Epoch[20](2500/2500): Loss: 0.2276
===> Epoch 20 Complete: Avg. Loss: 0.2322
===> Timestamp: [2025-08-03 16:52:12]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2270
===> Epoch[20](200/2500): Loss: 0.2391
===> Epoch[20](300/2500): Loss: 0.2502
===> Epoch[20](400/2500): Loss: 0.2395
===> Epoch[20](500/2500): Loss: 0.2472
===> Epoch[20](600/2500): Loss: 0.2269
===> Epoch[20](700/2500): Loss: 0.2227
===> Epoch[20](800/2500): Loss: 0.2259
===> Epoch[20](900/2500): Loss: 0.2315
===> Epoch[20](1000/2500): Loss: 0.2235
===> Epoch[20](1100/2500): Loss: 0.2104
===> Epoch[20](1200/2500): Loss: 0.2334
===> Epoch[20](1300/2500): Loss: 0.2248
===> Epoch[20](1400/2500): Loss: 0.2367
===> Epoch[20](1500/2500): Loss: 0.2268
===> Epoch[20](1600/2500): Loss: 0.2258
===> Epoch[20](1700/2500): Loss: 0.2234
===> Epoch[20](1800/2500): Loss: 0.2198
===> Epoch[20](1900/2500): Loss: 0.2336
===> Epoch[20](2000/2500): Loss: 0.2094
===> Epoch[20](2100/2500): Loss: 0.2390
===> Epoch[20](2200/2500): Loss: 0.2159
===> Epoch[20](2300/2500): Loss: 0.2268
===> Epoch[20](2400/2500): Loss: 0.2387
===> Epoch[20](2500/2500): Loss: 0.2276
===> Epoch 20 Complete: Avg. Loss: 0.2322
===> Timestamp: [2025-08-03 16:52:12]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2270
===> Epoch[20](200/2500): Loss: 0.2391
===> Epoch[20](300/2500): Loss: 0.2502
===> Epoch[20](400/2500): Loss: 0.2395
===> Epoch[20](500/2500): Loss: 0.2472
===> Epoch[20](600/2500): Loss: 0.2269
===> Epoch[20](700/2500): Loss: 0.2227
===> Epoch[20](800/2500): Loss: 0.2259
===> Epoch[20](900/2500): Loss: 0.2315
===> Epoch[20](1000/2500): Loss: 0.2235
===> Epoch[20](1100/2500): Loss: 0.2104
===> Epoch[20](1200/2500): Loss: 0.2334
===> Epoch[20](1300/2500): Loss: 0.2248
===> Epoch[20](1400/2500): Loss: 0.2367
===> Epoch[20](1500/2500): Loss: 0.2268
===> Epoch[20](1600/2500): Loss: 0.2258
===> Epoch[20](1700/2500): Loss: 0.2234
===> Epoch[20](1800/2500): Loss: 0.2198
===> Epoch[20](1900/2500): Loss: 0.2336
===> Epoch[20](2000/2500): Loss: 0.2094
===> Epoch[20](2100/2500): Loss: 0.2390
===> Epoch[20](2200/2500): Loss: 0.2159
===> Epoch[20](2300/2500): Loss: 0.2268
===> Epoch[20](2400/2500): Loss: 0.2387
===> Epoch[20](2500/2500): Loss: 0.2276
===> Epoch 20 Complete: Avg. Loss: 0.2322
===> Timestamp: [2025-08-03 16:52:12]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2270
===> Epoch[20](200/2500): Loss: 0.2391
===> Epoch[20](300/2500): Loss: 0.2502
===> Epoch[20](400/2500): Loss: 0.2395
===> Epoch[20](500/2500): Loss: 0.2472
===> Epoch[20](600/2500): Loss: 0.2269
===> Epoch[20](700/2500): Loss: 0.2227
===> Epoch[20](800/2500): Loss: 0.2259
===> Epoch[20](900/2500): Loss: 0.2315
===> Epoch[20](1000/2500): Loss: 0.2235
===> Epoch[20](1100/2500): Loss: 0.2104
===> Epoch[20](1200/2500): Loss: 0.2334
===> Epoch[20](1300/2500): Loss: 0.2248
===> Epoch[20](1400/2500): Loss: 0.2367
===> Epoch[20](1500/2500): Loss: 0.2268
===> Epoch[20](1600/2500): Loss: 0.2258
===> Epoch[20](1700/2500): Loss: 0.2234
===> Epoch[20](1800/2500): Loss: 0.2198
===> Epoch[20](1900/2500): Loss: 0.2336
===> Epoch[20](2000/2500): Loss: 0.2094
===> Epoch[20](2100/2500): Loss: 0.2390
===> Epoch[20](2200/2500): Loss: 0.2159
===> Epoch[20](2300/2500): Loss: 0.2268
===> Epoch[20](2400/2500): Loss: 0.2387
===> Epoch[20](2500/2500): Loss: 0.2276
===> Epoch 20 Complete: Avg. Loss: 0.2322
===> Timestamp: [2025-08-03 16:52:12]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2270
===> Epoch[20](200/2500): Loss: 0.2391
===> Epoch[20](300/2500): Loss: 0.2502
===> Epoch[20](400/2500): Loss: 0.2395
===> Epoch[20](500/2500): Loss: 0.2472
===> Epoch[20](600/2500): Loss: 0.2269
===> Epoch[20](700/2500): Loss: 0.2227
===> Epoch[20](800/2500): Loss: 0.2259
===> Epoch[20](900/2500): Loss: 0.2315
===> Epoch[20](1000/2500): Loss: 0.2235
===> Epoch[20](1100/2500): Loss: 0.2104
===> Epoch[20](1200/2500): Loss: 0.2334
===> Epoch[20](1300/2500): Loss: 0.2248
===> Epoch[20](1400/2500): Loss: 0.2367
===> Epoch[20](1500/2500): Loss: 0.2268
===> Epoch[20](1600/2500): Loss: 0.2258
===> Epoch[20](1700/2500): Loss: 0.2234
===> Epoch[20](1800/2500): Loss: 0.2198
===> Epoch[20](1900/2500): Loss: 0.2336
===> Epoch[20](2000/2500): Loss: 0.2094
===> Epoch[20](2100/2500): Loss: 0.2390
===> Epoch[20](2200/2500): Loss: 0.2159
===> Epoch[20](2300/2500): Loss: 0.2268
===> Epoch[20](2400/2500): Loss: 0.2387
===> Epoch[20](2500/2500): Loss: 0.2276
===> Epoch 20 Complete: Avg. Loss: 0.2322
===> Timestamp: [2025-08-03 16:52:12]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2270
===> Epoch[20](200/2500): Loss: 0.2391
===> Epoch[20](300/2500): Loss: 0.2502
===> Epoch[20](400/2500): Loss: 0.2395
===> Epoch[20](500/2500): Loss: 0.2472
===> Epoch[20](600/2500): Loss: 0.2269
===> Epoch[20](700/2500): Loss: 0.2227
===> Epoch[20](800/2500): Loss: 0.2259
===> Epoch[20](900/2500): Loss: 0.2315
===> Epoch[20](1000/2500): Loss: 0.2235
===> Epoch[20](1100/2500): Loss: 0.2104
===> Epoch[20](1200/2500): Loss: 0.2334
===> Epoch[20](1300/2500): Loss: 0.2248
===> Epoch[20](1400/2500): Loss: 0.2367
===> Epoch[20](1500/2500): Loss: 0.2268
===> Epoch[20](1600/2500): Loss: 0.2258
===> Epoch[20](1700/2500): Loss: 0.2234
===> Epoch[20](1800/2500): Loss: 0.2198
===> Epoch[20](1900/2500): Loss: 0.2336
===> Epoch[20](2000/2500): Loss: 0.2094
===> Epoch[20](2100/2500): Loss: 0.2390
===> Epoch[20](2200/2500): Loss: 0.2159
===> Epoch[20](2300/2500): Loss: 0.2268
===> Epoch[20](2400/2500): Loss: 0.2387
===> Epoch[20](2500/2500): Loss: 0.2276
===> Epoch 20 Complete: Avg. Loss: 0.2322
===> Timestamp: [2025-08-03 16:52:12]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2270
===> Epoch[20](200/2500): Loss: 0.2391
===> Epoch[20](300/2500): Loss: 0.2502
===> Epoch[20](400/2500): Loss: 0.2395
===> Epoch[20](500/2500): Loss: 0.2472
===> Epoch[20](600/2500): Loss: 0.2269
===> Epoch[20](700/2500): Loss: 0.2227
===> Epoch[20](800/2500): Loss: 0.2259
===> Epoch[20](900/2500): Loss: 0.2315
===> Epoch[20](1000/2500): Loss: 0.2235
===> Epoch[20](1100/2500): Loss: 0.2104
===> Epoch[20](1200/2500): Loss: 0.2334
===> Epoch[20](1300/2500): Loss: 0.2248
===> Epoch[20](1400/2500): Loss: 0.2367
===> Epoch[20](1500/2500): Loss: 0.2268
===> Epoch[20](1600/2500): Loss: 0.2258
===> Epoch[20](1700/2500): Loss: 0.2234
===> Epoch[20](1800/2500): Loss: 0.2198
===> Epoch[20](1900/2500): Loss: 0.2336
===> Epoch[20](2000/2500): Loss: 0.2094
===> Epoch[20](2100/2500): Loss: 0.2390
===> Epoch[20](2200/2500): Loss: 0.2159
===> Epoch[20](2300/2500): Loss: 0.2268
===> Epoch[20](2400/2500): Loss: 0.2387
===> Epoch[20](2500/2500): Loss: 0.2276
===> Epoch 20 Complete: Avg. Loss: 0.2322
===> Timestamp: [2025-08-03 16:52:12]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2270
===> Epoch[20](200/2500): Loss: 0.2391
===> Epoch[20](300/2500): Loss: 0.2502
===> Epoch[20](400/2500): Loss: 0.2395
===> Epoch[20](500/2500): Loss: 0.2472
===> Epoch[20](600/2500): Loss: 0.2269
===> Epoch[20](700/2500): Loss: 0.2227
===> Epoch[20](800/2500): Loss: 0.2259
===> Epoch[20](900/2500): Loss: 0.2315
===> Epoch[20](1000/2500): Loss: 0.2235
===> Epoch[20](1100/2500): Loss: 0.2104
===> Epoch[20](1200/2500): Loss: 0.2334
===> Epoch[20](1300/2500): Loss: 0.2248
===> Epoch[20](1400/2500): Loss: 0.2367
===> Epoch[20](1500/2500): Loss: 0.2268
===> Epoch[20](1600/2500): Loss: 0.2258
===> Epoch[20](1700/2500): Loss: 0.2234
===> Epoch[20](1800/2500): Loss: 0.2198
===> Epoch[20](1900/2500): Loss: 0.2336
===> Epoch[20](2000/2500): Loss: 0.2094
===> Epoch[20](2100/2500): Loss: 0.2390
===> Epoch[20](2200/2500): Loss: 0.2159
===> Epoch[20](2300/2500): Loss: 0.2268
===> Epoch[20](2400/2500): Loss: 0.2387
===> Epoch[20](2500/2500): Loss: 0.2276
===> Epoch 20 Complete: Avg. Loss: 0.2322
===> Timestamp: [2025-08-03 16:52:12]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2270
===> Epoch[20](200/2500): Loss: 0.2391
===> Epoch[20](300/2500): Loss: 0.2502
===> Epoch[20](400/2500): Loss: 0.2395
===> Epoch[20](500/2500): Loss: 0.2472
===> Epoch[20](600/2500): Loss: 0.2269
===> Epoch[20](700/2500): Loss: 0.2227
===> Epoch[20](800/2500): Loss: 0.2259
===> Epoch[20](900/2500): Loss: 0.2315
===> Epoch[20](1000/2500): Loss: 0.2235
===> Epoch[20](1100/2500): Loss: 0.2104
===> Epoch[20](1200/2500): Loss: 0.2334
===> Epoch[20](1300/2500): Loss: 0.2248
===> Epoch[20](1400/2500): Loss: 0.2367
===> Epoch[20](1500/2500): Loss: 0.2268
===> Epoch[20](1600/2500): Loss: 0.2258
===> Epoch[20](1700/2500): Loss: 0.2234
===> Epoch[20](1800/2500): Loss: 0.2198
===> Epoch[20](1900/2500): Loss: 0.2336
===> Epoch[20](2000/2500): Loss: 0.2094
===> Epoch[20](2100/2500): Loss: 0.2390
===> Epoch[20](2200/2500): Loss: 0.2159
===> Epoch[20](2300/2500): Loss: 0.2268
===> Epoch[20](2400/2500): Loss: 0.2387
===> Epoch[20](2500/2500): Loss: 0.2276
===> Epoch 20 Complete: Avg. Loss: 0.2322
===> Timestamp: [2025-08-03 16:52:12]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2213
===> Epoch[21](200/2500): Loss: 0.2429
===> Epoch[21](300/2500): Loss: 0.2509
===> Epoch[21](400/2500): Loss: 0.2065
===> Epoch[21](500/2500): Loss: 0.2300
===> Epoch[21](600/2500): Loss: 0.2196
===> Epoch[21](700/2500): Loss: 0.2548
===> Epoch[21](800/2500): Loss: 0.2369
===> Epoch[21](900/2500): Loss: 0.2552
===> Epoch[21](1000/2500): Loss: 0.2240
===> Epoch[21](1100/2500): Loss: 0.2254
===> Epoch[21](1200/2500): Loss: 0.2386
===> Epoch[21](1300/2500): Loss: 0.2383
===> Epoch[21](1400/2500): Loss: 0.2418
===> Epoch[21](1500/2500): Loss: 0.2215
===> Epoch[21](1600/2500): Loss: 0.2392
===> Epoch[21](1700/2500): Loss: 0.2446
===> Epoch[21](1800/2500): Loss: 0.2374
===> Epoch[21](1900/2500): Loss: 0.2284
===> Epoch[21](2000/2500): Loss: 0.2307
===> Epoch[21](2100/2500): Loss: 0.2277
===> Epoch[21](2200/2500): Loss: 0.2276
===> Epoch[21](2300/2500): Loss: 0.2182
===> Epoch[21](2400/2500): Loss: 0.2151
===> Epoch[21](2500/2500): Loss: 0.2219
===> Epoch 21 Complete: Avg. Loss: 0.2309
===> Timestamp: [2025-08-03 16:56:45]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2213
===> Epoch[21](200/2500): Loss: 0.2429
===> Epoch[21](300/2500): Loss: 0.2509
===> Epoch[21](400/2500): Loss: 0.2065
===> Epoch[21](500/2500): Loss: 0.2300
===> Epoch[21](600/2500): Loss: 0.2196
===> Epoch[21](700/2500): Loss: 0.2548
===> Epoch[21](800/2500): Loss: 0.2369
===> Epoch[21](900/2500): Loss: 0.2552
===> Epoch[21](1000/2500): Loss: 0.2240
===> Epoch[21](1100/2500): Loss: 0.2254
===> Epoch[21](1200/2500): Loss: 0.2386
===> Epoch[21](1300/2500): Loss: 0.2383
===> Epoch[21](1400/2500): Loss: 0.2418
===> Epoch[21](1500/2500): Loss: 0.2215
===> Epoch[21](1600/2500): Loss: 0.2392
===> Epoch[21](1700/2500): Loss: 0.2446
===> Epoch[21](1800/2500): Loss: 0.2374
===> Epoch[21](1900/2500): Loss: 0.2284
===> Epoch[21](2000/2500): Loss: 0.2307
===> Epoch[21](2100/2500): Loss: 0.2277
===> Epoch[21](2200/2500): Loss: 0.2276
===> Epoch[21](2300/2500): Loss: 0.2182
===> Epoch[21](2400/2500): Loss: 0.2151
===> Epoch[21](2500/2500): Loss: 0.2219
===> Epoch 21 Complete: Avg. Loss: 0.2309
===> Timestamp: [2025-08-03 16:56:45]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2213
===> Epoch[21](200/2500): Loss: 0.2429
===> Epoch[21](300/2500): Loss: 0.2509
===> Epoch[21](400/2500): Loss: 0.2065
===> Epoch[21](500/2500): Loss: 0.2300
===> Epoch[21](600/2500): Loss: 0.2196
===> Epoch[21](700/2500): Loss: 0.2548
===> Epoch[21](800/2500): Loss: 0.2369
===> Epoch[21](900/2500): Loss: 0.2552
===> Epoch[21](1000/2500): Loss: 0.2240
===> Epoch[21](1100/2500): Loss: 0.2254
===> Epoch[21](1200/2500): Loss: 0.2386
===> Epoch[21](1300/2500): Loss: 0.2383
===> Epoch[21](1400/2500): Loss: 0.2418
===> Epoch[21](1500/2500): Loss: 0.2215
===> Epoch[21](1600/2500): Loss: 0.2392
===> Epoch[21](1700/2500): Loss: 0.2446
===> Epoch[21](1800/2500): Loss: 0.2374
===> Epoch[21](1900/2500): Loss: 0.2284
===> Epoch[21](2000/2500): Loss: 0.2307
===> Epoch[21](2100/2500): Loss: 0.2277
===> Epoch[21](2200/2500): Loss: 0.2276
===> Epoch[21](2300/2500): Loss: 0.2182
===> Epoch[21](2400/2500): Loss: 0.2151
===> Epoch[21](2500/2500): Loss: 0.2219
===> Epoch 21 Complete: Avg. Loss: 0.2309
===> Timestamp: [2025-08-03 16:56:45]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2213
===> Epoch[21](200/2500): Loss: 0.2429
===> Epoch[21](300/2500): Loss: 0.2509
===> Epoch[21](400/2500): Loss: 0.2065
===> Epoch[21](500/2500): Loss: 0.2300
===> Epoch[21](600/2500): Loss: 0.2196
===> Epoch[21](700/2500): Loss: 0.2548
===> Epoch[21](800/2500): Loss: 0.2369
===> Epoch[21](900/2500): Loss: 0.2552
===> Epoch[21](1000/2500): Loss: 0.2240
===> Epoch[21](1100/2500): Loss: 0.2254
===> Epoch[21](1200/2500): Loss: 0.2386
===> Epoch[21](1300/2500): Loss: 0.2383
===> Epoch[21](1400/2500): Loss: 0.2418
===> Epoch[21](1500/2500): Loss: 0.2215
===> Epoch[21](1600/2500): Loss: 0.2392
===> Epoch[21](1700/2500): Loss: 0.2446
===> Epoch[21](1800/2500): Loss: 0.2374
===> Epoch[21](1900/2500): Loss: 0.2284
===> Epoch[21](2000/2500): Loss: 0.2307
===> Epoch[21](2100/2500): Loss: 0.2277
===> Epoch[21](2200/2500): Loss: 0.2276
===> Epoch[21](2300/2500): Loss: 0.2182
===> Epoch[21](2400/2500): Loss: 0.2151
===> Epoch[21](2500/2500): Loss: 0.2219
===> Epoch 21 Complete: Avg. Loss: 0.2309
===> Timestamp: [2025-08-03 16:56:45]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2213
===> Epoch[21](200/2500): Loss: 0.2429
===> Epoch[21](300/2500): Loss: 0.2509
===> Epoch[21](400/2500): Loss: 0.2065
===> Epoch[21](500/2500): Loss: 0.2300
===> Epoch[21](600/2500): Loss: 0.2196
===> Epoch[21](700/2500): Loss: 0.2548
===> Epoch[21](800/2500): Loss: 0.2369
===> Epoch[21](900/2500): Loss: 0.2552
===> Epoch[21](1000/2500): Loss: 0.2240
===> Epoch[21](1100/2500): Loss: 0.2254
===> Epoch[21](1200/2500): Loss: 0.2386
===> Epoch[21](1300/2500): Loss: 0.2383
===> Epoch[21](1400/2500): Loss: 0.2418
===> Epoch[21](1500/2500): Loss: 0.2215
===> Epoch[21](1600/2500): Loss: 0.2392
===> Epoch[21](1700/2500): Loss: 0.2446
===> Epoch[21](1800/2500): Loss: 0.2374
===> Epoch[21](1900/2500): Loss: 0.2284
===> Epoch[21](2000/2500): Loss: 0.2307
===> Epoch[21](2100/2500): Loss: 0.2277
===> Epoch[21](2200/2500): Loss: 0.2276
===> Epoch[21](2300/2500): Loss: 0.2182
===> Epoch[21](2400/2500): Loss: 0.2151
===> Epoch[21](2500/2500): Loss: 0.2219
===> Epoch 21 Complete: Avg. Loss: 0.2309
===> Timestamp: [2025-08-03 16:56:45]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2213
===> Epoch[21](200/2500): Loss: 0.2429
===> Epoch[21](300/2500): Loss: 0.2509
===> Epoch[21](400/2500): Loss: 0.2065
===> Epoch[21](500/2500): Loss: 0.2300
===> Epoch[21](600/2500): Loss: 0.2196
===> Epoch[21](700/2500): Loss: 0.2548
===> Epoch[21](800/2500): Loss: 0.2369
===> Epoch[21](900/2500): Loss: 0.2552
===> Epoch[21](1000/2500): Loss: 0.2240
===> Epoch[21](1100/2500): Loss: 0.2254
===> Epoch[21](1200/2500): Loss: 0.2386
===> Epoch[21](1300/2500): Loss: 0.2383
===> Epoch[21](1400/2500): Loss: 0.2418
===> Epoch[21](1500/2500): Loss: 0.2215
===> Epoch[21](1600/2500): Loss: 0.2392
===> Epoch[21](1700/2500): Loss: 0.2446
===> Epoch[21](1800/2500): Loss: 0.2374
===> Epoch[21](1900/2500): Loss: 0.2284
===> Epoch[21](2000/2500): Loss: 0.2307
===> Epoch[21](2100/2500): Loss: 0.2277
===> Epoch[21](2200/2500): Loss: 0.2276
===> Epoch[21](2300/2500): Loss: 0.2182
===> Epoch[21](2400/2500): Loss: 0.2151
===> Epoch[21](2500/2500): Loss: 0.2219
===> Epoch 21 Complete: Avg. Loss: 0.2309
===> Timestamp: [2025-08-03 16:56:45]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2213
===> Epoch[21](200/2500): Loss: 0.2429
===> Epoch[21](300/2500): Loss: 0.2509
===> Epoch[21](400/2500): Loss: 0.2065
===> Epoch[21](500/2500): Loss: 0.2300
===> Epoch[21](600/2500): Loss: 0.2196
===> Epoch[21](700/2500): Loss: 0.2548
===> Epoch[21](800/2500): Loss: 0.2369
===> Epoch[21](900/2500): Loss: 0.2552
===> Epoch[21](1000/2500): Loss: 0.2240
===> Epoch[21](1100/2500): Loss: 0.2254
===> Epoch[21](1200/2500): Loss: 0.2386
===> Epoch[21](1300/2500): Loss: 0.2383
===> Epoch[21](1400/2500): Loss: 0.2418
===> Epoch[21](1500/2500): Loss: 0.2215
===> Epoch[21](1600/2500): Loss: 0.2392
===> Epoch[21](1700/2500): Loss: 0.2446
===> Epoch[21](1800/2500): Loss: 0.2374
===> Epoch[21](1900/2500): Loss: 0.2284
===> Epoch[21](2000/2500): Loss: 0.2307
===> Epoch[21](2100/2500): Loss: 0.2277
===> Epoch[21](2200/2500): Loss: 0.2276
===> Epoch[21](2300/2500): Loss: 0.2182
===> Epoch[21](2400/2500): Loss: 0.2151
===> Epoch[21](2500/2500): Loss: 0.2219
===> Epoch 21 Complete: Avg. Loss: 0.2309
===> Timestamp: [2025-08-03 16:56:45]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2213
===> Epoch[21](200/2500): Loss: 0.2429
===> Epoch[21](300/2500): Loss: 0.2509
===> Epoch[21](400/2500): Loss: 0.2065
===> Epoch[21](500/2500): Loss: 0.2300
===> Epoch[21](600/2500): Loss: 0.2196
===> Epoch[21](700/2500): Loss: 0.2548
===> Epoch[21](800/2500): Loss: 0.2369
===> Epoch[21](900/2500): Loss: 0.2552
===> Epoch[21](1000/2500): Loss: 0.2240
===> Epoch[21](1100/2500): Loss: 0.2254
===> Epoch[21](1200/2500): Loss: 0.2386
===> Epoch[21](1300/2500): Loss: 0.2383
===> Epoch[21](1400/2500): Loss: 0.2418
===> Epoch[21](1500/2500): Loss: 0.2215
===> Epoch[21](1600/2500): Loss: 0.2392
===> Epoch[21](1700/2500): Loss: 0.2446
===> Epoch[21](1800/2500): Loss: 0.2374
===> Epoch[21](1900/2500): Loss: 0.2284
===> Epoch[21](2000/2500): Loss: 0.2307
===> Epoch[21](2100/2500): Loss: 0.2277
===> Epoch[21](2200/2500): Loss: 0.2276
===> Epoch[21](2300/2500): Loss: 0.2182
===> Epoch[21](2400/2500): Loss: 0.2151
===> Epoch[21](2500/2500): Loss: 0.2219
===> Epoch 21 Complete: Avg. Loss: 0.2309
===> Timestamp: [2025-08-03 16:56:45]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2213
===> Epoch[21](200/2500): Loss: 0.2429
===> Epoch[21](300/2500): Loss: 0.2509
===> Epoch[21](400/2500): Loss: 0.2065
===> Epoch[21](500/2500): Loss: 0.2300
===> Epoch[21](600/2500): Loss: 0.2196
===> Epoch[21](700/2500): Loss: 0.2548
===> Epoch[21](800/2500): Loss: 0.2369
===> Epoch[21](900/2500): Loss: 0.2552
===> Epoch[21](1000/2500): Loss: 0.2240
===> Epoch[21](1100/2500): Loss: 0.2254
===> Epoch[21](1200/2500): Loss: 0.2386
===> Epoch[21](1300/2500): Loss: 0.2383
===> Epoch[21](1400/2500): Loss: 0.2418
===> Epoch[21](1500/2500): Loss: 0.2215
===> Epoch[21](1600/2500): Loss: 0.2392
===> Epoch[21](1700/2500): Loss: 0.2446
===> Epoch[21](1800/2500): Loss: 0.2374
===> Epoch[21](1900/2500): Loss: 0.2284
===> Epoch[21](2000/2500): Loss: 0.2307
===> Epoch[21](2100/2500): Loss: 0.2277
===> Epoch[21](2200/2500): Loss: 0.2276
===> Epoch[21](2300/2500): Loss: 0.2182
===> Epoch[21](2400/2500): Loss: 0.2151
===> Epoch[21](2500/2500): Loss: 0.2219
===> Epoch 21 Complete: Avg. Loss: 0.2309
===> Timestamp: [2025-08-03 16:56:45]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2213
===> Epoch[21](200/2500): Loss: 0.2429
===> Epoch[21](300/2500): Loss: 0.2509
===> Epoch[21](400/2500): Loss: 0.2065
===> Epoch[21](500/2500): Loss: 0.2300
===> Epoch[21](600/2500): Loss: 0.2196
===> Epoch[21](700/2500): Loss: 0.2548
===> Epoch[21](800/2500): Loss: 0.2369
===> Epoch[21](900/2500): Loss: 0.2552
===> Epoch[21](1000/2500): Loss: 0.2240
===> Epoch[21](1100/2500): Loss: 0.2254
===> Epoch[21](1200/2500): Loss: 0.2386
===> Epoch[21](1300/2500): Loss: 0.2383
===> Epoch[21](1400/2500): Loss: 0.2418
===> Epoch[21](1500/2500): Loss: 0.2215
===> Epoch[21](1600/2500): Loss: 0.2392
===> Epoch[21](1700/2500): Loss: 0.2446
===> Epoch[21](1800/2500): Loss: 0.2374
===> Epoch[21](1900/2500): Loss: 0.2284
===> Epoch[21](2000/2500): Loss: 0.2307
===> Epoch[21](2100/2500): Loss: 0.2277
===> Epoch[21](2200/2500): Loss: 0.2276
===> Epoch[21](2300/2500): Loss: 0.2182
===> Epoch[21](2400/2500): Loss: 0.2151
===> Epoch[21](2500/2500): Loss: 0.2219
===> Epoch 21 Complete: Avg. Loss: 0.2309
===> Timestamp: [2025-08-03 16:56:45]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2213
===> Epoch[21](200/2500): Loss: 0.2429
===> Epoch[21](300/2500): Loss: 0.2509
===> Epoch[21](400/2500): Loss: 0.2065
===> Epoch[21](500/2500): Loss: 0.2300
===> Epoch[21](600/2500): Loss: 0.2196
===> Epoch[21](700/2500): Loss: 0.2548
===> Epoch[21](800/2500): Loss: 0.2369
===> Epoch[21](900/2500): Loss: 0.2552
===> Epoch[21](1000/2500): Loss: 0.2240
===> Epoch[21](1100/2500): Loss: 0.2254
===> Epoch[21](1200/2500): Loss: 0.2386
===> Epoch[21](1300/2500): Loss: 0.2383
===> Epoch[21](1400/2500): Loss: 0.2418
===> Epoch[21](1500/2500): Loss: 0.2215
===> Epoch[21](1600/2500): Loss: 0.2392
===> Epoch[21](1700/2500): Loss: 0.2446
===> Epoch[21](1800/2500): Loss: 0.2374
===> Epoch[21](1900/2500): Loss: 0.2284
===> Epoch[21](2000/2500): Loss: 0.2307
===> Epoch[21](2100/2500): Loss: 0.2277
===> Epoch[21](2200/2500): Loss: 0.2276
===> Epoch[21](2300/2500): Loss: 0.2182
===> Epoch[21](2400/2500): Loss: 0.2151
===> Epoch[21](2500/2500): Loss: 0.2219
===> Epoch 21 Complete: Avg. Loss: 0.2309
===> Timestamp: [2025-08-03 16:56:45]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2213
===> Epoch[21](200/2500): Loss: 0.2429
===> Epoch[21](300/2500): Loss: 0.2509
===> Epoch[21](400/2500): Loss: 0.2065
===> Epoch[21](500/2500): Loss: 0.2300
===> Epoch[21](600/2500): Loss: 0.2196
===> Epoch[21](700/2500): Loss: 0.2548
===> Epoch[21](800/2500): Loss: 0.2369
===> Epoch[21](900/2500): Loss: 0.2552
===> Epoch[21](1000/2500): Loss: 0.2240
===> Epoch[21](1100/2500): Loss: 0.2254
===> Epoch[21](1200/2500): Loss: 0.2386
===> Epoch[21](1300/2500): Loss: 0.2383
===> Epoch[21](1400/2500): Loss: 0.2418
===> Epoch[21](1500/2500): Loss: 0.2215
===> Epoch[21](1600/2500): Loss: 0.2392
===> Epoch[21](1700/2500): Loss: 0.2446
===> Epoch[21](1800/2500): Loss: 0.2374
===> Epoch[21](1900/2500): Loss: 0.2284
===> Epoch[21](2000/2500): Loss: 0.2307
===> Epoch[21](2100/2500): Loss: 0.2277
===> Epoch[21](2200/2500): Loss: 0.2276
===> Epoch[21](2300/2500): Loss: 0.2182
===> Epoch[21](2400/2500): Loss: 0.2151
===> Epoch[21](2500/2500): Loss: 0.2219
===> Epoch 21 Complete: Avg. Loss: 0.2309
===> Timestamp: [2025-08-03 16:56:45]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2213
===> Epoch[21](200/2500): Loss: 0.2429
===> Epoch[21](300/2500): Loss: 0.2509
===> Epoch[21](400/2500): Loss: 0.2065
===> Epoch[21](500/2500): Loss: 0.2300
===> Epoch[21](600/2500): Loss: 0.2196
===> Epoch[21](700/2500): Loss: 0.2548
===> Epoch[21](800/2500): Loss: 0.2369
===> Epoch[21](900/2500): Loss: 0.2552
===> Epoch[21](1000/2500): Loss: 0.2240
===> Epoch[21](1100/2500): Loss: 0.2254
===> Epoch[21](1200/2500): Loss: 0.2386
===> Epoch[21](1300/2500): Loss: 0.2383
===> Epoch[21](1400/2500): Loss: 0.2418
===> Epoch[21](1500/2500): Loss: 0.2215
===> Epoch[21](1600/2500): Loss: 0.2392
===> Epoch[21](1700/2500): Loss: 0.2446
===> Epoch[21](1800/2500): Loss: 0.2374
===> Epoch[21](1900/2500): Loss: 0.2284
===> Epoch[21](2000/2500): Loss: 0.2307
===> Epoch[21](2100/2500): Loss: 0.2277
===> Epoch[21](2200/2500): Loss: 0.2276
===> Epoch[21](2300/2500): Loss: 0.2182
===> Epoch[21](2400/2500): Loss: 0.2151
===> Epoch[21](2500/2500): Loss: 0.2219
===> Epoch 21 Complete: Avg. Loss: 0.2309
===> Timestamp: [2025-08-03 16:56:45]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2213
===> Epoch[21](200/2500): Loss: 0.2429
===> Epoch[21](300/2500): Loss: 0.2509
===> Epoch[21](400/2500): Loss: 0.2065
===> Epoch[21](500/2500): Loss: 0.2300
===> Epoch[21](600/2500): Loss: 0.2196
===> Epoch[21](700/2500): Loss: 0.2548
===> Epoch[21](800/2500): Loss: 0.2369
===> Epoch[21](900/2500): Loss: 0.2552
===> Epoch[21](1000/2500): Loss: 0.2240
===> Epoch[21](1100/2500): Loss: 0.2254
===> Epoch[21](1200/2500): Loss: 0.2386
===> Epoch[21](1300/2500): Loss: 0.2383
===> Epoch[21](1400/2500): Loss: 0.2418
===> Epoch[21](1500/2500): Loss: 0.2215
===> Epoch[21](1600/2500): Loss: 0.2392
===> Epoch[21](1700/2500): Loss: 0.2446
===> Epoch[21](1800/2500): Loss: 0.2374
===> Epoch[21](1900/2500): Loss: 0.2284
===> Epoch[21](2000/2500): Loss: 0.2307
===> Epoch[21](2100/2500): Loss: 0.2277
===> Epoch[21](2200/2500): Loss: 0.2276
===> Epoch[21](2300/2500): Loss: 0.2182
===> Epoch[21](2400/2500): Loss: 0.2151
===> Epoch[21](2500/2500): Loss: 0.2219
===> Epoch 21 Complete: Avg. Loss: 0.2309
===> Timestamp: [2025-08-03 16:56:45]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2213
===> Epoch[21](200/2500): Loss: 0.2429
===> Epoch[21](300/2500): Loss: 0.2509
===> Epoch[21](400/2500): Loss: 0.2065
===> Epoch[21](500/2500): Loss: 0.2300
===> Epoch[21](600/2500): Loss: 0.2196
===> Epoch[21](700/2500): Loss: 0.2548
===> Epoch[21](800/2500): Loss: 0.2369
===> Epoch[21](900/2500): Loss: 0.2552
===> Epoch[21](1000/2500): Loss: 0.2240
===> Epoch[21](1100/2500): Loss: 0.2254
===> Epoch[21](1200/2500): Loss: 0.2386
===> Epoch[21](1300/2500): Loss: 0.2383
===> Epoch[21](1400/2500): Loss: 0.2418
===> Epoch[21](1500/2500): Loss: 0.2215
===> Epoch[21](1600/2500): Loss: 0.2392
===> Epoch[21](1700/2500): Loss: 0.2446
===> Epoch[21](1800/2500): Loss: 0.2374
===> Epoch[21](1900/2500): Loss: 0.2284
===> Epoch[21](2000/2500): Loss: 0.2307
===> Epoch[21](2100/2500): Loss: 0.2277
===> Epoch[21](2200/2500): Loss: 0.2276
===> Epoch[21](2300/2500): Loss: 0.2182
===> Epoch[21](2400/2500): Loss: 0.2151
===> Epoch[21](2500/2500): Loss: 0.2219
===> Epoch 21 Complete: Avg. Loss: 0.2309
===> Timestamp: [2025-08-03 16:56:45]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2213
===> Epoch[21](200/2500): Loss: 0.2429
===> Epoch[21](300/2500): Loss: 0.2509
===> Epoch[21](400/2500): Loss: 0.2065
===> Epoch[21](500/2500): Loss: 0.2300
===> Epoch[21](600/2500): Loss: 0.2196
===> Epoch[21](700/2500): Loss: 0.2548
===> Epoch[21](800/2500): Loss: 0.2369
===> Epoch[21](900/2500): Loss: 0.2552
===> Epoch[21](1000/2500): Loss: 0.2240
===> Epoch[21](1100/2500): Loss: 0.2254
===> Epoch[21](1200/2500): Loss: 0.2386
===> Epoch[21](1300/2500): Loss: 0.2383
===> Epoch[21](1400/2500): Loss: 0.2418
===> Epoch[21](1500/2500): Loss: 0.2215
===> Epoch[21](1600/2500): Loss: 0.2392
===> Epoch[21](1700/2500): Loss: 0.2446
===> Epoch[21](1800/2500): Loss: 0.2374
===> Epoch[21](1900/2500): Loss: 0.2284
===> Epoch[21](2000/2500): Loss: 0.2307
===> Epoch[21](2100/2500): Loss: 0.2277
===> Epoch[21](2200/2500): Loss: 0.2276
===> Epoch[21](2300/2500): Loss: 0.2182
===> Epoch[21](2400/2500): Loss: 0.2151
===> Epoch[21](2500/2500): Loss: 0.2219
===> Epoch 21 Complete: Avg. Loss: 0.2309
===> Timestamp: [2025-08-03 16:56:45]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2213
===> Epoch[21](200/2500): Loss: 0.2429
===> Epoch[21](300/2500): Loss: 0.2509
===> Epoch[21](400/2500): Loss: 0.2065
===> Epoch[21](500/2500): Loss: 0.2300
===> Epoch[21](600/2500): Loss: 0.2196
===> Epoch[21](700/2500): Loss: 0.2548
===> Epoch[21](800/2500): Loss: 0.2369
===> Epoch[21](900/2500): Loss: 0.2552
===> Epoch[21](1000/2500): Loss: 0.2240
===> Epoch[21](1100/2500): Loss: 0.2254
===> Epoch[21](1200/2500): Loss: 0.2386
===> Epoch[21](1300/2500): Loss: 0.2383
===> Epoch[21](1400/2500): Loss: 0.2418
===> Epoch[21](1500/2500): Loss: 0.2215
===> Epoch[21](1600/2500): Loss: 0.2392
===> Epoch[21](1700/2500): Loss: 0.2446
===> Epoch[21](1800/2500): Loss: 0.2374
===> Epoch[21](1900/2500): Loss: 0.2284
===> Epoch[21](2000/2500): Loss: 0.2307
===> Epoch[21](2100/2500): Loss: 0.2277
===> Epoch[21](2200/2500): Loss: 0.2276
===> Epoch[21](2300/2500): Loss: 0.2182
===> Epoch[21](2400/2500): Loss: 0.2151
===> Epoch[21](2500/2500): Loss: 0.2219
===> Epoch 21 Complete: Avg. Loss: 0.2309
===> Timestamp: [2025-08-03 16:56:45]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2213
===> Epoch[21](200/2500): Loss: 0.2429
===> Epoch[21](300/2500): Loss: 0.2509
===> Epoch[21](400/2500): Loss: 0.2065
===> Epoch[21](500/2500): Loss: 0.2300
===> Epoch[21](600/2500): Loss: 0.2196
===> Epoch[21](700/2500): Loss: 0.2548
===> Epoch[21](800/2500): Loss: 0.2369
===> Epoch[21](900/2500): Loss: 0.2552
===> Epoch[21](1000/2500): Loss: 0.2240
===> Epoch[21](1100/2500): Loss: 0.2254
===> Epoch[21](1200/2500): Loss: 0.2386
===> Epoch[21](1300/2500): Loss: 0.2383
===> Epoch[21](1400/2500): Loss: 0.2418
===> Epoch[21](1500/2500): Loss: 0.2215
===> Epoch[21](1600/2500): Loss: 0.2392
===> Epoch[21](1700/2500): Loss: 0.2446
===> Epoch[21](1800/2500): Loss: 0.2374
===> Epoch[21](1900/2500): Loss: 0.2284
===> Epoch[21](2000/2500): Loss: 0.2307
===> Epoch[21](2100/2500): Loss: 0.2277
===> Epoch[21](2200/2500): Loss: 0.2276
===> Epoch[21](2300/2500): Loss: 0.2182
===> Epoch[21](2400/2500): Loss: 0.2151
===> Epoch[21](2500/2500): Loss: 0.2219
===> Epoch 21 Complete: Avg. Loss: 0.2309
===> Timestamp: [2025-08-03 16:56:45]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2213
===> Epoch[21](200/2500): Loss: 0.2429
===> Epoch[21](300/2500): Loss: 0.2509
===> Epoch[21](400/2500): Loss: 0.2065
===> Epoch[21](500/2500): Loss: 0.2300
===> Epoch[21](600/2500): Loss: 0.2196
===> Epoch[21](700/2500): Loss: 0.2548
===> Epoch[21](800/2500): Loss: 0.2369
===> Epoch[21](900/2500): Loss: 0.2552
===> Epoch[21](1000/2500): Loss: 0.2240
===> Epoch[21](1100/2500): Loss: 0.2254
===> Epoch[21](1200/2500): Loss: 0.2386
===> Epoch[21](1300/2500): Loss: 0.2383
===> Epoch[21](1400/2500): Loss: 0.2418
===> Epoch[21](1500/2500): Loss: 0.2215
===> Epoch[21](1600/2500): Loss: 0.2392
===> Epoch[21](1700/2500): Loss: 0.2446
===> Epoch[21](1800/2500): Loss: 0.2374
===> Epoch[21](1900/2500): Loss: 0.2284
===> Epoch[21](2000/2500): Loss: 0.2307
===> Epoch[21](2100/2500): Loss: 0.2277
===> Epoch[21](2200/2500): Loss: 0.2276
===> Epoch[21](2300/2500): Loss: 0.2182
===> Epoch[21](2400/2500): Loss: 0.2151
===> Epoch[21](2500/2500): Loss: 0.2219
===> Epoch 21 Complete: Avg. Loss: 0.2309
===> Timestamp: [2025-08-03 16:56:45]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2213
===> Epoch[21](200/2500): Loss: 0.2429
===> Epoch[21](300/2500): Loss: 0.2509
===> Epoch[21](400/2500): Loss: 0.2065
===> Epoch[21](500/2500): Loss: 0.2300
===> Epoch[21](600/2500): Loss: 0.2196
===> Epoch[21](700/2500): Loss: 0.2548
===> Epoch[21](800/2500): Loss: 0.2369
===> Epoch[21](900/2500): Loss: 0.2552
===> Epoch[21](1000/2500): Loss: 0.2240
===> Epoch[21](1100/2500): Loss: 0.2254
===> Epoch[21](1200/2500): Loss: 0.2386
===> Epoch[21](1300/2500): Loss: 0.2383
===> Epoch[21](1400/2500): Loss: 0.2418
===> Epoch[21](1500/2500): Loss: 0.2215
===> Epoch[21](1600/2500): Loss: 0.2392
===> Epoch[21](1700/2500): Loss: 0.2446
===> Epoch[21](1800/2500): Loss: 0.2374
===> Epoch[21](1900/2500): Loss: 0.2284
===> Epoch[21](2000/2500): Loss: 0.2307
===> Epoch[21](2100/2500): Loss: 0.2277
===> Epoch[21](2200/2500): Loss: 0.2276
===> Epoch[21](2300/2500): Loss: 0.2182
===> Epoch[21](2400/2500): Loss: 0.2151
===> Epoch[21](2500/2500): Loss: 0.2219
===> Epoch 21 Complete: Avg. Loss: 0.2309
===> Timestamp: [2025-08-03 16:56:45]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2213
===> Epoch[21](200/2500): Loss: 0.2429
===> Epoch[21](300/2500): Loss: 0.2509
===> Epoch[21](400/2500): Loss: 0.2065
===> Epoch[21](500/2500): Loss: 0.2300
===> Epoch[21](600/2500): Loss: 0.2196
===> Epoch[21](700/2500): Loss: 0.2548
===> Epoch[21](800/2500): Loss: 0.2369
===> Epoch[21](900/2500): Loss: 0.2552
===> Epoch[21](1000/2500): Loss: 0.2240
===> Epoch[21](1100/2500): Loss: 0.2254
===> Epoch[21](1200/2500): Loss: 0.2386
===> Epoch[21](1300/2500): Loss: 0.2383
===> Epoch[21](1400/2500): Loss: 0.2418
===> Epoch[21](1500/2500): Loss: 0.2215
===> Epoch[21](1600/2500): Loss: 0.2392
===> Epoch[21](1700/2500): Loss: 0.2446
===> Epoch[21](1800/2500): Loss: 0.2374
===> Epoch[21](1900/2500): Loss: 0.2284
===> Epoch[21](2000/2500): Loss: 0.2307
===> Epoch[21](2100/2500): Loss: 0.2277
===> Epoch[21](2200/2500): Loss: 0.2276
===> Epoch[21](2300/2500): Loss: 0.2182
===> Epoch[21](2400/2500): Loss: 0.2151
===> Epoch[21](2500/2500): Loss: 0.2219
===> Epoch 21 Complete: Avg. Loss: 0.2309
===> Timestamp: [2025-08-03 16:56:45]
===> Loading train datasets
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.2477
===> Epoch[22](200/2500): Loss: 0.2212
===> Epoch[22](300/2500): Loss: 0.2278
===> Epoch[22](400/2500): Loss: 0.2364
===> Epoch[22](500/2500): Loss: 0.2299
===> Epoch[22](600/2500): Loss: 0.2154
===> Epoch[22](700/2500): Loss: 0.2375
===> Epoch[22](800/2500): Loss: 0.2294
===> Epoch[22](900/2500): Loss: 0.2393
===> Epoch[22](1000/2500): Loss: 0.2300
===> Epoch[22](1100/2500): Loss: 0.2179
===> Epoch[22](1200/2500): Loss: 0.2475
===> Epoch[22](1300/2500): Loss: 0.2332
===> Epoch[22](1400/2500): Loss: 0.2434
===> Epoch[22](1500/2500): Loss: 0.2237
===> Epoch[22](1600/2500): Loss: 0.2396
===> Epoch[22](1700/2500): Loss: 0.2331
===> Epoch[22](1800/2500): Loss: 0.2375
===> Epoch[22](1900/2500): Loss: 0.2275
===> Epoch[22](2000/2500): Loss: 0.2151
===> Epoch[22](2100/2500): Loss: 0.2328
===> Epoch[22](2200/2500): Loss: 0.2205
===> Epoch[22](2300/2500): Loss: 0.2232
===> Epoch[22](2400/2500): Loss: 0.2239
===> Epoch[22](2500/2500): Loss: 0.2611
===> Epoch 22 Complete: Avg. Loss: 0.2296
===> Timestamp: [2025-08-03 17:01:19]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.2477
===> Epoch[22](200/2500): Loss: 0.2212
===> Epoch[22](300/2500): Loss: 0.2278
===> Epoch[22](400/2500): Loss: 0.2364
===> Epoch[22](500/2500): Loss: 0.2299
===> Epoch[22](600/2500): Loss: 0.2154
===> Epoch[22](700/2500): Loss: 0.2375
===> Epoch[22](800/2500): Loss: 0.2294
===> Epoch[22](900/2500): Loss: 0.2393
===> Epoch[22](1000/2500): Loss: 0.2300
===> Epoch[22](1100/2500): Loss: 0.2179
===> Epoch[22](1200/2500): Loss: 0.2475
===> Epoch[22](1300/2500): Loss: 0.2332
===> Epoch[22](1400/2500): Loss: 0.2434
===> Epoch[22](1500/2500): Loss: 0.2237
===> Epoch[22](1600/2500): Loss: 0.2396
===> Epoch[22](1700/2500): Loss: 0.2331
===> Epoch[22](1800/2500): Loss: 0.2375
===> Epoch[22](1900/2500): Loss: 0.2275
===> Epoch[22](2000/2500): Loss: 0.2151
===> Epoch[22](2100/2500): Loss: 0.2328
===> Epoch[22](2200/2500): Loss: 0.2205
===> Epoch[22](2300/2500): Loss: 0.2232
===> Epoch[22](2400/2500): Loss: 0.2239
===> Epoch[22](2500/2500): Loss: 0.2611
===> Epoch 22 Complete: Avg. Loss: 0.2296
===> Timestamp: [2025-08-03 17:01:19]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.2477
===> Epoch[22](200/2500): Loss: 0.2212
===> Epoch[22](300/2500): Loss: 0.2278
===> Epoch[22](400/2500): Loss: 0.2364
===> Epoch[22](500/2500): Loss: 0.2299
===> Epoch[22](600/2500): Loss: 0.2154
===> Epoch[22](700/2500): Loss: 0.2375
===> Epoch[22](800/2500): Loss: 0.2294
===> Epoch[22](900/2500): Loss: 0.2393
===> Epoch[22](1000/2500): Loss: 0.2300
===> Epoch[22](1100/2500): Loss: 0.2179
===> Epoch[22](1200/2500): Loss: 0.2475
===> Epoch[22](1300/2500): Loss: 0.2332
===> Epoch[22](1400/2500): Loss: 0.2434
===> Epoch[22](1500/2500): Loss: 0.2237
===> Epoch[22](1600/2500): Loss: 0.2396
===> Epoch[22](1700/2500): Loss: 0.2331
===> Epoch[22](1800/2500): Loss: 0.2375
===> Epoch[22](1900/2500): Loss: 0.2275
===> Epoch[22](2000/2500): Loss: 0.2151
===> Epoch[22](2100/2500): Loss: 0.2328
===> Epoch[22](2200/2500): Loss: 0.2205
===> Epoch[22](2300/2500): Loss: 0.2232
===> Epoch[22](2400/2500): Loss: 0.2239
===> Epoch[22](2500/2500): Loss: 0.2611
===> Epoch 22 Complete: Avg. Loss: 0.2296
===> Timestamp: [2025-08-03 17:01:19]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.2477
===> Epoch[22](200/2500): Loss: 0.2212
===> Epoch[22](300/2500): Loss: 0.2278
===> Epoch[22](400/2500): Loss: 0.2364
===> Epoch[22](500/2500): Loss: 0.2299
===> Epoch[22](600/2500): Loss: 0.2154
===> Epoch[22](700/2500): Loss: 0.2375
===> Epoch[22](800/2500): Loss: 0.2294
===> Epoch[22](900/2500): Loss: 0.2393
===> Epoch[22](1000/2500): Loss: 0.2300
===> Epoch[22](1100/2500): Loss: 0.2179
===> Epoch[22](1200/2500): Loss: 0.2475
===> Epoch[22](1300/2500): Loss: 0.2332
===> Epoch[22](1400/2500): Loss: 0.2434
===> Epoch[22](1500/2500): Loss: 0.2237
===> Epoch[22](1600/2500): Loss: 0.2396
===> Epoch[22](1700/2500): Loss: 0.2331
===> Epoch[22](1800/2500): Loss: 0.2375
===> Epoch[22](1900/2500): Loss: 0.2275
===> Epoch[22](2000/2500): Loss: 0.2151
===> Epoch[22](2100/2500): Loss: 0.2328
===> Epoch[22](2200/2500): Loss: 0.2205
===> Epoch[22](2300/2500): Loss: 0.2232
===> Epoch[22](2400/2500): Loss: 0.2239
===> Epoch[22](2500/2500): Loss: 0.2611
===> Epoch 22 Complete: Avg. Loss: 0.2296
===> Timestamp: [2025-08-03 17:01:19]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.2477
===> Epoch[22](200/2500): Loss: 0.2212
===> Epoch[22](300/2500): Loss: 0.2278
===> Epoch[22](400/2500): Loss: 0.2364
===> Epoch[22](500/2500): Loss: 0.2299
===> Epoch[22](600/2500): Loss: 0.2154
===> Epoch[22](700/2500): Loss: 0.2375
===> Epoch[22](800/2500): Loss: 0.2294
===> Epoch[22](900/2500): Loss: 0.2393
===> Epoch[22](1000/2500): Loss: 0.2300
===> Epoch[22](1100/2500): Loss: 0.2179
===> Epoch[22](1200/2500): Loss: 0.2475
===> Epoch[22](1300/2500): Loss: 0.2332
===> Epoch[22](1400/2500): Loss: 0.2434
===> Epoch[22](1500/2500): Loss: 0.2237
===> Epoch[22](1600/2500): Loss: 0.2396
===> Epoch[22](1700/2500): Loss: 0.2331
===> Epoch[22](1800/2500): Loss: 0.2375
===> Epoch[22](1900/2500): Loss: 0.2275
===> Epoch[22](2000/2500): Loss: 0.2151
===> Epoch[22](2100/2500): Loss: 0.2328
===> Epoch[22](2200/2500): Loss: 0.2205
===> Epoch[22](2300/2500): Loss: 0.2232
===> Epoch[22](2400/2500): Loss: 0.2239
===> Epoch[22](2500/2500): Loss: 0.2611
===> Epoch 22 Complete: Avg. Loss: 0.2296
===> Timestamp: [2025-08-03 17:01:19]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.2477
===> Epoch[22](200/2500): Loss: 0.2212
===> Epoch[22](300/2500): Loss: 0.2278
===> Epoch[22](400/2500): Loss: 0.2364
===> Epoch[22](500/2500): Loss: 0.2299
===> Epoch[22](600/2500): Loss: 0.2154
===> Epoch[22](700/2500): Loss: 0.2375
===> Epoch[22](800/2500): Loss: 0.2294
===> Epoch[22](900/2500): Loss: 0.2393
===> Epoch[22](1000/2500): Loss: 0.2300
===> Epoch[22](1100/2500): Loss: 0.2179
===> Epoch[22](1200/2500): Loss: 0.2475
===> Epoch[22](1300/2500): Loss: 0.2332
===> Epoch[22](1400/2500): Loss: 0.2434
===> Epoch[22](1500/2500): Loss: 0.2237
===> Epoch[22](1600/2500): Loss: 0.2396
===> Epoch[22](1700/2500): Loss: 0.2331
===> Epoch[22](1800/2500): Loss: 0.2375
===> Epoch[22](1900/2500): Loss: 0.2275
===> Epoch[22](2000/2500): Loss: 0.2151
===> Epoch[22](2100/2500): Loss: 0.2328
===> Epoch[22](2200/2500): Loss: 0.2205
===> Epoch[22](2300/2500): Loss: 0.2232
===> Epoch[22](2400/2500): Loss: 0.2239
===> Epoch[22](2500/2500): Loss: 0.2611
===> Epoch 22 Complete: Avg. Loss: 0.2296
===> Timestamp: [2025-08-03 17:01:19]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.2477
===> Epoch[22](200/2500): Loss: 0.2212
===> Epoch[22](300/2500): Loss: 0.2278
===> Epoch[22](400/2500): Loss: 0.2364
===> Epoch[22](500/2500): Loss: 0.2299
===> Epoch[22](600/2500): Loss: 0.2154
===> Epoch[22](700/2500): Loss: 0.2375
===> Epoch[22](800/2500): Loss: 0.2294
===> Epoch[22](900/2500): Loss: 0.2393
===> Epoch[22](1000/2500): Loss: 0.2300
===> Epoch[22](1100/2500): Loss: 0.2179
===> Epoch[22](1200/2500): Loss: 0.2475
===> Epoch[22](1300/2500): Loss: 0.2332
===> Epoch[22](1400/2500): Loss: 0.2434
===> Epoch[22](1500/2500): Loss: 0.2237
===> Epoch[22](1600/2500): Loss: 0.2396
===> Epoch[22](1700/2500): Loss: 0.2331
===> Epoch[22](1800/2500): Loss: 0.2375
===> Epoch[22](1900/2500): Loss: 0.2275
===> Epoch[22](2000/2500): Loss: 0.2151
===> Epoch[22](2100/2500): Loss: 0.2328
===> Epoch[22](2200/2500): Loss: 0.2205
===> Epoch[22](2300/2500): Loss: 0.2232
===> Epoch[22](2400/2500): Loss: 0.2239
===> Epoch[22](2500/2500): Loss: 0.2611
===> Epoch 22 Complete: Avg. Loss: 0.2296
===> Timestamp: [2025-08-03 17:01:19]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.2477
===> Epoch[22](200/2500): Loss: 0.2212
===> Epoch[22](300/2500): Loss: 0.2278
===> Epoch[22](400/2500): Loss: 0.2364
===> Epoch[22](500/2500): Loss: 0.2299
===> Epoch[22](600/2500): Loss: 0.2154
===> Epoch[22](700/2500): Loss: 0.2375
===> Epoch[22](800/2500): Loss: 0.2294
===> Epoch[22](900/2500): Loss: 0.2393
===> Epoch[22](1000/2500): Loss: 0.2300
===> Epoch[22](1100/2500): Loss: 0.2179
===> Epoch[22](1200/2500): Loss: 0.2475
===> Epoch[22](1300/2500): Loss: 0.2332
===> Epoch[22](1400/2500): Loss: 0.2434
===> Epoch[22](1500/2500): Loss: 0.2237
===> Epoch[22](1600/2500): Loss: 0.2396
===> Epoch[22](1700/2500): Loss: 0.2331
===> Epoch[22](1800/2500): Loss: 0.2375
===> Epoch[22](1900/2500): Loss: 0.2275
===> Epoch[22](2000/2500): Loss: 0.2151
===> Epoch[22](2100/2500): Loss: 0.2328
===> Epoch[22](2200/2500): Loss: 0.2205
===> Epoch[22](2300/2500): Loss: 0.2232
===> Epoch[22](2400/2500): Loss: 0.2239
===> Epoch[22](2500/2500): Loss: 0.2611
===> Epoch 22 Complete: Avg. Loss: 0.2296
===> Timestamp: [2025-08-03 17:01:19]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.2477
===> Epoch[22](200/2500): Loss: 0.2212
===> Epoch[22](300/2500): Loss: 0.2278
===> Epoch[22](400/2500): Loss: 0.2364
===> Epoch[22](500/2500): Loss: 0.2299
===> Epoch[22](600/2500): Loss: 0.2154
===> Epoch[22](700/2500): Loss: 0.2375
===> Epoch[22](800/2500): Loss: 0.2294
===> Epoch[22](900/2500): Loss: 0.2393
===> Epoch[22](1000/2500): Loss: 0.2300
===> Epoch[22](1100/2500): Loss: 0.2179
===> Epoch[22](1200/2500): Loss: 0.2475
===> Epoch[22](1300/2500): Loss: 0.2332
===> Epoch[22](1400/2500): Loss: 0.2434
===> Epoch[22](1500/2500): Loss: 0.2237
===> Epoch[22](1600/2500): Loss: 0.2396
===> Epoch[22](1700/2500): Loss: 0.2331
===> Epoch[22](1800/2500): Loss: 0.2375
===> Epoch[22](1900/2500): Loss: 0.2275
===> Epoch[22](2000/2500): Loss: 0.2151
===> Epoch[22](2100/2500): Loss: 0.2328
===> Epoch[22](2200/2500): Loss: 0.2205
===> Epoch[22](2300/2500): Loss: 0.2232
===> Epoch[22](2400/2500): Loss: 0.2239
===> Epoch[22](2500/2500): Loss: 0.2611
===> Epoch 22 Complete: Avg. Loss: 0.2296
===> Timestamp: [2025-08-03 17:01:19]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.2477
===> Epoch[22](200/2500): Loss: 0.2212
===> Epoch[22](300/2500): Loss: 0.2278
===> Epoch[22](400/2500): Loss: 0.2364
===> Epoch[22](500/2500): Loss: 0.2299
===> Epoch[22](600/2500): Loss: 0.2154
===> Epoch[22](700/2500): Loss: 0.2375
===> Epoch[22](800/2500): Loss: 0.2294
===> Epoch[22](900/2500): Loss: 0.2393
===> Epoch[22](1000/2500): Loss: 0.2300
===> Epoch[22](1100/2500): Loss: 0.2179
===> Epoch[22](1200/2500): Loss: 0.2475
===> Epoch[22](1300/2500): Loss: 0.2332
===> Epoch[22](1400/2500): Loss: 0.2434
===> Epoch[22](1500/2500): Loss: 0.2237
===> Epoch[22](1600/2500): Loss: 0.2396
===> Epoch[22](1700/2500): Loss: 0.2331
===> Epoch[22](1800/2500): Loss: 0.2375
===> Epoch[22](1900/2500): Loss: 0.2275
===> Epoch[22](2000/2500): Loss: 0.2151
===> Epoch[22](2100/2500): Loss: 0.2328
===> Epoch[22](2200/2500): Loss: 0.2205
===> Epoch[22](2300/2500): Loss: 0.2232
===> Epoch[22](2400/2500): Loss: 0.2239
===> Epoch[22](2500/2500): Loss: 0.2611
===> Epoch 22 Complete: Avg. Loss: 0.2296
===> Timestamp: [2025-08-03 17:01:19]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.2477
===> Epoch[22](200/2500): Loss: 0.2212
===> Epoch[22](300/2500): Loss: 0.2278
===> Epoch[22](400/2500): Loss: 0.2364
===> Epoch[22](500/2500): Loss: 0.2299
===> Epoch[22](600/2500): Loss: 0.2154
===> Epoch[22](700/2500): Loss: 0.2375
===> Epoch[22](800/2500): Loss: 0.2294
===> Epoch[22](900/2500): Loss: 0.2393
===> Epoch[22](1000/2500): Loss: 0.2300
===> Epoch[22](1100/2500): Loss: 0.2179
===> Epoch[22](1200/2500): Loss: 0.2475
===> Epoch[22](1300/2500): Loss: 0.2332
===> Epoch[22](1400/2500): Loss: 0.2434
===> Epoch[22](1500/2500): Loss: 0.2237
===> Epoch[22](1600/2500): Loss: 0.2396
===> Epoch[22](1700/2500): Loss: 0.2331
===> Epoch[22](1800/2500): Loss: 0.2375
===> Epoch[22](1900/2500): Loss: 0.2275
===> Epoch[22](2000/2500): Loss: 0.2151
===> Epoch[22](2100/2500): Loss: 0.2328
===> Epoch[22](2200/2500): Loss: 0.2205
===> Epoch[22](2300/2500): Loss: 0.2232
===> Epoch[22](2400/2500): Loss: 0.2239
===> Epoch[22](2500/2500): Loss: 0.2611
===> Epoch 22 Complete: Avg. Loss: 0.2296
===> Timestamp: [2025-08-03 17:01:19]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.2477
===> Epoch[22](200/2500): Loss: 0.2212
===> Epoch[22](300/2500): Loss: 0.2278
===> Epoch[22](400/2500): Loss: 0.2364
===> Epoch[22](500/2500): Loss: 0.2299
===> Epoch[22](600/2500): Loss: 0.2154
===> Epoch[22](700/2500): Loss: 0.2375
===> Epoch[22](800/2500): Loss: 0.2294
===> Epoch[22](900/2500): Loss: 0.2393
===> Epoch[22](1000/2500): Loss: 0.2300
===> Epoch[22](1100/2500): Loss: 0.2179
===> Epoch[22](1200/2500): Loss: 0.2475
===> Epoch[22](1300/2500): Loss: 0.2332
===> Epoch[22](1400/2500): Loss: 0.2434
===> Epoch[22](1500/2500): Loss: 0.2237
===> Epoch[22](1600/2500): Loss: 0.2396
===> Epoch[22](1700/2500): Loss: 0.2331
===> Epoch[22](1800/2500): Loss: 0.2375
===> Epoch[22](1900/2500): Loss: 0.2275
===> Epoch[22](2000/2500): Loss: 0.2151
===> Epoch[22](2100/2500): Loss: 0.2328
===> Epoch[22](2200/2500): Loss: 0.2205
===> Epoch[22](2300/2500): Loss: 0.2232
===> Epoch[22](2400/2500): Loss: 0.2239
===> Epoch[22](2500/2500): Loss: 0.2611
===> Epoch 22 Complete: Avg. Loss: 0.2296
===> Timestamp: [2025-08-03 17:01:19]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.2477
===> Epoch[22](200/2500): Loss: 0.2212
===> Epoch[22](300/2500): Loss: 0.2278
===> Epoch[22](400/2500): Loss: 0.2364
===> Epoch[22](500/2500): Loss: 0.2299
===> Epoch[22](600/2500): Loss: 0.2154
===> Epoch[22](700/2500): Loss: 0.2375
===> Epoch[22](800/2500): Loss: 0.2294
===> Epoch[22](900/2500): Loss: 0.2393
===> Epoch[22](1000/2500): Loss: 0.2300
===> Epoch[22](1100/2500): Loss: 0.2179
===> Epoch[22](1200/2500): Loss: 0.2475
===> Epoch[22](1300/2500): Loss: 0.2332
===> Epoch[22](1400/2500): Loss: 0.2434
===> Epoch[22](1500/2500): Loss: 0.2237
===> Epoch[22](1600/2500): Loss: 0.2396
===> Epoch[22](1700/2500): Loss: 0.2331
===> Epoch[22](1800/2500): Loss: 0.2375
===> Epoch[22](1900/2500): Loss: 0.2275
===> Epoch[22](2000/2500): Loss: 0.2151
===> Epoch[22](2100/2500): Loss: 0.2328
===> Epoch[22](2200/2500): Loss: 0.2205
===> Epoch[22](2300/2500): Loss: 0.2232
===> Epoch[22](2400/2500): Loss: 0.2239
===> Epoch[22](2500/2500): Loss: 0.2611
===> Epoch 22 Complete: Avg. Loss: 0.2296
===> Timestamp: [2025-08-03 17:01:19]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.2477
===> Epoch[22](200/2500): Loss: 0.2212
===> Epoch[22](300/2500): Loss: 0.2278
===> Epoch[22](400/2500): Loss: 0.2364
===> Epoch[22](500/2500): Loss: 0.2299
===> Epoch[22](600/2500): Loss: 0.2154
===> Epoch[22](700/2500): Loss: 0.2375
===> Epoch[22](800/2500): Loss: 0.2294
===> Epoch[22](900/2500): Loss: 0.2393
===> Epoch[22](1000/2500): Loss: 0.2300
===> Epoch[22](1100/2500): Loss: 0.2179
===> Epoch[22](1200/2500): Loss: 0.2475
===> Epoch[22](1300/2500): Loss: 0.2332
===> Epoch[22](1400/2500): Loss: 0.2434
===> Epoch[22](1500/2500): Loss: 0.2237
===> Epoch[22](1600/2500): Loss: 0.2396
===> Epoch[22](1700/2500): Loss: 0.2331
===> Epoch[22](1800/2500): Loss: 0.2375
===> Epoch[22](1900/2500): Loss: 0.2275
===> Epoch[22](2000/2500): Loss: 0.2151
===> Epoch[22](2100/2500): Loss: 0.2328
===> Epoch[22](2200/2500): Loss: 0.2205
===> Epoch[22](2300/2500): Loss: 0.2232
===> Epoch[22](2400/2500): Loss: 0.2239
===> Epoch[22](2500/2500): Loss: 0.2611
===> Epoch 22 Complete: Avg. Loss: 0.2296
===> Timestamp: [2025-08-03 17:01:19]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.2477
===> Epoch[22](200/2500): Loss: 0.2212
===> Epoch[22](300/2500): Loss: 0.2278
===> Epoch[22](400/2500): Loss: 0.2364
===> Epoch[22](500/2500): Loss: 0.2299
===> Epoch[22](600/2500): Loss: 0.2154
===> Epoch[22](700/2500): Loss: 0.2375
===> Epoch[22](800/2500): Loss: 0.2294
===> Epoch[22](900/2500): Loss: 0.2393
===> Epoch[22](1000/2500): Loss: 0.2300
===> Epoch[22](1100/2500): Loss: 0.2179
===> Epoch[22](1200/2500): Loss: 0.2475
===> Epoch[22](1300/2500): Loss: 0.2332
===> Epoch[22](1400/2500): Loss: 0.2434
===> Epoch[22](1500/2500): Loss: 0.2237
===> Epoch[22](1600/2500): Loss: 0.2396
===> Epoch[22](1700/2500): Loss: 0.2331
===> Epoch[22](1800/2500): Loss: 0.2375
===> Epoch[22](1900/2500): Loss: 0.2275
===> Epoch[22](2000/2500): Loss: 0.2151
===> Epoch[22](2100/2500): Loss: 0.2328
===> Epoch[22](2200/2500): Loss: 0.2205
===> Epoch[22](2300/2500): Loss: 0.2232
===> Epoch[22](2400/2500): Loss: 0.2239
===> Epoch[22](2500/2500): Loss: 0.2611
===> Epoch 22 Complete: Avg. Loss: 0.2296
===> Timestamp: [2025-08-03 17:01:19]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.2477
===> Epoch[22](200/2500): Loss: 0.2212
===> Epoch[22](300/2500): Loss: 0.2278
===> Epoch[22](400/2500): Loss: 0.2364
===> Epoch[22](500/2500): Loss: 0.2299
===> Epoch[22](600/2500): Loss: 0.2154
===> Epoch[22](700/2500): Loss: 0.2375
===> Epoch[22](800/2500): Loss: 0.2294
===> Epoch[22](900/2500): Loss: 0.2393
===> Epoch[22](1000/2500): Loss: 0.2300
===> Epoch[22](1100/2500): Loss: 0.2179
===> Epoch[22](1200/2500): Loss: 0.2475
===> Epoch[22](1300/2500): Loss: 0.2332
===> Epoch[22](1400/2500): Loss: 0.2434
===> Epoch[22](1500/2500): Loss: 0.2237
===> Epoch[22](1600/2500): Loss: 0.2396
===> Epoch[22](1700/2500): Loss: 0.2331
===> Epoch[22](1800/2500): Loss: 0.2375
===> Epoch[22](1900/2500): Loss: 0.2275
===> Epoch[22](2000/2500): Loss: 0.2151
===> Epoch[22](2100/2500): Loss: 0.2328
===> Epoch[22](2200/2500): Loss: 0.2205
===> Epoch[22](2300/2500): Loss: 0.2232
===> Epoch[22](2400/2500): Loss: 0.2239
===> Epoch[22](2500/2500): Loss: 0.2611
===> Epoch 22 Complete: Avg. Loss: 0.2296
===> Timestamp: [2025-08-03 17:01:19]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.2477
===> Epoch[22](200/2500): Loss: 0.2212
===> Epoch[22](300/2500): Loss: 0.2278
===> Epoch[22](400/2500): Loss: 0.2364
===> Epoch[22](500/2500): Loss: 0.2299
===> Epoch[22](600/2500): Loss: 0.2154
===> Epoch[22](700/2500): Loss: 0.2375
===> Epoch[22](800/2500): Loss: 0.2294
===> Epoch[22](900/2500): Loss: 0.2393
===> Epoch[22](1000/2500): Loss: 0.2300
===> Epoch[22](1100/2500): Loss: 0.2179
===> Epoch[22](1200/2500): Loss: 0.2475
===> Epoch[22](1300/2500): Loss: 0.2332
===> Epoch[22](1400/2500): Loss: 0.2434
===> Epoch[22](1500/2500): Loss: 0.2237
===> Epoch[22](1600/2500): Loss: 0.2396
===> Epoch[22](1700/2500): Loss: 0.2331
===> Epoch[22](1800/2500): Loss: 0.2375
===> Epoch[22](1900/2500): Loss: 0.2275
===> Epoch[22](2000/2500): Loss: 0.2151
===> Epoch[22](2100/2500): Loss: 0.2328
===> Epoch[22](2200/2500): Loss: 0.2205
===> Epoch[22](2300/2500): Loss: 0.2232
===> Epoch[22](2400/2500): Loss: 0.2239
===> Epoch[22](2500/2500): Loss: 0.2611
===> Epoch 22 Complete: Avg. Loss: 0.2296
===> Timestamp: [2025-08-03 17:01:19]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.2477
===> Epoch[22](200/2500): Loss: 0.2212
===> Epoch[22](300/2500): Loss: 0.2278
===> Epoch[22](400/2500): Loss: 0.2364
===> Epoch[22](500/2500): Loss: 0.2299
===> Epoch[22](600/2500): Loss: 0.2154
===> Epoch[22](700/2500): Loss: 0.2375
===> Epoch[22](800/2500): Loss: 0.2294
===> Epoch[22](900/2500): Loss: 0.2393
===> Epoch[22](1000/2500): Loss: 0.2300
===> Epoch[22](1100/2500): Loss: 0.2179
===> Epoch[22](1200/2500): Loss: 0.2475
===> Epoch[22](1300/2500): Loss: 0.2332
===> Epoch[22](1400/2500): Loss: 0.2434
===> Epoch[22](1500/2500): Loss: 0.2237
===> Epoch[22](1600/2500): Loss: 0.2396
===> Epoch[22](1700/2500): Loss: 0.2331
===> Epoch[22](1800/2500): Loss: 0.2375
===> Epoch[22](1900/2500): Loss: 0.2275
===> Epoch[22](2000/2500): Loss: 0.2151
===> Epoch[22](2100/2500): Loss: 0.2328
===> Epoch[22](2200/2500): Loss: 0.2205
===> Epoch[22](2300/2500): Loss: 0.2232
===> Epoch[22](2400/2500): Loss: 0.2239
===> Epoch[22](2500/2500): Loss: 0.2611
===> Epoch 22 Complete: Avg. Loss: 0.2296
===> Timestamp: [2025-08-03 17:01:19]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.2477
===> Epoch[22](200/2500): Loss: 0.2212
===> Epoch[22](300/2500): Loss: 0.2278
===> Epoch[22](400/2500): Loss: 0.2364
===> Epoch[22](500/2500): Loss: 0.2299
===> Epoch[22](600/2500): Loss: 0.2154
===> Epoch[22](700/2500): Loss: 0.2375
===> Epoch[22](800/2500): Loss: 0.2294
===> Epoch[22](900/2500): Loss: 0.2393
===> Epoch[22](1000/2500): Loss: 0.2300
===> Epoch[22](1100/2500): Loss: 0.2179
===> Epoch[22](1200/2500): Loss: 0.2475
===> Epoch[22](1300/2500): Loss: 0.2332
===> Epoch[22](1400/2500): Loss: 0.2434
===> Epoch[22](1500/2500): Loss: 0.2237
===> Epoch[22](1600/2500): Loss: 0.2396
===> Epoch[22](1700/2500): Loss: 0.2331
===> Epoch[22](1800/2500): Loss: 0.2375
===> Epoch[22](1900/2500): Loss: 0.2275
===> Epoch[22](2000/2500): Loss: 0.2151
===> Epoch[22](2100/2500): Loss: 0.2328
===> Epoch[22](2200/2500): Loss: 0.2205
===> Epoch[22](2300/2500): Loss: 0.2232
===> Epoch[22](2400/2500): Loss: 0.2239
===> Epoch[22](2500/2500): Loss: 0.2611
===> Epoch 22 Complete: Avg. Loss: 0.2296
===> Timestamp: [2025-08-03 17:01:19]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.2477
===> Epoch[22](200/2500): Loss: 0.2212
===> Epoch[22](300/2500): Loss: 0.2278
===> Epoch[22](400/2500): Loss: 0.2364
===> Epoch[22](500/2500): Loss: 0.2299
===> Epoch[22](600/2500): Loss: 0.2154
===> Epoch[22](700/2500): Loss: 0.2375
===> Epoch[22](800/2500): Loss: 0.2294
===> Epoch[22](900/2500): Loss: 0.2393
===> Epoch[22](1000/2500): Loss: 0.2300
===> Epoch[22](1100/2500): Loss: 0.2179
===> Epoch[22](1200/2500): Loss: 0.2475
===> Epoch[22](1300/2500): Loss: 0.2332
===> Epoch[22](1400/2500): Loss: 0.2434
===> Epoch[22](1500/2500): Loss: 0.2237
===> Epoch[22](1600/2500): Loss: 0.2396
===> Epoch[22](1700/2500): Loss: 0.2331
===> Epoch[22](1800/2500): Loss: 0.2375
===> Epoch[22](1900/2500): Loss: 0.2275
===> Epoch[22](2000/2500): Loss: 0.2151
===> Epoch[22](2100/2500): Loss: 0.2328
===> Epoch[22](2200/2500): Loss: 0.2205
===> Epoch[22](2300/2500): Loss: 0.2232
===> Epoch[22](2400/2500): Loss: 0.2239
===> Epoch[22](2500/2500): Loss: 0.2611
===> Epoch 22 Complete: Avg. Loss: 0.2296
===> Timestamp: [2025-08-03 17:01:19]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.2477
===> Epoch[22](200/2500): Loss: 0.2212
===> Epoch[22](300/2500): Loss: 0.2278
===> Epoch[22](400/2500): Loss: 0.2364
===> Epoch[22](500/2500): Loss: 0.2299
===> Epoch[22](600/2500): Loss: 0.2154
===> Epoch[22](700/2500): Loss: 0.2375
===> Epoch[22](800/2500): Loss: 0.2294
===> Epoch[22](900/2500): Loss: 0.2393
===> Epoch[22](1000/2500): Loss: 0.2300
===> Epoch[22](1100/2500): Loss: 0.2179
===> Epoch[22](1200/2500): Loss: 0.2475
===> Epoch[22](1300/2500): Loss: 0.2332
===> Epoch[22](1400/2500): Loss: 0.2434
===> Epoch[22](1500/2500): Loss: 0.2237
===> Epoch[22](1600/2500): Loss: 0.2396
===> Epoch[22](1700/2500): Loss: 0.2331
===> Epoch[22](1800/2500): Loss: 0.2375
===> Epoch[22](1900/2500): Loss: 0.2275
===> Epoch[22](2000/2500): Loss: 0.2151
===> Epoch[22](2100/2500): Loss: 0.2328
===> Epoch[22](2200/2500): Loss: 0.2205
===> Epoch[22](2300/2500): Loss: 0.2232
===> Epoch[22](2400/2500): Loss: 0.2239
===> Epoch[22](2500/2500): Loss: 0.2611
===> Epoch 22 Complete: Avg. Loss: 0.2296
===> Timestamp: [2025-08-03 17:01:19]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.2477
===> Epoch[22](200/2500): Loss: 0.2212
===> Epoch[22](300/2500): Loss: 0.2278
===> Epoch[22](400/2500): Loss: 0.2364
===> Epoch[22](500/2500): Loss: 0.2299
===> Epoch[22](600/2500): Loss: 0.2154
===> Epoch[22](700/2500): Loss: 0.2375
===> Epoch[22](800/2500): Loss: 0.2294
===> Epoch[22](900/2500): Loss: 0.2393
===> Epoch[22](1000/2500): Loss: 0.2300
===> Epoch[22](1100/2500): Loss: 0.2179
===> Epoch[22](1200/2500): Loss: 0.2475
===> Epoch[22](1300/2500): Loss: 0.2332
===> Epoch[22](1400/2500): Loss: 0.2434
===> Epoch[22](1500/2500): Loss: 0.2237
===> Epoch[22](1600/2500): Loss: 0.2396
===> Epoch[22](1700/2500): Loss: 0.2331
===> Epoch[22](1800/2500): Loss: 0.2375
===> Epoch[22](1900/2500): Loss: 0.2275
===> Epoch[22](2000/2500): Loss: 0.2151
===> Epoch[22](2100/2500): Loss: 0.2328
===> Epoch[22](2200/2500): Loss: 0.2205
===> Epoch[22](2300/2500): Loss: 0.2232
===> Epoch[22](2400/2500): Loss: 0.2239
===> Epoch[22](2500/2500): Loss: 0.2611
===> Epoch 22 Complete: Avg. Loss: 0.2296
===> Timestamp: [2025-08-03 17:01:19]
===> Loading train datasets
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2267
===> Epoch[23](200/2500): Loss: 0.2328
===> Epoch[23](300/2500): Loss: 0.2268
===> Epoch[23](400/2500): Loss: 0.2170
===> Epoch[23](500/2500): Loss: 0.2496
===> Epoch[23](600/2500): Loss: 0.2509
===> Epoch[23](700/2500): Loss: 0.2266
===> Epoch[23](800/2500): Loss: 0.2343
===> Epoch[23](900/2500): Loss: 0.2238
===> Epoch[23](1000/2500): Loss: 0.2359
===> Epoch[23](1100/2500): Loss: 0.2076
===> Epoch[23](1200/2500): Loss: 0.2333
===> Epoch[23](1300/2500): Loss: 0.2418
===> Epoch[23](1400/2500): Loss: 0.2252
===> Epoch[23](1500/2500): Loss: 0.2291
===> Epoch[23](1600/2500): Loss: 0.2326
===> Epoch[23](1700/2500): Loss: 0.2434
===> Epoch[23](1800/2500): Loss: 0.1998
===> Epoch[23](1900/2500): Loss: 0.2124
===> Epoch[23](2000/2500): Loss: 0.2198
===> Epoch[23](2100/2500): Loss: 0.2488
===> Epoch[23](2200/2500): Loss: 0.2477
===> Epoch[23](2300/2500): Loss: 0.2144
===> Epoch[23](2400/2500): Loss: 0.2170
===> Epoch[23](2500/2500): Loss: 0.2303
===> Epoch 23 Complete: Avg. Loss: 0.2287
===> Timestamp: [2025-08-03 17:05:53]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2267
===> Epoch[23](200/2500): Loss: 0.2328
===> Epoch[23](300/2500): Loss: 0.2268
===> Epoch[23](400/2500): Loss: 0.2170
===> Epoch[23](500/2500): Loss: 0.2496
===> Epoch[23](600/2500): Loss: 0.2509
===> Epoch[23](700/2500): Loss: 0.2266
===> Epoch[23](800/2500): Loss: 0.2343
===> Epoch[23](900/2500): Loss: 0.2238
===> Epoch[23](1000/2500): Loss: 0.2359
===> Epoch[23](1100/2500): Loss: 0.2076
===> Epoch[23](1200/2500): Loss: 0.2333
===> Epoch[23](1300/2500): Loss: 0.2418
===> Epoch[23](1400/2500): Loss: 0.2252
===> Epoch[23](1500/2500): Loss: 0.2291
===> Epoch[23](1600/2500): Loss: 0.2326
===> Epoch[23](1700/2500): Loss: 0.2434
===> Epoch[23](1800/2500): Loss: 0.1998
===> Epoch[23](1900/2500): Loss: 0.2124
===> Epoch[23](2000/2500): Loss: 0.2198
===> Epoch[23](2100/2500): Loss: 0.2488
===> Epoch[23](2200/2500): Loss: 0.2477
===> Epoch[23](2300/2500): Loss: 0.2144
===> Epoch[23](2400/2500): Loss: 0.2170
===> Epoch[23](2500/2500): Loss: 0.2303
===> Epoch 23 Complete: Avg. Loss: 0.2287
===> Timestamp: [2025-08-03 17:05:53]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2267
===> Epoch[23](200/2500): Loss: 0.2328
===> Epoch[23](300/2500): Loss: 0.2268
===> Epoch[23](400/2500): Loss: 0.2170
===> Epoch[23](500/2500): Loss: 0.2496
===> Epoch[23](600/2500): Loss: 0.2509
===> Epoch[23](700/2500): Loss: 0.2266
===> Epoch[23](800/2500): Loss: 0.2343
===> Epoch[23](900/2500): Loss: 0.2238
===> Epoch[23](1000/2500): Loss: 0.2359
===> Epoch[23](1100/2500): Loss: 0.2076
===> Epoch[23](1200/2500): Loss: 0.2333
===> Epoch[23](1300/2500): Loss: 0.2418
===> Epoch[23](1400/2500): Loss: 0.2252
===> Epoch[23](1500/2500): Loss: 0.2291
===> Epoch[23](1600/2500): Loss: 0.2326
===> Epoch[23](1700/2500): Loss: 0.2434
===> Epoch[23](1800/2500): Loss: 0.1998
===> Epoch[23](1900/2500): Loss: 0.2124
===> Epoch[23](2000/2500): Loss: 0.2198
===> Epoch[23](2100/2500): Loss: 0.2488
===> Epoch[23](2200/2500): Loss: 0.2477
===> Epoch[23](2300/2500): Loss: 0.2144
===> Epoch[23](2400/2500): Loss: 0.2170
===> Epoch[23](2500/2500): Loss: 0.2303
===> Epoch 23 Complete: Avg. Loss: 0.2287
===> Timestamp: [2025-08-03 17:05:53]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2267
===> Epoch[23](200/2500): Loss: 0.2328
===> Epoch[23](300/2500): Loss: 0.2268
===> Epoch[23](400/2500): Loss: 0.2170
===> Epoch[23](500/2500): Loss: 0.2496
===> Epoch[23](600/2500): Loss: 0.2509
===> Epoch[23](700/2500): Loss: 0.2266
===> Epoch[23](800/2500): Loss: 0.2343
===> Epoch[23](900/2500): Loss: 0.2238
===> Epoch[23](1000/2500): Loss: 0.2359
===> Epoch[23](1100/2500): Loss: 0.2076
===> Epoch[23](1200/2500): Loss: 0.2333
===> Epoch[23](1300/2500): Loss: 0.2418
===> Epoch[23](1400/2500): Loss: 0.2252
===> Epoch[23](1500/2500): Loss: 0.2291
===> Epoch[23](1600/2500): Loss: 0.2326
===> Epoch[23](1700/2500): Loss: 0.2434
===> Epoch[23](1800/2500): Loss: 0.1998
===> Epoch[23](1900/2500): Loss: 0.2124
===> Epoch[23](2000/2500): Loss: 0.2198
===> Epoch[23](2100/2500): Loss: 0.2488
===> Epoch[23](2200/2500): Loss: 0.2477
===> Epoch[23](2300/2500): Loss: 0.2144
===> Epoch[23](2400/2500): Loss: 0.2170
===> Epoch[23](2500/2500): Loss: 0.2303
===> Epoch 23 Complete: Avg. Loss: 0.2287
===> Timestamp: [2025-08-03 17:05:53]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2267
===> Epoch[23](200/2500): Loss: 0.2328
===> Epoch[23](300/2500): Loss: 0.2268
===> Epoch[23](400/2500): Loss: 0.2170
===> Epoch[23](500/2500): Loss: 0.2496
===> Epoch[23](600/2500): Loss: 0.2509
===> Epoch[23](700/2500): Loss: 0.2266
===> Epoch[23](800/2500): Loss: 0.2343
===> Epoch[23](900/2500): Loss: 0.2238
===> Epoch[23](1000/2500): Loss: 0.2359
===> Epoch[23](1100/2500): Loss: 0.2076
===> Epoch[23](1200/2500): Loss: 0.2333
===> Epoch[23](1300/2500): Loss: 0.2418
===> Epoch[23](1400/2500): Loss: 0.2252
===> Epoch[23](1500/2500): Loss: 0.2291
===> Epoch[23](1600/2500): Loss: 0.2326
===> Epoch[23](1700/2500): Loss: 0.2434
===> Epoch[23](1800/2500): Loss: 0.1998
===> Epoch[23](1900/2500): Loss: 0.2124
===> Epoch[23](2000/2500): Loss: 0.2198
===> Epoch[23](2100/2500): Loss: 0.2488
===> Epoch[23](2200/2500): Loss: 0.2477
===> Epoch[23](2300/2500): Loss: 0.2144
===> Epoch[23](2400/2500): Loss: 0.2170
===> Epoch[23](2500/2500): Loss: 0.2303
===> Epoch 23 Complete: Avg. Loss: 0.2287
===> Timestamp: [2025-08-03 17:05:53]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2267
===> Epoch[23](200/2500): Loss: 0.2328
===> Epoch[23](300/2500): Loss: 0.2268
===> Epoch[23](400/2500): Loss: 0.2170
===> Epoch[23](500/2500): Loss: 0.2496
===> Epoch[23](600/2500): Loss: 0.2509
===> Epoch[23](700/2500): Loss: 0.2266
===> Epoch[23](800/2500): Loss: 0.2343
===> Epoch[23](900/2500): Loss: 0.2238
===> Epoch[23](1000/2500): Loss: 0.2359
===> Epoch[23](1100/2500): Loss: 0.2076
===> Epoch[23](1200/2500): Loss: 0.2333
===> Epoch[23](1300/2500): Loss: 0.2418
===> Epoch[23](1400/2500): Loss: 0.2252
===> Epoch[23](1500/2500): Loss: 0.2291
===> Epoch[23](1600/2500): Loss: 0.2326
===> Epoch[23](1700/2500): Loss: 0.2434
===> Epoch[23](1800/2500): Loss: 0.1998
===> Epoch[23](1900/2500): Loss: 0.2124
===> Epoch[23](2000/2500): Loss: 0.2198
===> Epoch[23](2100/2500): Loss: 0.2488
===> Epoch[23](2200/2500): Loss: 0.2477
===> Epoch[23](2300/2500): Loss: 0.2144
===> Epoch[23](2400/2500): Loss: 0.2170
===> Epoch[23](2500/2500): Loss: 0.2303
===> Epoch 23 Complete: Avg. Loss: 0.2287
===> Timestamp: [2025-08-03 17:05:53]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2267
===> Epoch[23](200/2500): Loss: 0.2328
===> Epoch[23](300/2500): Loss: 0.2268
===> Epoch[23](400/2500): Loss: 0.2170
===> Epoch[23](500/2500): Loss: 0.2496
===> Epoch[23](600/2500): Loss: 0.2509
===> Epoch[23](700/2500): Loss: 0.2266
===> Epoch[23](800/2500): Loss: 0.2343
===> Epoch[23](900/2500): Loss: 0.2238
===> Epoch[23](1000/2500): Loss: 0.2359
===> Epoch[23](1100/2500): Loss: 0.2076
===> Epoch[23](1200/2500): Loss: 0.2333
===> Epoch[23](1300/2500): Loss: 0.2418
===> Epoch[23](1400/2500): Loss: 0.2252
===> Epoch[23](1500/2500): Loss: 0.2291
===> Epoch[23](1600/2500): Loss: 0.2326
===> Epoch[23](1700/2500): Loss: 0.2434
===> Epoch[23](1800/2500): Loss: 0.1998
===> Epoch[23](1900/2500): Loss: 0.2124
===> Epoch[23](2000/2500): Loss: 0.2198
===> Epoch[23](2100/2500): Loss: 0.2488
===> Epoch[23](2200/2500): Loss: 0.2477
===> Epoch[23](2300/2500): Loss: 0.2144
===> Epoch[23](2400/2500): Loss: 0.2170
===> Epoch[23](2500/2500): Loss: 0.2303
===> Epoch 23 Complete: Avg. Loss: 0.2287
===> Timestamp: [2025-08-03 17:05:53]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2267
===> Epoch[23](200/2500): Loss: 0.2328
===> Epoch[23](300/2500): Loss: 0.2268
===> Epoch[23](400/2500): Loss: 0.2170
===> Epoch[23](500/2500): Loss: 0.2496
===> Epoch[23](600/2500): Loss: 0.2509
===> Epoch[23](700/2500): Loss: 0.2266
===> Epoch[23](800/2500): Loss: 0.2343
===> Epoch[23](900/2500): Loss: 0.2238
===> Epoch[23](1000/2500): Loss: 0.2359
===> Epoch[23](1100/2500): Loss: 0.2076
===> Epoch[23](1200/2500): Loss: 0.2333
===> Epoch[23](1300/2500): Loss: 0.2418
===> Epoch[23](1400/2500): Loss: 0.2252
===> Epoch[23](1500/2500): Loss: 0.2291
===> Epoch[23](1600/2500): Loss: 0.2326
===> Epoch[23](1700/2500): Loss: 0.2434
===> Epoch[23](1800/2500): Loss: 0.1998
===> Epoch[23](1900/2500): Loss: 0.2124
===> Epoch[23](2000/2500): Loss: 0.2198
===> Epoch[23](2100/2500): Loss: 0.2488
===> Epoch[23](2200/2500): Loss: 0.2477
===> Epoch[23](2300/2500): Loss: 0.2144
===> Epoch[23](2400/2500): Loss: 0.2170
===> Epoch[23](2500/2500): Loss: 0.2303
===> Epoch 23 Complete: Avg. Loss: 0.2287
===> Timestamp: [2025-08-03 17:05:53]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2267
===> Epoch[23](200/2500): Loss: 0.2328
===> Epoch[23](300/2500): Loss: 0.2268
===> Epoch[23](400/2500): Loss: 0.2170
===> Epoch[23](500/2500): Loss: 0.2496
===> Epoch[23](600/2500): Loss: 0.2509
===> Epoch[23](700/2500): Loss: 0.2266
===> Epoch[23](800/2500): Loss: 0.2343
===> Epoch[23](900/2500): Loss: 0.2238
===> Epoch[23](1000/2500): Loss: 0.2359
===> Epoch[23](1100/2500): Loss: 0.2076
===> Epoch[23](1200/2500): Loss: 0.2333
===> Epoch[23](1300/2500): Loss: 0.2418
===> Epoch[23](1400/2500): Loss: 0.2252
===> Epoch[23](1500/2500): Loss: 0.2291
===> Epoch[23](1600/2500): Loss: 0.2326
===> Epoch[23](1700/2500): Loss: 0.2434
===> Epoch[23](1800/2500): Loss: 0.1998
===> Epoch[23](1900/2500): Loss: 0.2124
===> Epoch[23](2000/2500): Loss: 0.2198
===> Epoch[23](2100/2500): Loss: 0.2488
===> Epoch[23](2200/2500): Loss: 0.2477
===> Epoch[23](2300/2500): Loss: 0.2144
===> Epoch[23](2400/2500): Loss: 0.2170
===> Epoch[23](2500/2500): Loss: 0.2303
===> Epoch 23 Complete: Avg. Loss: 0.2287
===> Timestamp: [2025-08-03 17:05:53]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2267
===> Epoch[23](200/2500): Loss: 0.2328
===> Epoch[23](300/2500): Loss: 0.2268
===> Epoch[23](400/2500): Loss: 0.2170
===> Epoch[23](500/2500): Loss: 0.2496
===> Epoch[23](600/2500): Loss: 0.2509
===> Epoch[23](700/2500): Loss: 0.2266
===> Epoch[23](800/2500): Loss: 0.2343
===> Epoch[23](900/2500): Loss: 0.2238
===> Epoch[23](1000/2500): Loss: 0.2359
===> Epoch[23](1100/2500): Loss: 0.2076
===> Epoch[23](1200/2500): Loss: 0.2333
===> Epoch[23](1300/2500): Loss: 0.2418
===> Epoch[23](1400/2500): Loss: 0.2252
===> Epoch[23](1500/2500): Loss: 0.2291
===> Epoch[23](1600/2500): Loss: 0.2326
===> Epoch[23](1700/2500): Loss: 0.2434
===> Epoch[23](1800/2500): Loss: 0.1998
===> Epoch[23](1900/2500): Loss: 0.2124
===> Epoch[23](2000/2500): Loss: 0.2198
===> Epoch[23](2100/2500): Loss: 0.2488
===> Epoch[23](2200/2500): Loss: 0.2477
===> Epoch[23](2300/2500): Loss: 0.2144
===> Epoch[23](2400/2500): Loss: 0.2170
===> Epoch[23](2500/2500): Loss: 0.2303
===> Epoch 23 Complete: Avg. Loss: 0.2287
===> Timestamp: [2025-08-03 17:05:53]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2267
===> Epoch[23](200/2500): Loss: 0.2328
===> Epoch[23](300/2500): Loss: 0.2268
===> Epoch[23](400/2500): Loss: 0.2170
===> Epoch[23](500/2500): Loss: 0.2496
===> Epoch[23](600/2500): Loss: 0.2509
===> Epoch[23](700/2500): Loss: 0.2266
===> Epoch[23](800/2500): Loss: 0.2343
===> Epoch[23](900/2500): Loss: 0.2238
===> Epoch[23](1000/2500): Loss: 0.2359
===> Epoch[23](1100/2500): Loss: 0.2076
===> Epoch[23](1200/2500): Loss: 0.2333
===> Epoch[23](1300/2500): Loss: 0.2418
===> Epoch[23](1400/2500): Loss: 0.2252
===> Epoch[23](1500/2500): Loss: 0.2291
===> Epoch[23](1600/2500): Loss: 0.2326
===> Epoch[23](1700/2500): Loss: 0.2434
===> Epoch[23](1800/2500): Loss: 0.1998
===> Epoch[23](1900/2500): Loss: 0.2124
===> Epoch[23](2000/2500): Loss: 0.2198
===> Epoch[23](2100/2500): Loss: 0.2488
===> Epoch[23](2200/2500): Loss: 0.2477
===> Epoch[23](2300/2500): Loss: 0.2144
===> Epoch[23](2400/2500): Loss: 0.2170
===> Epoch[23](2500/2500): Loss: 0.2303
===> Epoch 23 Complete: Avg. Loss: 0.2287
===> Timestamp: [2025-08-03 17:05:53]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2267
===> Epoch[23](200/2500): Loss: 0.2328
===> Epoch[23](300/2500): Loss: 0.2268
===> Epoch[23](400/2500): Loss: 0.2170
===> Epoch[23](500/2500): Loss: 0.2496
===> Epoch[23](600/2500): Loss: 0.2509
===> Epoch[23](700/2500): Loss: 0.2266
===> Epoch[23](800/2500): Loss: 0.2343
===> Epoch[23](900/2500): Loss: 0.2238
===> Epoch[23](1000/2500): Loss: 0.2359
===> Epoch[23](1100/2500): Loss: 0.2076
===> Epoch[23](1200/2500): Loss: 0.2333
===> Epoch[23](1300/2500): Loss: 0.2418
===> Epoch[23](1400/2500): Loss: 0.2252
===> Epoch[23](1500/2500): Loss: 0.2291
===> Epoch[23](1600/2500): Loss: 0.2326
===> Epoch[23](1700/2500): Loss: 0.2434
===> Epoch[23](1800/2500): Loss: 0.1998
===> Epoch[23](1900/2500): Loss: 0.2124
===> Epoch[23](2000/2500): Loss: 0.2198
===> Epoch[23](2100/2500): Loss: 0.2488
===> Epoch[23](2200/2500): Loss: 0.2477
===> Epoch[23](2300/2500): Loss: 0.2144
===> Epoch[23](2400/2500): Loss: 0.2170
===> Epoch[23](2500/2500): Loss: 0.2303
===> Epoch 23 Complete: Avg. Loss: 0.2287
===> Timestamp: [2025-08-03 17:05:53]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2267
===> Epoch[23](200/2500): Loss: 0.2328
===> Epoch[23](300/2500): Loss: 0.2268
===> Epoch[23](400/2500): Loss: 0.2170
===> Epoch[23](500/2500): Loss: 0.2496
===> Epoch[23](600/2500): Loss: 0.2509
===> Epoch[23](700/2500): Loss: 0.2266
===> Epoch[23](800/2500): Loss: 0.2343
===> Epoch[23](900/2500): Loss: 0.2238
===> Epoch[23](1000/2500): Loss: 0.2359
===> Epoch[23](1100/2500): Loss: 0.2076
===> Epoch[23](1200/2500): Loss: 0.2333
===> Epoch[23](1300/2500): Loss: 0.2418
===> Epoch[23](1400/2500): Loss: 0.2252
===> Epoch[23](1500/2500): Loss: 0.2291
===> Epoch[23](1600/2500): Loss: 0.2326
===> Epoch[23](1700/2500): Loss: 0.2434
===> Epoch[23](1800/2500): Loss: 0.1998
===> Epoch[23](1900/2500): Loss: 0.2124
===> Epoch[23](2000/2500): Loss: 0.2198
===> Epoch[23](2100/2500): Loss: 0.2488
===> Epoch[23](2200/2500): Loss: 0.2477
===> Epoch[23](2300/2500): Loss: 0.2144
===> Epoch[23](2400/2500): Loss: 0.2170
===> Epoch[23](2500/2500): Loss: 0.2303
===> Epoch 23 Complete: Avg. Loss: 0.2287
===> Timestamp: [2025-08-03 17:05:53]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2267
===> Epoch[23](200/2500): Loss: 0.2328
===> Epoch[23](300/2500): Loss: 0.2268
===> Epoch[23](400/2500): Loss: 0.2170
===> Epoch[23](500/2500): Loss: 0.2496
===> Epoch[23](600/2500): Loss: 0.2509
===> Epoch[23](700/2500): Loss: 0.2266
===> Epoch[23](800/2500): Loss: 0.2343
===> Epoch[23](900/2500): Loss: 0.2238
===> Epoch[23](1000/2500): Loss: 0.2359
===> Epoch[23](1100/2500): Loss: 0.2076
===> Epoch[23](1200/2500): Loss: 0.2333
===> Epoch[23](1300/2500): Loss: 0.2418
===> Epoch[23](1400/2500): Loss: 0.2252
===> Epoch[23](1500/2500): Loss: 0.2291
===> Epoch[23](1600/2500): Loss: 0.2326
===> Epoch[23](1700/2500): Loss: 0.2434
===> Epoch[23](1800/2500): Loss: 0.1998
===> Epoch[23](1900/2500): Loss: 0.2124
===> Epoch[23](2000/2500): Loss: 0.2198
===> Epoch[23](2100/2500): Loss: 0.2488
===> Epoch[23](2200/2500): Loss: 0.2477
===> Epoch[23](2300/2500): Loss: 0.2144
===> Epoch[23](2400/2500): Loss: 0.2170
===> Epoch[23](2500/2500): Loss: 0.2303
===> Epoch 23 Complete: Avg. Loss: 0.2287
===> Timestamp: [2025-08-03 17:05:53]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2267
===> Epoch[23](200/2500): Loss: 0.2328
===> Epoch[23](300/2500): Loss: 0.2268
===> Epoch[23](400/2500): Loss: 0.2170
===> Epoch[23](500/2500): Loss: 0.2496
===> Epoch[23](600/2500): Loss: 0.2509
===> Epoch[23](700/2500): Loss: 0.2266
===> Epoch[23](800/2500): Loss: 0.2343
===> Epoch[23](900/2500): Loss: 0.2238
===> Epoch[23](1000/2500): Loss: 0.2359
===> Epoch[23](1100/2500): Loss: 0.2076
===> Epoch[23](1200/2500): Loss: 0.2333
===> Epoch[23](1300/2500): Loss: 0.2418
===> Epoch[23](1400/2500): Loss: 0.2252
===> Epoch[23](1500/2500): Loss: 0.2291
===> Epoch[23](1600/2500): Loss: 0.2326
===> Epoch[23](1700/2500): Loss: 0.2434
===> Epoch[23](1800/2500): Loss: 0.1998
===> Epoch[23](1900/2500): Loss: 0.2124
===> Epoch[23](2000/2500): Loss: 0.2198
===> Epoch[23](2100/2500): Loss: 0.2488
===> Epoch[23](2200/2500): Loss: 0.2477
===> Epoch[23](2300/2500): Loss: 0.2144
===> Epoch[23](2400/2500): Loss: 0.2170
===> Epoch[23](2500/2500): Loss: 0.2303
===> Epoch 23 Complete: Avg. Loss: 0.2287
===> Timestamp: [2025-08-03 17:05:53]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2267
===> Epoch[23](200/2500): Loss: 0.2328
===> Epoch[23](300/2500): Loss: 0.2268
===> Epoch[23](400/2500): Loss: 0.2170
===> Epoch[23](500/2500): Loss: 0.2496
===> Epoch[23](600/2500): Loss: 0.2509
===> Epoch[23](700/2500): Loss: 0.2266
===> Epoch[23](800/2500): Loss: 0.2343
===> Epoch[23](900/2500): Loss: 0.2238
===> Epoch[23](1000/2500): Loss: 0.2359
===> Epoch[23](1100/2500): Loss: 0.2076
===> Epoch[23](1200/2500): Loss: 0.2333
===> Epoch[23](1300/2500): Loss: 0.2418
===> Epoch[23](1400/2500): Loss: 0.2252
===> Epoch[23](1500/2500): Loss: 0.2291
===> Epoch[23](1600/2500): Loss: 0.2326
===> Epoch[23](1700/2500): Loss: 0.2434
===> Epoch[23](1800/2500): Loss: 0.1998
===> Epoch[23](1900/2500): Loss: 0.2124
===> Epoch[23](2000/2500): Loss: 0.2198
===> Epoch[23](2100/2500): Loss: 0.2488
===> Epoch[23](2200/2500): Loss: 0.2477
===> Epoch[23](2300/2500): Loss: 0.2144
===> Epoch[23](2400/2500): Loss: 0.2170
===> Epoch[23](2500/2500): Loss: 0.2303
===> Epoch 23 Complete: Avg. Loss: 0.2287
===> Timestamp: [2025-08-03 17:05:53]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2267
===> Epoch[23](200/2500): Loss: 0.2328
===> Epoch[23](300/2500): Loss: 0.2268
===> Epoch[23](400/2500): Loss: 0.2170
===> Epoch[23](500/2500): Loss: 0.2496
===> Epoch[23](600/2500): Loss: 0.2509
===> Epoch[23](700/2500): Loss: 0.2266
===> Epoch[23](800/2500): Loss: 0.2343
===> Epoch[23](900/2500): Loss: 0.2238
===> Epoch[23](1000/2500): Loss: 0.2359
===> Epoch[23](1100/2500): Loss: 0.2076
===> Epoch[23](1200/2500): Loss: 0.2333
===> Epoch[23](1300/2500): Loss: 0.2418
===> Epoch[23](1400/2500): Loss: 0.2252
===> Epoch[23](1500/2500): Loss: 0.2291
===> Epoch[23](1600/2500): Loss: 0.2326
===> Epoch[23](1700/2500): Loss: 0.2434
===> Epoch[23](1800/2500): Loss: 0.1998
===> Epoch[23](1900/2500): Loss: 0.2124
===> Epoch[23](2000/2500): Loss: 0.2198
===> Epoch[23](2100/2500): Loss: 0.2488
===> Epoch[23](2200/2500): Loss: 0.2477
===> Epoch[23](2300/2500): Loss: 0.2144
===> Epoch[23](2400/2500): Loss: 0.2170
===> Epoch[23](2500/2500): Loss: 0.2303
===> Epoch 23 Complete: Avg. Loss: 0.2287
===> Timestamp: [2025-08-03 17:05:53]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2267
===> Epoch[23](200/2500): Loss: 0.2328
===> Epoch[23](300/2500): Loss: 0.2268
===> Epoch[23](400/2500): Loss: 0.2170
===> Epoch[23](500/2500): Loss: 0.2496
===> Epoch[23](600/2500): Loss: 0.2509
===> Epoch[23](700/2500): Loss: 0.2266
===> Epoch[23](800/2500): Loss: 0.2343
===> Epoch[23](900/2500): Loss: 0.2238
===> Epoch[23](1000/2500): Loss: 0.2359
===> Epoch[23](1100/2500): Loss: 0.2076
===> Epoch[23](1200/2500): Loss: 0.2333
===> Epoch[23](1300/2500): Loss: 0.2418
===> Epoch[23](1400/2500): Loss: 0.2252
===> Epoch[23](1500/2500): Loss: 0.2291
===> Epoch[23](1600/2500): Loss: 0.2326
===> Epoch[23](1700/2500): Loss: 0.2434
===> Epoch[23](1800/2500): Loss: 0.1998
===> Epoch[23](1900/2500): Loss: 0.2124
===> Epoch[23](2000/2500): Loss: 0.2198
===> Epoch[23](2100/2500): Loss: 0.2488
===> Epoch[23](2200/2500): Loss: 0.2477
===> Epoch[23](2300/2500): Loss: 0.2144
===> Epoch[23](2400/2500): Loss: 0.2170
===> Epoch[23](2500/2500): Loss: 0.2303
===> Epoch 23 Complete: Avg. Loss: 0.2287
===> Timestamp: [2025-08-03 17:05:53]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2267
===> Epoch[23](200/2500): Loss: 0.2328
===> Epoch[23](300/2500): Loss: 0.2268
===> Epoch[23](400/2500): Loss: 0.2170
===> Epoch[23](500/2500): Loss: 0.2496
===> Epoch[23](600/2500): Loss: 0.2509
===> Epoch[23](700/2500): Loss: 0.2266
===> Epoch[23](800/2500): Loss: 0.2343
===> Epoch[23](900/2500): Loss: 0.2238
===> Epoch[23](1000/2500): Loss: 0.2359
===> Epoch[23](1100/2500): Loss: 0.2076
===> Epoch[23](1200/2500): Loss: 0.2333
===> Epoch[23](1300/2500): Loss: 0.2418
===> Epoch[23](1400/2500): Loss: 0.2252
===> Epoch[23](1500/2500): Loss: 0.2291
===> Epoch[23](1600/2500): Loss: 0.2326
===> Epoch[23](1700/2500): Loss: 0.2434
===> Epoch[23](1800/2500): Loss: 0.1998
===> Epoch[23](1900/2500): Loss: 0.2124
===> Epoch[23](2000/2500): Loss: 0.2198
===> Epoch[23](2100/2500): Loss: 0.2488
===> Epoch[23](2200/2500): Loss: 0.2477
===> Epoch[23](2300/2500): Loss: 0.2144
===> Epoch[23](2400/2500): Loss: 0.2170
===> Epoch[23](2500/2500): Loss: 0.2303
===> Epoch 23 Complete: Avg. Loss: 0.2287
===> Timestamp: [2025-08-03 17:05:53]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2267
===> Epoch[23](200/2500): Loss: 0.2328
===> Epoch[23](300/2500): Loss: 0.2268
===> Epoch[23](400/2500): Loss: 0.2170
===> Epoch[23](500/2500): Loss: 0.2496
===> Epoch[23](600/2500): Loss: 0.2509
===> Epoch[23](700/2500): Loss: 0.2266
===> Epoch[23](800/2500): Loss: 0.2343
===> Epoch[23](900/2500): Loss: 0.2238
===> Epoch[23](1000/2500): Loss: 0.2359
===> Epoch[23](1100/2500): Loss: 0.2076
===> Epoch[23](1200/2500): Loss: 0.2333
===> Epoch[23](1300/2500): Loss: 0.2418
===> Epoch[23](1400/2500): Loss: 0.2252
===> Epoch[23](1500/2500): Loss: 0.2291
===> Epoch[23](1600/2500): Loss: 0.2326
===> Epoch[23](1700/2500): Loss: 0.2434
===> Epoch[23](1800/2500): Loss: 0.1998
===> Epoch[23](1900/2500): Loss: 0.2124
===> Epoch[23](2000/2500): Loss: 0.2198
===> Epoch[23](2100/2500): Loss: 0.2488
===> Epoch[23](2200/2500): Loss: 0.2477
===> Epoch[23](2300/2500): Loss: 0.2144
===> Epoch[23](2400/2500): Loss: 0.2170
===> Epoch[23](2500/2500): Loss: 0.2303
===> Epoch 23 Complete: Avg. Loss: 0.2287
===> Timestamp: [2025-08-03 17:05:53]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2267
===> Epoch[23](200/2500): Loss: 0.2328
===> Epoch[23](300/2500): Loss: 0.2268
===> Epoch[23](400/2500): Loss: 0.2170
===> Epoch[23](500/2500): Loss: 0.2496
===> Epoch[23](600/2500): Loss: 0.2509
===> Epoch[23](700/2500): Loss: 0.2266
===> Epoch[23](800/2500): Loss: 0.2343
===> Epoch[23](900/2500): Loss: 0.2238
===> Epoch[23](1000/2500): Loss: 0.2359
===> Epoch[23](1100/2500): Loss: 0.2076
===> Epoch[23](1200/2500): Loss: 0.2333
===> Epoch[23](1300/2500): Loss: 0.2418
===> Epoch[23](1400/2500): Loss: 0.2252
===> Epoch[23](1500/2500): Loss: 0.2291
===> Epoch[23](1600/2500): Loss: 0.2326
===> Epoch[23](1700/2500): Loss: 0.2434
===> Epoch[23](1800/2500): Loss: 0.1998
===> Epoch[23](1900/2500): Loss: 0.2124
===> Epoch[23](2000/2500): Loss: 0.2198
===> Epoch[23](2100/2500): Loss: 0.2488
===> Epoch[23](2200/2500): Loss: 0.2477
===> Epoch[23](2300/2500): Loss: 0.2144
===> Epoch[23](2400/2500): Loss: 0.2170
===> Epoch[23](2500/2500): Loss: 0.2303
===> Epoch 23 Complete: Avg. Loss: 0.2287
===> Timestamp: [2025-08-03 17:05:53]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2267
===> Epoch[23](200/2500): Loss: 0.2328
===> Epoch[23](300/2500): Loss: 0.2268
===> Epoch[23](400/2500): Loss: 0.2170
===> Epoch[23](500/2500): Loss: 0.2496
===> Epoch[23](600/2500): Loss: 0.2509
===> Epoch[23](700/2500): Loss: 0.2266
===> Epoch[23](800/2500): Loss: 0.2343
===> Epoch[23](900/2500): Loss: 0.2238
===> Epoch[23](1000/2500): Loss: 0.2359
===> Epoch[23](1100/2500): Loss: 0.2076
===> Epoch[23](1200/2500): Loss: 0.2333
===> Epoch[23](1300/2500): Loss: 0.2418
===> Epoch[23](1400/2500): Loss: 0.2252
===> Epoch[23](1500/2500): Loss: 0.2291
===> Epoch[23](1600/2500): Loss: 0.2326
===> Epoch[23](1700/2500): Loss: 0.2434
===> Epoch[23](1800/2500): Loss: 0.1998
===> Epoch[23](1900/2500): Loss: 0.2124
===> Epoch[23](2000/2500): Loss: 0.2198
===> Epoch[23](2100/2500): Loss: 0.2488
===> Epoch[23](2200/2500): Loss: 0.2477
===> Epoch[23](2300/2500): Loss: 0.2144
===> Epoch[23](2400/2500): Loss: 0.2170
===> Epoch[23](2500/2500): Loss: 0.2303
===> Epoch 23 Complete: Avg. Loss: 0.2287
===> Timestamp: [2025-08-03 17:05:53]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2267
===> Epoch[23](200/2500): Loss: 0.2328
===> Epoch[23](300/2500): Loss: 0.2268
===> Epoch[23](400/2500): Loss: 0.2170
===> Epoch[23](500/2500): Loss: 0.2496
===> Epoch[23](600/2500): Loss: 0.2509
===> Epoch[23](700/2500): Loss: 0.2266
===> Epoch[23](800/2500): Loss: 0.2343
===> Epoch[23](900/2500): Loss: 0.2238
===> Epoch[23](1000/2500): Loss: 0.2359
===> Epoch[23](1100/2500): Loss: 0.2076
===> Epoch[23](1200/2500): Loss: 0.2333
===> Epoch[23](1300/2500): Loss: 0.2418
===> Epoch[23](1400/2500): Loss: 0.2252
===> Epoch[23](1500/2500): Loss: 0.2291
===> Epoch[23](1600/2500): Loss: 0.2326
===> Epoch[23](1700/2500): Loss: 0.2434
===> Epoch[23](1800/2500): Loss: 0.1998
===> Epoch[23](1900/2500): Loss: 0.2124
===> Epoch[23](2000/2500): Loss: 0.2198
===> Epoch[23](2100/2500): Loss: 0.2488
===> Epoch[23](2200/2500): Loss: 0.2477
===> Epoch[23](2300/2500): Loss: 0.2144
===> Epoch[23](2400/2500): Loss: 0.2170
===> Epoch[23](2500/2500): Loss: 0.2303
===> Epoch 23 Complete: Avg. Loss: 0.2287
===> Timestamp: [2025-08-03 17:05:53]
===> Loading train datasets
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2198
===> Epoch[24](200/2500): Loss: 0.2287
===> Epoch[24](300/2500): Loss: 0.2371
===> Epoch[24](400/2500): Loss: 0.2416
===> Epoch[24](500/2500): Loss: 0.2573
===> Epoch[24](600/2500): Loss: 0.2188
===> Epoch[24](700/2500): Loss: 0.2251
===> Epoch[24](800/2500): Loss: 0.2350
===> Epoch[24](900/2500): Loss: 0.2250
===> Epoch[24](1000/2500): Loss: 0.2382
===> Epoch[24](1100/2500): Loss: 0.2354
===> Epoch[24](1200/2500): Loss: 0.2713
===> Epoch[24](1300/2500): Loss: 0.2158
===> Epoch[24](1400/2500): Loss: 0.2309
===> Epoch[24](1500/2500): Loss: 0.2225
===> Epoch[24](1600/2500): Loss: 0.2528
===> Epoch[24](1700/2500): Loss: 0.2247
===> Epoch[24](1800/2500): Loss: 0.2269
===> Epoch[24](1900/2500): Loss: 0.2280
===> Epoch[24](2000/2500): Loss: 0.2122
===> Epoch[24](2100/2500): Loss: 0.2367
===> Epoch[24](2200/2500): Loss: 0.2253
===> Epoch[24](2300/2500): Loss: 0.2239
===> Epoch[24](2400/2500): Loss: 0.2279
===> Epoch[24](2500/2500): Loss: 0.2024
===> Epoch 24 Complete: Avg. Loss: 0.2273
===> Timestamp: [2025-08-03 17:10:27]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2198
===> Epoch[24](200/2500): Loss: 0.2287
===> Epoch[24](300/2500): Loss: 0.2371
===> Epoch[24](400/2500): Loss: 0.2416
===> Epoch[24](500/2500): Loss: 0.2573
===> Epoch[24](600/2500): Loss: 0.2188
===> Epoch[24](700/2500): Loss: 0.2251
===> Epoch[24](800/2500): Loss: 0.2350
===> Epoch[24](900/2500): Loss: 0.2250
===> Epoch[24](1000/2500): Loss: 0.2382
===> Epoch[24](1100/2500): Loss: 0.2354
===> Epoch[24](1200/2500): Loss: 0.2713
===> Epoch[24](1300/2500): Loss: 0.2158
===> Epoch[24](1400/2500): Loss: 0.2309
===> Epoch[24](1500/2500): Loss: 0.2225
===> Epoch[24](1600/2500): Loss: 0.2528
===> Epoch[24](1700/2500): Loss: 0.2247
===> Epoch[24](1800/2500): Loss: 0.2269
===> Epoch[24](1900/2500): Loss: 0.2280
===> Epoch[24](2000/2500): Loss: 0.2122
===> Epoch[24](2100/2500): Loss: 0.2367
===> Epoch[24](2200/2500): Loss: 0.2253
===> Epoch[24](2300/2500): Loss: 0.2239
===> Epoch[24](2400/2500): Loss: 0.2279
===> Epoch[24](2500/2500): Loss: 0.2024
===> Epoch 24 Complete: Avg. Loss: 0.2273
===> Timestamp: [2025-08-03 17:10:27]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2198
===> Epoch[24](200/2500): Loss: 0.2287
===> Epoch[24](300/2500): Loss: 0.2371
===> Epoch[24](400/2500): Loss: 0.2416
===> Epoch[24](500/2500): Loss: 0.2573
===> Epoch[24](600/2500): Loss: 0.2188
===> Epoch[24](700/2500): Loss: 0.2251
===> Epoch[24](800/2500): Loss: 0.2350
===> Epoch[24](900/2500): Loss: 0.2250
===> Epoch[24](1000/2500): Loss: 0.2382
===> Epoch[24](1100/2500): Loss: 0.2354
===> Epoch[24](1200/2500): Loss: 0.2713
===> Epoch[24](1300/2500): Loss: 0.2158
===> Epoch[24](1400/2500): Loss: 0.2309
===> Epoch[24](1500/2500): Loss: 0.2225
===> Epoch[24](1600/2500): Loss: 0.2528
===> Epoch[24](1700/2500): Loss: 0.2247
===> Epoch[24](1800/2500): Loss: 0.2269
===> Epoch[24](1900/2500): Loss: 0.2280
===> Epoch[24](2000/2500): Loss: 0.2122
===> Epoch[24](2100/2500): Loss: 0.2367
===> Epoch[24](2200/2500): Loss: 0.2253
===> Epoch[24](2300/2500): Loss: 0.2239
===> Epoch[24](2400/2500): Loss: 0.2279
===> Epoch[24](2500/2500): Loss: 0.2024
===> Epoch 24 Complete: Avg. Loss: 0.2273
===> Timestamp: [2025-08-03 17:10:27]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2198
===> Epoch[24](200/2500): Loss: 0.2287
===> Epoch[24](300/2500): Loss: 0.2371
===> Epoch[24](400/2500): Loss: 0.2416
===> Epoch[24](500/2500): Loss: 0.2573
===> Epoch[24](600/2500): Loss: 0.2188
===> Epoch[24](700/2500): Loss: 0.2251
===> Epoch[24](800/2500): Loss: 0.2350
===> Epoch[24](900/2500): Loss: 0.2250
===> Epoch[24](1000/2500): Loss: 0.2382
===> Epoch[24](1100/2500): Loss: 0.2354
===> Epoch[24](1200/2500): Loss: 0.2713
===> Epoch[24](1300/2500): Loss: 0.2158
===> Epoch[24](1400/2500): Loss: 0.2309
===> Epoch[24](1500/2500): Loss: 0.2225
===> Epoch[24](1600/2500): Loss: 0.2528
===> Epoch[24](1700/2500): Loss: 0.2247
===> Epoch[24](1800/2500): Loss: 0.2269
===> Epoch[24](1900/2500): Loss: 0.2280
===> Epoch[24](2000/2500): Loss: 0.2122
===> Epoch[24](2100/2500): Loss: 0.2367
===> Epoch[24](2200/2500): Loss: 0.2253
===> Epoch[24](2300/2500): Loss: 0.2239
===> Epoch[24](2400/2500): Loss: 0.2279
===> Epoch[24](2500/2500): Loss: 0.2024
===> Epoch 24 Complete: Avg. Loss: 0.2273
===> Timestamp: [2025-08-03 17:10:27]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2198
===> Epoch[24](200/2500): Loss: 0.2287
===> Epoch[24](300/2500): Loss: 0.2371
===> Epoch[24](400/2500): Loss: 0.2416
===> Epoch[24](500/2500): Loss: 0.2573
===> Epoch[24](600/2500): Loss: 0.2188
===> Epoch[24](700/2500): Loss: 0.2251
===> Epoch[24](800/2500): Loss: 0.2350
===> Epoch[24](900/2500): Loss: 0.2250
===> Epoch[24](1000/2500): Loss: 0.2382
===> Epoch[24](1100/2500): Loss: 0.2354
===> Epoch[24](1200/2500): Loss: 0.2713
===> Epoch[24](1300/2500): Loss: 0.2158
===> Epoch[24](1400/2500): Loss: 0.2309
===> Epoch[24](1500/2500): Loss: 0.2225
===> Epoch[24](1600/2500): Loss: 0.2528
===> Epoch[24](1700/2500): Loss: 0.2247
===> Epoch[24](1800/2500): Loss: 0.2269
===> Epoch[24](1900/2500): Loss: 0.2280
===> Epoch[24](2000/2500): Loss: 0.2122
===> Epoch[24](2100/2500): Loss: 0.2367
===> Epoch[24](2200/2500): Loss: 0.2253
===> Epoch[24](2300/2500): Loss: 0.2239
===> Epoch[24](2400/2500): Loss: 0.2279
===> Epoch[24](2500/2500): Loss: 0.2024
===> Epoch 24 Complete: Avg. Loss: 0.2273
===> Timestamp: [2025-08-03 17:10:27]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2198
===> Epoch[24](200/2500): Loss: 0.2287
===> Epoch[24](300/2500): Loss: 0.2371
===> Epoch[24](400/2500): Loss: 0.2416
===> Epoch[24](500/2500): Loss: 0.2573
===> Epoch[24](600/2500): Loss: 0.2188
===> Epoch[24](700/2500): Loss: 0.2251
===> Epoch[24](800/2500): Loss: 0.2350
===> Epoch[24](900/2500): Loss: 0.2250
===> Epoch[24](1000/2500): Loss: 0.2382
===> Epoch[24](1100/2500): Loss: 0.2354
===> Epoch[24](1200/2500): Loss: 0.2713
===> Epoch[24](1300/2500): Loss: 0.2158
===> Epoch[24](1400/2500): Loss: 0.2309
===> Epoch[24](1500/2500): Loss: 0.2225
===> Epoch[24](1600/2500): Loss: 0.2528
===> Epoch[24](1700/2500): Loss: 0.2247
===> Epoch[24](1800/2500): Loss: 0.2269
===> Epoch[24](1900/2500): Loss: 0.2280
===> Epoch[24](2000/2500): Loss: 0.2122
===> Epoch[24](2100/2500): Loss: 0.2367
===> Epoch[24](2200/2500): Loss: 0.2253
===> Epoch[24](2300/2500): Loss: 0.2239
===> Epoch[24](2400/2500): Loss: 0.2279
===> Epoch[24](2500/2500): Loss: 0.2024
===> Epoch 24 Complete: Avg. Loss: 0.2273
===> Timestamp: [2025-08-03 17:10:27]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2198
===> Epoch[24](200/2500): Loss: 0.2287
===> Epoch[24](300/2500): Loss: 0.2371
===> Epoch[24](400/2500): Loss: 0.2416
===> Epoch[24](500/2500): Loss: 0.2573
===> Epoch[24](600/2500): Loss: 0.2188
===> Epoch[24](700/2500): Loss: 0.2251
===> Epoch[24](800/2500): Loss: 0.2350
===> Epoch[24](900/2500): Loss: 0.2250
===> Epoch[24](1000/2500): Loss: 0.2382
===> Epoch[24](1100/2500): Loss: 0.2354
===> Epoch[24](1200/2500): Loss: 0.2713
===> Epoch[24](1300/2500): Loss: 0.2158
===> Epoch[24](1400/2500): Loss: 0.2309
===> Epoch[24](1500/2500): Loss: 0.2225
===> Epoch[24](1600/2500): Loss: 0.2528
===> Epoch[24](1700/2500): Loss: 0.2247
===> Epoch[24](1800/2500): Loss: 0.2269
===> Epoch[24](1900/2500): Loss: 0.2280
===> Epoch[24](2000/2500): Loss: 0.2122
===> Epoch[24](2100/2500): Loss: 0.2367
===> Epoch[24](2200/2500): Loss: 0.2253
===> Epoch[24](2300/2500): Loss: 0.2239
===> Epoch[24](2400/2500): Loss: 0.2279
===> Epoch[24](2500/2500): Loss: 0.2024
===> Epoch 24 Complete: Avg. Loss: 0.2273
===> Timestamp: [2025-08-03 17:10:27]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2198
===> Epoch[24](200/2500): Loss: 0.2287
===> Epoch[24](300/2500): Loss: 0.2371
===> Epoch[24](400/2500): Loss: 0.2416
===> Epoch[24](500/2500): Loss: 0.2573
===> Epoch[24](600/2500): Loss: 0.2188
===> Epoch[24](700/2500): Loss: 0.2251
===> Epoch[24](800/2500): Loss: 0.2350
===> Epoch[24](900/2500): Loss: 0.2250
===> Epoch[24](1000/2500): Loss: 0.2382
===> Epoch[24](1100/2500): Loss: 0.2354
===> Epoch[24](1200/2500): Loss: 0.2713
===> Epoch[24](1300/2500): Loss: 0.2158
===> Epoch[24](1400/2500): Loss: 0.2309
===> Epoch[24](1500/2500): Loss: 0.2225
===> Epoch[24](1600/2500): Loss: 0.2528
===> Epoch[24](1700/2500): Loss: 0.2247
===> Epoch[24](1800/2500): Loss: 0.2269
===> Epoch[24](1900/2500): Loss: 0.2280
===> Epoch[24](2000/2500): Loss: 0.2122
===> Epoch[24](2100/2500): Loss: 0.2367
===> Epoch[24](2200/2500): Loss: 0.2253
===> Epoch[24](2300/2500): Loss: 0.2239
===> Epoch[24](2400/2500): Loss: 0.2279
===> Epoch[24](2500/2500): Loss: 0.2024
===> Epoch 24 Complete: Avg. Loss: 0.2273
===> Timestamp: [2025-08-03 17:10:27]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2198
===> Epoch[24](200/2500): Loss: 0.2287
===> Epoch[24](300/2500): Loss: 0.2371
===> Epoch[24](400/2500): Loss: 0.2416
===> Epoch[24](500/2500): Loss: 0.2573
===> Epoch[24](600/2500): Loss: 0.2188
===> Epoch[24](700/2500): Loss: 0.2251
===> Epoch[24](800/2500): Loss: 0.2350
===> Epoch[24](900/2500): Loss: 0.2250
===> Epoch[24](1000/2500): Loss: 0.2382
===> Epoch[24](1100/2500): Loss: 0.2354
===> Epoch[24](1200/2500): Loss: 0.2713
===> Epoch[24](1300/2500): Loss: 0.2158
===> Epoch[24](1400/2500): Loss: 0.2309
===> Epoch[24](1500/2500): Loss: 0.2225
===> Epoch[24](1600/2500): Loss: 0.2528
===> Epoch[24](1700/2500): Loss: 0.2247
===> Epoch[24](1800/2500): Loss: 0.2269
===> Epoch[24](1900/2500): Loss: 0.2280
===> Epoch[24](2000/2500): Loss: 0.2122
===> Epoch[24](2100/2500): Loss: 0.2367
===> Epoch[24](2200/2500): Loss: 0.2253
===> Epoch[24](2300/2500): Loss: 0.2239
===> Epoch[24](2400/2500): Loss: 0.2279
===> Epoch[24](2500/2500): Loss: 0.2024
===> Epoch 24 Complete: Avg. Loss: 0.2273
===> Timestamp: [2025-08-03 17:10:27]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2198
===> Epoch[24](200/2500): Loss: 0.2287
===> Epoch[24](300/2500): Loss: 0.2371
===> Epoch[24](400/2500): Loss: 0.2416
===> Epoch[24](500/2500): Loss: 0.2573
===> Epoch[24](600/2500): Loss: 0.2188
===> Epoch[24](700/2500): Loss: 0.2251
===> Epoch[24](800/2500): Loss: 0.2350
===> Epoch[24](900/2500): Loss: 0.2250
===> Epoch[24](1000/2500): Loss: 0.2382
===> Epoch[24](1100/2500): Loss: 0.2354
===> Epoch[24](1200/2500): Loss: 0.2713
===> Epoch[24](1300/2500): Loss: 0.2158
===> Epoch[24](1400/2500): Loss: 0.2309
===> Epoch[24](1500/2500): Loss: 0.2225
===> Epoch[24](1600/2500): Loss: 0.2528
===> Epoch[24](1700/2500): Loss: 0.2247
===> Epoch[24](1800/2500): Loss: 0.2269
===> Epoch[24](1900/2500): Loss: 0.2280
===> Epoch[24](2000/2500): Loss: 0.2122
===> Epoch[24](2100/2500): Loss: 0.2367
===> Epoch[24](2200/2500): Loss: 0.2253
===> Epoch[24](2300/2500): Loss: 0.2239
===> Epoch[24](2400/2500): Loss: 0.2279
===> Epoch[24](2500/2500): Loss: 0.2024
===> Epoch 24 Complete: Avg. Loss: 0.2273
===> Timestamp: [2025-08-03 17:10:27]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2198
===> Epoch[24](200/2500): Loss: 0.2287
===> Epoch[24](300/2500): Loss: 0.2371
===> Epoch[24](400/2500): Loss: 0.2416
===> Epoch[24](500/2500): Loss: 0.2573
===> Epoch[24](600/2500): Loss: 0.2188
===> Epoch[24](700/2500): Loss: 0.2251
===> Epoch[24](800/2500): Loss: 0.2350
===> Epoch[24](900/2500): Loss: 0.2250
===> Epoch[24](1000/2500): Loss: 0.2382
===> Epoch[24](1100/2500): Loss: 0.2354
===> Epoch[24](1200/2500): Loss: 0.2713
===> Epoch[24](1300/2500): Loss: 0.2158
===> Epoch[24](1400/2500): Loss: 0.2309
===> Epoch[24](1500/2500): Loss: 0.2225
===> Epoch[24](1600/2500): Loss: 0.2528
===> Epoch[24](1700/2500): Loss: 0.2247
===> Epoch[24](1800/2500): Loss: 0.2269
===> Epoch[24](1900/2500): Loss: 0.2280
===> Epoch[24](2000/2500): Loss: 0.2122
===> Epoch[24](2100/2500): Loss: 0.2367
===> Epoch[24](2200/2500): Loss: 0.2253
===> Epoch[24](2300/2500): Loss: 0.2239
===> Epoch[24](2400/2500): Loss: 0.2279
===> Epoch[24](2500/2500): Loss: 0.2024
===> Epoch 24 Complete: Avg. Loss: 0.2273
===> Timestamp: [2025-08-03 17:10:27]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2198
===> Epoch[24](200/2500): Loss: 0.2287
===> Epoch[24](300/2500): Loss: 0.2371
===> Epoch[24](400/2500): Loss: 0.2416
===> Epoch[24](500/2500): Loss: 0.2573
===> Epoch[24](600/2500): Loss: 0.2188
===> Epoch[24](700/2500): Loss: 0.2251
===> Epoch[24](800/2500): Loss: 0.2350
===> Epoch[24](900/2500): Loss: 0.2250
===> Epoch[24](1000/2500): Loss: 0.2382
===> Epoch[24](1100/2500): Loss: 0.2354
===> Epoch[24](1200/2500): Loss: 0.2713
===> Epoch[24](1300/2500): Loss: 0.2158
===> Epoch[24](1400/2500): Loss: 0.2309
===> Epoch[24](1500/2500): Loss: 0.2225
===> Epoch[24](1600/2500): Loss: 0.2528
===> Epoch[24](1700/2500): Loss: 0.2247
===> Epoch[24](1800/2500): Loss: 0.2269
===> Epoch[24](1900/2500): Loss: 0.2280
===> Epoch[24](2000/2500): Loss: 0.2122
===> Epoch[24](2100/2500): Loss: 0.2367
===> Epoch[24](2200/2500): Loss: 0.2253
===> Epoch[24](2300/2500): Loss: 0.2239
===> Epoch[24](2400/2500): Loss: 0.2279
===> Epoch[24](2500/2500): Loss: 0.2024
===> Epoch 24 Complete: Avg. Loss: 0.2273
===> Timestamp: [2025-08-03 17:10:27]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2198
===> Epoch[24](200/2500): Loss: 0.2287
===> Epoch[24](300/2500): Loss: 0.2371
===> Epoch[24](400/2500): Loss: 0.2416
===> Epoch[24](500/2500): Loss: 0.2573
===> Epoch[24](600/2500): Loss: 0.2188
===> Epoch[24](700/2500): Loss: 0.2251
===> Epoch[24](800/2500): Loss: 0.2350
===> Epoch[24](900/2500): Loss: 0.2250
===> Epoch[24](1000/2500): Loss: 0.2382
===> Epoch[24](1100/2500): Loss: 0.2354
===> Epoch[24](1200/2500): Loss: 0.2713
===> Epoch[24](1300/2500): Loss: 0.2158
===> Epoch[24](1400/2500): Loss: 0.2309
===> Epoch[24](1500/2500): Loss: 0.2225
===> Epoch[24](1600/2500): Loss: 0.2528
===> Epoch[24](1700/2500): Loss: 0.2247
===> Epoch[24](1800/2500): Loss: 0.2269
===> Epoch[24](1900/2500): Loss: 0.2280
===> Epoch[24](2000/2500): Loss: 0.2122
===> Epoch[24](2100/2500): Loss: 0.2367
===> Epoch[24](2200/2500): Loss: 0.2253
===> Epoch[24](2300/2500): Loss: 0.2239
===> Epoch[24](2400/2500): Loss: 0.2279
===> Epoch[24](2500/2500): Loss: 0.2024
===> Epoch 24 Complete: Avg. Loss: 0.2273
===> Timestamp: [2025-08-03 17:10:27]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2198
===> Epoch[24](200/2500): Loss: 0.2287
===> Epoch[24](300/2500): Loss: 0.2371
===> Epoch[24](400/2500): Loss: 0.2416
===> Epoch[24](500/2500): Loss: 0.2573
===> Epoch[24](600/2500): Loss: 0.2188
===> Epoch[24](700/2500): Loss: 0.2251
===> Epoch[24](800/2500): Loss: 0.2350
===> Epoch[24](900/2500): Loss: 0.2250
===> Epoch[24](1000/2500): Loss: 0.2382
===> Epoch[24](1100/2500): Loss: 0.2354
===> Epoch[24](1200/2500): Loss: 0.2713
===> Epoch[24](1300/2500): Loss: 0.2158
===> Epoch[24](1400/2500): Loss: 0.2309
===> Epoch[24](1500/2500): Loss: 0.2225
===> Epoch[24](1600/2500): Loss: 0.2528
===> Epoch[24](1700/2500): Loss: 0.2247
===> Epoch[24](1800/2500): Loss: 0.2269
===> Epoch[24](1900/2500): Loss: 0.2280
===> Epoch[24](2000/2500): Loss: 0.2122
===> Epoch[24](2100/2500): Loss: 0.2367
===> Epoch[24](2200/2500): Loss: 0.2253
===> Epoch[24](2300/2500): Loss: 0.2239
===> Epoch[24](2400/2500): Loss: 0.2279
===> Epoch[24](2500/2500): Loss: 0.2024
===> Epoch 24 Complete: Avg. Loss: 0.2273
===> Timestamp: [2025-08-03 17:10:27]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2198
===> Epoch[24](200/2500): Loss: 0.2287
===> Epoch[24](300/2500): Loss: 0.2371
===> Epoch[24](400/2500): Loss: 0.2416
===> Epoch[24](500/2500): Loss: 0.2573
===> Epoch[24](600/2500): Loss: 0.2188
===> Epoch[24](700/2500): Loss: 0.2251
===> Epoch[24](800/2500): Loss: 0.2350
===> Epoch[24](900/2500): Loss: 0.2250
===> Epoch[24](1000/2500): Loss: 0.2382
===> Epoch[24](1100/2500): Loss: 0.2354
===> Epoch[24](1200/2500): Loss: 0.2713
===> Epoch[24](1300/2500): Loss: 0.2158
===> Epoch[24](1400/2500): Loss: 0.2309
===> Epoch[24](1500/2500): Loss: 0.2225
===> Epoch[24](1600/2500): Loss: 0.2528
===> Epoch[24](1700/2500): Loss: 0.2247
===> Epoch[24](1800/2500): Loss: 0.2269
===> Epoch[24](1900/2500): Loss: 0.2280
===> Epoch[24](2000/2500): Loss: 0.2122
===> Epoch[24](2100/2500): Loss: 0.2367
===> Epoch[24](2200/2500): Loss: 0.2253
===> Epoch[24](2300/2500): Loss: 0.2239
===> Epoch[24](2400/2500): Loss: 0.2279
===> Epoch[24](2500/2500): Loss: 0.2024
===> Epoch 24 Complete: Avg. Loss: 0.2273
===> Timestamp: [2025-08-03 17:10:27]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2198
===> Epoch[24](200/2500): Loss: 0.2287
===> Epoch[24](300/2500): Loss: 0.2371
===> Epoch[24](400/2500): Loss: 0.2416
===> Epoch[24](500/2500): Loss: 0.2573
===> Epoch[24](600/2500): Loss: 0.2188
===> Epoch[24](700/2500): Loss: 0.2251
===> Epoch[24](800/2500): Loss: 0.2350
===> Epoch[24](900/2500): Loss: 0.2250
===> Epoch[24](1000/2500): Loss: 0.2382
===> Epoch[24](1100/2500): Loss: 0.2354
===> Epoch[24](1200/2500): Loss: 0.2713
===> Epoch[24](1300/2500): Loss: 0.2158
===> Epoch[24](1400/2500): Loss: 0.2309
===> Epoch[24](1500/2500): Loss: 0.2225
===> Epoch[24](1600/2500): Loss: 0.2528
===> Epoch[24](1700/2500): Loss: 0.2247
===> Epoch[24](1800/2500): Loss: 0.2269
===> Epoch[24](1900/2500): Loss: 0.2280
===> Epoch[24](2000/2500): Loss: 0.2122
===> Epoch[24](2100/2500): Loss: 0.2367
===> Epoch[24](2200/2500): Loss: 0.2253
===> Epoch[24](2300/2500): Loss: 0.2239
===> Epoch[24](2400/2500): Loss: 0.2279
===> Epoch[24](2500/2500): Loss: 0.2024
===> Epoch 24 Complete: Avg. Loss: 0.2273
===> Timestamp: [2025-08-03 17:10:27]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2198
===> Epoch[24](200/2500): Loss: 0.2287
===> Epoch[24](300/2500): Loss: 0.2371
===> Epoch[24](400/2500): Loss: 0.2416
===> Epoch[24](500/2500): Loss: 0.2573
===> Epoch[24](600/2500): Loss: 0.2188
===> Epoch[24](700/2500): Loss: 0.2251
===> Epoch[24](800/2500): Loss: 0.2350
===> Epoch[24](900/2500): Loss: 0.2250
===> Epoch[24](1000/2500): Loss: 0.2382
===> Epoch[24](1100/2500): Loss: 0.2354
===> Epoch[24](1200/2500): Loss: 0.2713
===> Epoch[24](1300/2500): Loss: 0.2158
===> Epoch[24](1400/2500): Loss: 0.2309
===> Epoch[24](1500/2500): Loss: 0.2225
===> Epoch[24](1600/2500): Loss: 0.2528
===> Epoch[24](1700/2500): Loss: 0.2247
===> Epoch[24](1800/2500): Loss: 0.2269
===> Epoch[24](1900/2500): Loss: 0.2280
===> Epoch[24](2000/2500): Loss: 0.2122
===> Epoch[24](2100/2500): Loss: 0.2367
===> Epoch[24](2200/2500): Loss: 0.2253
===> Epoch[24](2300/2500): Loss: 0.2239
===> Epoch[24](2400/2500): Loss: 0.2279
===> Epoch[24](2500/2500): Loss: 0.2024
===> Epoch 24 Complete: Avg. Loss: 0.2273
===> Timestamp: [2025-08-03 17:10:27]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2198
===> Epoch[24](200/2500): Loss: 0.2287
===> Epoch[24](300/2500): Loss: 0.2371
===> Epoch[24](400/2500): Loss: 0.2416
===> Epoch[24](500/2500): Loss: 0.2573
===> Epoch[24](600/2500): Loss: 0.2188
===> Epoch[24](700/2500): Loss: 0.2251
===> Epoch[24](800/2500): Loss: 0.2350
===> Epoch[24](900/2500): Loss: 0.2250
===> Epoch[24](1000/2500): Loss: 0.2382
===> Epoch[24](1100/2500): Loss: 0.2354
===> Epoch[24](1200/2500): Loss: 0.2713
===> Epoch[24](1300/2500): Loss: 0.2158
===> Epoch[24](1400/2500): Loss: 0.2309
===> Epoch[24](1500/2500): Loss: 0.2225
===> Epoch[24](1600/2500): Loss: 0.2528
===> Epoch[24](1700/2500): Loss: 0.2247
===> Epoch[24](1800/2500): Loss: 0.2269
===> Epoch[24](1900/2500): Loss: 0.2280
===> Epoch[24](2000/2500): Loss: 0.2122
===> Epoch[24](2100/2500): Loss: 0.2367
===> Epoch[24](2200/2500): Loss: 0.2253
===> Epoch[24](2300/2500): Loss: 0.2239
===> Epoch[24](2400/2500): Loss: 0.2279
===> Epoch[24](2500/2500): Loss: 0.2024
===> Epoch 24 Complete: Avg. Loss: 0.2273
===> Timestamp: [2025-08-03 17:10:27]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2198
===> Epoch[24](200/2500): Loss: 0.2287
===> Epoch[24](300/2500): Loss: 0.2371
===> Epoch[24](400/2500): Loss: 0.2416
===> Epoch[24](500/2500): Loss: 0.2573
===> Epoch[24](600/2500): Loss: 0.2188
===> Epoch[24](700/2500): Loss: 0.2251
===> Epoch[24](800/2500): Loss: 0.2350
===> Epoch[24](900/2500): Loss: 0.2250
===> Epoch[24](1000/2500): Loss: 0.2382
===> Epoch[24](1100/2500): Loss: 0.2354
===> Epoch[24](1200/2500): Loss: 0.2713
===> Epoch[24](1300/2500): Loss: 0.2158
===> Epoch[24](1400/2500): Loss: 0.2309
===> Epoch[24](1500/2500): Loss: 0.2225
===> Epoch[24](1600/2500): Loss: 0.2528
===> Epoch[24](1700/2500): Loss: 0.2247
===> Epoch[24](1800/2500): Loss: 0.2269
===> Epoch[24](1900/2500): Loss: 0.2280
===> Epoch[24](2000/2500): Loss: 0.2122
===> Epoch[24](2100/2500): Loss: 0.2367
===> Epoch[24](2200/2500): Loss: 0.2253
===> Epoch[24](2300/2500): Loss: 0.2239
===> Epoch[24](2400/2500): Loss: 0.2279
===> Epoch[24](2500/2500): Loss: 0.2024
===> Epoch 24 Complete: Avg. Loss: 0.2273
===> Timestamp: [2025-08-03 17:10:27]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2198
===> Epoch[24](200/2500): Loss: 0.2287
===> Epoch[24](300/2500): Loss: 0.2371
===> Epoch[24](400/2500): Loss: 0.2416
===> Epoch[24](500/2500): Loss: 0.2573
===> Epoch[24](600/2500): Loss: 0.2188
===> Epoch[24](700/2500): Loss: 0.2251
===> Epoch[24](800/2500): Loss: 0.2350
===> Epoch[24](900/2500): Loss: 0.2250
===> Epoch[24](1000/2500): Loss: 0.2382
===> Epoch[24](1100/2500): Loss: 0.2354
===> Epoch[24](1200/2500): Loss: 0.2713
===> Epoch[24](1300/2500): Loss: 0.2158
===> Epoch[24](1400/2500): Loss: 0.2309
===> Epoch[24](1500/2500): Loss: 0.2225
===> Epoch[24](1600/2500): Loss: 0.2528
===> Epoch[24](1700/2500): Loss: 0.2247
===> Epoch[24](1800/2500): Loss: 0.2269
===> Epoch[24](1900/2500): Loss: 0.2280
===> Epoch[24](2000/2500): Loss: 0.2122
===> Epoch[24](2100/2500): Loss: 0.2367
===> Epoch[24](2200/2500): Loss: 0.2253
===> Epoch[24](2300/2500): Loss: 0.2239
===> Epoch[24](2400/2500): Loss: 0.2279
===> Epoch[24](2500/2500): Loss: 0.2024
===> Epoch 24 Complete: Avg. Loss: 0.2273
===> Timestamp: [2025-08-03 17:10:27]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2198
===> Epoch[24](200/2500): Loss: 0.2287
===> Epoch[24](300/2500): Loss: 0.2371
===> Epoch[24](400/2500): Loss: 0.2416
===> Epoch[24](500/2500): Loss: 0.2573
===> Epoch[24](600/2500): Loss: 0.2188
===> Epoch[24](700/2500): Loss: 0.2251
===> Epoch[24](800/2500): Loss: 0.2350
===> Epoch[24](900/2500): Loss: 0.2250
===> Epoch[24](1000/2500): Loss: 0.2382
===> Epoch[24](1100/2500): Loss: 0.2354
===> Epoch[24](1200/2500): Loss: 0.2713
===> Epoch[24](1300/2500): Loss: 0.2158
===> Epoch[24](1400/2500): Loss: 0.2309
===> Epoch[24](1500/2500): Loss: 0.2225
===> Epoch[24](1600/2500): Loss: 0.2528
===> Epoch[24](1700/2500): Loss: 0.2247
===> Epoch[24](1800/2500): Loss: 0.2269
===> Epoch[24](1900/2500): Loss: 0.2280
===> Epoch[24](2000/2500): Loss: 0.2122
===> Epoch[24](2100/2500): Loss: 0.2367
===> Epoch[24](2200/2500): Loss: 0.2253
===> Epoch[24](2300/2500): Loss: 0.2239
===> Epoch[24](2400/2500): Loss: 0.2279
===> Epoch[24](2500/2500): Loss: 0.2024
===> Epoch 24 Complete: Avg. Loss: 0.2273
===> Timestamp: [2025-08-03 17:10:27]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2198
===> Epoch[24](200/2500): Loss: 0.2287
===> Epoch[24](300/2500): Loss: 0.2371
===> Epoch[24](400/2500): Loss: 0.2416
===> Epoch[24](500/2500): Loss: 0.2573
===> Epoch[24](600/2500): Loss: 0.2188
===> Epoch[24](700/2500): Loss: 0.2251
===> Epoch[24](800/2500): Loss: 0.2350
===> Epoch[24](900/2500): Loss: 0.2250
===> Epoch[24](1000/2500): Loss: 0.2382
===> Epoch[24](1100/2500): Loss: 0.2354
===> Epoch[24](1200/2500): Loss: 0.2713
===> Epoch[24](1300/2500): Loss: 0.2158
===> Epoch[24](1400/2500): Loss: 0.2309
===> Epoch[24](1500/2500): Loss: 0.2225
===> Epoch[24](1600/2500): Loss: 0.2528
===> Epoch[24](1700/2500): Loss: 0.2247
===> Epoch[24](1800/2500): Loss: 0.2269
===> Epoch[24](1900/2500): Loss: 0.2280
===> Epoch[24](2000/2500): Loss: 0.2122
===> Epoch[24](2100/2500): Loss: 0.2367
===> Epoch[24](2200/2500): Loss: 0.2253
===> Epoch[24](2300/2500): Loss: 0.2239
===> Epoch[24](2400/2500): Loss: 0.2279
===> Epoch[24](2500/2500): Loss: 0.2024
===> Epoch 24 Complete: Avg. Loss: 0.2273
===> Timestamp: [2025-08-03 17:10:27]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2198
===> Epoch[24](200/2500): Loss: 0.2287
===> Epoch[24](300/2500): Loss: 0.2371
===> Epoch[24](400/2500): Loss: 0.2416
===> Epoch[24](500/2500): Loss: 0.2573
===> Epoch[24](600/2500): Loss: 0.2188
===> Epoch[24](700/2500): Loss: 0.2251
===> Epoch[24](800/2500): Loss: 0.2350
===> Epoch[24](900/2500): Loss: 0.2250
===> Epoch[24](1000/2500): Loss: 0.2382
===> Epoch[24](1100/2500): Loss: 0.2354
===> Epoch[24](1200/2500): Loss: 0.2713
===> Epoch[24](1300/2500): Loss: 0.2158
===> Epoch[24](1400/2500): Loss: 0.2309
===> Epoch[24](1500/2500): Loss: 0.2225
===> Epoch[24](1600/2500): Loss: 0.2528
===> Epoch[24](1700/2500): Loss: 0.2247
===> Epoch[24](1800/2500): Loss: 0.2269
===> Epoch[24](1900/2500): Loss: 0.2280
===> Epoch[24](2000/2500): Loss: 0.2122
===> Epoch[24](2100/2500): Loss: 0.2367
===> Epoch[24](2200/2500): Loss: 0.2253
===> Epoch[24](2300/2500): Loss: 0.2239
===> Epoch[24](2400/2500): Loss: 0.2279
===> Epoch[24](2500/2500): Loss: 0.2024
===> Epoch 24 Complete: Avg. Loss: 0.2273
===> Timestamp: [2025-08-03 17:10:27]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2198
===> Epoch[24](200/2500): Loss: 0.2287
===> Epoch[24](300/2500): Loss: 0.2371
===> Epoch[24](400/2500): Loss: 0.2416
===> Epoch[24](500/2500): Loss: 0.2573
===> Epoch[24](600/2500): Loss: 0.2188
===> Epoch[24](700/2500): Loss: 0.2251
===> Epoch[24](800/2500): Loss: 0.2350
===> Epoch[24](900/2500): Loss: 0.2250
===> Epoch[24](1000/2500): Loss: 0.2382
===> Epoch[24](1100/2500): Loss: 0.2354
===> Epoch[24](1200/2500): Loss: 0.2713
===> Epoch[24](1300/2500): Loss: 0.2158
===> Epoch[24](1400/2500): Loss: 0.2309
===> Epoch[24](1500/2500): Loss: 0.2225
===> Epoch[24](1600/2500): Loss: 0.2528
===> Epoch[24](1700/2500): Loss: 0.2247
===> Epoch[24](1800/2500): Loss: 0.2269
===> Epoch[24](1900/2500): Loss: 0.2280
===> Epoch[24](2000/2500): Loss: 0.2122
===> Epoch[24](2100/2500): Loss: 0.2367
===> Epoch[24](2200/2500): Loss: 0.2253
===> Epoch[24](2300/2500): Loss: 0.2239
===> Epoch[24](2400/2500): Loss: 0.2279
===> Epoch[24](2500/2500): Loss: 0.2024
===> Epoch 24 Complete: Avg. Loss: 0.2273
===> Timestamp: [2025-08-03 17:10:27]
===> Loading train datasets
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2181
===> Epoch[25](200/2500): Loss: 0.2176
===> Epoch[25](300/2500): Loss: 0.2400
===> Epoch[25](400/2500): Loss: 0.2107
===> Epoch[25](500/2500): Loss: 0.2111
===> Epoch[25](600/2500): Loss: 0.2363
===> Epoch[25](700/2500): Loss: 0.2083
===> Epoch[25](800/2500): Loss: 0.2203
===> Epoch[25](900/2500): Loss: 0.2487
===> Epoch[25](1000/2500): Loss: 0.2231
===> Epoch[25](1100/2500): Loss: 0.2264
===> Epoch[25](1200/2500): Loss: 0.2366
===> Epoch[25](1300/2500): Loss: 0.2245
===> Epoch[25](1400/2500): Loss: 0.2205
===> Epoch[25](1500/2500): Loss: 0.2141
===> Epoch[25](1600/2500): Loss: 0.2243
===> Epoch[25](1700/2500): Loss: 0.2340
===> Epoch[25](1800/2500): Loss: 0.2309
===> Epoch[25](1900/2500): Loss: 0.2279
===> Epoch[25](2000/2500): Loss: 0.2169
===> Epoch[25](2100/2500): Loss: 0.2336
===> Epoch[25](2200/2500): Loss: 0.2461
===> Epoch[25](2300/2500): Loss: 0.2131
===> Epoch[25](2400/2500): Loss: 0.2262
===> Epoch[25](2500/2500): Loss: 0.2198
===> Epoch 25 Complete: Avg. Loss: 0.2261
===> Timestamp: [2025-08-03 17:15:00]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2181
===> Epoch[25](200/2500): Loss: 0.2176
===> Epoch[25](300/2500): Loss: 0.2400
===> Epoch[25](400/2500): Loss: 0.2107
===> Epoch[25](500/2500): Loss: 0.2111
===> Epoch[25](600/2500): Loss: 0.2363
===> Epoch[25](700/2500): Loss: 0.2083
===> Epoch[25](800/2500): Loss: 0.2203
===> Epoch[25](900/2500): Loss: 0.2487
===> Epoch[25](1000/2500): Loss: 0.2231
===> Epoch[25](1100/2500): Loss: 0.2264
===> Epoch[25](1200/2500): Loss: 0.2366
===> Epoch[25](1300/2500): Loss: 0.2245
===> Epoch[25](1400/2500): Loss: 0.2205
===> Epoch[25](1500/2500): Loss: 0.2141
===> Epoch[25](1600/2500): Loss: 0.2243
===> Epoch[25](1700/2500): Loss: 0.2340
===> Epoch[25](1800/2500): Loss: 0.2309
===> Epoch[25](1900/2500): Loss: 0.2279
===> Epoch[25](2000/2500): Loss: 0.2169
===> Epoch[25](2100/2500): Loss: 0.2336
===> Epoch[25](2200/2500): Loss: 0.2461
===> Epoch[25](2300/2500): Loss: 0.2131
===> Epoch[25](2400/2500): Loss: 0.2262
===> Epoch[25](2500/2500): Loss: 0.2198
===> Epoch 25 Complete: Avg. Loss: 0.2261
===> Timestamp: [2025-08-03 17:15:00]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2181
===> Epoch[25](200/2500): Loss: 0.2176
===> Epoch[25](300/2500): Loss: 0.2400
===> Epoch[25](400/2500): Loss: 0.2107
===> Epoch[25](500/2500): Loss: 0.2111
===> Epoch[25](600/2500): Loss: 0.2363
===> Epoch[25](700/2500): Loss: 0.2083
===> Epoch[25](800/2500): Loss: 0.2203
===> Epoch[25](900/2500): Loss: 0.2487
===> Epoch[25](1000/2500): Loss: 0.2231
===> Epoch[25](1100/2500): Loss: 0.2264
===> Epoch[25](1200/2500): Loss: 0.2366
===> Epoch[25](1300/2500): Loss: 0.2245
===> Epoch[25](1400/2500): Loss: 0.2205
===> Epoch[25](1500/2500): Loss: 0.2141
===> Epoch[25](1600/2500): Loss: 0.2243
===> Epoch[25](1700/2500): Loss: 0.2340
===> Epoch[25](1800/2500): Loss: 0.2309
===> Epoch[25](1900/2500): Loss: 0.2279
===> Epoch[25](2000/2500): Loss: 0.2169
===> Epoch[25](2100/2500): Loss: 0.2336
===> Epoch[25](2200/2500): Loss: 0.2461
===> Epoch[25](2300/2500): Loss: 0.2131
===> Epoch[25](2400/2500): Loss: 0.2262
===> Epoch[25](2500/2500): Loss: 0.2198
===> Epoch 25 Complete: Avg. Loss: 0.2261
===> Timestamp: [2025-08-03 17:15:00]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2181
===> Epoch[25](200/2500): Loss: 0.2176
===> Epoch[25](300/2500): Loss: 0.2400
===> Epoch[25](400/2500): Loss: 0.2107
===> Epoch[25](500/2500): Loss: 0.2111
===> Epoch[25](600/2500): Loss: 0.2363
===> Epoch[25](700/2500): Loss: 0.2083
===> Epoch[25](800/2500): Loss: 0.2203
===> Epoch[25](900/2500): Loss: 0.2487
===> Epoch[25](1000/2500): Loss: 0.2231
===> Epoch[25](1100/2500): Loss: 0.2264
===> Epoch[25](1200/2500): Loss: 0.2366
===> Epoch[25](1300/2500): Loss: 0.2245
===> Epoch[25](1400/2500): Loss: 0.2205
===> Epoch[25](1500/2500): Loss: 0.2141
===> Epoch[25](1600/2500): Loss: 0.2243
===> Epoch[25](1700/2500): Loss: 0.2340
===> Epoch[25](1800/2500): Loss: 0.2309
===> Epoch[25](1900/2500): Loss: 0.2279
===> Epoch[25](2000/2500): Loss: 0.2169
===> Epoch[25](2100/2500): Loss: 0.2336
===> Epoch[25](2200/2500): Loss: 0.2461
===> Epoch[25](2300/2500): Loss: 0.2131
===> Epoch[25](2400/2500): Loss: 0.2262
===> Epoch[25](2500/2500): Loss: 0.2198
===> Epoch 25 Complete: Avg. Loss: 0.2261
===> Timestamp: [2025-08-03 17:15:00]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2181
===> Epoch[25](200/2500): Loss: 0.2176
===> Epoch[25](300/2500): Loss: 0.2400
===> Epoch[25](400/2500): Loss: 0.2107
===> Epoch[25](500/2500): Loss: 0.2111
===> Epoch[25](600/2500): Loss: 0.2363
===> Epoch[25](700/2500): Loss: 0.2083
===> Epoch[25](800/2500): Loss: 0.2203
===> Epoch[25](900/2500): Loss: 0.2487
===> Epoch[25](1000/2500): Loss: 0.2231
===> Epoch[25](1100/2500): Loss: 0.2264
===> Epoch[25](1200/2500): Loss: 0.2366
===> Epoch[25](1300/2500): Loss: 0.2245
===> Epoch[25](1400/2500): Loss: 0.2205
===> Epoch[25](1500/2500): Loss: 0.2141
===> Epoch[25](1600/2500): Loss: 0.2243
===> Epoch[25](1700/2500): Loss: 0.2340
===> Epoch[25](1800/2500): Loss: 0.2309
===> Epoch[25](1900/2500): Loss: 0.2279
===> Epoch[25](2000/2500): Loss: 0.2169
===> Epoch[25](2100/2500): Loss: 0.2336
===> Epoch[25](2200/2500): Loss: 0.2461
===> Epoch[25](2300/2500): Loss: 0.2131
===> Epoch[25](2400/2500): Loss: 0.2262
===> Epoch[25](2500/2500): Loss: 0.2198
===> Epoch 25 Complete: Avg. Loss: 0.2261
===> Timestamp: [2025-08-03 17:15:00]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2181
===> Epoch[25](200/2500): Loss: 0.2176
===> Epoch[25](300/2500): Loss: 0.2400
===> Epoch[25](400/2500): Loss: 0.2107
===> Epoch[25](500/2500): Loss: 0.2111
===> Epoch[25](600/2500): Loss: 0.2363
===> Epoch[25](700/2500): Loss: 0.2083
===> Epoch[25](800/2500): Loss: 0.2203
===> Epoch[25](900/2500): Loss: 0.2487
===> Epoch[25](1000/2500): Loss: 0.2231
===> Epoch[25](1100/2500): Loss: 0.2264
===> Epoch[25](1200/2500): Loss: 0.2366
===> Epoch[25](1300/2500): Loss: 0.2245
===> Epoch[25](1400/2500): Loss: 0.2205
===> Epoch[25](1500/2500): Loss: 0.2141
===> Epoch[25](1600/2500): Loss: 0.2243
===> Epoch[25](1700/2500): Loss: 0.2340
===> Epoch[25](1800/2500): Loss: 0.2309
===> Epoch[25](1900/2500): Loss: 0.2279
===> Epoch[25](2000/2500): Loss: 0.2169
===> Epoch[25](2100/2500): Loss: 0.2336
===> Epoch[25](2200/2500): Loss: 0.2461
===> Epoch[25](2300/2500): Loss: 0.2131
===> Epoch[25](2400/2500): Loss: 0.2262
===> Epoch[25](2500/2500): Loss: 0.2198
===> Epoch 25 Complete: Avg. Loss: 0.2261
===> Timestamp: [2025-08-03 17:15:00]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2181
===> Epoch[25](200/2500): Loss: 0.2176
===> Epoch[25](300/2500): Loss: 0.2400
===> Epoch[25](400/2500): Loss: 0.2107
===> Epoch[25](500/2500): Loss: 0.2111
===> Epoch[25](600/2500): Loss: 0.2363
===> Epoch[25](700/2500): Loss: 0.2083
===> Epoch[25](800/2500): Loss: 0.2203
===> Epoch[25](900/2500): Loss: 0.2487
===> Epoch[25](1000/2500): Loss: 0.2231
===> Epoch[25](1100/2500): Loss: 0.2264
===> Epoch[25](1200/2500): Loss: 0.2366
===> Epoch[25](1300/2500): Loss: 0.2245
===> Epoch[25](1400/2500): Loss: 0.2205
===> Epoch[25](1500/2500): Loss: 0.2141
===> Epoch[25](1600/2500): Loss: 0.2243
===> Epoch[25](1700/2500): Loss: 0.2340
===> Epoch[25](1800/2500): Loss: 0.2309
===> Epoch[25](1900/2500): Loss: 0.2279
===> Epoch[25](2000/2500): Loss: 0.2169
===> Epoch[25](2100/2500): Loss: 0.2336
===> Epoch[25](2200/2500): Loss: 0.2461
===> Epoch[25](2300/2500): Loss: 0.2131
===> Epoch[25](2400/2500): Loss: 0.2262
===> Epoch[25](2500/2500): Loss: 0.2198
===> Epoch 25 Complete: Avg. Loss: 0.2261
===> Timestamp: [2025-08-03 17:15:00]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2181
===> Epoch[25](200/2500): Loss: 0.2176
===> Epoch[25](300/2500): Loss: 0.2400
===> Epoch[25](400/2500): Loss: 0.2107
===> Epoch[25](500/2500): Loss: 0.2111
===> Epoch[25](600/2500): Loss: 0.2363
===> Epoch[25](700/2500): Loss: 0.2083
===> Epoch[25](800/2500): Loss: 0.2203
===> Epoch[25](900/2500): Loss: 0.2487
===> Epoch[25](1000/2500): Loss: 0.2231
===> Epoch[25](1100/2500): Loss: 0.2264
===> Epoch[25](1200/2500): Loss: 0.2366
===> Epoch[25](1300/2500): Loss: 0.2245
===> Epoch[25](1400/2500): Loss: 0.2205
===> Epoch[25](1500/2500): Loss: 0.2141
===> Epoch[25](1600/2500): Loss: 0.2243
===> Epoch[25](1700/2500): Loss: 0.2340
===> Epoch[25](1800/2500): Loss: 0.2309
===> Epoch[25](1900/2500): Loss: 0.2279
===> Epoch[25](2000/2500): Loss: 0.2169
===> Epoch[25](2100/2500): Loss: 0.2336
===> Epoch[25](2200/2500): Loss: 0.2461
===> Epoch[25](2300/2500): Loss: 0.2131
===> Epoch[25](2400/2500): Loss: 0.2262
===> Epoch[25](2500/2500): Loss: 0.2198
===> Epoch 25 Complete: Avg. Loss: 0.2261
===> Timestamp: [2025-08-03 17:15:00]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2181
===> Epoch[25](200/2500): Loss: 0.2176
===> Epoch[25](300/2500): Loss: 0.2400
===> Epoch[25](400/2500): Loss: 0.2107
===> Epoch[25](500/2500): Loss: 0.2111
===> Epoch[25](600/2500): Loss: 0.2363
===> Epoch[25](700/2500): Loss: 0.2083
===> Epoch[25](800/2500): Loss: 0.2203
===> Epoch[25](900/2500): Loss: 0.2487
===> Epoch[25](1000/2500): Loss: 0.2231
===> Epoch[25](1100/2500): Loss: 0.2264
===> Epoch[25](1200/2500): Loss: 0.2366
===> Epoch[25](1300/2500): Loss: 0.2245
===> Epoch[25](1400/2500): Loss: 0.2205
===> Epoch[25](1500/2500): Loss: 0.2141
===> Epoch[25](1600/2500): Loss: 0.2243
===> Epoch[25](1700/2500): Loss: 0.2340
===> Epoch[25](1800/2500): Loss: 0.2309
===> Epoch[25](1900/2500): Loss: 0.2279
===> Epoch[25](2000/2500): Loss: 0.2169
===> Epoch[25](2100/2500): Loss: 0.2336
===> Epoch[25](2200/2500): Loss: 0.2461
===> Epoch[25](2300/2500): Loss: 0.2131
===> Epoch[25](2400/2500): Loss: 0.2262
===> Epoch[25](2500/2500): Loss: 0.2198
===> Epoch 25 Complete: Avg. Loss: 0.2261
===> Timestamp: [2025-08-03 17:15:00]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2181
===> Epoch[25](200/2500): Loss: 0.2176
===> Epoch[25](300/2500): Loss: 0.2400
===> Epoch[25](400/2500): Loss: 0.2107
===> Epoch[25](500/2500): Loss: 0.2111
===> Epoch[25](600/2500): Loss: 0.2363
===> Epoch[25](700/2500): Loss: 0.2083
===> Epoch[25](800/2500): Loss: 0.2203
===> Epoch[25](900/2500): Loss: 0.2487
===> Epoch[25](1000/2500): Loss: 0.2231
===> Epoch[25](1100/2500): Loss: 0.2264
===> Epoch[25](1200/2500): Loss: 0.2366
===> Epoch[25](1300/2500): Loss: 0.2245
===> Epoch[25](1400/2500): Loss: 0.2205
===> Epoch[25](1500/2500): Loss: 0.2141
===> Epoch[25](1600/2500): Loss: 0.2243
===> Epoch[25](1700/2500): Loss: 0.2340
===> Epoch[25](1800/2500): Loss: 0.2309
===> Epoch[25](1900/2500): Loss: 0.2279
===> Epoch[25](2000/2500): Loss: 0.2169
===> Epoch[25](2100/2500): Loss: 0.2336
===> Epoch[25](2200/2500): Loss: 0.2461
===> Epoch[25](2300/2500): Loss: 0.2131
===> Epoch[25](2400/2500): Loss: 0.2262
===> Epoch[25](2500/2500): Loss: 0.2198
===> Epoch 25 Complete: Avg. Loss: 0.2261
===> Timestamp: [2025-08-03 17:15:00]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2181
===> Epoch[25](200/2500): Loss: 0.2176
===> Epoch[25](300/2500): Loss: 0.2400
===> Epoch[25](400/2500): Loss: 0.2107
===> Epoch[25](500/2500): Loss: 0.2111
===> Epoch[25](600/2500): Loss: 0.2363
===> Epoch[25](700/2500): Loss: 0.2083
===> Epoch[25](800/2500): Loss: 0.2203
===> Epoch[25](900/2500): Loss: 0.2487
===> Epoch[25](1000/2500): Loss: 0.2231
===> Epoch[25](1100/2500): Loss: 0.2264
===> Epoch[25](1200/2500): Loss: 0.2366
===> Epoch[25](1300/2500): Loss: 0.2245
===> Epoch[25](1400/2500): Loss: 0.2205
===> Epoch[25](1500/2500): Loss: 0.2141
===> Epoch[25](1600/2500): Loss: 0.2243
===> Epoch[25](1700/2500): Loss: 0.2340
===> Epoch[25](1800/2500): Loss: 0.2309
===> Epoch[25](1900/2500): Loss: 0.2279
===> Epoch[25](2000/2500): Loss: 0.2169
===> Epoch[25](2100/2500): Loss: 0.2336
===> Epoch[25](2200/2500): Loss: 0.2461
===> Epoch[25](2300/2500): Loss: 0.2131
===> Epoch[25](2400/2500): Loss: 0.2262
===> Epoch[25](2500/2500): Loss: 0.2198
===> Epoch 25 Complete: Avg. Loss: 0.2261
===> Timestamp: [2025-08-03 17:15:00]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2181
===> Epoch[25](200/2500): Loss: 0.2176
===> Epoch[25](300/2500): Loss: 0.2400
===> Epoch[25](400/2500): Loss: 0.2107
===> Epoch[25](500/2500): Loss: 0.2111
===> Epoch[25](600/2500): Loss: 0.2363
===> Epoch[25](700/2500): Loss: 0.2083
===> Epoch[25](800/2500): Loss: 0.2203
===> Epoch[25](900/2500): Loss: 0.2487
===> Epoch[25](1000/2500): Loss: 0.2231
===> Epoch[25](1100/2500): Loss: 0.2264
===> Epoch[25](1200/2500): Loss: 0.2366
===> Epoch[25](1300/2500): Loss: 0.2245
===> Epoch[25](1400/2500): Loss: 0.2205
===> Epoch[25](1500/2500): Loss: 0.2141
===> Epoch[25](1600/2500): Loss: 0.2243
===> Epoch[25](1700/2500): Loss: 0.2340
===> Epoch[25](1800/2500): Loss: 0.2309
===> Epoch[25](1900/2500): Loss: 0.2279
===> Epoch[25](2000/2500): Loss: 0.2169
===> Epoch[25](2100/2500): Loss: 0.2336
===> Epoch[25](2200/2500): Loss: 0.2461
===> Epoch[25](2300/2500): Loss: 0.2131
===> Epoch[25](2400/2500): Loss: 0.2262
===> Epoch[25](2500/2500): Loss: 0.2198
===> Epoch 25 Complete: Avg. Loss: 0.2261
===> Timestamp: [2025-08-03 17:15:00]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2181
===> Epoch[25](200/2500): Loss: 0.2176
===> Epoch[25](300/2500): Loss: 0.2400
===> Epoch[25](400/2500): Loss: 0.2107
===> Epoch[25](500/2500): Loss: 0.2111
===> Epoch[25](600/2500): Loss: 0.2363
===> Epoch[25](700/2500): Loss: 0.2083
===> Epoch[25](800/2500): Loss: 0.2203
===> Epoch[25](900/2500): Loss: 0.2487
===> Epoch[25](1000/2500): Loss: 0.2231
===> Epoch[25](1100/2500): Loss: 0.2264
===> Epoch[25](1200/2500): Loss: 0.2366
===> Epoch[25](1300/2500): Loss: 0.2245
===> Epoch[25](1400/2500): Loss: 0.2205
===> Epoch[25](1500/2500): Loss: 0.2141
===> Epoch[25](1600/2500): Loss: 0.2243
===> Epoch[25](1700/2500): Loss: 0.2340
===> Epoch[25](1800/2500): Loss: 0.2309
===> Epoch[25](1900/2500): Loss: 0.2279
===> Epoch[25](2000/2500): Loss: 0.2169
===> Epoch[25](2100/2500): Loss: 0.2336
===> Epoch[25](2200/2500): Loss: 0.2461
===> Epoch[25](2300/2500): Loss: 0.2131
===> Epoch[25](2400/2500): Loss: 0.2262
===> Epoch[25](2500/2500): Loss: 0.2198
===> Epoch 25 Complete: Avg. Loss: 0.2261
===> Timestamp: [2025-08-03 17:15:00]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2181
===> Epoch[25](200/2500): Loss: 0.2176
===> Epoch[25](300/2500): Loss: 0.2400
===> Epoch[25](400/2500): Loss: 0.2107
===> Epoch[25](500/2500): Loss: 0.2111
===> Epoch[25](600/2500): Loss: 0.2363
===> Epoch[25](700/2500): Loss: 0.2083
===> Epoch[25](800/2500): Loss: 0.2203
===> Epoch[25](900/2500): Loss: 0.2487
===> Epoch[25](1000/2500): Loss: 0.2231
===> Epoch[25](1100/2500): Loss: 0.2264
===> Epoch[25](1200/2500): Loss: 0.2366
===> Epoch[25](1300/2500): Loss: 0.2245
===> Epoch[25](1400/2500): Loss: 0.2205
===> Epoch[25](1500/2500): Loss: 0.2141
===> Epoch[25](1600/2500): Loss: 0.2243
===> Epoch[25](1700/2500): Loss: 0.2340
===> Epoch[25](1800/2500): Loss: 0.2309
===> Epoch[25](1900/2500): Loss: 0.2279
===> Epoch[25](2000/2500): Loss: 0.2169
===> Epoch[25](2100/2500): Loss: 0.2336
===> Epoch[25](2200/2500): Loss: 0.2461
===> Epoch[25](2300/2500): Loss: 0.2131
===> Epoch[25](2400/2500): Loss: 0.2262
===> Epoch[25](2500/2500): Loss: 0.2198
===> Epoch 25 Complete: Avg. Loss: 0.2261
===> Timestamp: [2025-08-03 17:15:00]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2181
===> Epoch[25](200/2500): Loss: 0.2176
===> Epoch[25](300/2500): Loss: 0.2400
===> Epoch[25](400/2500): Loss: 0.2107
===> Epoch[25](500/2500): Loss: 0.2111
===> Epoch[25](600/2500): Loss: 0.2363
===> Epoch[25](700/2500): Loss: 0.2083
===> Epoch[25](800/2500): Loss: 0.2203
===> Epoch[25](900/2500): Loss: 0.2487
===> Epoch[25](1000/2500): Loss: 0.2231
===> Epoch[25](1100/2500): Loss: 0.2264
===> Epoch[25](1200/2500): Loss: 0.2366
===> Epoch[25](1300/2500): Loss: 0.2245
===> Epoch[25](1400/2500): Loss: 0.2205
===> Epoch[25](1500/2500): Loss: 0.2141
===> Epoch[25](1600/2500): Loss: 0.2243
===> Epoch[25](1700/2500): Loss: 0.2340
===> Epoch[25](1800/2500): Loss: 0.2309
===> Epoch[25](1900/2500): Loss: 0.2279
===> Epoch[25](2000/2500): Loss: 0.2169
===> Epoch[25](2100/2500): Loss: 0.2336
===> Epoch[25](2200/2500): Loss: 0.2461
===> Epoch[25](2300/2500): Loss: 0.2131
===> Epoch[25](2400/2500): Loss: 0.2262
===> Epoch[25](2500/2500): Loss: 0.2198
===> Epoch 25 Complete: Avg. Loss: 0.2261
===> Timestamp: [2025-08-03 17:15:00]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2181
===> Epoch[25](200/2500): Loss: 0.2176
===> Epoch[25](300/2500): Loss: 0.2400
===> Epoch[25](400/2500): Loss: 0.2107
===> Epoch[25](500/2500): Loss: 0.2111
===> Epoch[25](600/2500): Loss: 0.2363
===> Epoch[25](700/2500): Loss: 0.2083
===> Epoch[25](800/2500): Loss: 0.2203
===> Epoch[25](900/2500): Loss: 0.2487
===> Epoch[25](1000/2500): Loss: 0.2231
===> Epoch[25](1100/2500): Loss: 0.2264
===> Epoch[25](1200/2500): Loss: 0.2366
===> Epoch[25](1300/2500): Loss: 0.2245
===> Epoch[25](1400/2500): Loss: 0.2205
===> Epoch[25](1500/2500): Loss: 0.2141
===> Epoch[25](1600/2500): Loss: 0.2243
===> Epoch[25](1700/2500): Loss: 0.2340
===> Epoch[25](1800/2500): Loss: 0.2309
===> Epoch[25](1900/2500): Loss: 0.2279
===> Epoch[25](2000/2500): Loss: 0.2169
===> Epoch[25](2100/2500): Loss: 0.2336
===> Epoch[25](2200/2500): Loss: 0.2461
===> Epoch[25](2300/2500): Loss: 0.2131
===> Epoch[25](2400/2500): Loss: 0.2262
===> Epoch[25](2500/2500): Loss: 0.2198
===> Epoch 25 Complete: Avg. Loss: 0.2261
===> Timestamp: [2025-08-03 17:15:00]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2181
===> Epoch[25](200/2500): Loss: 0.2176
===> Epoch[25](300/2500): Loss: 0.2400
===> Epoch[25](400/2500): Loss: 0.2107
===> Epoch[25](500/2500): Loss: 0.2111
===> Epoch[25](600/2500): Loss: 0.2363
===> Epoch[25](700/2500): Loss: 0.2083
===> Epoch[25](800/2500): Loss: 0.2203
===> Epoch[25](900/2500): Loss: 0.2487
===> Epoch[25](1000/2500): Loss: 0.2231
===> Epoch[25](1100/2500): Loss: 0.2264
===> Epoch[25](1200/2500): Loss: 0.2366
===> Epoch[25](1300/2500): Loss: 0.2245
===> Epoch[25](1400/2500): Loss: 0.2205
===> Epoch[25](1500/2500): Loss: 0.2141
===> Epoch[25](1600/2500): Loss: 0.2243
===> Epoch[25](1700/2500): Loss: 0.2340
===> Epoch[25](1800/2500): Loss: 0.2309
===> Epoch[25](1900/2500): Loss: 0.2279
===> Epoch[25](2000/2500): Loss: 0.2169
===> Epoch[25](2100/2500): Loss: 0.2336
===> Epoch[25](2200/2500): Loss: 0.2461
===> Epoch[25](2300/2500): Loss: 0.2131
===> Epoch[25](2400/2500): Loss: 0.2262
===> Epoch[25](2500/2500): Loss: 0.2198
===> Epoch 25 Complete: Avg. Loss: 0.2261
===> Timestamp: [2025-08-03 17:15:00]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2181
===> Epoch[25](200/2500): Loss: 0.2176
===> Epoch[25](300/2500): Loss: 0.2400
===> Epoch[25](400/2500): Loss: 0.2107
===> Epoch[25](500/2500): Loss: 0.2111
===> Epoch[25](600/2500): Loss: 0.2363
===> Epoch[25](700/2500): Loss: 0.2083
===> Epoch[25](800/2500): Loss: 0.2203
===> Epoch[25](900/2500): Loss: 0.2487
===> Epoch[25](1000/2500): Loss: 0.2231
===> Epoch[25](1100/2500): Loss: 0.2264
===> Epoch[25](1200/2500): Loss: 0.2366
===> Epoch[25](1300/2500): Loss: 0.2245
===> Epoch[25](1400/2500): Loss: 0.2205
===> Epoch[25](1500/2500): Loss: 0.2141
===> Epoch[25](1600/2500): Loss: 0.2243
===> Epoch[25](1700/2500): Loss: 0.2340
===> Epoch[25](1800/2500): Loss: 0.2309
===> Epoch[25](1900/2500): Loss: 0.2279
===> Epoch[25](2000/2500): Loss: 0.2169
===> Epoch[25](2100/2500): Loss: 0.2336
===> Epoch[25](2200/2500): Loss: 0.2461
===> Epoch[25](2300/2500): Loss: 0.2131
===> Epoch[25](2400/2500): Loss: 0.2262
===> Epoch[25](2500/2500): Loss: 0.2198
===> Epoch 25 Complete: Avg. Loss: 0.2261
===> Timestamp: [2025-08-03 17:15:00]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2181
===> Epoch[25](200/2500): Loss: 0.2176
===> Epoch[25](300/2500): Loss: 0.2400
===> Epoch[25](400/2500): Loss: 0.2107
===> Epoch[25](500/2500): Loss: 0.2111
===> Epoch[25](600/2500): Loss: 0.2363
===> Epoch[25](700/2500): Loss: 0.2083
===> Epoch[25](800/2500): Loss: 0.2203
===> Epoch[25](900/2500): Loss: 0.2487
===> Epoch[25](1000/2500): Loss: 0.2231
===> Epoch[25](1100/2500): Loss: 0.2264
===> Epoch[25](1200/2500): Loss: 0.2366
===> Epoch[25](1300/2500): Loss: 0.2245
===> Epoch[25](1400/2500): Loss: 0.2205
===> Epoch[25](1500/2500): Loss: 0.2141
===> Epoch[25](1600/2500): Loss: 0.2243
===> Epoch[25](1700/2500): Loss: 0.2340
===> Epoch[25](1800/2500): Loss: 0.2309
===> Epoch[25](1900/2500): Loss: 0.2279
===> Epoch[25](2000/2500): Loss: 0.2169
===> Epoch[25](2100/2500): Loss: 0.2336
===> Epoch[25](2200/2500): Loss: 0.2461
===> Epoch[25](2300/2500): Loss: 0.2131
===> Epoch[25](2400/2500): Loss: 0.2262
===> Epoch[25](2500/2500): Loss: 0.2198
===> Epoch 25 Complete: Avg. Loss: 0.2261
===> Timestamp: [2025-08-03 17:15:00]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2181
===> Epoch[25](200/2500): Loss: 0.2176
===> Epoch[25](300/2500): Loss: 0.2400
===> Epoch[25](400/2500): Loss: 0.2107
===> Epoch[25](500/2500): Loss: 0.2111
===> Epoch[25](600/2500): Loss: 0.2363
===> Epoch[25](700/2500): Loss: 0.2083
===> Epoch[25](800/2500): Loss: 0.2203
===> Epoch[25](900/2500): Loss: 0.2487
===> Epoch[25](1000/2500): Loss: 0.2231
===> Epoch[25](1100/2500): Loss: 0.2264
===> Epoch[25](1200/2500): Loss: 0.2366
===> Epoch[25](1300/2500): Loss: 0.2245
===> Epoch[25](1400/2500): Loss: 0.2205
===> Epoch[25](1500/2500): Loss: 0.2141
===> Epoch[25](1600/2500): Loss: 0.2243
===> Epoch[25](1700/2500): Loss: 0.2340
===> Epoch[25](1800/2500): Loss: 0.2309
===> Epoch[25](1900/2500): Loss: 0.2279
===> Epoch[25](2000/2500): Loss: 0.2169
===> Epoch[25](2100/2500): Loss: 0.2336
===> Epoch[25](2200/2500): Loss: 0.2461
===> Epoch[25](2300/2500): Loss: 0.2131
===> Epoch[25](2400/2500): Loss: 0.2262
===> Epoch[25](2500/2500): Loss: 0.2198
===> Epoch 25 Complete: Avg. Loss: 0.2261
===> Timestamp: [2025-08-03 17:15:00]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2181
===> Epoch[25](200/2500): Loss: 0.2176
===> Epoch[25](300/2500): Loss: 0.2400
===> Epoch[25](400/2500): Loss: 0.2107
===> Epoch[25](500/2500): Loss: 0.2111
===> Epoch[25](600/2500): Loss: 0.2363
===> Epoch[25](700/2500): Loss: 0.2083
===> Epoch[25](800/2500): Loss: 0.2203
===> Epoch[25](900/2500): Loss: 0.2487
===> Epoch[25](1000/2500): Loss: 0.2231
===> Epoch[25](1100/2500): Loss: 0.2264
===> Epoch[25](1200/2500): Loss: 0.2366
===> Epoch[25](1300/2500): Loss: 0.2245
===> Epoch[25](1400/2500): Loss: 0.2205
===> Epoch[25](1500/2500): Loss: 0.2141
===> Epoch[25](1600/2500): Loss: 0.2243
===> Epoch[25](1700/2500): Loss: 0.2340
===> Epoch[25](1800/2500): Loss: 0.2309
===> Epoch[25](1900/2500): Loss: 0.2279
===> Epoch[25](2000/2500): Loss: 0.2169
===> Epoch[25](2100/2500): Loss: 0.2336
===> Epoch[25](2200/2500): Loss: 0.2461
===> Epoch[25](2300/2500): Loss: 0.2131
===> Epoch[25](2400/2500): Loss: 0.2262
===> Epoch[25](2500/2500): Loss: 0.2198
===> Epoch 25 Complete: Avg. Loss: 0.2261
===> Timestamp: [2025-08-03 17:15:00]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2181
===> Epoch[25](200/2500): Loss: 0.2176
===> Epoch[25](300/2500): Loss: 0.2400
===> Epoch[25](400/2500): Loss: 0.2107
===> Epoch[25](500/2500): Loss: 0.2111
===> Epoch[25](600/2500): Loss: 0.2363
===> Epoch[25](700/2500): Loss: 0.2083
===> Epoch[25](800/2500): Loss: 0.2203
===> Epoch[25](900/2500): Loss: 0.2487
===> Epoch[25](1000/2500): Loss: 0.2231
===> Epoch[25](1100/2500): Loss: 0.2264
===> Epoch[25](1200/2500): Loss: 0.2366
===> Epoch[25](1300/2500): Loss: 0.2245
===> Epoch[25](1400/2500): Loss: 0.2205
===> Epoch[25](1500/2500): Loss: 0.2141
===> Epoch[25](1600/2500): Loss: 0.2243
===> Epoch[25](1700/2500): Loss: 0.2340
===> Epoch[25](1800/2500): Loss: 0.2309
===> Epoch[25](1900/2500): Loss: 0.2279
===> Epoch[25](2000/2500): Loss: 0.2169
===> Epoch[25](2100/2500): Loss: 0.2336
===> Epoch[25](2200/2500): Loss: 0.2461
===> Epoch[25](2300/2500): Loss: 0.2131
===> Epoch[25](2400/2500): Loss: 0.2262
===> Epoch[25](2500/2500): Loss: 0.2198
===> Epoch 25 Complete: Avg. Loss: 0.2261
===> Timestamp: [2025-08-03 17:15:00]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2181
===> Epoch[25](200/2500): Loss: 0.2176
===> Epoch[25](300/2500): Loss: 0.2400
===> Epoch[25](400/2500): Loss: 0.2107
===> Epoch[25](500/2500): Loss: 0.2111
===> Epoch[25](600/2500): Loss: 0.2363
===> Epoch[25](700/2500): Loss: 0.2083
===> Epoch[25](800/2500): Loss: 0.2203
===> Epoch[25](900/2500): Loss: 0.2487
===> Epoch[25](1000/2500): Loss: 0.2231
===> Epoch[25](1100/2500): Loss: 0.2264
===> Epoch[25](1200/2500): Loss: 0.2366
===> Epoch[25](1300/2500): Loss: 0.2245
===> Epoch[25](1400/2500): Loss: 0.2205
===> Epoch[25](1500/2500): Loss: 0.2141
===> Epoch[25](1600/2500): Loss: 0.2243
===> Epoch[25](1700/2500): Loss: 0.2340
===> Epoch[25](1800/2500): Loss: 0.2309
===> Epoch[25](1900/2500): Loss: 0.2279
===> Epoch[25](2000/2500): Loss: 0.2169
===> Epoch[25](2100/2500): Loss: 0.2336
===> Epoch[25](2200/2500): Loss: 0.2461
===> Epoch[25](2300/2500): Loss: 0.2131
===> Epoch[25](2400/2500): Loss: 0.2262
===> Epoch[25](2500/2500): Loss: 0.2198
===> Epoch 25 Complete: Avg. Loss: 0.2261
===> Timestamp: [2025-08-03 17:15:00]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2181
===> Epoch[25](200/2500): Loss: 0.2176
===> Epoch[25](300/2500): Loss: 0.2400
===> Epoch[25](400/2500): Loss: 0.2107
===> Epoch[25](500/2500): Loss: 0.2111
===> Epoch[25](600/2500): Loss: 0.2363
===> Epoch[25](700/2500): Loss: 0.2083
===> Epoch[25](800/2500): Loss: 0.2203
===> Epoch[25](900/2500): Loss: 0.2487
===> Epoch[25](1000/2500): Loss: 0.2231
===> Epoch[25](1100/2500): Loss: 0.2264
===> Epoch[25](1200/2500): Loss: 0.2366
===> Epoch[25](1300/2500): Loss: 0.2245
===> Epoch[25](1400/2500): Loss: 0.2205
===> Epoch[25](1500/2500): Loss: 0.2141
===> Epoch[25](1600/2500): Loss: 0.2243
===> Epoch[25](1700/2500): Loss: 0.2340
===> Epoch[25](1800/2500): Loss: 0.2309
===> Epoch[25](1900/2500): Loss: 0.2279
===> Epoch[25](2000/2500): Loss: 0.2169
===> Epoch[25](2100/2500): Loss: 0.2336
===> Epoch[25](2200/2500): Loss: 0.2461
===> Epoch[25](2300/2500): Loss: 0.2131
===> Epoch[25](2400/2500): Loss: 0.2262
===> Epoch[25](2500/2500): Loss: 0.2198
===> Epoch 25 Complete: Avg. Loss: 0.2261
===> Timestamp: [2025-08-03 17:15:00]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2181
===> Epoch[25](200/2500): Loss: 0.2176
===> Epoch[25](300/2500): Loss: 0.2400
===> Epoch[25](400/2500): Loss: 0.2107
===> Epoch[25](500/2500): Loss: 0.2111
===> Epoch[25](600/2500): Loss: 0.2363
===> Epoch[25](700/2500): Loss: 0.2083
===> Epoch[25](800/2500): Loss: 0.2203
===> Epoch[25](900/2500): Loss: 0.2487
===> Epoch[25](1000/2500): Loss: 0.2231
===> Epoch[25](1100/2500): Loss: 0.2264
===> Epoch[25](1200/2500): Loss: 0.2366
===> Epoch[25](1300/2500): Loss: 0.2245
===> Epoch[25](1400/2500): Loss: 0.2205
===> Epoch[25](1500/2500): Loss: 0.2141
===> Epoch[25](1600/2500): Loss: 0.2243
===> Epoch[25](1700/2500): Loss: 0.2340
===> Epoch[25](1800/2500): Loss: 0.2309
===> Epoch[25](1900/2500): Loss: 0.2279
===> Epoch[25](2000/2500): Loss: 0.2169
===> Epoch[25](2100/2500): Loss: 0.2336
===> Epoch[25](2200/2500): Loss: 0.2461
===> Epoch[25](2300/2500): Loss: 0.2131
===> Epoch[25](2400/2500): Loss: 0.2262
===> Epoch[25](2500/2500): Loss: 0.2198
===> Epoch 25 Complete: Avg. Loss: 0.2261
===> Timestamp: [2025-08-03 17:15:00]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2268
===> Epoch[26](200/2500): Loss: 0.2169
===> Epoch[26](300/2500): Loss: 0.2102
===> Epoch[26](400/2500): Loss: 0.2205
===> Epoch[26](500/2500): Loss: 0.2406
===> Epoch[26](600/2500): Loss: 0.2292
===> Epoch[26](700/2500): Loss: 0.2367
===> Epoch[26](800/2500): Loss: 0.2366
===> Epoch[26](900/2500): Loss: 0.2296
===> Epoch[26](1000/2500): Loss: 0.2340
===> Epoch[26](1100/2500): Loss: 0.2392
===> Epoch[26](1200/2500): Loss: 0.2267
===> Epoch[26](1300/2500): Loss: 0.2017
===> Epoch[26](1400/2500): Loss: 0.2107
===> Epoch[26](1500/2500): Loss: 0.2295
===> Epoch[26](1600/2500): Loss: 0.2177
===> Epoch[26](1700/2500): Loss: 0.2230
===> Epoch[26](1800/2500): Loss: 0.2138
===> Epoch[26](1900/2500): Loss: 0.2100
===> Epoch[26](2000/2500): Loss: 0.2389
===> Epoch[26](2100/2500): Loss: 0.2463
===> Epoch[26](2200/2500): Loss: 0.2387
===> Epoch[26](2300/2500): Loss: 0.2394
===> Epoch[26](2400/2500): Loss: 0.2254
===> Epoch[26](2500/2500): Loss: 0.2255
===> Epoch 26 Complete: Avg. Loss: 0.2255
===> Timestamp: [2025-08-03 17:19:34]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2268
===> Epoch[26](200/2500): Loss: 0.2169
===> Epoch[26](300/2500): Loss: 0.2102
===> Epoch[26](400/2500): Loss: 0.2205
===> Epoch[26](500/2500): Loss: 0.2406
===> Epoch[26](600/2500): Loss: 0.2292
===> Epoch[26](700/2500): Loss: 0.2367
===> Epoch[26](800/2500): Loss: 0.2366
===> Epoch[26](900/2500): Loss: 0.2296
===> Epoch[26](1000/2500): Loss: 0.2340
===> Epoch[26](1100/2500): Loss: 0.2392
===> Epoch[26](1200/2500): Loss: 0.2267
===> Epoch[26](1300/2500): Loss: 0.2017
===> Epoch[26](1400/2500): Loss: 0.2107
===> Epoch[26](1500/2500): Loss: 0.2295
===> Epoch[26](1600/2500): Loss: 0.2177
===> Epoch[26](1700/2500): Loss: 0.2230
===> Epoch[26](1800/2500): Loss: 0.2138
===> Epoch[26](1900/2500): Loss: 0.2100
===> Epoch[26](2000/2500): Loss: 0.2389
===> Epoch[26](2100/2500): Loss: 0.2463
===> Epoch[26](2200/2500): Loss: 0.2387
===> Epoch[26](2300/2500): Loss: 0.2394
===> Epoch[26](2400/2500): Loss: 0.2254
===> Epoch[26](2500/2500): Loss: 0.2255
===> Epoch 26 Complete: Avg. Loss: 0.2255
===> Timestamp: [2025-08-03 17:19:34]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2268
===> Epoch[26](200/2500): Loss: 0.2169
===> Epoch[26](300/2500): Loss: 0.2102
===> Epoch[26](400/2500): Loss: 0.2205
===> Epoch[26](500/2500): Loss: 0.2406
===> Epoch[26](600/2500): Loss: 0.2292
===> Epoch[26](700/2500): Loss: 0.2367
===> Epoch[26](800/2500): Loss: 0.2366
===> Epoch[26](900/2500): Loss: 0.2296
===> Epoch[26](1000/2500): Loss: 0.2340
===> Epoch[26](1100/2500): Loss: 0.2392
===> Epoch[26](1200/2500): Loss: 0.2267
===> Epoch[26](1300/2500): Loss: 0.2017
===> Epoch[26](1400/2500): Loss: 0.2107
===> Epoch[26](1500/2500): Loss: 0.2295
===> Epoch[26](1600/2500): Loss: 0.2177
===> Epoch[26](1700/2500): Loss: 0.2230
===> Epoch[26](1800/2500): Loss: 0.2138
===> Epoch[26](1900/2500): Loss: 0.2100
===> Epoch[26](2000/2500): Loss: 0.2389
===> Epoch[26](2100/2500): Loss: 0.2463
===> Epoch[26](2200/2500): Loss: 0.2387
===> Epoch[26](2300/2500): Loss: 0.2394
===> Epoch[26](2400/2500): Loss: 0.2254
===> Epoch[26](2500/2500): Loss: 0.2255
===> Epoch 26 Complete: Avg. Loss: 0.2255
===> Timestamp: [2025-08-03 17:19:34]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2268
===> Epoch[26](200/2500): Loss: 0.2169
===> Epoch[26](300/2500): Loss: 0.2102
===> Epoch[26](400/2500): Loss: 0.2205
===> Epoch[26](500/2500): Loss: 0.2406
===> Epoch[26](600/2500): Loss: 0.2292
===> Epoch[26](700/2500): Loss: 0.2367
===> Epoch[26](800/2500): Loss: 0.2366
===> Epoch[26](900/2500): Loss: 0.2296
===> Epoch[26](1000/2500): Loss: 0.2340
===> Epoch[26](1100/2500): Loss: 0.2392
===> Epoch[26](1200/2500): Loss: 0.2267
===> Epoch[26](1300/2500): Loss: 0.2017
===> Epoch[26](1400/2500): Loss: 0.2107
===> Epoch[26](1500/2500): Loss: 0.2295
===> Epoch[26](1600/2500): Loss: 0.2177
===> Epoch[26](1700/2500): Loss: 0.2230
===> Epoch[26](1800/2500): Loss: 0.2138
===> Epoch[26](1900/2500): Loss: 0.2100
===> Epoch[26](2000/2500): Loss: 0.2389
===> Epoch[26](2100/2500): Loss: 0.2463
===> Epoch[26](2200/2500): Loss: 0.2387
===> Epoch[26](2300/2500): Loss: 0.2394
===> Epoch[26](2400/2500): Loss: 0.2254
===> Epoch[26](2500/2500): Loss: 0.2255
===> Epoch 26 Complete: Avg. Loss: 0.2255
===> Timestamp: [2025-08-03 17:19:34]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2268
===> Epoch[26](200/2500): Loss: 0.2169
===> Epoch[26](300/2500): Loss: 0.2102
===> Epoch[26](400/2500): Loss: 0.2205
===> Epoch[26](500/2500): Loss: 0.2406
===> Epoch[26](600/2500): Loss: 0.2292
===> Epoch[26](700/2500): Loss: 0.2367
===> Epoch[26](800/2500): Loss: 0.2366
===> Epoch[26](900/2500): Loss: 0.2296
===> Epoch[26](1000/2500): Loss: 0.2340
===> Epoch[26](1100/2500): Loss: 0.2392
===> Epoch[26](1200/2500): Loss: 0.2267
===> Epoch[26](1300/2500): Loss: 0.2017
===> Epoch[26](1400/2500): Loss: 0.2107
===> Epoch[26](1500/2500): Loss: 0.2295
===> Epoch[26](1600/2500): Loss: 0.2177
===> Epoch[26](1700/2500): Loss: 0.2230
===> Epoch[26](1800/2500): Loss: 0.2138
===> Epoch[26](1900/2500): Loss: 0.2100
===> Epoch[26](2000/2500): Loss: 0.2389
===> Epoch[26](2100/2500): Loss: 0.2463
===> Epoch[26](2200/2500): Loss: 0.2387
===> Epoch[26](2300/2500): Loss: 0.2394
===> Epoch[26](2400/2500): Loss: 0.2254
===> Epoch[26](2500/2500): Loss: 0.2255
===> Epoch 26 Complete: Avg. Loss: 0.2255
===> Timestamp: [2025-08-03 17:19:34]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2268
===> Epoch[26](200/2500): Loss: 0.2169
===> Epoch[26](300/2500): Loss: 0.2102
===> Epoch[26](400/2500): Loss: 0.2205
===> Epoch[26](500/2500): Loss: 0.2406
===> Epoch[26](600/2500): Loss: 0.2292
===> Epoch[26](700/2500): Loss: 0.2367
===> Epoch[26](800/2500): Loss: 0.2366
===> Epoch[26](900/2500): Loss: 0.2296
===> Epoch[26](1000/2500): Loss: 0.2340
===> Epoch[26](1100/2500): Loss: 0.2392
===> Epoch[26](1200/2500): Loss: 0.2267
===> Epoch[26](1300/2500): Loss: 0.2017
===> Epoch[26](1400/2500): Loss: 0.2107
===> Epoch[26](1500/2500): Loss: 0.2295
===> Epoch[26](1600/2500): Loss: 0.2177
===> Epoch[26](1700/2500): Loss: 0.2230
===> Epoch[26](1800/2500): Loss: 0.2138
===> Epoch[26](1900/2500): Loss: 0.2100
===> Epoch[26](2000/2500): Loss: 0.2389
===> Epoch[26](2100/2500): Loss: 0.2463
===> Epoch[26](2200/2500): Loss: 0.2387
===> Epoch[26](2300/2500): Loss: 0.2394
===> Epoch[26](2400/2500): Loss: 0.2254
===> Epoch[26](2500/2500): Loss: 0.2255
===> Epoch 26 Complete: Avg. Loss: 0.2255
===> Timestamp: [2025-08-03 17:19:34]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2268
===> Epoch[26](200/2500): Loss: 0.2169
===> Epoch[26](300/2500): Loss: 0.2102
===> Epoch[26](400/2500): Loss: 0.2205
===> Epoch[26](500/2500): Loss: 0.2406
===> Epoch[26](600/2500): Loss: 0.2292
===> Epoch[26](700/2500): Loss: 0.2367
===> Epoch[26](800/2500): Loss: 0.2366
===> Epoch[26](900/2500): Loss: 0.2296
===> Epoch[26](1000/2500): Loss: 0.2340
===> Epoch[26](1100/2500): Loss: 0.2392
===> Epoch[26](1200/2500): Loss: 0.2267
===> Epoch[26](1300/2500): Loss: 0.2017
===> Epoch[26](1400/2500): Loss: 0.2107
===> Epoch[26](1500/2500): Loss: 0.2295
===> Epoch[26](1600/2500): Loss: 0.2177
===> Epoch[26](1700/2500): Loss: 0.2230
===> Epoch[26](1800/2500): Loss: 0.2138
===> Epoch[26](1900/2500): Loss: 0.2100
===> Epoch[26](2000/2500): Loss: 0.2389
===> Epoch[26](2100/2500): Loss: 0.2463
===> Epoch[26](2200/2500): Loss: 0.2387
===> Epoch[26](2300/2500): Loss: 0.2394
===> Epoch[26](2400/2500): Loss: 0.2254
===> Epoch[26](2500/2500): Loss: 0.2255
===> Epoch 26 Complete: Avg. Loss: 0.2255
===> Timestamp: [2025-08-03 17:19:34]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2268
===> Epoch[26](200/2500): Loss: 0.2169
===> Epoch[26](300/2500): Loss: 0.2102
===> Epoch[26](400/2500): Loss: 0.2205
===> Epoch[26](500/2500): Loss: 0.2406
===> Epoch[26](600/2500): Loss: 0.2292
===> Epoch[26](700/2500): Loss: 0.2367
===> Epoch[26](800/2500): Loss: 0.2366
===> Epoch[26](900/2500): Loss: 0.2296
===> Epoch[26](1000/2500): Loss: 0.2340
===> Epoch[26](1100/2500): Loss: 0.2392
===> Epoch[26](1200/2500): Loss: 0.2267
===> Epoch[26](1300/2500): Loss: 0.2017
===> Epoch[26](1400/2500): Loss: 0.2107
===> Epoch[26](1500/2500): Loss: 0.2295
===> Epoch[26](1600/2500): Loss: 0.2177
===> Epoch[26](1700/2500): Loss: 0.2230
===> Epoch[26](1800/2500): Loss: 0.2138
===> Epoch[26](1900/2500): Loss: 0.2100
===> Epoch[26](2000/2500): Loss: 0.2389
===> Epoch[26](2100/2500): Loss: 0.2463
===> Epoch[26](2200/2500): Loss: 0.2387
===> Epoch[26](2300/2500): Loss: 0.2394
===> Epoch[26](2400/2500): Loss: 0.2254
===> Epoch[26](2500/2500): Loss: 0.2255
===> Epoch 26 Complete: Avg. Loss: 0.2255
===> Timestamp: [2025-08-03 17:19:34]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2268
===> Epoch[26](200/2500): Loss: 0.2169
===> Epoch[26](300/2500): Loss: 0.2102
===> Epoch[26](400/2500): Loss: 0.2205
===> Epoch[26](500/2500): Loss: 0.2406
===> Epoch[26](600/2500): Loss: 0.2292
===> Epoch[26](700/2500): Loss: 0.2367
===> Epoch[26](800/2500): Loss: 0.2366
===> Epoch[26](900/2500): Loss: 0.2296
===> Epoch[26](1000/2500): Loss: 0.2340
===> Epoch[26](1100/2500): Loss: 0.2392
===> Epoch[26](1200/2500): Loss: 0.2267
===> Epoch[26](1300/2500): Loss: 0.2017
===> Epoch[26](1400/2500): Loss: 0.2107
===> Epoch[26](1500/2500): Loss: 0.2295
===> Epoch[26](1600/2500): Loss: 0.2177
===> Epoch[26](1700/2500): Loss: 0.2230
===> Epoch[26](1800/2500): Loss: 0.2138
===> Epoch[26](1900/2500): Loss: 0.2100
===> Epoch[26](2000/2500): Loss: 0.2389
===> Epoch[26](2100/2500): Loss: 0.2463
===> Epoch[26](2200/2500): Loss: 0.2387
===> Epoch[26](2300/2500): Loss: 0.2394
===> Epoch[26](2400/2500): Loss: 0.2254
===> Epoch[26](2500/2500): Loss: 0.2255
===> Epoch 26 Complete: Avg. Loss: 0.2255
===> Timestamp: [2025-08-03 17:19:34]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2268
===> Epoch[26](200/2500): Loss: 0.2169
===> Epoch[26](300/2500): Loss: 0.2102
===> Epoch[26](400/2500): Loss: 0.2205
===> Epoch[26](500/2500): Loss: 0.2406
===> Epoch[26](600/2500): Loss: 0.2292
===> Epoch[26](700/2500): Loss: 0.2367
===> Epoch[26](800/2500): Loss: 0.2366
===> Epoch[26](900/2500): Loss: 0.2296
===> Epoch[26](1000/2500): Loss: 0.2340
===> Epoch[26](1100/2500): Loss: 0.2392
===> Epoch[26](1200/2500): Loss: 0.2267
===> Epoch[26](1300/2500): Loss: 0.2017
===> Epoch[26](1400/2500): Loss: 0.2107
===> Epoch[26](1500/2500): Loss: 0.2295
===> Epoch[26](1600/2500): Loss: 0.2177
===> Epoch[26](1700/2500): Loss: 0.2230
===> Epoch[26](1800/2500): Loss: 0.2138
===> Epoch[26](1900/2500): Loss: 0.2100
===> Epoch[26](2000/2500): Loss: 0.2389
===> Epoch[26](2100/2500): Loss: 0.2463
===> Epoch[26](2200/2500): Loss: 0.2387
===> Epoch[26](2300/2500): Loss: 0.2394
===> Epoch[26](2400/2500): Loss: 0.2254
===> Epoch[26](2500/2500): Loss: 0.2255
===> Epoch 26 Complete: Avg. Loss: 0.2255
===> Timestamp: [2025-08-03 17:19:34]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2268
===> Epoch[26](200/2500): Loss: 0.2169
===> Epoch[26](300/2500): Loss: 0.2102
===> Epoch[26](400/2500): Loss: 0.2205
===> Epoch[26](500/2500): Loss: 0.2406
===> Epoch[26](600/2500): Loss: 0.2292
===> Epoch[26](700/2500): Loss: 0.2367
===> Epoch[26](800/2500): Loss: 0.2366
===> Epoch[26](900/2500): Loss: 0.2296
===> Epoch[26](1000/2500): Loss: 0.2340
===> Epoch[26](1100/2500): Loss: 0.2392
===> Epoch[26](1200/2500): Loss: 0.2267
===> Epoch[26](1300/2500): Loss: 0.2017
===> Epoch[26](1400/2500): Loss: 0.2107
===> Epoch[26](1500/2500): Loss: 0.2295
===> Epoch[26](1600/2500): Loss: 0.2177
===> Epoch[26](1700/2500): Loss: 0.2230
===> Epoch[26](1800/2500): Loss: 0.2138
===> Epoch[26](1900/2500): Loss: 0.2100
===> Epoch[26](2000/2500): Loss: 0.2389
===> Epoch[26](2100/2500): Loss: 0.2463
===> Epoch[26](2200/2500): Loss: 0.2387
===> Epoch[26](2300/2500): Loss: 0.2394
===> Epoch[26](2400/2500): Loss: 0.2254
===> Epoch[26](2500/2500): Loss: 0.2255
===> Epoch 26 Complete: Avg. Loss: 0.2255
===> Timestamp: [2025-08-03 17:19:34]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2268
===> Epoch[26](200/2500): Loss: 0.2169
===> Epoch[26](300/2500): Loss: 0.2102
===> Epoch[26](400/2500): Loss: 0.2205
===> Epoch[26](500/2500): Loss: 0.2406
===> Epoch[26](600/2500): Loss: 0.2292
===> Epoch[26](700/2500): Loss: 0.2367
===> Epoch[26](800/2500): Loss: 0.2366
===> Epoch[26](900/2500): Loss: 0.2296
===> Epoch[26](1000/2500): Loss: 0.2340
===> Epoch[26](1100/2500): Loss: 0.2392
===> Epoch[26](1200/2500): Loss: 0.2267
===> Epoch[26](1300/2500): Loss: 0.2017
===> Epoch[26](1400/2500): Loss: 0.2107
===> Epoch[26](1500/2500): Loss: 0.2295
===> Epoch[26](1600/2500): Loss: 0.2177
===> Epoch[26](1700/2500): Loss: 0.2230
===> Epoch[26](1800/2500): Loss: 0.2138
===> Epoch[26](1900/2500): Loss: 0.2100
===> Epoch[26](2000/2500): Loss: 0.2389
===> Epoch[26](2100/2500): Loss: 0.2463
===> Epoch[26](2200/2500): Loss: 0.2387
===> Epoch[26](2300/2500): Loss: 0.2394
===> Epoch[26](2400/2500): Loss: 0.2254
===> Epoch[26](2500/2500): Loss: 0.2255
===> Epoch 26 Complete: Avg. Loss: 0.2255
===> Timestamp: [2025-08-03 17:19:34]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2268
===> Epoch[26](200/2500): Loss: 0.2169
===> Epoch[26](300/2500): Loss: 0.2102
===> Epoch[26](400/2500): Loss: 0.2205
===> Epoch[26](500/2500): Loss: 0.2406
===> Epoch[26](600/2500): Loss: 0.2292
===> Epoch[26](700/2500): Loss: 0.2367
===> Epoch[26](800/2500): Loss: 0.2366
===> Epoch[26](900/2500): Loss: 0.2296
===> Epoch[26](1000/2500): Loss: 0.2340
===> Epoch[26](1100/2500): Loss: 0.2392
===> Epoch[26](1200/2500): Loss: 0.2267
===> Epoch[26](1300/2500): Loss: 0.2017
===> Epoch[26](1400/2500): Loss: 0.2107
===> Epoch[26](1500/2500): Loss: 0.2295
===> Epoch[26](1600/2500): Loss: 0.2177
===> Epoch[26](1700/2500): Loss: 0.2230
===> Epoch[26](1800/2500): Loss: 0.2138
===> Epoch[26](1900/2500): Loss: 0.2100
===> Epoch[26](2000/2500): Loss: 0.2389
===> Epoch[26](2100/2500): Loss: 0.2463
===> Epoch[26](2200/2500): Loss: 0.2387
===> Epoch[26](2300/2500): Loss: 0.2394
===> Epoch[26](2400/2500): Loss: 0.2254
===> Epoch[26](2500/2500): Loss: 0.2255
===> Epoch 26 Complete: Avg. Loss: 0.2255
===> Timestamp: [2025-08-03 17:19:34]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2268
===> Epoch[26](200/2500): Loss: 0.2169
===> Epoch[26](300/2500): Loss: 0.2102
===> Epoch[26](400/2500): Loss: 0.2205
===> Epoch[26](500/2500): Loss: 0.2406
===> Epoch[26](600/2500): Loss: 0.2292
===> Epoch[26](700/2500): Loss: 0.2367
===> Epoch[26](800/2500): Loss: 0.2366
===> Epoch[26](900/2500): Loss: 0.2296
===> Epoch[26](1000/2500): Loss: 0.2340
===> Epoch[26](1100/2500): Loss: 0.2392
===> Epoch[26](1200/2500): Loss: 0.2267
===> Epoch[26](1300/2500): Loss: 0.2017
===> Epoch[26](1400/2500): Loss: 0.2107
===> Epoch[26](1500/2500): Loss: 0.2295
===> Epoch[26](1600/2500): Loss: 0.2177
===> Epoch[26](1700/2500): Loss: 0.2230
===> Epoch[26](1800/2500): Loss: 0.2138
===> Epoch[26](1900/2500): Loss: 0.2100
===> Epoch[26](2000/2500): Loss: 0.2389
===> Epoch[26](2100/2500): Loss: 0.2463
===> Epoch[26](2200/2500): Loss: 0.2387
===> Epoch[26](2300/2500): Loss: 0.2394
===> Epoch[26](2400/2500): Loss: 0.2254
===> Epoch[26](2500/2500): Loss: 0.2255
===> Epoch 26 Complete: Avg. Loss: 0.2255
===> Timestamp: [2025-08-03 17:19:34]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2268
===> Epoch[26](200/2500): Loss: 0.2169
===> Epoch[26](300/2500): Loss: 0.2102
===> Epoch[26](400/2500): Loss: 0.2205
===> Epoch[26](500/2500): Loss: 0.2406
===> Epoch[26](600/2500): Loss: 0.2292
===> Epoch[26](700/2500): Loss: 0.2367
===> Epoch[26](800/2500): Loss: 0.2366
===> Epoch[26](900/2500): Loss: 0.2296
===> Epoch[26](1000/2500): Loss: 0.2340
===> Epoch[26](1100/2500): Loss: 0.2392
===> Epoch[26](1200/2500): Loss: 0.2267
===> Epoch[26](1300/2500): Loss: 0.2017
===> Epoch[26](1400/2500): Loss: 0.2107
===> Epoch[26](1500/2500): Loss: 0.2295
===> Epoch[26](1600/2500): Loss: 0.2177
===> Epoch[26](1700/2500): Loss: 0.2230
===> Epoch[26](1800/2500): Loss: 0.2138
===> Epoch[26](1900/2500): Loss: 0.2100
===> Epoch[26](2000/2500): Loss: 0.2389
===> Epoch[26](2100/2500): Loss: 0.2463
===> Epoch[26](2200/2500): Loss: 0.2387
===> Epoch[26](2300/2500): Loss: 0.2394
===> Epoch[26](2400/2500): Loss: 0.2254
===> Epoch[26](2500/2500): Loss: 0.2255
===> Epoch 26 Complete: Avg. Loss: 0.2255
===> Timestamp: [2025-08-03 17:19:34]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2268
===> Epoch[26](200/2500): Loss: 0.2169
===> Epoch[26](300/2500): Loss: 0.2102
===> Epoch[26](400/2500): Loss: 0.2205
===> Epoch[26](500/2500): Loss: 0.2406
===> Epoch[26](600/2500): Loss: 0.2292
===> Epoch[26](700/2500): Loss: 0.2367
===> Epoch[26](800/2500): Loss: 0.2366
===> Epoch[26](900/2500): Loss: 0.2296
===> Epoch[26](1000/2500): Loss: 0.2340
===> Epoch[26](1100/2500): Loss: 0.2392
===> Epoch[26](1200/2500): Loss: 0.2267
===> Epoch[26](1300/2500): Loss: 0.2017
===> Epoch[26](1400/2500): Loss: 0.2107
===> Epoch[26](1500/2500): Loss: 0.2295
===> Epoch[26](1600/2500): Loss: 0.2177
===> Epoch[26](1700/2500): Loss: 0.2230
===> Epoch[26](1800/2500): Loss: 0.2138
===> Epoch[26](1900/2500): Loss: 0.2100
===> Epoch[26](2000/2500): Loss: 0.2389
===> Epoch[26](2100/2500): Loss: 0.2463
===> Epoch[26](2200/2500): Loss: 0.2387
===> Epoch[26](2300/2500): Loss: 0.2394
===> Epoch[26](2400/2500): Loss: 0.2254
===> Epoch[26](2500/2500): Loss: 0.2255
===> Epoch 26 Complete: Avg. Loss: 0.2255
===> Timestamp: [2025-08-03 17:19:34]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2268
===> Epoch[26](200/2500): Loss: 0.2169
===> Epoch[26](300/2500): Loss: 0.2102
===> Epoch[26](400/2500): Loss: 0.2205
===> Epoch[26](500/2500): Loss: 0.2406
===> Epoch[26](600/2500): Loss: 0.2292
===> Epoch[26](700/2500): Loss: 0.2367
===> Epoch[26](800/2500): Loss: 0.2366
===> Epoch[26](900/2500): Loss: 0.2296
===> Epoch[26](1000/2500): Loss: 0.2340
===> Epoch[26](1100/2500): Loss: 0.2392
===> Epoch[26](1200/2500): Loss: 0.2267
===> Epoch[26](1300/2500): Loss: 0.2017
===> Epoch[26](1400/2500): Loss: 0.2107
===> Epoch[26](1500/2500): Loss: 0.2295
===> Epoch[26](1600/2500): Loss: 0.2177
===> Epoch[26](1700/2500): Loss: 0.2230
===> Epoch[26](1800/2500): Loss: 0.2138
===> Epoch[26](1900/2500): Loss: 0.2100
===> Epoch[26](2000/2500): Loss: 0.2389
===> Epoch[26](2100/2500): Loss: 0.2463
===> Epoch[26](2200/2500): Loss: 0.2387
===> Epoch[26](2300/2500): Loss: 0.2394
===> Epoch[26](2400/2500): Loss: 0.2254
===> Epoch[26](2500/2500): Loss: 0.2255
===> Epoch 26 Complete: Avg. Loss: 0.2255
===> Timestamp: [2025-08-03 17:19:34]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2268
===> Epoch[26](200/2500): Loss: 0.2169
===> Epoch[26](300/2500): Loss: 0.2102
===> Epoch[26](400/2500): Loss: 0.2205
===> Epoch[26](500/2500): Loss: 0.2406
===> Epoch[26](600/2500): Loss: 0.2292
===> Epoch[26](700/2500): Loss: 0.2367
===> Epoch[26](800/2500): Loss: 0.2366
===> Epoch[26](900/2500): Loss: 0.2296
===> Epoch[26](1000/2500): Loss: 0.2340
===> Epoch[26](1100/2500): Loss: 0.2392
===> Epoch[26](1200/2500): Loss: 0.2267
===> Epoch[26](1300/2500): Loss: 0.2017
===> Epoch[26](1400/2500): Loss: 0.2107
===> Epoch[26](1500/2500): Loss: 0.2295
===> Epoch[26](1600/2500): Loss: 0.2177
===> Epoch[26](1700/2500): Loss: 0.2230
===> Epoch[26](1800/2500): Loss: 0.2138
===> Epoch[26](1900/2500): Loss: 0.2100
===> Epoch[26](2000/2500): Loss: 0.2389
===> Epoch[26](2100/2500): Loss: 0.2463
===> Epoch[26](2200/2500): Loss: 0.2387
===> Epoch[26](2300/2500): Loss: 0.2394
===> Epoch[26](2400/2500): Loss: 0.2254
===> Epoch[26](2500/2500): Loss: 0.2255
===> Epoch 26 Complete: Avg. Loss: 0.2255
===> Timestamp: [2025-08-03 17:19:34]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2268
===> Epoch[26](200/2500): Loss: 0.2169
===> Epoch[26](300/2500): Loss: 0.2102
===> Epoch[26](400/2500): Loss: 0.2205
===> Epoch[26](500/2500): Loss: 0.2406
===> Epoch[26](600/2500): Loss: 0.2292
===> Epoch[26](700/2500): Loss: 0.2367
===> Epoch[26](800/2500): Loss: 0.2366
===> Epoch[26](900/2500): Loss: 0.2296
===> Epoch[26](1000/2500): Loss: 0.2340
===> Epoch[26](1100/2500): Loss: 0.2392
===> Epoch[26](1200/2500): Loss: 0.2267
===> Epoch[26](1300/2500): Loss: 0.2017
===> Epoch[26](1400/2500): Loss: 0.2107
===> Epoch[26](1500/2500): Loss: 0.2295
===> Epoch[26](1600/2500): Loss: 0.2177
===> Epoch[26](1700/2500): Loss: 0.2230
===> Epoch[26](1800/2500): Loss: 0.2138
===> Epoch[26](1900/2500): Loss: 0.2100
===> Epoch[26](2000/2500): Loss: 0.2389
===> Epoch[26](2100/2500): Loss: 0.2463
===> Epoch[26](2200/2500): Loss: 0.2387
===> Epoch[26](2300/2500): Loss: 0.2394
===> Epoch[26](2400/2500): Loss: 0.2254
===> Epoch[26](2500/2500): Loss: 0.2255
===> Epoch 26 Complete: Avg. Loss: 0.2255
===> Timestamp: [2025-08-03 17:19:34]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2268
===> Epoch[26](200/2500): Loss: 0.2169
===> Epoch[26](300/2500): Loss: 0.2102
===> Epoch[26](400/2500): Loss: 0.2205
===> Epoch[26](500/2500): Loss: 0.2406
===> Epoch[26](600/2500): Loss: 0.2292
===> Epoch[26](700/2500): Loss: 0.2367
===> Epoch[26](800/2500): Loss: 0.2366
===> Epoch[26](900/2500): Loss: 0.2296
===> Epoch[26](1000/2500): Loss: 0.2340
===> Epoch[26](1100/2500): Loss: 0.2392
===> Epoch[26](1200/2500): Loss: 0.2267
===> Epoch[26](1300/2500): Loss: 0.2017
===> Epoch[26](1400/2500): Loss: 0.2107
===> Epoch[26](1500/2500): Loss: 0.2295
===> Epoch[26](1600/2500): Loss: 0.2177
===> Epoch[26](1700/2500): Loss: 0.2230
===> Epoch[26](1800/2500): Loss: 0.2138
===> Epoch[26](1900/2500): Loss: 0.2100
===> Epoch[26](2000/2500): Loss: 0.2389
===> Epoch[26](2100/2500): Loss: 0.2463
===> Epoch[26](2200/2500): Loss: 0.2387
===> Epoch[26](2300/2500): Loss: 0.2394
===> Epoch[26](2400/2500): Loss: 0.2254
===> Epoch[26](2500/2500): Loss: 0.2255
===> Epoch 26 Complete: Avg. Loss: 0.2255
===> Timestamp: [2025-08-03 17:19:34]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2268
===> Epoch[26](200/2500): Loss: 0.2169
===> Epoch[26](300/2500): Loss: 0.2102
===> Epoch[26](400/2500): Loss: 0.2205
===> Epoch[26](500/2500): Loss: 0.2406
===> Epoch[26](600/2500): Loss: 0.2292
===> Epoch[26](700/2500): Loss: 0.2367
===> Epoch[26](800/2500): Loss: 0.2366
===> Epoch[26](900/2500): Loss: 0.2296
===> Epoch[26](1000/2500): Loss: 0.2340
===> Epoch[26](1100/2500): Loss: 0.2392
===> Epoch[26](1200/2500): Loss: 0.2267
===> Epoch[26](1300/2500): Loss: 0.2017
===> Epoch[26](1400/2500): Loss: 0.2107
===> Epoch[26](1500/2500): Loss: 0.2295
===> Epoch[26](1600/2500): Loss: 0.2177
===> Epoch[26](1700/2500): Loss: 0.2230
===> Epoch[26](1800/2500): Loss: 0.2138
===> Epoch[26](1900/2500): Loss: 0.2100
===> Epoch[26](2000/2500): Loss: 0.2389
===> Epoch[26](2100/2500): Loss: 0.2463
===> Epoch[26](2200/2500): Loss: 0.2387
===> Epoch[26](2300/2500): Loss: 0.2394
===> Epoch[26](2400/2500): Loss: 0.2254
===> Epoch[26](2500/2500): Loss: 0.2255
===> Epoch 26 Complete: Avg. Loss: 0.2255
===> Timestamp: [2025-08-03 17:19:34]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2268
===> Epoch[26](200/2500): Loss: 0.2169
===> Epoch[26](300/2500): Loss: 0.2102
===> Epoch[26](400/2500): Loss: 0.2205
===> Epoch[26](500/2500): Loss: 0.2406
===> Epoch[26](600/2500): Loss: 0.2292
===> Epoch[26](700/2500): Loss: 0.2367
===> Epoch[26](800/2500): Loss: 0.2366
===> Epoch[26](900/2500): Loss: 0.2296
===> Epoch[26](1000/2500): Loss: 0.2340
===> Epoch[26](1100/2500): Loss: 0.2392
===> Epoch[26](1200/2500): Loss: 0.2267
===> Epoch[26](1300/2500): Loss: 0.2017
===> Epoch[26](1400/2500): Loss: 0.2107
===> Epoch[26](1500/2500): Loss: 0.2295
===> Epoch[26](1600/2500): Loss: 0.2177
===> Epoch[26](1700/2500): Loss: 0.2230
===> Epoch[26](1800/2500): Loss: 0.2138
===> Epoch[26](1900/2500): Loss: 0.2100
===> Epoch[26](2000/2500): Loss: 0.2389
===> Epoch[26](2100/2500): Loss: 0.2463
===> Epoch[26](2200/2500): Loss: 0.2387
===> Epoch[26](2300/2500): Loss: 0.2394
===> Epoch[26](2400/2500): Loss: 0.2254
===> Epoch[26](2500/2500): Loss: 0.2255
===> Epoch 26 Complete: Avg. Loss: 0.2255
===> Timestamp: [2025-08-03 17:19:34]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2268
===> Epoch[26](200/2500): Loss: 0.2169
===> Epoch[26](300/2500): Loss: 0.2102
===> Epoch[26](400/2500): Loss: 0.2205
===> Epoch[26](500/2500): Loss: 0.2406
===> Epoch[26](600/2500): Loss: 0.2292
===> Epoch[26](700/2500): Loss: 0.2367
===> Epoch[26](800/2500): Loss: 0.2366
===> Epoch[26](900/2500): Loss: 0.2296
===> Epoch[26](1000/2500): Loss: 0.2340
===> Epoch[26](1100/2500): Loss: 0.2392
===> Epoch[26](1200/2500): Loss: 0.2267
===> Epoch[26](1300/2500): Loss: 0.2017
===> Epoch[26](1400/2500): Loss: 0.2107
===> Epoch[26](1500/2500): Loss: 0.2295
===> Epoch[26](1600/2500): Loss: 0.2177
===> Epoch[26](1700/2500): Loss: 0.2230
===> Epoch[26](1800/2500): Loss: 0.2138
===> Epoch[26](1900/2500): Loss: 0.2100
===> Epoch[26](2000/2500): Loss: 0.2389
===> Epoch[26](2100/2500): Loss: 0.2463
===> Epoch[26](2200/2500): Loss: 0.2387
===> Epoch[26](2300/2500): Loss: 0.2394
===> Epoch[26](2400/2500): Loss: 0.2254
===> Epoch[26](2500/2500): Loss: 0.2255
===> Epoch 26 Complete: Avg. Loss: 0.2255
===> Timestamp: [2025-08-03 17:19:34]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2268
===> Epoch[26](200/2500): Loss: 0.2169
===> Epoch[26](300/2500): Loss: 0.2102
===> Epoch[26](400/2500): Loss: 0.2205
===> Epoch[26](500/2500): Loss: 0.2406
===> Epoch[26](600/2500): Loss: 0.2292
===> Epoch[26](700/2500): Loss: 0.2367
===> Epoch[26](800/2500): Loss: 0.2366
===> Epoch[26](900/2500): Loss: 0.2296
===> Epoch[26](1000/2500): Loss: 0.2340
===> Epoch[26](1100/2500): Loss: 0.2392
===> Epoch[26](1200/2500): Loss: 0.2267
===> Epoch[26](1300/2500): Loss: 0.2017
===> Epoch[26](1400/2500): Loss: 0.2107
===> Epoch[26](1500/2500): Loss: 0.2295
===> Epoch[26](1600/2500): Loss: 0.2177
===> Epoch[26](1700/2500): Loss: 0.2230
===> Epoch[26](1800/2500): Loss: 0.2138
===> Epoch[26](1900/2500): Loss: 0.2100
===> Epoch[26](2000/2500): Loss: 0.2389
===> Epoch[26](2100/2500): Loss: 0.2463
===> Epoch[26](2200/2500): Loss: 0.2387
===> Epoch[26](2300/2500): Loss: 0.2394
===> Epoch[26](2400/2500): Loss: 0.2254
===> Epoch[26](2500/2500): Loss: 0.2255
===> Epoch 26 Complete: Avg. Loss: 0.2255
===> Timestamp: [2025-08-03 17:19:34]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2268
===> Epoch[26](200/2500): Loss: 0.2169
===> Epoch[26](300/2500): Loss: 0.2102
===> Epoch[26](400/2500): Loss: 0.2205
===> Epoch[26](500/2500): Loss: 0.2406
===> Epoch[26](600/2500): Loss: 0.2292
===> Epoch[26](700/2500): Loss: 0.2367
===> Epoch[26](800/2500): Loss: 0.2366
===> Epoch[26](900/2500): Loss: 0.2296
===> Epoch[26](1000/2500): Loss: 0.2340
===> Epoch[26](1100/2500): Loss: 0.2392
===> Epoch[26](1200/2500): Loss: 0.2267
===> Epoch[26](1300/2500): Loss: 0.2017
===> Epoch[26](1400/2500): Loss: 0.2107
===> Epoch[26](1500/2500): Loss: 0.2295
===> Epoch[26](1600/2500): Loss: 0.2177
===> Epoch[26](1700/2500): Loss: 0.2230
===> Epoch[26](1800/2500): Loss: 0.2138
===> Epoch[26](1900/2500): Loss: 0.2100
===> Epoch[26](2000/2500): Loss: 0.2389
===> Epoch[26](2100/2500): Loss: 0.2463
===> Epoch[26](2200/2500): Loss: 0.2387
===> Epoch[26](2300/2500): Loss: 0.2394
===> Epoch[26](2400/2500): Loss: 0.2254
===> Epoch[26](2500/2500): Loss: 0.2255
===> Epoch 26 Complete: Avg. Loss: 0.2255
===> Timestamp: [2025-08-03 17:19:34]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2268
===> Epoch[26](200/2500): Loss: 0.2169
===> Epoch[26](300/2500): Loss: 0.2102
===> Epoch[26](400/2500): Loss: 0.2205
===> Epoch[26](500/2500): Loss: 0.2406
===> Epoch[26](600/2500): Loss: 0.2292
===> Epoch[26](700/2500): Loss: 0.2367
===> Epoch[26](800/2500): Loss: 0.2366
===> Epoch[26](900/2500): Loss: 0.2296
===> Epoch[26](1000/2500): Loss: 0.2340
===> Epoch[26](1100/2500): Loss: 0.2392
===> Epoch[26](1200/2500): Loss: 0.2267
===> Epoch[26](1300/2500): Loss: 0.2017
===> Epoch[26](1400/2500): Loss: 0.2107
===> Epoch[26](1500/2500): Loss: 0.2295
===> Epoch[26](1600/2500): Loss: 0.2177
===> Epoch[26](1700/2500): Loss: 0.2230
===> Epoch[26](1800/2500): Loss: 0.2138
===> Epoch[26](1900/2500): Loss: 0.2100
===> Epoch[26](2000/2500): Loss: 0.2389
===> Epoch[26](2100/2500): Loss: 0.2463
===> Epoch[26](2200/2500): Loss: 0.2387
===> Epoch[26](2300/2500): Loss: 0.2394
===> Epoch[26](2400/2500): Loss: 0.2254
===> Epoch[26](2500/2500): Loss: 0.2255
===> Epoch 26 Complete: Avg. Loss: 0.2255
===> Timestamp: [2025-08-03 17:19:34]
===> Loading train datasets
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2288
===> Epoch[27](200/2500): Loss: 0.2221
===> Epoch[27](300/2500): Loss: 0.2198
===> Epoch[27](400/2500): Loss: 0.2337
===> Epoch[27](500/2500): Loss: 0.2216
===> Epoch[27](600/2500): Loss: 0.2185
===> Epoch[27](700/2500): Loss: 0.2179
===> Epoch[27](800/2500): Loss: 0.2249
===> Epoch[27](900/2500): Loss: 0.2212
===> Epoch[27](1000/2500): Loss: 0.2342
===> Epoch[27](1100/2500): Loss: 0.2098
===> Epoch[27](1200/2500): Loss: 0.2125
===> Epoch[27](1300/2500): Loss: 0.2126
===> Epoch[27](1400/2500): Loss: 0.2140
===> Epoch[27](1500/2500): Loss: 0.2342
===> Epoch[27](1600/2500): Loss: 0.2135
===> Epoch[27](1700/2500): Loss: 0.2180
===> Epoch[27](1800/2500): Loss: 0.2270
===> Epoch[27](1900/2500): Loss: 0.2141
===> Epoch[27](2000/2500): Loss: 0.2072
===> Epoch[27](2100/2500): Loss: 0.2305
===> Epoch[27](2200/2500): Loss: 0.2193
===> Epoch[27](2300/2500): Loss: 0.2169
===> Epoch[27](2400/2500): Loss: 0.2399
===> Epoch[27](2500/2500): Loss: 0.2208
===> Epoch 27 Complete: Avg. Loss: 0.2235
===> Timestamp: [2025-08-03 17:24:08]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2288
===> Epoch[27](200/2500): Loss: 0.2221
===> Epoch[27](300/2500): Loss: 0.2198
===> Epoch[27](400/2500): Loss: 0.2337
===> Epoch[27](500/2500): Loss: 0.2216
===> Epoch[27](600/2500): Loss: 0.2185
===> Epoch[27](700/2500): Loss: 0.2179
===> Epoch[27](800/2500): Loss: 0.2249
===> Epoch[27](900/2500): Loss: 0.2212
===> Epoch[27](1000/2500): Loss: 0.2342
===> Epoch[27](1100/2500): Loss: 0.2098
===> Epoch[27](1200/2500): Loss: 0.2125
===> Epoch[27](1300/2500): Loss: 0.2126
===> Epoch[27](1400/2500): Loss: 0.2140
===> Epoch[27](1500/2500): Loss: 0.2342
===> Epoch[27](1600/2500): Loss: 0.2135
===> Epoch[27](1700/2500): Loss: 0.2180
===> Epoch[27](1800/2500): Loss: 0.2270
===> Epoch[27](1900/2500): Loss: 0.2141
===> Epoch[27](2000/2500): Loss: 0.2072
===> Epoch[27](2100/2500): Loss: 0.2305
===> Epoch[27](2200/2500): Loss: 0.2193
===> Epoch[27](2300/2500): Loss: 0.2169
===> Epoch[27](2400/2500): Loss: 0.2399
===> Epoch[27](2500/2500): Loss: 0.2208
===> Epoch 27 Complete: Avg. Loss: 0.2235
===> Timestamp: [2025-08-03 17:24:08]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2288
===> Epoch[27](200/2500): Loss: 0.2221
===> Epoch[27](300/2500): Loss: 0.2198
===> Epoch[27](400/2500): Loss: 0.2337
===> Epoch[27](500/2500): Loss: 0.2216
===> Epoch[27](600/2500): Loss: 0.2185
===> Epoch[27](700/2500): Loss: 0.2179
===> Epoch[27](800/2500): Loss: 0.2249
===> Epoch[27](900/2500): Loss: 0.2212
===> Epoch[27](1000/2500): Loss: 0.2342
===> Epoch[27](1100/2500): Loss: 0.2098
===> Epoch[27](1200/2500): Loss: 0.2125
===> Epoch[27](1300/2500): Loss: 0.2126
===> Epoch[27](1400/2500): Loss: 0.2140
===> Epoch[27](1500/2500): Loss: 0.2342
===> Epoch[27](1600/2500): Loss: 0.2135
===> Epoch[27](1700/2500): Loss: 0.2180
===> Epoch[27](1800/2500): Loss: 0.2270
===> Epoch[27](1900/2500): Loss: 0.2141
===> Epoch[27](2000/2500): Loss: 0.2072
===> Epoch[27](2100/2500): Loss: 0.2305
===> Epoch[27](2200/2500): Loss: 0.2193
===> Epoch[27](2300/2500): Loss: 0.2169
===> Epoch[27](2400/2500): Loss: 0.2399
===> Epoch[27](2500/2500): Loss: 0.2208
===> Epoch 27 Complete: Avg. Loss: 0.2235
===> Timestamp: [2025-08-03 17:24:08]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2288
===> Epoch[27](200/2500): Loss: 0.2221
===> Epoch[27](300/2500): Loss: 0.2198
===> Epoch[27](400/2500): Loss: 0.2337
===> Epoch[27](500/2500): Loss: 0.2216
===> Epoch[27](600/2500): Loss: 0.2185
===> Epoch[27](700/2500): Loss: 0.2179
===> Epoch[27](800/2500): Loss: 0.2249
===> Epoch[27](900/2500): Loss: 0.2212
===> Epoch[27](1000/2500): Loss: 0.2342
===> Epoch[27](1100/2500): Loss: 0.2098
===> Epoch[27](1200/2500): Loss: 0.2125
===> Epoch[27](1300/2500): Loss: 0.2126
===> Epoch[27](1400/2500): Loss: 0.2140
===> Epoch[27](1500/2500): Loss: 0.2342
===> Epoch[27](1600/2500): Loss: 0.2135
===> Epoch[27](1700/2500): Loss: 0.2180
===> Epoch[27](1800/2500): Loss: 0.2270
===> Epoch[27](1900/2500): Loss: 0.2141
===> Epoch[27](2000/2500): Loss: 0.2072
===> Epoch[27](2100/2500): Loss: 0.2305
===> Epoch[27](2200/2500): Loss: 0.2193
===> Epoch[27](2300/2500): Loss: 0.2169
===> Epoch[27](2400/2500): Loss: 0.2399
===> Epoch[27](2500/2500): Loss: 0.2208
===> Epoch 27 Complete: Avg. Loss: 0.2235
===> Timestamp: [2025-08-03 17:24:08]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2288
===> Epoch[27](200/2500): Loss: 0.2221
===> Epoch[27](300/2500): Loss: 0.2198
===> Epoch[27](400/2500): Loss: 0.2337
===> Epoch[27](500/2500): Loss: 0.2216
===> Epoch[27](600/2500): Loss: 0.2185
===> Epoch[27](700/2500): Loss: 0.2179
===> Epoch[27](800/2500): Loss: 0.2249
===> Epoch[27](900/2500): Loss: 0.2212
===> Epoch[27](1000/2500): Loss: 0.2342
===> Epoch[27](1100/2500): Loss: 0.2098
===> Epoch[27](1200/2500): Loss: 0.2125
===> Epoch[27](1300/2500): Loss: 0.2126
===> Epoch[27](1400/2500): Loss: 0.2140
===> Epoch[27](1500/2500): Loss: 0.2342
===> Epoch[27](1600/2500): Loss: 0.2135
===> Epoch[27](1700/2500): Loss: 0.2180
===> Epoch[27](1800/2500): Loss: 0.2270
===> Epoch[27](1900/2500): Loss: 0.2141
===> Epoch[27](2000/2500): Loss: 0.2072
===> Epoch[27](2100/2500): Loss: 0.2305
===> Epoch[27](2200/2500): Loss: 0.2193
===> Epoch[27](2300/2500): Loss: 0.2169
===> Epoch[27](2400/2500): Loss: 0.2399
===> Epoch[27](2500/2500): Loss: 0.2208
===> Epoch 27 Complete: Avg. Loss: 0.2235
===> Timestamp: [2025-08-03 17:24:08]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2288
===> Epoch[27](200/2500): Loss: 0.2221
===> Epoch[27](300/2500): Loss: 0.2198
===> Epoch[27](400/2500): Loss: 0.2337
===> Epoch[27](500/2500): Loss: 0.2216
===> Epoch[27](600/2500): Loss: 0.2185
===> Epoch[27](700/2500): Loss: 0.2179
===> Epoch[27](800/2500): Loss: 0.2249
===> Epoch[27](900/2500): Loss: 0.2212
===> Epoch[27](1000/2500): Loss: 0.2342
===> Epoch[27](1100/2500): Loss: 0.2098
===> Epoch[27](1200/2500): Loss: 0.2125
===> Epoch[27](1300/2500): Loss: 0.2126
===> Epoch[27](1400/2500): Loss: 0.2140
===> Epoch[27](1500/2500): Loss: 0.2342
===> Epoch[27](1600/2500): Loss: 0.2135
===> Epoch[27](1700/2500): Loss: 0.2180
===> Epoch[27](1800/2500): Loss: 0.2270
===> Epoch[27](1900/2500): Loss: 0.2141
===> Epoch[27](2000/2500): Loss: 0.2072
===> Epoch[27](2100/2500): Loss: 0.2305
===> Epoch[27](2200/2500): Loss: 0.2193
===> Epoch[27](2300/2500): Loss: 0.2169
===> Epoch[27](2400/2500): Loss: 0.2399
===> Epoch[27](2500/2500): Loss: 0.2208
===> Epoch 27 Complete: Avg. Loss: 0.2235
===> Timestamp: [2025-08-03 17:24:08]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2288
===> Epoch[27](200/2500): Loss: 0.2221
===> Epoch[27](300/2500): Loss: 0.2198
===> Epoch[27](400/2500): Loss: 0.2337
===> Epoch[27](500/2500): Loss: 0.2216
===> Epoch[27](600/2500): Loss: 0.2185
===> Epoch[27](700/2500): Loss: 0.2179
===> Epoch[27](800/2500): Loss: 0.2249
===> Epoch[27](900/2500): Loss: 0.2212
===> Epoch[27](1000/2500): Loss: 0.2342
===> Epoch[27](1100/2500): Loss: 0.2098
===> Epoch[27](1200/2500): Loss: 0.2125
===> Epoch[27](1300/2500): Loss: 0.2126
===> Epoch[27](1400/2500): Loss: 0.2140
===> Epoch[27](1500/2500): Loss: 0.2342
===> Epoch[27](1600/2500): Loss: 0.2135
===> Epoch[27](1700/2500): Loss: 0.2180
===> Epoch[27](1800/2500): Loss: 0.2270
===> Epoch[27](1900/2500): Loss: 0.2141
===> Epoch[27](2000/2500): Loss: 0.2072
===> Epoch[27](2100/2500): Loss: 0.2305
===> Epoch[27](2200/2500): Loss: 0.2193
===> Epoch[27](2300/2500): Loss: 0.2169
===> Epoch[27](2400/2500): Loss: 0.2399
===> Epoch[27](2500/2500): Loss: 0.2208
===> Epoch 27 Complete: Avg. Loss: 0.2235
===> Timestamp: [2025-08-03 17:24:08]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2288
===> Epoch[27](200/2500): Loss: 0.2221
===> Epoch[27](300/2500): Loss: 0.2198
===> Epoch[27](400/2500): Loss: 0.2337
===> Epoch[27](500/2500): Loss: 0.2216
===> Epoch[27](600/2500): Loss: 0.2185
===> Epoch[27](700/2500): Loss: 0.2179
===> Epoch[27](800/2500): Loss: 0.2249
===> Epoch[27](900/2500): Loss: 0.2212
===> Epoch[27](1000/2500): Loss: 0.2342
===> Epoch[27](1100/2500): Loss: 0.2098
===> Epoch[27](1200/2500): Loss: 0.2125
===> Epoch[27](1300/2500): Loss: 0.2126
===> Epoch[27](1400/2500): Loss: 0.2140
===> Epoch[27](1500/2500): Loss: 0.2342
===> Epoch[27](1600/2500): Loss: 0.2135
===> Epoch[27](1700/2500): Loss: 0.2180
===> Epoch[27](1800/2500): Loss: 0.2270
===> Epoch[27](1900/2500): Loss: 0.2141
===> Epoch[27](2000/2500): Loss: 0.2072
===> Epoch[27](2100/2500): Loss: 0.2305
===> Epoch[27](2200/2500): Loss: 0.2193
===> Epoch[27](2300/2500): Loss: 0.2169
===> Epoch[27](2400/2500): Loss: 0.2399
===> Epoch[27](2500/2500): Loss: 0.2208
===> Epoch 27 Complete: Avg. Loss: 0.2235
===> Timestamp: [2025-08-03 17:24:08]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2288
===> Epoch[27](200/2500): Loss: 0.2221
===> Epoch[27](300/2500): Loss: 0.2198
===> Epoch[27](400/2500): Loss: 0.2337
===> Epoch[27](500/2500): Loss: 0.2216
===> Epoch[27](600/2500): Loss: 0.2185
===> Epoch[27](700/2500): Loss: 0.2179
===> Epoch[27](800/2500): Loss: 0.2249
===> Epoch[27](900/2500): Loss: 0.2212
===> Epoch[27](1000/2500): Loss: 0.2342
===> Epoch[27](1100/2500): Loss: 0.2098
===> Epoch[27](1200/2500): Loss: 0.2125
===> Epoch[27](1300/2500): Loss: 0.2126
===> Epoch[27](1400/2500): Loss: 0.2140
===> Epoch[27](1500/2500): Loss: 0.2342
===> Epoch[27](1600/2500): Loss: 0.2135
===> Epoch[27](1700/2500): Loss: 0.2180
===> Epoch[27](1800/2500): Loss: 0.2270
===> Epoch[27](1900/2500): Loss: 0.2141
===> Epoch[27](2000/2500): Loss: 0.2072
===> Epoch[27](2100/2500): Loss: 0.2305
===> Epoch[27](2200/2500): Loss: 0.2193
===> Epoch[27](2300/2500): Loss: 0.2169
===> Epoch[27](2400/2500): Loss: 0.2399
===> Epoch[27](2500/2500): Loss: 0.2208
===> Epoch 27 Complete: Avg. Loss: 0.2235
===> Timestamp: [2025-08-03 17:24:08]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2288
===> Epoch[27](200/2500): Loss: 0.2221
===> Epoch[27](300/2500): Loss: 0.2198
===> Epoch[27](400/2500): Loss: 0.2337
===> Epoch[27](500/2500): Loss: 0.2216
===> Epoch[27](600/2500): Loss: 0.2185
===> Epoch[27](700/2500): Loss: 0.2179
===> Epoch[27](800/2500): Loss: 0.2249
===> Epoch[27](900/2500): Loss: 0.2212
===> Epoch[27](1000/2500): Loss: 0.2342
===> Epoch[27](1100/2500): Loss: 0.2098
===> Epoch[27](1200/2500): Loss: 0.2125
===> Epoch[27](1300/2500): Loss: 0.2126
===> Epoch[27](1400/2500): Loss: 0.2140
===> Epoch[27](1500/2500): Loss: 0.2342
===> Epoch[27](1600/2500): Loss: 0.2135
===> Epoch[27](1700/2500): Loss: 0.2180
===> Epoch[27](1800/2500): Loss: 0.2270
===> Epoch[27](1900/2500): Loss: 0.2141
===> Epoch[27](2000/2500): Loss: 0.2072
===> Epoch[27](2100/2500): Loss: 0.2305
===> Epoch[27](2200/2500): Loss: 0.2193
===> Epoch[27](2300/2500): Loss: 0.2169
===> Epoch[27](2400/2500): Loss: 0.2399
===> Epoch[27](2500/2500): Loss: 0.2208
===> Epoch 27 Complete: Avg. Loss: 0.2235
===> Timestamp: [2025-08-03 17:24:08]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2288
===> Epoch[27](200/2500): Loss: 0.2221
===> Epoch[27](300/2500): Loss: 0.2198
===> Epoch[27](400/2500): Loss: 0.2337
===> Epoch[27](500/2500): Loss: 0.2216
===> Epoch[27](600/2500): Loss: 0.2185
===> Epoch[27](700/2500): Loss: 0.2179
===> Epoch[27](800/2500): Loss: 0.2249
===> Epoch[27](900/2500): Loss: 0.2212
===> Epoch[27](1000/2500): Loss: 0.2342
===> Epoch[27](1100/2500): Loss: 0.2098
===> Epoch[27](1200/2500): Loss: 0.2125
===> Epoch[27](1300/2500): Loss: 0.2126
===> Epoch[27](1400/2500): Loss: 0.2140
===> Epoch[27](1500/2500): Loss: 0.2342
===> Epoch[27](1600/2500): Loss: 0.2135
===> Epoch[27](1700/2500): Loss: 0.2180
===> Epoch[27](1800/2500): Loss: 0.2270
===> Epoch[27](1900/2500): Loss: 0.2141
===> Epoch[27](2000/2500): Loss: 0.2072
===> Epoch[27](2100/2500): Loss: 0.2305
===> Epoch[27](2200/2500): Loss: 0.2193
===> Epoch[27](2300/2500): Loss: 0.2169
===> Epoch[27](2400/2500): Loss: 0.2399
===> Epoch[27](2500/2500): Loss: 0.2208
===> Epoch 27 Complete: Avg. Loss: 0.2235
===> Timestamp: [2025-08-03 17:24:08]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2288
===> Epoch[27](200/2500): Loss: 0.2221
===> Epoch[27](300/2500): Loss: 0.2198
===> Epoch[27](400/2500): Loss: 0.2337
===> Epoch[27](500/2500): Loss: 0.2216
===> Epoch[27](600/2500): Loss: 0.2185
===> Epoch[27](700/2500): Loss: 0.2179
===> Epoch[27](800/2500): Loss: 0.2249
===> Epoch[27](900/2500): Loss: 0.2212
===> Epoch[27](1000/2500): Loss: 0.2342
===> Epoch[27](1100/2500): Loss: 0.2098
===> Epoch[27](1200/2500): Loss: 0.2125
===> Epoch[27](1300/2500): Loss: 0.2126
===> Epoch[27](1400/2500): Loss: 0.2140
===> Epoch[27](1500/2500): Loss: 0.2342
===> Epoch[27](1600/2500): Loss: 0.2135
===> Epoch[27](1700/2500): Loss: 0.2180
===> Epoch[27](1800/2500): Loss: 0.2270
===> Epoch[27](1900/2500): Loss: 0.2141
===> Epoch[27](2000/2500): Loss: 0.2072
===> Epoch[27](2100/2500): Loss: 0.2305
===> Epoch[27](2200/2500): Loss: 0.2193
===> Epoch[27](2300/2500): Loss: 0.2169
===> Epoch[27](2400/2500): Loss: 0.2399
===> Epoch[27](2500/2500): Loss: 0.2208
===> Epoch 27 Complete: Avg. Loss: 0.2235
===> Timestamp: [2025-08-03 17:24:08]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2288
===> Epoch[27](200/2500): Loss: 0.2221
===> Epoch[27](300/2500): Loss: 0.2198
===> Epoch[27](400/2500): Loss: 0.2337
===> Epoch[27](500/2500): Loss: 0.2216
===> Epoch[27](600/2500): Loss: 0.2185
===> Epoch[27](700/2500): Loss: 0.2179
===> Epoch[27](800/2500): Loss: 0.2249
===> Epoch[27](900/2500): Loss: 0.2212
===> Epoch[27](1000/2500): Loss: 0.2342
===> Epoch[27](1100/2500): Loss: 0.2098
===> Epoch[27](1200/2500): Loss: 0.2125
===> Epoch[27](1300/2500): Loss: 0.2126
===> Epoch[27](1400/2500): Loss: 0.2140
===> Epoch[27](1500/2500): Loss: 0.2342
===> Epoch[27](1600/2500): Loss: 0.2135
===> Epoch[27](1700/2500): Loss: 0.2180
===> Epoch[27](1800/2500): Loss: 0.2270
===> Epoch[27](1900/2500): Loss: 0.2141
===> Epoch[27](2000/2500): Loss: 0.2072
===> Epoch[27](2100/2500): Loss: 0.2305
===> Epoch[27](2200/2500): Loss: 0.2193
===> Epoch[27](2300/2500): Loss: 0.2169
===> Epoch[27](2400/2500): Loss: 0.2399
===> Epoch[27](2500/2500): Loss: 0.2208
===> Epoch 27 Complete: Avg. Loss: 0.2235
===> Timestamp: [2025-08-03 17:24:08]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2288
===> Epoch[27](200/2500): Loss: 0.2221
===> Epoch[27](300/2500): Loss: 0.2198
===> Epoch[27](400/2500): Loss: 0.2337
===> Epoch[27](500/2500): Loss: 0.2216
===> Epoch[27](600/2500): Loss: 0.2185
===> Epoch[27](700/2500): Loss: 0.2179
===> Epoch[27](800/2500): Loss: 0.2249
===> Epoch[27](900/2500): Loss: 0.2212
===> Epoch[27](1000/2500): Loss: 0.2342
===> Epoch[27](1100/2500): Loss: 0.2098
===> Epoch[27](1200/2500): Loss: 0.2125
===> Epoch[27](1300/2500): Loss: 0.2126
===> Epoch[27](1400/2500): Loss: 0.2140
===> Epoch[27](1500/2500): Loss: 0.2342
===> Epoch[27](1600/2500): Loss: 0.2135
===> Epoch[27](1700/2500): Loss: 0.2180
===> Epoch[27](1800/2500): Loss: 0.2270
===> Epoch[27](1900/2500): Loss: 0.2141
===> Epoch[27](2000/2500): Loss: 0.2072
===> Epoch[27](2100/2500): Loss: 0.2305
===> Epoch[27](2200/2500): Loss: 0.2193
===> Epoch[27](2300/2500): Loss: 0.2169
===> Epoch[27](2400/2500): Loss: 0.2399
===> Epoch[27](2500/2500): Loss: 0.2208
===> Epoch 27 Complete: Avg. Loss: 0.2235
===> Timestamp: [2025-08-03 17:24:08]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2288
===> Epoch[27](200/2500): Loss: 0.2221
===> Epoch[27](300/2500): Loss: 0.2198
===> Epoch[27](400/2500): Loss: 0.2337
===> Epoch[27](500/2500): Loss: 0.2216
===> Epoch[27](600/2500): Loss: 0.2185
===> Epoch[27](700/2500): Loss: 0.2179
===> Epoch[27](800/2500): Loss: 0.2249
===> Epoch[27](900/2500): Loss: 0.2212
===> Epoch[27](1000/2500): Loss: 0.2342
===> Epoch[27](1100/2500): Loss: 0.2098
===> Epoch[27](1200/2500): Loss: 0.2125
===> Epoch[27](1300/2500): Loss: 0.2126
===> Epoch[27](1400/2500): Loss: 0.2140
===> Epoch[27](1500/2500): Loss: 0.2342
===> Epoch[27](1600/2500): Loss: 0.2135
===> Epoch[27](1700/2500): Loss: 0.2180
===> Epoch[27](1800/2500): Loss: 0.2270
===> Epoch[27](1900/2500): Loss: 0.2141
===> Epoch[27](2000/2500): Loss: 0.2072
===> Epoch[27](2100/2500): Loss: 0.2305
===> Epoch[27](2200/2500): Loss: 0.2193
===> Epoch[27](2300/2500): Loss: 0.2169
===> Epoch[27](2400/2500): Loss: 0.2399
===> Epoch[27](2500/2500): Loss: 0.2208
===> Epoch 27 Complete: Avg. Loss: 0.2235
===> Timestamp: [2025-08-03 17:24:08]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2288
===> Epoch[27](200/2500): Loss: 0.2221
===> Epoch[27](300/2500): Loss: 0.2198
===> Epoch[27](400/2500): Loss: 0.2337
===> Epoch[27](500/2500): Loss: 0.2216
===> Epoch[27](600/2500): Loss: 0.2185
===> Epoch[27](700/2500): Loss: 0.2179
===> Epoch[27](800/2500): Loss: 0.2249
===> Epoch[27](900/2500): Loss: 0.2212
===> Epoch[27](1000/2500): Loss: 0.2342
===> Epoch[27](1100/2500): Loss: 0.2098
===> Epoch[27](1200/2500): Loss: 0.2125
===> Epoch[27](1300/2500): Loss: 0.2126
===> Epoch[27](1400/2500): Loss: 0.2140
===> Epoch[27](1500/2500): Loss: 0.2342
===> Epoch[27](1600/2500): Loss: 0.2135
===> Epoch[27](1700/2500): Loss: 0.2180
===> Epoch[27](1800/2500): Loss: 0.2270
===> Epoch[27](1900/2500): Loss: 0.2141
===> Epoch[27](2000/2500): Loss: 0.2072
===> Epoch[27](2100/2500): Loss: 0.2305
===> Epoch[27](2200/2500): Loss: 0.2193
===> Epoch[27](2300/2500): Loss: 0.2169
===> Epoch[27](2400/2500): Loss: 0.2399
===> Epoch[27](2500/2500): Loss: 0.2208
===> Epoch 27 Complete: Avg. Loss: 0.2235
===> Timestamp: [2025-08-03 17:24:08]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2288
===> Epoch[27](200/2500): Loss: 0.2221
===> Epoch[27](300/2500): Loss: 0.2198
===> Epoch[27](400/2500): Loss: 0.2337
===> Epoch[27](500/2500): Loss: 0.2216
===> Epoch[27](600/2500): Loss: 0.2185
===> Epoch[27](700/2500): Loss: 0.2179
===> Epoch[27](800/2500): Loss: 0.2249
===> Epoch[27](900/2500): Loss: 0.2212
===> Epoch[27](1000/2500): Loss: 0.2342
===> Epoch[27](1100/2500): Loss: 0.2098
===> Epoch[27](1200/2500): Loss: 0.2125
===> Epoch[27](1300/2500): Loss: 0.2126
===> Epoch[27](1400/2500): Loss: 0.2140
===> Epoch[27](1500/2500): Loss: 0.2342
===> Epoch[27](1600/2500): Loss: 0.2135
===> Epoch[27](1700/2500): Loss: 0.2180
===> Epoch[27](1800/2500): Loss: 0.2270
===> Epoch[27](1900/2500): Loss: 0.2141
===> Epoch[27](2000/2500): Loss: 0.2072
===> Epoch[27](2100/2500): Loss: 0.2305
===> Epoch[27](2200/2500): Loss: 0.2193
===> Epoch[27](2300/2500): Loss: 0.2169
===> Epoch[27](2400/2500): Loss: 0.2399
===> Epoch[27](2500/2500): Loss: 0.2208
===> Epoch 27 Complete: Avg. Loss: 0.2235
===> Timestamp: [2025-08-03 17:24:08]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2288
===> Epoch[27](200/2500): Loss: 0.2221
===> Epoch[27](300/2500): Loss: 0.2198
===> Epoch[27](400/2500): Loss: 0.2337
===> Epoch[27](500/2500): Loss: 0.2216
===> Epoch[27](600/2500): Loss: 0.2185
===> Epoch[27](700/2500): Loss: 0.2179
===> Epoch[27](800/2500): Loss: 0.2249
===> Epoch[27](900/2500): Loss: 0.2212
===> Epoch[27](1000/2500): Loss: 0.2342
===> Epoch[27](1100/2500): Loss: 0.2098
===> Epoch[27](1200/2500): Loss: 0.2125
===> Epoch[27](1300/2500): Loss: 0.2126
===> Epoch[27](1400/2500): Loss: 0.2140
===> Epoch[27](1500/2500): Loss: 0.2342
===> Epoch[27](1600/2500): Loss: 0.2135
===> Epoch[27](1700/2500): Loss: 0.2180
===> Epoch[27](1800/2500): Loss: 0.2270
===> Epoch[27](1900/2500): Loss: 0.2141
===> Epoch[27](2000/2500): Loss: 0.2072
===> Epoch[27](2100/2500): Loss: 0.2305
===> Epoch[27](2200/2500): Loss: 0.2193
===> Epoch[27](2300/2500): Loss: 0.2169
===> Epoch[27](2400/2500): Loss: 0.2399
===> Epoch[27](2500/2500): Loss: 0.2208
===> Epoch 27 Complete: Avg. Loss: 0.2235
===> Timestamp: [2025-08-03 17:24:08]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2288
===> Epoch[27](200/2500): Loss: 0.2221
===> Epoch[27](300/2500): Loss: 0.2198
===> Epoch[27](400/2500): Loss: 0.2337
===> Epoch[27](500/2500): Loss: 0.2216
===> Epoch[27](600/2500): Loss: 0.2185
===> Epoch[27](700/2500): Loss: 0.2179
===> Epoch[27](800/2500): Loss: 0.2249
===> Epoch[27](900/2500): Loss: 0.2212
===> Epoch[27](1000/2500): Loss: 0.2342
===> Epoch[27](1100/2500): Loss: 0.2098
===> Epoch[27](1200/2500): Loss: 0.2125
===> Epoch[27](1300/2500): Loss: 0.2126
===> Epoch[27](1400/2500): Loss: 0.2140
===> Epoch[27](1500/2500): Loss: 0.2342
===> Epoch[27](1600/2500): Loss: 0.2135
===> Epoch[27](1700/2500): Loss: 0.2180
===> Epoch[27](1800/2500): Loss: 0.2270
===> Epoch[27](1900/2500): Loss: 0.2141
===> Epoch[27](2000/2500): Loss: 0.2072
===> Epoch[27](2100/2500): Loss: 0.2305
===> Epoch[27](2200/2500): Loss: 0.2193
===> Epoch[27](2300/2500): Loss: 0.2169
===> Epoch[27](2400/2500): Loss: 0.2399
===> Epoch[27](2500/2500): Loss: 0.2208
===> Epoch 27 Complete: Avg. Loss: 0.2235
===> Timestamp: [2025-08-03 17:24:08]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2288
===> Epoch[27](200/2500): Loss: 0.2221
===> Epoch[27](300/2500): Loss: 0.2198
===> Epoch[27](400/2500): Loss: 0.2337
===> Epoch[27](500/2500): Loss: 0.2216
===> Epoch[27](600/2500): Loss: 0.2185
===> Epoch[27](700/2500): Loss: 0.2179
===> Epoch[27](800/2500): Loss: 0.2249
===> Epoch[27](900/2500): Loss: 0.2212
===> Epoch[27](1000/2500): Loss: 0.2342
===> Epoch[27](1100/2500): Loss: 0.2098
===> Epoch[27](1200/2500): Loss: 0.2125
===> Epoch[27](1300/2500): Loss: 0.2126
===> Epoch[27](1400/2500): Loss: 0.2140
===> Epoch[27](1500/2500): Loss: 0.2342
===> Epoch[27](1600/2500): Loss: 0.2135
===> Epoch[27](1700/2500): Loss: 0.2180
===> Epoch[27](1800/2500): Loss: 0.2270
===> Epoch[27](1900/2500): Loss: 0.2141
===> Epoch[27](2000/2500): Loss: 0.2072
===> Epoch[27](2100/2500): Loss: 0.2305
===> Epoch[27](2200/2500): Loss: 0.2193
===> Epoch[27](2300/2500): Loss: 0.2169
===> Epoch[27](2400/2500): Loss: 0.2399
===> Epoch[27](2500/2500): Loss: 0.2208
===> Epoch 27 Complete: Avg. Loss: 0.2235
===> Timestamp: [2025-08-03 17:24:08]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2288
===> Epoch[27](200/2500): Loss: 0.2221
===> Epoch[27](300/2500): Loss: 0.2198
===> Epoch[27](400/2500): Loss: 0.2337
===> Epoch[27](500/2500): Loss: 0.2216
===> Epoch[27](600/2500): Loss: 0.2185
===> Epoch[27](700/2500): Loss: 0.2179
===> Epoch[27](800/2500): Loss: 0.2249
===> Epoch[27](900/2500): Loss: 0.2212
===> Epoch[27](1000/2500): Loss: 0.2342
===> Epoch[27](1100/2500): Loss: 0.2098
===> Epoch[27](1200/2500): Loss: 0.2125
===> Epoch[27](1300/2500): Loss: 0.2126
===> Epoch[27](1400/2500): Loss: 0.2140
===> Epoch[27](1500/2500): Loss: 0.2342
===> Epoch[27](1600/2500): Loss: 0.2135
===> Epoch[27](1700/2500): Loss: 0.2180
===> Epoch[27](1800/2500): Loss: 0.2270
===> Epoch[27](1900/2500): Loss: 0.2141
===> Epoch[27](2000/2500): Loss: 0.2072
===> Epoch[27](2100/2500): Loss: 0.2305
===> Epoch[27](2200/2500): Loss: 0.2193
===> Epoch[27](2300/2500): Loss: 0.2169
===> Epoch[27](2400/2500): Loss: 0.2399
===> Epoch[27](2500/2500): Loss: 0.2208
===> Epoch 27 Complete: Avg. Loss: 0.2235
===> Timestamp: [2025-08-03 17:24:08]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2288
===> Epoch[27](200/2500): Loss: 0.2221
===> Epoch[27](300/2500): Loss: 0.2198
===> Epoch[27](400/2500): Loss: 0.2337
===> Epoch[27](500/2500): Loss: 0.2216
===> Epoch[27](600/2500): Loss: 0.2185
===> Epoch[27](700/2500): Loss: 0.2179
===> Epoch[27](800/2500): Loss: 0.2249
===> Epoch[27](900/2500): Loss: 0.2212
===> Epoch[27](1000/2500): Loss: 0.2342
===> Epoch[27](1100/2500): Loss: 0.2098
===> Epoch[27](1200/2500): Loss: 0.2125
===> Epoch[27](1300/2500): Loss: 0.2126
===> Epoch[27](1400/2500): Loss: 0.2140
===> Epoch[27](1500/2500): Loss: 0.2342
===> Epoch[27](1600/2500): Loss: 0.2135
===> Epoch[27](1700/2500): Loss: 0.2180
===> Epoch[27](1800/2500): Loss: 0.2270
===> Epoch[27](1900/2500): Loss: 0.2141
===> Epoch[27](2000/2500): Loss: 0.2072
===> Epoch[27](2100/2500): Loss: 0.2305
===> Epoch[27](2200/2500): Loss: 0.2193
===> Epoch[27](2300/2500): Loss: 0.2169
===> Epoch[27](2400/2500): Loss: 0.2399
===> Epoch[27](2500/2500): Loss: 0.2208
===> Epoch 27 Complete: Avg. Loss: 0.2235
===> Timestamp: [2025-08-03 17:24:08]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2288
===> Epoch[27](200/2500): Loss: 0.2221
===> Epoch[27](300/2500): Loss: 0.2198
===> Epoch[27](400/2500): Loss: 0.2337
===> Epoch[27](500/2500): Loss: 0.2216
===> Epoch[27](600/2500): Loss: 0.2185
===> Epoch[27](700/2500): Loss: 0.2179
===> Epoch[27](800/2500): Loss: 0.2249
===> Epoch[27](900/2500): Loss: 0.2212
===> Epoch[27](1000/2500): Loss: 0.2342
===> Epoch[27](1100/2500): Loss: 0.2098
===> Epoch[27](1200/2500): Loss: 0.2125
===> Epoch[27](1300/2500): Loss: 0.2126
===> Epoch[27](1400/2500): Loss: 0.2140
===> Epoch[27](1500/2500): Loss: 0.2342
===> Epoch[27](1600/2500): Loss: 0.2135
===> Epoch[27](1700/2500): Loss: 0.2180
===> Epoch[27](1800/2500): Loss: 0.2270
===> Epoch[27](1900/2500): Loss: 0.2141
===> Epoch[27](2000/2500): Loss: 0.2072
===> Epoch[27](2100/2500): Loss: 0.2305
===> Epoch[27](2200/2500): Loss: 0.2193
===> Epoch[27](2300/2500): Loss: 0.2169
===> Epoch[27](2400/2500): Loss: 0.2399
===> Epoch[27](2500/2500): Loss: 0.2208
===> Epoch 27 Complete: Avg. Loss: 0.2235
===> Timestamp: [2025-08-03 17:24:08]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2288
===> Epoch[27](200/2500): Loss: 0.2221
===> Epoch[27](300/2500): Loss: 0.2198
===> Epoch[27](400/2500): Loss: 0.2337
===> Epoch[27](500/2500): Loss: 0.2216
===> Epoch[27](600/2500): Loss: 0.2185
===> Epoch[27](700/2500): Loss: 0.2179
===> Epoch[27](800/2500): Loss: 0.2249
===> Epoch[27](900/2500): Loss: 0.2212
===> Epoch[27](1000/2500): Loss: 0.2342
===> Epoch[27](1100/2500): Loss: 0.2098
===> Epoch[27](1200/2500): Loss: 0.2125
===> Epoch[27](1300/2500): Loss: 0.2126
===> Epoch[27](1400/2500): Loss: 0.2140
===> Epoch[27](1500/2500): Loss: 0.2342
===> Epoch[27](1600/2500): Loss: 0.2135
===> Epoch[27](1700/2500): Loss: 0.2180
===> Epoch[27](1800/2500): Loss: 0.2270
===> Epoch[27](1900/2500): Loss: 0.2141
===> Epoch[27](2000/2500): Loss: 0.2072
===> Epoch[27](2100/2500): Loss: 0.2305
===> Epoch[27](2200/2500): Loss: 0.2193
===> Epoch[27](2300/2500): Loss: 0.2169
===> Epoch[27](2400/2500): Loss: 0.2399
===> Epoch[27](2500/2500): Loss: 0.2208
===> Epoch 27 Complete: Avg. Loss: 0.2235
===> Timestamp: [2025-08-03 17:24:08]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2288
===> Epoch[27](200/2500): Loss: 0.2221
===> Epoch[27](300/2500): Loss: 0.2198
===> Epoch[27](400/2500): Loss: 0.2337
===> Epoch[27](500/2500): Loss: 0.2216
===> Epoch[27](600/2500): Loss: 0.2185
===> Epoch[27](700/2500): Loss: 0.2179
===> Epoch[27](800/2500): Loss: 0.2249
===> Epoch[27](900/2500): Loss: 0.2212
===> Epoch[27](1000/2500): Loss: 0.2342
===> Epoch[27](1100/2500): Loss: 0.2098
===> Epoch[27](1200/2500): Loss: 0.2125
===> Epoch[27](1300/2500): Loss: 0.2126
===> Epoch[27](1400/2500): Loss: 0.2140
===> Epoch[27](1500/2500): Loss: 0.2342
===> Epoch[27](1600/2500): Loss: 0.2135
===> Epoch[27](1700/2500): Loss: 0.2180
===> Epoch[27](1800/2500): Loss: 0.2270
===> Epoch[27](1900/2500): Loss: 0.2141
===> Epoch[27](2000/2500): Loss: 0.2072
===> Epoch[27](2100/2500): Loss: 0.2305
===> Epoch[27](2200/2500): Loss: 0.2193
===> Epoch[27](2300/2500): Loss: 0.2169
===> Epoch[27](2400/2500): Loss: 0.2399
===> Epoch[27](2500/2500): Loss: 0.2208
===> Epoch 27 Complete: Avg. Loss: 0.2235
===> Timestamp: [2025-08-03 17:24:08]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2288
===> Epoch[27](200/2500): Loss: 0.2221
===> Epoch[27](300/2500): Loss: 0.2198
===> Epoch[27](400/2500): Loss: 0.2337
===> Epoch[27](500/2500): Loss: 0.2216
===> Epoch[27](600/2500): Loss: 0.2185
===> Epoch[27](700/2500): Loss: 0.2179
===> Epoch[27](800/2500): Loss: 0.2249
===> Epoch[27](900/2500): Loss: 0.2212
===> Epoch[27](1000/2500): Loss: 0.2342
===> Epoch[27](1100/2500): Loss: 0.2098
===> Epoch[27](1200/2500): Loss: 0.2125
===> Epoch[27](1300/2500): Loss: 0.2126
===> Epoch[27](1400/2500): Loss: 0.2140
===> Epoch[27](1500/2500): Loss: 0.2342
===> Epoch[27](1600/2500): Loss: 0.2135
===> Epoch[27](1700/2500): Loss: 0.2180
===> Epoch[27](1800/2500): Loss: 0.2270
===> Epoch[27](1900/2500): Loss: 0.2141
===> Epoch[27](2000/2500): Loss: 0.2072
===> Epoch[27](2100/2500): Loss: 0.2305
===> Epoch[27](2200/2500): Loss: 0.2193
===> Epoch[27](2300/2500): Loss: 0.2169
===> Epoch[27](2400/2500): Loss: 0.2399
===> Epoch[27](2500/2500): Loss: 0.2208
===> Epoch 27 Complete: Avg. Loss: 0.2235
===> Timestamp: [2025-08-03 17:24:08]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2288
===> Epoch[27](200/2500): Loss: 0.2221
===> Epoch[27](300/2500): Loss: 0.2198
===> Epoch[27](400/2500): Loss: 0.2337
===> Epoch[27](500/2500): Loss: 0.2216
===> Epoch[27](600/2500): Loss: 0.2185
===> Epoch[27](700/2500): Loss: 0.2179
===> Epoch[27](800/2500): Loss: 0.2249
===> Epoch[27](900/2500): Loss: 0.2212
===> Epoch[27](1000/2500): Loss: 0.2342
===> Epoch[27](1100/2500): Loss: 0.2098
===> Epoch[27](1200/2500): Loss: 0.2125
===> Epoch[27](1300/2500): Loss: 0.2126
===> Epoch[27](1400/2500): Loss: 0.2140
===> Epoch[27](1500/2500): Loss: 0.2342
===> Epoch[27](1600/2500): Loss: 0.2135
===> Epoch[27](1700/2500): Loss: 0.2180
===> Epoch[27](1800/2500): Loss: 0.2270
===> Epoch[27](1900/2500): Loss: 0.2141
===> Epoch[27](2000/2500): Loss: 0.2072
===> Epoch[27](2100/2500): Loss: 0.2305
===> Epoch[27](2200/2500): Loss: 0.2193
===> Epoch[27](2300/2500): Loss: 0.2169
===> Epoch[27](2400/2500): Loss: 0.2399
===> Epoch[27](2500/2500): Loss: 0.2208
===> Epoch 27 Complete: Avg. Loss: 0.2235
===> Timestamp: [2025-08-03 17:24:08]
===> Loading train datasets
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.2414
===> Epoch[28](200/2500): Loss: 0.2136
===> Epoch[28](300/2500): Loss: 0.2345
===> Epoch[28](400/2500): Loss: 0.2244
===> Epoch[28](500/2500): Loss: 0.2138
===> Epoch[28](600/2500): Loss: 0.2265
===> Epoch[28](700/2500): Loss: 0.2338
===> Epoch[28](800/2500): Loss: 0.2207
===> Epoch[28](900/2500): Loss: 0.2228
===> Epoch[28](1000/2500): Loss: 0.2081
===> Epoch[28](1100/2500): Loss: 0.2290
===> Epoch[28](1200/2500): Loss: 0.1991
===> Epoch[28](1300/2500): Loss: 0.2313
===> Epoch[28](1400/2500): Loss: 0.2196
===> Epoch[28](1500/2500): Loss: 0.2099
===> Epoch[28](1600/2500): Loss: 0.2104
===> Epoch[28](1700/2500): Loss: 0.2219
===> Epoch[28](1800/2500): Loss: 0.2377
===> Epoch[28](1900/2500): Loss: 0.2255
===> Epoch[28](2000/2500): Loss: 0.2129
===> Epoch[28](2100/2500): Loss: 0.2078
===> Epoch[28](2200/2500): Loss: 0.2165
===> Epoch[28](2300/2500): Loss: 0.2105
===> Epoch[28](2400/2500): Loss: 0.2062
===> Epoch[28](2500/2500): Loss: 0.2157
===> Epoch 28 Complete: Avg. Loss: 0.2220
===> Timestamp: [2025-08-03 17:28:41]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.2414
===> Epoch[28](200/2500): Loss: 0.2136
===> Epoch[28](300/2500): Loss: 0.2345
===> Epoch[28](400/2500): Loss: 0.2244
===> Epoch[28](500/2500): Loss: 0.2138
===> Epoch[28](600/2500): Loss: 0.2265
===> Epoch[28](700/2500): Loss: 0.2338
===> Epoch[28](800/2500): Loss: 0.2207
===> Epoch[28](900/2500): Loss: 0.2228
===> Epoch[28](1000/2500): Loss: 0.2081
===> Epoch[28](1100/2500): Loss: 0.2290
===> Epoch[28](1200/2500): Loss: 0.1991
===> Epoch[28](1300/2500): Loss: 0.2313
===> Epoch[28](1400/2500): Loss: 0.2196
===> Epoch[28](1500/2500): Loss: 0.2099
===> Epoch[28](1600/2500): Loss: 0.2104
===> Epoch[28](1700/2500): Loss: 0.2219
===> Epoch[28](1800/2500): Loss: 0.2377
===> Epoch[28](1900/2500): Loss: 0.2255
===> Epoch[28](2000/2500): Loss: 0.2129
===> Epoch[28](2100/2500): Loss: 0.2078
===> Epoch[28](2200/2500): Loss: 0.2165
===> Epoch[28](2300/2500): Loss: 0.2105
===> Epoch[28](2400/2500): Loss: 0.2062
===> Epoch[28](2500/2500): Loss: 0.2157
===> Epoch 28 Complete: Avg. Loss: 0.2220
===> Timestamp: [2025-08-03 17:28:41]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.2414
===> Epoch[28](200/2500): Loss: 0.2136
===> Epoch[28](300/2500): Loss: 0.2345
===> Epoch[28](400/2500): Loss: 0.2244
===> Epoch[28](500/2500): Loss: 0.2138
===> Epoch[28](600/2500): Loss: 0.2265
===> Epoch[28](700/2500): Loss: 0.2338
===> Epoch[28](800/2500): Loss: 0.2207
===> Epoch[28](900/2500): Loss: 0.2228
===> Epoch[28](1000/2500): Loss: 0.2081
===> Epoch[28](1100/2500): Loss: 0.2290
===> Epoch[28](1200/2500): Loss: 0.1991
===> Epoch[28](1300/2500): Loss: 0.2313
===> Epoch[28](1400/2500): Loss: 0.2196
===> Epoch[28](1500/2500): Loss: 0.2099
===> Epoch[28](1600/2500): Loss: 0.2104
===> Epoch[28](1700/2500): Loss: 0.2219
===> Epoch[28](1800/2500): Loss: 0.2377
===> Epoch[28](1900/2500): Loss: 0.2255
===> Epoch[28](2000/2500): Loss: 0.2129
===> Epoch[28](2100/2500): Loss: 0.2078
===> Epoch[28](2200/2500): Loss: 0.2165
===> Epoch[28](2300/2500): Loss: 0.2105
===> Epoch[28](2400/2500): Loss: 0.2062
===> Epoch[28](2500/2500): Loss: 0.2157
===> Epoch 28 Complete: Avg. Loss: 0.2220
===> Timestamp: [2025-08-03 17:28:41]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.2414
===> Epoch[28](200/2500): Loss: 0.2136
===> Epoch[28](300/2500): Loss: 0.2345
===> Epoch[28](400/2500): Loss: 0.2244
===> Epoch[28](500/2500): Loss: 0.2138
===> Epoch[28](600/2500): Loss: 0.2265
===> Epoch[28](700/2500): Loss: 0.2338
===> Epoch[28](800/2500): Loss: 0.2207
===> Epoch[28](900/2500): Loss: 0.2228
===> Epoch[28](1000/2500): Loss: 0.2081
===> Epoch[28](1100/2500): Loss: 0.2290
===> Epoch[28](1200/2500): Loss: 0.1991
===> Epoch[28](1300/2500): Loss: 0.2313
===> Epoch[28](1400/2500): Loss: 0.2196
===> Epoch[28](1500/2500): Loss: 0.2099
===> Epoch[28](1600/2500): Loss: 0.2104
===> Epoch[28](1700/2500): Loss: 0.2219
===> Epoch[28](1800/2500): Loss: 0.2377
===> Epoch[28](1900/2500): Loss: 0.2255
===> Epoch[28](2000/2500): Loss: 0.2129
===> Epoch[28](2100/2500): Loss: 0.2078
===> Epoch[28](2200/2500): Loss: 0.2165
===> Epoch[28](2300/2500): Loss: 0.2105
===> Epoch[28](2400/2500): Loss: 0.2062
===> Epoch[28](2500/2500): Loss: 0.2157
===> Epoch 28 Complete: Avg. Loss: 0.2220
===> Timestamp: [2025-08-03 17:28:41]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.2414
===> Epoch[28](200/2500): Loss: 0.2136
===> Epoch[28](300/2500): Loss: 0.2345
===> Epoch[28](400/2500): Loss: 0.2244
===> Epoch[28](500/2500): Loss: 0.2138
===> Epoch[28](600/2500): Loss: 0.2265
===> Epoch[28](700/2500): Loss: 0.2338
===> Epoch[28](800/2500): Loss: 0.2207
===> Epoch[28](900/2500): Loss: 0.2228
===> Epoch[28](1000/2500): Loss: 0.2081
===> Epoch[28](1100/2500): Loss: 0.2290
===> Epoch[28](1200/2500): Loss: 0.1991
===> Epoch[28](1300/2500): Loss: 0.2313
===> Epoch[28](1400/2500): Loss: 0.2196
===> Epoch[28](1500/2500): Loss: 0.2099
===> Epoch[28](1600/2500): Loss: 0.2104
===> Epoch[28](1700/2500): Loss: 0.2219
===> Epoch[28](1800/2500): Loss: 0.2377
===> Epoch[28](1900/2500): Loss: 0.2255
===> Epoch[28](2000/2500): Loss: 0.2129
===> Epoch[28](2100/2500): Loss: 0.2078
===> Epoch[28](2200/2500): Loss: 0.2165
===> Epoch[28](2300/2500): Loss: 0.2105
===> Epoch[28](2400/2500): Loss: 0.2062
===> Epoch[28](2500/2500): Loss: 0.2157
===> Epoch 28 Complete: Avg. Loss: 0.2220
===> Timestamp: [2025-08-03 17:28:41]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.2414
===> Epoch[28](200/2500): Loss: 0.2136
===> Epoch[28](300/2500): Loss: 0.2345
===> Epoch[28](400/2500): Loss: 0.2244
===> Epoch[28](500/2500): Loss: 0.2138
===> Epoch[28](600/2500): Loss: 0.2265
===> Epoch[28](700/2500): Loss: 0.2338
===> Epoch[28](800/2500): Loss: 0.2207
===> Epoch[28](900/2500): Loss: 0.2228
===> Epoch[28](1000/2500): Loss: 0.2081
===> Epoch[28](1100/2500): Loss: 0.2290
===> Epoch[28](1200/2500): Loss: 0.1991
===> Epoch[28](1300/2500): Loss: 0.2313
===> Epoch[28](1400/2500): Loss: 0.2196
===> Epoch[28](1500/2500): Loss: 0.2099
===> Epoch[28](1600/2500): Loss: 0.2104
===> Epoch[28](1700/2500): Loss: 0.2219
===> Epoch[28](1800/2500): Loss: 0.2377
===> Epoch[28](1900/2500): Loss: 0.2255
===> Epoch[28](2000/2500): Loss: 0.2129
===> Epoch[28](2100/2500): Loss: 0.2078
===> Epoch[28](2200/2500): Loss: 0.2165
===> Epoch[28](2300/2500): Loss: 0.2105
===> Epoch[28](2400/2500): Loss: 0.2062
===> Epoch[28](2500/2500): Loss: 0.2157
===> Epoch 28 Complete: Avg. Loss: 0.2220
===> Timestamp: [2025-08-03 17:28:41]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.2414
===> Epoch[28](200/2500): Loss: 0.2136
===> Epoch[28](300/2500): Loss: 0.2345
===> Epoch[28](400/2500): Loss: 0.2244
===> Epoch[28](500/2500): Loss: 0.2138
===> Epoch[28](600/2500): Loss: 0.2265
===> Epoch[28](700/2500): Loss: 0.2338
===> Epoch[28](800/2500): Loss: 0.2207
===> Epoch[28](900/2500): Loss: 0.2228
===> Epoch[28](1000/2500): Loss: 0.2081
===> Epoch[28](1100/2500): Loss: 0.2290
===> Epoch[28](1200/2500): Loss: 0.1991
===> Epoch[28](1300/2500): Loss: 0.2313
===> Epoch[28](1400/2500): Loss: 0.2196
===> Epoch[28](1500/2500): Loss: 0.2099
===> Epoch[28](1600/2500): Loss: 0.2104
===> Epoch[28](1700/2500): Loss: 0.2219
===> Epoch[28](1800/2500): Loss: 0.2377
===> Epoch[28](1900/2500): Loss: 0.2255
===> Epoch[28](2000/2500): Loss: 0.2129
===> Epoch[28](2100/2500): Loss: 0.2078
===> Epoch[28](2200/2500): Loss: 0.2165
===> Epoch[28](2300/2500): Loss: 0.2105
===> Epoch[28](2400/2500): Loss: 0.2062
===> Epoch[28](2500/2500): Loss: 0.2157
===> Epoch 28 Complete: Avg. Loss: 0.2220
===> Timestamp: [2025-08-03 17:28:41]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.2414
===> Epoch[28](200/2500): Loss: 0.2136
===> Epoch[28](300/2500): Loss: 0.2345
===> Epoch[28](400/2500): Loss: 0.2244
===> Epoch[28](500/2500): Loss: 0.2138
===> Epoch[28](600/2500): Loss: 0.2265
===> Epoch[28](700/2500): Loss: 0.2338
===> Epoch[28](800/2500): Loss: 0.2207
===> Epoch[28](900/2500): Loss: 0.2228
===> Epoch[28](1000/2500): Loss: 0.2081
===> Epoch[28](1100/2500): Loss: 0.2290
===> Epoch[28](1200/2500): Loss: 0.1991
===> Epoch[28](1300/2500): Loss: 0.2313
===> Epoch[28](1400/2500): Loss: 0.2196
===> Epoch[28](1500/2500): Loss: 0.2099
===> Epoch[28](1600/2500): Loss: 0.2104
===> Epoch[28](1700/2500): Loss: 0.2219
===> Epoch[28](1800/2500): Loss: 0.2377
===> Epoch[28](1900/2500): Loss: 0.2255
===> Epoch[28](2000/2500): Loss: 0.2129
===> Epoch[28](2100/2500): Loss: 0.2078
===> Epoch[28](2200/2500): Loss: 0.2165
===> Epoch[28](2300/2500): Loss: 0.2105
===> Epoch[28](2400/2500): Loss: 0.2062
===> Epoch[28](2500/2500): Loss: 0.2157
===> Epoch 28 Complete: Avg. Loss: 0.2220
===> Timestamp: [2025-08-03 17:28:41]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.2414
===> Epoch[28](200/2500): Loss: 0.2136
===> Epoch[28](300/2500): Loss: 0.2345
===> Epoch[28](400/2500): Loss: 0.2244
===> Epoch[28](500/2500): Loss: 0.2138
===> Epoch[28](600/2500): Loss: 0.2265
===> Epoch[28](700/2500): Loss: 0.2338
===> Epoch[28](800/2500): Loss: 0.2207
===> Epoch[28](900/2500): Loss: 0.2228
===> Epoch[28](1000/2500): Loss: 0.2081
===> Epoch[28](1100/2500): Loss: 0.2290
===> Epoch[28](1200/2500): Loss: 0.1991
===> Epoch[28](1300/2500): Loss: 0.2313
===> Epoch[28](1400/2500): Loss: 0.2196
===> Epoch[28](1500/2500): Loss: 0.2099
===> Epoch[28](1600/2500): Loss: 0.2104
===> Epoch[28](1700/2500): Loss: 0.2219
===> Epoch[28](1800/2500): Loss: 0.2377
===> Epoch[28](1900/2500): Loss: 0.2255
===> Epoch[28](2000/2500): Loss: 0.2129
===> Epoch[28](2100/2500): Loss: 0.2078
===> Epoch[28](2200/2500): Loss: 0.2165
===> Epoch[28](2300/2500): Loss: 0.2105
===> Epoch[28](2400/2500): Loss: 0.2062
===> Epoch[28](2500/2500): Loss: 0.2157
===> Epoch 28 Complete: Avg. Loss: 0.2220
===> Timestamp: [2025-08-03 17:28:41]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.2414
===> Epoch[28](200/2500): Loss: 0.2136
===> Epoch[28](300/2500): Loss: 0.2345
===> Epoch[28](400/2500): Loss: 0.2244
===> Epoch[28](500/2500): Loss: 0.2138
===> Epoch[28](600/2500): Loss: 0.2265
===> Epoch[28](700/2500): Loss: 0.2338
===> Epoch[28](800/2500): Loss: 0.2207
===> Epoch[28](900/2500): Loss: 0.2228
===> Epoch[28](1000/2500): Loss: 0.2081
===> Epoch[28](1100/2500): Loss: 0.2290
===> Epoch[28](1200/2500): Loss: 0.1991
===> Epoch[28](1300/2500): Loss: 0.2313
===> Epoch[28](1400/2500): Loss: 0.2196
===> Epoch[28](1500/2500): Loss: 0.2099
===> Epoch[28](1600/2500): Loss: 0.2104
===> Epoch[28](1700/2500): Loss: 0.2219
===> Epoch[28](1800/2500): Loss: 0.2377
===> Epoch[28](1900/2500): Loss: 0.2255
===> Epoch[28](2000/2500): Loss: 0.2129
===> Epoch[28](2100/2500): Loss: 0.2078
===> Epoch[28](2200/2500): Loss: 0.2165
===> Epoch[28](2300/2500): Loss: 0.2105
===> Epoch[28](2400/2500): Loss: 0.2062
===> Epoch[28](2500/2500): Loss: 0.2157
===> Epoch 28 Complete: Avg. Loss: 0.2220
===> Timestamp: [2025-08-03 17:28:41]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.2414
===> Epoch[28](200/2500): Loss: 0.2136
===> Epoch[28](300/2500): Loss: 0.2345
===> Epoch[28](400/2500): Loss: 0.2244
===> Epoch[28](500/2500): Loss: 0.2138
===> Epoch[28](600/2500): Loss: 0.2265
===> Epoch[28](700/2500): Loss: 0.2338
===> Epoch[28](800/2500): Loss: 0.2207
===> Epoch[28](900/2500): Loss: 0.2228
===> Epoch[28](1000/2500): Loss: 0.2081
===> Epoch[28](1100/2500): Loss: 0.2290
===> Epoch[28](1200/2500): Loss: 0.1991
===> Epoch[28](1300/2500): Loss: 0.2313
===> Epoch[28](1400/2500): Loss: 0.2196
===> Epoch[28](1500/2500): Loss: 0.2099
===> Epoch[28](1600/2500): Loss: 0.2104
===> Epoch[28](1700/2500): Loss: 0.2219
===> Epoch[28](1800/2500): Loss: 0.2377
===> Epoch[28](1900/2500): Loss: 0.2255
===> Epoch[28](2000/2500): Loss: 0.2129
===> Epoch[28](2100/2500): Loss: 0.2078
===> Epoch[28](2200/2500): Loss: 0.2165
===> Epoch[28](2300/2500): Loss: 0.2105
===> Epoch[28](2400/2500): Loss: 0.2062
===> Epoch[28](2500/2500): Loss: 0.2157
===> Epoch 28 Complete: Avg. Loss: 0.2220
===> Timestamp: [2025-08-03 17:28:41]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.2414
===> Epoch[28](200/2500): Loss: 0.2136
===> Epoch[28](300/2500): Loss: 0.2345
===> Epoch[28](400/2500): Loss: 0.2244
===> Epoch[28](500/2500): Loss: 0.2138
===> Epoch[28](600/2500): Loss: 0.2265
===> Epoch[28](700/2500): Loss: 0.2338
===> Epoch[28](800/2500): Loss: 0.2207
===> Epoch[28](900/2500): Loss: 0.2228
===> Epoch[28](1000/2500): Loss: 0.2081
===> Epoch[28](1100/2500): Loss: 0.2290
===> Epoch[28](1200/2500): Loss: 0.1991
===> Epoch[28](1300/2500): Loss: 0.2313
===> Epoch[28](1400/2500): Loss: 0.2196
===> Epoch[28](1500/2500): Loss: 0.2099
===> Epoch[28](1600/2500): Loss: 0.2104
===> Epoch[28](1700/2500): Loss: 0.2219
===> Epoch[28](1800/2500): Loss: 0.2377
===> Epoch[28](1900/2500): Loss: 0.2255
===> Epoch[28](2000/2500): Loss: 0.2129
===> Epoch[28](2100/2500): Loss: 0.2078
===> Epoch[28](2200/2500): Loss: 0.2165
===> Epoch[28](2300/2500): Loss: 0.2105
===> Epoch[28](2400/2500): Loss: 0.2062
===> Epoch[28](2500/2500): Loss: 0.2157
===> Epoch 28 Complete: Avg. Loss: 0.2220
===> Timestamp: [2025-08-03 17:28:41]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.2414
===> Epoch[28](200/2500): Loss: 0.2136
===> Epoch[28](300/2500): Loss: 0.2345
===> Epoch[28](400/2500): Loss: 0.2244
===> Epoch[28](500/2500): Loss: 0.2138
===> Epoch[28](600/2500): Loss: 0.2265
===> Epoch[28](700/2500): Loss: 0.2338
===> Epoch[28](800/2500): Loss: 0.2207
===> Epoch[28](900/2500): Loss: 0.2228
===> Epoch[28](1000/2500): Loss: 0.2081
===> Epoch[28](1100/2500): Loss: 0.2290
===> Epoch[28](1200/2500): Loss: 0.1991
===> Epoch[28](1300/2500): Loss: 0.2313
===> Epoch[28](1400/2500): Loss: 0.2196
===> Epoch[28](1500/2500): Loss: 0.2099
===> Epoch[28](1600/2500): Loss: 0.2104
===> Epoch[28](1700/2500): Loss: 0.2219
===> Epoch[28](1800/2500): Loss: 0.2377
===> Epoch[28](1900/2500): Loss: 0.2255
===> Epoch[28](2000/2500): Loss: 0.2129
===> Epoch[28](2100/2500): Loss: 0.2078
===> Epoch[28](2200/2500): Loss: 0.2165
===> Epoch[28](2300/2500): Loss: 0.2105
===> Epoch[28](2400/2500): Loss: 0.2062
===> Epoch[28](2500/2500): Loss: 0.2157
===> Epoch 28 Complete: Avg. Loss: 0.2220
===> Timestamp: [2025-08-03 17:28:41]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.2414
===> Epoch[28](200/2500): Loss: 0.2136
===> Epoch[28](300/2500): Loss: 0.2345
===> Epoch[28](400/2500): Loss: 0.2244
===> Epoch[28](500/2500): Loss: 0.2138
===> Epoch[28](600/2500): Loss: 0.2265
===> Epoch[28](700/2500): Loss: 0.2338
===> Epoch[28](800/2500): Loss: 0.2207
===> Epoch[28](900/2500): Loss: 0.2228
===> Epoch[28](1000/2500): Loss: 0.2081
===> Epoch[28](1100/2500): Loss: 0.2290
===> Epoch[28](1200/2500): Loss: 0.1991
===> Epoch[28](1300/2500): Loss: 0.2313
===> Epoch[28](1400/2500): Loss: 0.2196
===> Epoch[28](1500/2500): Loss: 0.2099
===> Epoch[28](1600/2500): Loss: 0.2104
===> Epoch[28](1700/2500): Loss: 0.2219
===> Epoch[28](1800/2500): Loss: 0.2377
===> Epoch[28](1900/2500): Loss: 0.2255
===> Epoch[28](2000/2500): Loss: 0.2129
===> Epoch[28](2100/2500): Loss: 0.2078
===> Epoch[28](2200/2500): Loss: 0.2165
===> Epoch[28](2300/2500): Loss: 0.2105
===> Epoch[28](2400/2500): Loss: 0.2062
===> Epoch[28](2500/2500): Loss: 0.2157
===> Epoch 28 Complete: Avg. Loss: 0.2220
===> Timestamp: [2025-08-03 17:28:41]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.2414
===> Epoch[28](200/2500): Loss: 0.2136
===> Epoch[28](300/2500): Loss: 0.2345
===> Epoch[28](400/2500): Loss: 0.2244
===> Epoch[28](500/2500): Loss: 0.2138
===> Epoch[28](600/2500): Loss: 0.2265
===> Epoch[28](700/2500): Loss: 0.2338
===> Epoch[28](800/2500): Loss: 0.2207
===> Epoch[28](900/2500): Loss: 0.2228
===> Epoch[28](1000/2500): Loss: 0.2081
===> Epoch[28](1100/2500): Loss: 0.2290
===> Epoch[28](1200/2500): Loss: 0.1991
===> Epoch[28](1300/2500): Loss: 0.2313
===> Epoch[28](1400/2500): Loss: 0.2196
===> Epoch[28](1500/2500): Loss: 0.2099
===> Epoch[28](1600/2500): Loss: 0.2104
===> Epoch[28](1700/2500): Loss: 0.2219
===> Epoch[28](1800/2500): Loss: 0.2377
===> Epoch[28](1900/2500): Loss: 0.2255
===> Epoch[28](2000/2500): Loss: 0.2129
===> Epoch[28](2100/2500): Loss: 0.2078
===> Epoch[28](2200/2500): Loss: 0.2165
===> Epoch[28](2300/2500): Loss: 0.2105
===> Epoch[28](2400/2500): Loss: 0.2062
===> Epoch[28](2500/2500): Loss: 0.2157
===> Epoch 28 Complete: Avg. Loss: 0.2220
===> Timestamp: [2025-08-03 17:28:41]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.2414
===> Epoch[28](200/2500): Loss: 0.2136
===> Epoch[28](300/2500): Loss: 0.2345
===> Epoch[28](400/2500): Loss: 0.2244
===> Epoch[28](500/2500): Loss: 0.2138
===> Epoch[28](600/2500): Loss: 0.2265
===> Epoch[28](700/2500): Loss: 0.2338
===> Epoch[28](800/2500): Loss: 0.2207
===> Epoch[28](900/2500): Loss: 0.2228
===> Epoch[28](1000/2500): Loss: 0.2081
===> Epoch[28](1100/2500): Loss: 0.2290
===> Epoch[28](1200/2500): Loss: 0.1991
===> Epoch[28](1300/2500): Loss: 0.2313
===> Epoch[28](1400/2500): Loss: 0.2196
===> Epoch[28](1500/2500): Loss: 0.2099
===> Epoch[28](1600/2500): Loss: 0.2104
===> Epoch[28](1700/2500): Loss: 0.2219
===> Epoch[28](1800/2500): Loss: 0.2377
===> Epoch[28](1900/2500): Loss: 0.2255
===> Epoch[28](2000/2500): Loss: 0.2129
===> Epoch[28](2100/2500): Loss: 0.2078
===> Epoch[28](2200/2500): Loss: 0.2165
===> Epoch[28](2300/2500): Loss: 0.2105
===> Epoch[28](2400/2500): Loss: 0.2062
===> Epoch[28](2500/2500): Loss: 0.2157
===> Epoch 28 Complete: Avg. Loss: 0.2220
===> Timestamp: [2025-08-03 17:28:41]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.2414
===> Epoch[28](200/2500): Loss: 0.2136
===> Epoch[28](300/2500): Loss: 0.2345
===> Epoch[28](400/2500): Loss: 0.2244
===> Epoch[28](500/2500): Loss: 0.2138
===> Epoch[28](600/2500): Loss: 0.2265
===> Epoch[28](700/2500): Loss: 0.2338
===> Epoch[28](800/2500): Loss: 0.2207
===> Epoch[28](900/2500): Loss: 0.2228
===> Epoch[28](1000/2500): Loss: 0.2081
===> Epoch[28](1100/2500): Loss: 0.2290
===> Epoch[28](1200/2500): Loss: 0.1991
===> Epoch[28](1300/2500): Loss: 0.2313
===> Epoch[28](1400/2500): Loss: 0.2196
===> Epoch[28](1500/2500): Loss: 0.2099
===> Epoch[28](1600/2500): Loss: 0.2104
===> Epoch[28](1700/2500): Loss: 0.2219
===> Epoch[28](1800/2500): Loss: 0.2377
===> Epoch[28](1900/2500): Loss: 0.2255
===> Epoch[28](2000/2500): Loss: 0.2129
===> Epoch[28](2100/2500): Loss: 0.2078
===> Epoch[28](2200/2500): Loss: 0.2165
===> Epoch[28](2300/2500): Loss: 0.2105
===> Epoch[28](2400/2500): Loss: 0.2062
===> Epoch[28](2500/2500): Loss: 0.2157
===> Epoch 28 Complete: Avg. Loss: 0.2220
===> Timestamp: [2025-08-03 17:28:41]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.2414
===> Epoch[28](200/2500): Loss: 0.2136
===> Epoch[28](300/2500): Loss: 0.2345
===> Epoch[28](400/2500): Loss: 0.2244
===> Epoch[28](500/2500): Loss: 0.2138
===> Epoch[28](600/2500): Loss: 0.2265
===> Epoch[28](700/2500): Loss: 0.2338
===> Epoch[28](800/2500): Loss: 0.2207
===> Epoch[28](900/2500): Loss: 0.2228
===> Epoch[28](1000/2500): Loss: 0.2081
===> Epoch[28](1100/2500): Loss: 0.2290
===> Epoch[28](1200/2500): Loss: 0.1991
===> Epoch[28](1300/2500): Loss: 0.2313
===> Epoch[28](1400/2500): Loss: 0.2196
===> Epoch[28](1500/2500): Loss: 0.2099
===> Epoch[28](1600/2500): Loss: 0.2104
===> Epoch[28](1700/2500): Loss: 0.2219
===> Epoch[28](1800/2500): Loss: 0.2377
===> Epoch[28](1900/2500): Loss: 0.2255
===> Epoch[28](2000/2500): Loss: 0.2129
===> Epoch[28](2100/2500): Loss: 0.2078
===> Epoch[28](2200/2500): Loss: 0.2165
===> Epoch[28](2300/2500): Loss: 0.2105
===> Epoch[28](2400/2500): Loss: 0.2062
===> Epoch[28](2500/2500): Loss: 0.2157
===> Epoch 28 Complete: Avg. Loss: 0.2220
===> Timestamp: [2025-08-03 17:28:41]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.2414
===> Epoch[28](200/2500): Loss: 0.2136
===> Epoch[28](300/2500): Loss: 0.2345
===> Epoch[28](400/2500): Loss: 0.2244
===> Epoch[28](500/2500): Loss: 0.2138
===> Epoch[28](600/2500): Loss: 0.2265
===> Epoch[28](700/2500): Loss: 0.2338
===> Epoch[28](800/2500): Loss: 0.2207
===> Epoch[28](900/2500): Loss: 0.2228
===> Epoch[28](1000/2500): Loss: 0.2081
===> Epoch[28](1100/2500): Loss: 0.2290
===> Epoch[28](1200/2500): Loss: 0.1991
===> Epoch[28](1300/2500): Loss: 0.2313
===> Epoch[28](1400/2500): Loss: 0.2196
===> Epoch[28](1500/2500): Loss: 0.2099
===> Epoch[28](1600/2500): Loss: 0.2104
===> Epoch[28](1700/2500): Loss: 0.2219
===> Epoch[28](1800/2500): Loss: 0.2377
===> Epoch[28](1900/2500): Loss: 0.2255
===> Epoch[28](2000/2500): Loss: 0.2129
===> Epoch[28](2100/2500): Loss: 0.2078
===> Epoch[28](2200/2500): Loss: 0.2165
===> Epoch[28](2300/2500): Loss: 0.2105
===> Epoch[28](2400/2500): Loss: 0.2062
===> Epoch[28](2500/2500): Loss: 0.2157
===> Epoch 28 Complete: Avg. Loss: 0.2220
===> Timestamp: [2025-08-03 17:28:41]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.2414
===> Epoch[28](200/2500): Loss: 0.2136
===> Epoch[28](300/2500): Loss: 0.2345
===> Epoch[28](400/2500): Loss: 0.2244
===> Epoch[28](500/2500): Loss: 0.2138
===> Epoch[28](600/2500): Loss: 0.2265
===> Epoch[28](700/2500): Loss: 0.2338
===> Epoch[28](800/2500): Loss: 0.2207
===> Epoch[28](900/2500): Loss: 0.2228
===> Epoch[28](1000/2500): Loss: 0.2081
===> Epoch[28](1100/2500): Loss: 0.2290
===> Epoch[28](1200/2500): Loss: 0.1991
===> Epoch[28](1300/2500): Loss: 0.2313
===> Epoch[28](1400/2500): Loss: 0.2196
===> Epoch[28](1500/2500): Loss: 0.2099
===> Epoch[28](1600/2500): Loss: 0.2104
===> Epoch[28](1700/2500): Loss: 0.2219
===> Epoch[28](1800/2500): Loss: 0.2377
===> Epoch[28](1900/2500): Loss: 0.2255
===> Epoch[28](2000/2500): Loss: 0.2129
===> Epoch[28](2100/2500): Loss: 0.2078
===> Epoch[28](2200/2500): Loss: 0.2165
===> Epoch[28](2300/2500): Loss: 0.2105
===> Epoch[28](2400/2500): Loss: 0.2062
===> Epoch[28](2500/2500): Loss: 0.2157
===> Epoch 28 Complete: Avg. Loss: 0.2220
===> Timestamp: [2025-08-03 17:28:41]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.2414
===> Epoch[28](200/2500): Loss: 0.2136
===> Epoch[28](300/2500): Loss: 0.2345
===> Epoch[28](400/2500): Loss: 0.2244
===> Epoch[28](500/2500): Loss: 0.2138
===> Epoch[28](600/2500): Loss: 0.2265
===> Epoch[28](700/2500): Loss: 0.2338
===> Epoch[28](800/2500): Loss: 0.2207
===> Epoch[28](900/2500): Loss: 0.2228
===> Epoch[28](1000/2500): Loss: 0.2081
===> Epoch[28](1100/2500): Loss: 0.2290
===> Epoch[28](1200/2500): Loss: 0.1991
===> Epoch[28](1300/2500): Loss: 0.2313
===> Epoch[28](1400/2500): Loss: 0.2196
===> Epoch[28](1500/2500): Loss: 0.2099
===> Epoch[28](1600/2500): Loss: 0.2104
===> Epoch[28](1700/2500): Loss: 0.2219
===> Epoch[28](1800/2500): Loss: 0.2377
===> Epoch[28](1900/2500): Loss: 0.2255
===> Epoch[28](2000/2500): Loss: 0.2129
===> Epoch[28](2100/2500): Loss: 0.2078
===> Epoch[28](2200/2500): Loss: 0.2165
===> Epoch[28](2300/2500): Loss: 0.2105
===> Epoch[28](2400/2500): Loss: 0.2062
===> Epoch[28](2500/2500): Loss: 0.2157
===> Epoch 28 Complete: Avg. Loss: 0.2220
===> Timestamp: [2025-08-03 17:28:41]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.2414
===> Epoch[28](200/2500): Loss: 0.2136
===> Epoch[28](300/2500): Loss: 0.2345
===> Epoch[28](400/2500): Loss: 0.2244
===> Epoch[28](500/2500): Loss: 0.2138
===> Epoch[28](600/2500): Loss: 0.2265
===> Epoch[28](700/2500): Loss: 0.2338
===> Epoch[28](800/2500): Loss: 0.2207
===> Epoch[28](900/2500): Loss: 0.2228
===> Epoch[28](1000/2500): Loss: 0.2081
===> Epoch[28](1100/2500): Loss: 0.2290
===> Epoch[28](1200/2500): Loss: 0.1991
===> Epoch[28](1300/2500): Loss: 0.2313
===> Epoch[28](1400/2500): Loss: 0.2196
===> Epoch[28](1500/2500): Loss: 0.2099
===> Epoch[28](1600/2500): Loss: 0.2104
===> Epoch[28](1700/2500): Loss: 0.2219
===> Epoch[28](1800/2500): Loss: 0.2377
===> Epoch[28](1900/2500): Loss: 0.2255
===> Epoch[28](2000/2500): Loss: 0.2129
===> Epoch[28](2100/2500): Loss: 0.2078
===> Epoch[28](2200/2500): Loss: 0.2165
===> Epoch[28](2300/2500): Loss: 0.2105
===> Epoch[28](2400/2500): Loss: 0.2062
===> Epoch[28](2500/2500): Loss: 0.2157
===> Epoch 28 Complete: Avg. Loss: 0.2220
===> Timestamp: [2025-08-03 17:28:41]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.2414
===> Epoch[28](200/2500): Loss: 0.2136
===> Epoch[28](300/2500): Loss: 0.2345
===> Epoch[28](400/2500): Loss: 0.2244
===> Epoch[28](500/2500): Loss: 0.2138
===> Epoch[28](600/2500): Loss: 0.2265
===> Epoch[28](700/2500): Loss: 0.2338
===> Epoch[28](800/2500): Loss: 0.2207
===> Epoch[28](900/2500): Loss: 0.2228
===> Epoch[28](1000/2500): Loss: 0.2081
===> Epoch[28](1100/2500): Loss: 0.2290
===> Epoch[28](1200/2500): Loss: 0.1991
===> Epoch[28](1300/2500): Loss: 0.2313
===> Epoch[28](1400/2500): Loss: 0.2196
===> Epoch[28](1500/2500): Loss: 0.2099
===> Epoch[28](1600/2500): Loss: 0.2104
===> Epoch[28](1700/2500): Loss: 0.2219
===> Epoch[28](1800/2500): Loss: 0.2377
===> Epoch[28](1900/2500): Loss: 0.2255
===> Epoch[28](2000/2500): Loss: 0.2129
===> Epoch[28](2100/2500): Loss: 0.2078
===> Epoch[28](2200/2500): Loss: 0.2165
===> Epoch[28](2300/2500): Loss: 0.2105
===> Epoch[28](2400/2500): Loss: 0.2062
===> Epoch[28](2500/2500): Loss: 0.2157
===> Epoch 28 Complete: Avg. Loss: 0.2220
===> Timestamp: [2025-08-03 17:28:41]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.2414
===> Epoch[28](200/2500): Loss: 0.2136
===> Epoch[28](300/2500): Loss: 0.2345
===> Epoch[28](400/2500): Loss: 0.2244
===> Epoch[28](500/2500): Loss: 0.2138
===> Epoch[28](600/2500): Loss: 0.2265
===> Epoch[28](700/2500): Loss: 0.2338
===> Epoch[28](800/2500): Loss: 0.2207
===> Epoch[28](900/2500): Loss: 0.2228
===> Epoch[28](1000/2500): Loss: 0.2081
===> Epoch[28](1100/2500): Loss: 0.2290
===> Epoch[28](1200/2500): Loss: 0.1991
===> Epoch[28](1300/2500): Loss: 0.2313
===> Epoch[28](1400/2500): Loss: 0.2196
===> Epoch[28](1500/2500): Loss: 0.2099
===> Epoch[28](1600/2500): Loss: 0.2104
===> Epoch[28](1700/2500): Loss: 0.2219
===> Epoch[28](1800/2500): Loss: 0.2377
===> Epoch[28](1900/2500): Loss: 0.2255
===> Epoch[28](2000/2500): Loss: 0.2129
===> Epoch[28](2100/2500): Loss: 0.2078
===> Epoch[28](2200/2500): Loss: 0.2165
===> Epoch[28](2300/2500): Loss: 0.2105
===> Epoch[28](2400/2500): Loss: 0.2062
===> Epoch[28](2500/2500): Loss: 0.2157
===> Epoch 28 Complete: Avg. Loss: 0.2220
===> Timestamp: [2025-08-03 17:28:41]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.2414
===> Epoch[28](200/2500): Loss: 0.2136
===> Epoch[28](300/2500): Loss: 0.2345
===> Epoch[28](400/2500): Loss: 0.2244
===> Epoch[28](500/2500): Loss: 0.2138
===> Epoch[28](600/2500): Loss: 0.2265
===> Epoch[28](700/2500): Loss: 0.2338
===> Epoch[28](800/2500): Loss: 0.2207
===> Epoch[28](900/2500): Loss: 0.2228
===> Epoch[28](1000/2500): Loss: 0.2081
===> Epoch[28](1100/2500): Loss: 0.2290
===> Epoch[28](1200/2500): Loss: 0.1991
===> Epoch[28](1300/2500): Loss: 0.2313
===> Epoch[28](1400/2500): Loss: 0.2196
===> Epoch[28](1500/2500): Loss: 0.2099
===> Epoch[28](1600/2500): Loss: 0.2104
===> Epoch[28](1700/2500): Loss: 0.2219
===> Epoch[28](1800/2500): Loss: 0.2377
===> Epoch[28](1900/2500): Loss: 0.2255
===> Epoch[28](2000/2500): Loss: 0.2129
===> Epoch[28](2100/2500): Loss: 0.2078
===> Epoch[28](2200/2500): Loss: 0.2165
===> Epoch[28](2300/2500): Loss: 0.2105
===> Epoch[28](2400/2500): Loss: 0.2062
===> Epoch[28](2500/2500): Loss: 0.2157
===> Epoch 28 Complete: Avg. Loss: 0.2220
===> Timestamp: [2025-08-03 17:28:41]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.2414
===> Epoch[28](200/2500): Loss: 0.2136
===> Epoch[28](300/2500): Loss: 0.2345
===> Epoch[28](400/2500): Loss: 0.2244
===> Epoch[28](500/2500): Loss: 0.2138
===> Epoch[28](600/2500): Loss: 0.2265
===> Epoch[28](700/2500): Loss: 0.2338
===> Epoch[28](800/2500): Loss: 0.2207
===> Epoch[28](900/2500): Loss: 0.2228
===> Epoch[28](1000/2500): Loss: 0.2081
===> Epoch[28](1100/2500): Loss: 0.2290
===> Epoch[28](1200/2500): Loss: 0.1991
===> Epoch[28](1300/2500): Loss: 0.2313
===> Epoch[28](1400/2500): Loss: 0.2196
===> Epoch[28](1500/2500): Loss: 0.2099
===> Epoch[28](1600/2500): Loss: 0.2104
===> Epoch[28](1700/2500): Loss: 0.2219
===> Epoch[28](1800/2500): Loss: 0.2377
===> Epoch[28](1900/2500): Loss: 0.2255
===> Epoch[28](2000/2500): Loss: 0.2129
===> Epoch[28](2100/2500): Loss: 0.2078
===> Epoch[28](2200/2500): Loss: 0.2165
===> Epoch[28](2300/2500): Loss: 0.2105
===> Epoch[28](2400/2500): Loss: 0.2062
===> Epoch[28](2500/2500): Loss: 0.2157
===> Epoch 28 Complete: Avg. Loss: 0.2220
===> Timestamp: [2025-08-03 17:28:41]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.2414
===> Epoch[28](200/2500): Loss: 0.2136
===> Epoch[28](300/2500): Loss: 0.2345
===> Epoch[28](400/2500): Loss: 0.2244
===> Epoch[28](500/2500): Loss: 0.2138
===> Epoch[28](600/2500): Loss: 0.2265
===> Epoch[28](700/2500): Loss: 0.2338
===> Epoch[28](800/2500): Loss: 0.2207
===> Epoch[28](900/2500): Loss: 0.2228
===> Epoch[28](1000/2500): Loss: 0.2081
===> Epoch[28](1100/2500): Loss: 0.2290
===> Epoch[28](1200/2500): Loss: 0.1991
===> Epoch[28](1300/2500): Loss: 0.2313
===> Epoch[28](1400/2500): Loss: 0.2196
===> Epoch[28](1500/2500): Loss: 0.2099
===> Epoch[28](1600/2500): Loss: 0.2104
===> Epoch[28](1700/2500): Loss: 0.2219
===> Epoch[28](1800/2500): Loss: 0.2377
===> Epoch[28](1900/2500): Loss: 0.2255
===> Epoch[28](2000/2500): Loss: 0.2129
===> Epoch[28](2100/2500): Loss: 0.2078
===> Epoch[28](2200/2500): Loss: 0.2165
===> Epoch[28](2300/2500): Loss: 0.2105
===> Epoch[28](2400/2500): Loss: 0.2062
===> Epoch[28](2500/2500): Loss: 0.2157
===> Epoch 28 Complete: Avg. Loss: 0.2220
===> Timestamp: [2025-08-03 17:28:41]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.2414
===> Epoch[28](200/2500): Loss: 0.2136
===> Epoch[28](300/2500): Loss: 0.2345
===> Epoch[28](400/2500): Loss: 0.2244
===> Epoch[28](500/2500): Loss: 0.2138
===> Epoch[28](600/2500): Loss: 0.2265
===> Epoch[28](700/2500): Loss: 0.2338
===> Epoch[28](800/2500): Loss: 0.2207
===> Epoch[28](900/2500): Loss: 0.2228
===> Epoch[28](1000/2500): Loss: 0.2081
===> Epoch[28](1100/2500): Loss: 0.2290
===> Epoch[28](1200/2500): Loss: 0.1991
===> Epoch[28](1300/2500): Loss: 0.2313
===> Epoch[28](1400/2500): Loss: 0.2196
===> Epoch[28](1500/2500): Loss: 0.2099
===> Epoch[28](1600/2500): Loss: 0.2104
===> Epoch[28](1700/2500): Loss: 0.2219
===> Epoch[28](1800/2500): Loss: 0.2377
===> Epoch[28](1900/2500): Loss: 0.2255
===> Epoch[28](2000/2500): Loss: 0.2129
===> Epoch[28](2100/2500): Loss: 0.2078
===> Epoch[28](2200/2500): Loss: 0.2165
===> Epoch[28](2300/2500): Loss: 0.2105
===> Epoch[28](2400/2500): Loss: 0.2062
===> Epoch[28](2500/2500): Loss: 0.2157
===> Epoch 28 Complete: Avg. Loss: 0.2220
===> Timestamp: [2025-08-03 17:28:41]
===> Loading train datasets
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2319
===> Epoch[29](200/2500): Loss: 0.2191
===> Epoch[29](300/2500): Loss: 0.2128
===> Epoch[29](400/2500): Loss: 0.2229
===> Epoch[29](500/2500): Loss: 0.2256
===> Epoch[29](600/2500): Loss: 0.2226
===> Epoch[29](700/2500): Loss: 0.2225
===> Epoch[29](800/2500): Loss: 0.2186
===> Epoch[29](900/2500): Loss: 0.2021
===> Epoch[29](1000/2500): Loss: 0.2139
===> Epoch[29](1100/2500): Loss: 0.2185
===> Epoch[29](1200/2500): Loss: 0.2277
===> Epoch[29](1300/2500): Loss: 0.2127
===> Epoch[29](1400/2500): Loss: 0.2383
===> Epoch[29](1500/2500): Loss: 0.2351
===> Epoch[29](1600/2500): Loss: 0.2167
===> Epoch[29](1700/2500): Loss: 0.2349
===> Epoch[29](1800/2500): Loss: 0.2444
===> Epoch[29](1900/2500): Loss: 0.2351
===> Epoch[29](2000/2500): Loss: 0.2208
===> Epoch[29](2100/2500): Loss: 0.2173
===> Epoch[29](2200/2500): Loss: 0.2381
===> Epoch[29](2300/2500): Loss: 0.2330
===> Epoch[29](2400/2500): Loss: 0.2330
===> Epoch[29](2500/2500): Loss: 0.2140
===> Epoch 29 Complete: Avg. Loss: 0.2206
===> Timestamp: [2025-08-03 17:33:15]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2319
===> Epoch[29](200/2500): Loss: 0.2191
===> Epoch[29](300/2500): Loss: 0.2128
===> Epoch[29](400/2500): Loss: 0.2229
===> Epoch[29](500/2500): Loss: 0.2256
===> Epoch[29](600/2500): Loss: 0.2226
===> Epoch[29](700/2500): Loss: 0.2225
===> Epoch[29](800/2500): Loss: 0.2186
===> Epoch[29](900/2500): Loss: 0.2021
===> Epoch[29](1000/2500): Loss: 0.2139
===> Epoch[29](1100/2500): Loss: 0.2185
===> Epoch[29](1200/2500): Loss: 0.2277
===> Epoch[29](1300/2500): Loss: 0.2127
===> Epoch[29](1400/2500): Loss: 0.2383
===> Epoch[29](1500/2500): Loss: 0.2351
===> Epoch[29](1600/2500): Loss: 0.2167
===> Epoch[29](1700/2500): Loss: 0.2349
===> Epoch[29](1800/2500): Loss: 0.2444
===> Epoch[29](1900/2500): Loss: 0.2351
===> Epoch[29](2000/2500): Loss: 0.2208
===> Epoch[29](2100/2500): Loss: 0.2173
===> Epoch[29](2200/2500): Loss: 0.2381
===> Epoch[29](2300/2500): Loss: 0.2330
===> Epoch[29](2400/2500): Loss: 0.2330
===> Epoch[29](2500/2500): Loss: 0.2140
===> Epoch 29 Complete: Avg. Loss: 0.2206
===> Timestamp: [2025-08-03 17:33:15]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2319
===> Epoch[29](200/2500): Loss: 0.2191
===> Epoch[29](300/2500): Loss: 0.2128
===> Epoch[29](400/2500): Loss: 0.2229
===> Epoch[29](500/2500): Loss: 0.2256
===> Epoch[29](600/2500): Loss: 0.2226
===> Epoch[29](700/2500): Loss: 0.2225
===> Epoch[29](800/2500): Loss: 0.2186
===> Epoch[29](900/2500): Loss: 0.2021
===> Epoch[29](1000/2500): Loss: 0.2139
===> Epoch[29](1100/2500): Loss: 0.2185
===> Epoch[29](1200/2500): Loss: 0.2277
===> Epoch[29](1300/2500): Loss: 0.2127
===> Epoch[29](1400/2500): Loss: 0.2383
===> Epoch[29](1500/2500): Loss: 0.2351
===> Epoch[29](1600/2500): Loss: 0.2167
===> Epoch[29](1700/2500): Loss: 0.2349
===> Epoch[29](1800/2500): Loss: 0.2444
===> Epoch[29](1900/2500): Loss: 0.2351
===> Epoch[29](2000/2500): Loss: 0.2208
===> Epoch[29](2100/2500): Loss: 0.2173
===> Epoch[29](2200/2500): Loss: 0.2381
===> Epoch[29](2300/2500): Loss: 0.2330
===> Epoch[29](2400/2500): Loss: 0.2330
===> Epoch[29](2500/2500): Loss: 0.2140
===> Epoch 29 Complete: Avg. Loss: 0.2206
===> Timestamp: [2025-08-03 17:33:15]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2319
===> Epoch[29](200/2500): Loss: 0.2191
===> Epoch[29](300/2500): Loss: 0.2128
===> Epoch[29](400/2500): Loss: 0.2229
===> Epoch[29](500/2500): Loss: 0.2256
===> Epoch[29](600/2500): Loss: 0.2226
===> Epoch[29](700/2500): Loss: 0.2225
===> Epoch[29](800/2500): Loss: 0.2186
===> Epoch[29](900/2500): Loss: 0.2021
===> Epoch[29](1000/2500): Loss: 0.2139
===> Epoch[29](1100/2500): Loss: 0.2185
===> Epoch[29](1200/2500): Loss: 0.2277
===> Epoch[29](1300/2500): Loss: 0.2127
===> Epoch[29](1400/2500): Loss: 0.2383
===> Epoch[29](1500/2500): Loss: 0.2351
===> Epoch[29](1600/2500): Loss: 0.2167
===> Epoch[29](1700/2500): Loss: 0.2349
===> Epoch[29](1800/2500): Loss: 0.2444
===> Epoch[29](1900/2500): Loss: 0.2351
===> Epoch[29](2000/2500): Loss: 0.2208
===> Epoch[29](2100/2500): Loss: 0.2173
===> Epoch[29](2200/2500): Loss: 0.2381
===> Epoch[29](2300/2500): Loss: 0.2330
===> Epoch[29](2400/2500): Loss: 0.2330
===> Epoch[29](2500/2500): Loss: 0.2140
===> Epoch 29 Complete: Avg. Loss: 0.2206
===> Timestamp: [2025-08-03 17:33:15]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2319
===> Epoch[29](200/2500): Loss: 0.2191
===> Epoch[29](300/2500): Loss: 0.2128
===> Epoch[29](400/2500): Loss: 0.2229
===> Epoch[29](500/2500): Loss: 0.2256
===> Epoch[29](600/2500): Loss: 0.2226
===> Epoch[29](700/2500): Loss: 0.2225
===> Epoch[29](800/2500): Loss: 0.2186
===> Epoch[29](900/2500): Loss: 0.2021
===> Epoch[29](1000/2500): Loss: 0.2139
===> Epoch[29](1100/2500): Loss: 0.2185
===> Epoch[29](1200/2500): Loss: 0.2277
===> Epoch[29](1300/2500): Loss: 0.2127
===> Epoch[29](1400/2500): Loss: 0.2383
===> Epoch[29](1500/2500): Loss: 0.2351
===> Epoch[29](1600/2500): Loss: 0.2167
===> Epoch[29](1700/2500): Loss: 0.2349
===> Epoch[29](1800/2500): Loss: 0.2444
===> Epoch[29](1900/2500): Loss: 0.2351
===> Epoch[29](2000/2500): Loss: 0.2208
===> Epoch[29](2100/2500): Loss: 0.2173
===> Epoch[29](2200/2500): Loss: 0.2381
===> Epoch[29](2300/2500): Loss: 0.2330
===> Epoch[29](2400/2500): Loss: 0.2330
===> Epoch[29](2500/2500): Loss: 0.2140
===> Epoch 29 Complete: Avg. Loss: 0.2206
===> Timestamp: [2025-08-03 17:33:15]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2319
===> Epoch[29](200/2500): Loss: 0.2191
===> Epoch[29](300/2500): Loss: 0.2128
===> Epoch[29](400/2500): Loss: 0.2229
===> Epoch[29](500/2500): Loss: 0.2256
===> Epoch[29](600/2500): Loss: 0.2226
===> Epoch[29](700/2500): Loss: 0.2225
===> Epoch[29](800/2500): Loss: 0.2186
===> Epoch[29](900/2500): Loss: 0.2021
===> Epoch[29](1000/2500): Loss: 0.2139
===> Epoch[29](1100/2500): Loss: 0.2185
===> Epoch[29](1200/2500): Loss: 0.2277
===> Epoch[29](1300/2500): Loss: 0.2127
===> Epoch[29](1400/2500): Loss: 0.2383
===> Epoch[29](1500/2500): Loss: 0.2351
===> Epoch[29](1600/2500): Loss: 0.2167
===> Epoch[29](1700/2500): Loss: 0.2349
===> Epoch[29](1800/2500): Loss: 0.2444
===> Epoch[29](1900/2500): Loss: 0.2351
===> Epoch[29](2000/2500): Loss: 0.2208
===> Epoch[29](2100/2500): Loss: 0.2173
===> Epoch[29](2200/2500): Loss: 0.2381
===> Epoch[29](2300/2500): Loss: 0.2330
===> Epoch[29](2400/2500): Loss: 0.2330
===> Epoch[29](2500/2500): Loss: 0.2140
===> Epoch 29 Complete: Avg. Loss: 0.2206
===> Timestamp: [2025-08-03 17:33:15]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2319
===> Epoch[29](200/2500): Loss: 0.2191
===> Epoch[29](300/2500): Loss: 0.2128
===> Epoch[29](400/2500): Loss: 0.2229
===> Epoch[29](500/2500): Loss: 0.2256
===> Epoch[29](600/2500): Loss: 0.2226
===> Epoch[29](700/2500): Loss: 0.2225
===> Epoch[29](800/2500): Loss: 0.2186
===> Epoch[29](900/2500): Loss: 0.2021
===> Epoch[29](1000/2500): Loss: 0.2139
===> Epoch[29](1100/2500): Loss: 0.2185
===> Epoch[29](1200/2500): Loss: 0.2277
===> Epoch[29](1300/2500): Loss: 0.2127
===> Epoch[29](1400/2500): Loss: 0.2383
===> Epoch[29](1500/2500): Loss: 0.2351
===> Epoch[29](1600/2500): Loss: 0.2167
===> Epoch[29](1700/2500): Loss: 0.2349
===> Epoch[29](1800/2500): Loss: 0.2444
===> Epoch[29](1900/2500): Loss: 0.2351
===> Epoch[29](2000/2500): Loss: 0.2208
===> Epoch[29](2100/2500): Loss: 0.2173
===> Epoch[29](2200/2500): Loss: 0.2381
===> Epoch[29](2300/2500): Loss: 0.2330
===> Epoch[29](2400/2500): Loss: 0.2330
===> Epoch[29](2500/2500): Loss: 0.2140
===> Epoch 29 Complete: Avg. Loss: 0.2206
===> Timestamp: [2025-08-03 17:33:15]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2319
===> Epoch[29](200/2500): Loss: 0.2191
===> Epoch[29](300/2500): Loss: 0.2128
===> Epoch[29](400/2500): Loss: 0.2229
===> Epoch[29](500/2500): Loss: 0.2256
===> Epoch[29](600/2500): Loss: 0.2226
===> Epoch[29](700/2500): Loss: 0.2225
===> Epoch[29](800/2500): Loss: 0.2186
===> Epoch[29](900/2500): Loss: 0.2021
===> Epoch[29](1000/2500): Loss: 0.2139
===> Epoch[29](1100/2500): Loss: 0.2185
===> Epoch[29](1200/2500): Loss: 0.2277
===> Epoch[29](1300/2500): Loss: 0.2127
===> Epoch[29](1400/2500): Loss: 0.2383
===> Epoch[29](1500/2500): Loss: 0.2351
===> Epoch[29](1600/2500): Loss: 0.2167
===> Epoch[29](1700/2500): Loss: 0.2349
===> Epoch[29](1800/2500): Loss: 0.2444
===> Epoch[29](1900/2500): Loss: 0.2351
===> Epoch[29](2000/2500): Loss: 0.2208
===> Epoch[29](2100/2500): Loss: 0.2173
===> Epoch[29](2200/2500): Loss: 0.2381
===> Epoch[29](2300/2500): Loss: 0.2330
===> Epoch[29](2400/2500): Loss: 0.2330
===> Epoch[29](2500/2500): Loss: 0.2140
===> Epoch 29 Complete: Avg. Loss: 0.2206
===> Timestamp: [2025-08-03 17:33:15]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2319
===> Epoch[29](200/2500): Loss: 0.2191
===> Epoch[29](300/2500): Loss: 0.2128
===> Epoch[29](400/2500): Loss: 0.2229
===> Epoch[29](500/2500): Loss: 0.2256
===> Epoch[29](600/2500): Loss: 0.2226
===> Epoch[29](700/2500): Loss: 0.2225
===> Epoch[29](800/2500): Loss: 0.2186
===> Epoch[29](900/2500): Loss: 0.2021
===> Epoch[29](1000/2500): Loss: 0.2139
===> Epoch[29](1100/2500): Loss: 0.2185
===> Epoch[29](1200/2500): Loss: 0.2277
===> Epoch[29](1300/2500): Loss: 0.2127
===> Epoch[29](1400/2500): Loss: 0.2383
===> Epoch[29](1500/2500): Loss: 0.2351
===> Epoch[29](1600/2500): Loss: 0.2167
===> Epoch[29](1700/2500): Loss: 0.2349
===> Epoch[29](1800/2500): Loss: 0.2444
===> Epoch[29](1900/2500): Loss: 0.2351
===> Epoch[29](2000/2500): Loss: 0.2208
===> Epoch[29](2100/2500): Loss: 0.2173
===> Epoch[29](2200/2500): Loss: 0.2381
===> Epoch[29](2300/2500): Loss: 0.2330
===> Epoch[29](2400/2500): Loss: 0.2330
===> Epoch[29](2500/2500): Loss: 0.2140
===> Epoch 29 Complete: Avg. Loss: 0.2206
===> Timestamp: [2025-08-03 17:33:15]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2319
===> Epoch[29](200/2500): Loss: 0.2191
===> Epoch[29](300/2500): Loss: 0.2128
===> Epoch[29](400/2500): Loss: 0.2229
===> Epoch[29](500/2500): Loss: 0.2256
===> Epoch[29](600/2500): Loss: 0.2226
===> Epoch[29](700/2500): Loss: 0.2225
===> Epoch[29](800/2500): Loss: 0.2186
===> Epoch[29](900/2500): Loss: 0.2021
===> Epoch[29](1000/2500): Loss: 0.2139
===> Epoch[29](1100/2500): Loss: 0.2185
===> Epoch[29](1200/2500): Loss: 0.2277
===> Epoch[29](1300/2500): Loss: 0.2127
===> Epoch[29](1400/2500): Loss: 0.2383
===> Epoch[29](1500/2500): Loss: 0.2351
===> Epoch[29](1600/2500): Loss: 0.2167
===> Epoch[29](1700/2500): Loss: 0.2349
===> Epoch[29](1800/2500): Loss: 0.2444
===> Epoch[29](1900/2500): Loss: 0.2351
===> Epoch[29](2000/2500): Loss: 0.2208
===> Epoch[29](2100/2500): Loss: 0.2173
===> Epoch[29](2200/2500): Loss: 0.2381
===> Epoch[29](2300/2500): Loss: 0.2330
===> Epoch[29](2400/2500): Loss: 0.2330
===> Epoch[29](2500/2500): Loss: 0.2140
===> Epoch 29 Complete: Avg. Loss: 0.2206
===> Timestamp: [2025-08-03 17:33:15]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2319
===> Epoch[29](200/2500): Loss: 0.2191
===> Epoch[29](300/2500): Loss: 0.2128
===> Epoch[29](400/2500): Loss: 0.2229
===> Epoch[29](500/2500): Loss: 0.2256
===> Epoch[29](600/2500): Loss: 0.2226
===> Epoch[29](700/2500): Loss: 0.2225
===> Epoch[29](800/2500): Loss: 0.2186
===> Epoch[29](900/2500): Loss: 0.2021
===> Epoch[29](1000/2500): Loss: 0.2139
===> Epoch[29](1100/2500): Loss: 0.2185
===> Epoch[29](1200/2500): Loss: 0.2277
===> Epoch[29](1300/2500): Loss: 0.2127
===> Epoch[29](1400/2500): Loss: 0.2383
===> Epoch[29](1500/2500): Loss: 0.2351
===> Epoch[29](1600/2500): Loss: 0.2167
===> Epoch[29](1700/2500): Loss: 0.2349
===> Epoch[29](1800/2500): Loss: 0.2444
===> Epoch[29](1900/2500): Loss: 0.2351
===> Epoch[29](2000/2500): Loss: 0.2208
===> Epoch[29](2100/2500): Loss: 0.2173
===> Epoch[29](2200/2500): Loss: 0.2381
===> Epoch[29](2300/2500): Loss: 0.2330
===> Epoch[29](2400/2500): Loss: 0.2330
===> Epoch[29](2500/2500): Loss: 0.2140
===> Epoch 29 Complete: Avg. Loss: 0.2206
===> Timestamp: [2025-08-03 17:33:15]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2319
===> Epoch[29](200/2500): Loss: 0.2191
===> Epoch[29](300/2500): Loss: 0.2128
===> Epoch[29](400/2500): Loss: 0.2229
===> Epoch[29](500/2500): Loss: 0.2256
===> Epoch[29](600/2500): Loss: 0.2226
===> Epoch[29](700/2500): Loss: 0.2225
===> Epoch[29](800/2500): Loss: 0.2186
===> Epoch[29](900/2500): Loss: 0.2021
===> Epoch[29](1000/2500): Loss: 0.2139
===> Epoch[29](1100/2500): Loss: 0.2185
===> Epoch[29](1200/2500): Loss: 0.2277
===> Epoch[29](1300/2500): Loss: 0.2127
===> Epoch[29](1400/2500): Loss: 0.2383
===> Epoch[29](1500/2500): Loss: 0.2351
===> Epoch[29](1600/2500): Loss: 0.2167
===> Epoch[29](1700/2500): Loss: 0.2349
===> Epoch[29](1800/2500): Loss: 0.2444
===> Epoch[29](1900/2500): Loss: 0.2351
===> Epoch[29](2000/2500): Loss: 0.2208
===> Epoch[29](2100/2500): Loss: 0.2173
===> Epoch[29](2200/2500): Loss: 0.2381
===> Epoch[29](2300/2500): Loss: 0.2330
===> Epoch[29](2400/2500): Loss: 0.2330
===> Epoch[29](2500/2500): Loss: 0.2140
===> Epoch 29 Complete: Avg. Loss: 0.2206
===> Timestamp: [2025-08-03 17:33:15]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2319
===> Epoch[29](200/2500): Loss: 0.2191
===> Epoch[29](300/2500): Loss: 0.2128
===> Epoch[29](400/2500): Loss: 0.2229
===> Epoch[29](500/2500): Loss: 0.2256
===> Epoch[29](600/2500): Loss: 0.2226
===> Epoch[29](700/2500): Loss: 0.2225
===> Epoch[29](800/2500): Loss: 0.2186
===> Epoch[29](900/2500): Loss: 0.2021
===> Epoch[29](1000/2500): Loss: 0.2139
===> Epoch[29](1100/2500): Loss: 0.2185
===> Epoch[29](1200/2500): Loss: 0.2277
===> Epoch[29](1300/2500): Loss: 0.2127
===> Epoch[29](1400/2500): Loss: 0.2383
===> Epoch[29](1500/2500): Loss: 0.2351
===> Epoch[29](1600/2500): Loss: 0.2167
===> Epoch[29](1700/2500): Loss: 0.2349
===> Epoch[29](1800/2500): Loss: 0.2444
===> Epoch[29](1900/2500): Loss: 0.2351
===> Epoch[29](2000/2500): Loss: 0.2208
===> Epoch[29](2100/2500): Loss: 0.2173
===> Epoch[29](2200/2500): Loss: 0.2381
===> Epoch[29](2300/2500): Loss: 0.2330
===> Epoch[29](2400/2500): Loss: 0.2330
===> Epoch[29](2500/2500): Loss: 0.2140
===> Epoch 29 Complete: Avg. Loss: 0.2206
===> Timestamp: [2025-08-03 17:33:15]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2319
===> Epoch[29](200/2500): Loss: 0.2191
===> Epoch[29](300/2500): Loss: 0.2128
===> Epoch[29](400/2500): Loss: 0.2229
===> Epoch[29](500/2500): Loss: 0.2256
===> Epoch[29](600/2500): Loss: 0.2226
===> Epoch[29](700/2500): Loss: 0.2225
===> Epoch[29](800/2500): Loss: 0.2186
===> Epoch[29](900/2500): Loss: 0.2021
===> Epoch[29](1000/2500): Loss: 0.2139
===> Epoch[29](1100/2500): Loss: 0.2185
===> Epoch[29](1200/2500): Loss: 0.2277
===> Epoch[29](1300/2500): Loss: 0.2127
===> Epoch[29](1400/2500): Loss: 0.2383
===> Epoch[29](1500/2500): Loss: 0.2351
===> Epoch[29](1600/2500): Loss: 0.2167
===> Epoch[29](1700/2500): Loss: 0.2349
===> Epoch[29](1800/2500): Loss: 0.2444
===> Epoch[29](1900/2500): Loss: 0.2351
===> Epoch[29](2000/2500): Loss: 0.2208
===> Epoch[29](2100/2500): Loss: 0.2173
===> Epoch[29](2200/2500): Loss: 0.2381
===> Epoch[29](2300/2500): Loss: 0.2330
===> Epoch[29](2400/2500): Loss: 0.2330
===> Epoch[29](2500/2500): Loss: 0.2140
===> Epoch 29 Complete: Avg. Loss: 0.2206
===> Timestamp: [2025-08-03 17:33:15]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2319
===> Epoch[29](200/2500): Loss: 0.2191
===> Epoch[29](300/2500): Loss: 0.2128
===> Epoch[29](400/2500): Loss: 0.2229
===> Epoch[29](500/2500): Loss: 0.2256
===> Epoch[29](600/2500): Loss: 0.2226
===> Epoch[29](700/2500): Loss: 0.2225
===> Epoch[29](800/2500): Loss: 0.2186
===> Epoch[29](900/2500): Loss: 0.2021
===> Epoch[29](1000/2500): Loss: 0.2139
===> Epoch[29](1100/2500): Loss: 0.2185
===> Epoch[29](1200/2500): Loss: 0.2277
===> Epoch[29](1300/2500): Loss: 0.2127
===> Epoch[29](1400/2500): Loss: 0.2383
===> Epoch[29](1500/2500): Loss: 0.2351
===> Epoch[29](1600/2500): Loss: 0.2167
===> Epoch[29](1700/2500): Loss: 0.2349
===> Epoch[29](1800/2500): Loss: 0.2444
===> Epoch[29](1900/2500): Loss: 0.2351
===> Epoch[29](2000/2500): Loss: 0.2208
===> Epoch[29](2100/2500): Loss: 0.2173
===> Epoch[29](2200/2500): Loss: 0.2381
===> Epoch[29](2300/2500): Loss: 0.2330
===> Epoch[29](2400/2500): Loss: 0.2330
===> Epoch[29](2500/2500): Loss: 0.2140
===> Epoch 29 Complete: Avg. Loss: 0.2206
===> Timestamp: [2025-08-03 17:33:15]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2319
===> Epoch[29](200/2500): Loss: 0.2191
===> Epoch[29](300/2500): Loss: 0.2128
===> Epoch[29](400/2500): Loss: 0.2229
===> Epoch[29](500/2500): Loss: 0.2256
===> Epoch[29](600/2500): Loss: 0.2226
===> Epoch[29](700/2500): Loss: 0.2225
===> Epoch[29](800/2500): Loss: 0.2186
===> Epoch[29](900/2500): Loss: 0.2021
===> Epoch[29](1000/2500): Loss: 0.2139
===> Epoch[29](1100/2500): Loss: 0.2185
===> Epoch[29](1200/2500): Loss: 0.2277
===> Epoch[29](1300/2500): Loss: 0.2127
===> Epoch[29](1400/2500): Loss: 0.2383
===> Epoch[29](1500/2500): Loss: 0.2351
===> Epoch[29](1600/2500): Loss: 0.2167
===> Epoch[29](1700/2500): Loss: 0.2349
===> Epoch[29](1800/2500): Loss: 0.2444
===> Epoch[29](1900/2500): Loss: 0.2351
===> Epoch[29](2000/2500): Loss: 0.2208
===> Epoch[29](2100/2500): Loss: 0.2173
===> Epoch[29](2200/2500): Loss: 0.2381
===> Epoch[29](2300/2500): Loss: 0.2330
===> Epoch[29](2400/2500): Loss: 0.2330
===> Epoch[29](2500/2500): Loss: 0.2140
===> Epoch 29 Complete: Avg. Loss: 0.2206
===> Timestamp: [2025-08-03 17:33:15]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2319
===> Epoch[29](200/2500): Loss: 0.2191
===> Epoch[29](300/2500): Loss: 0.2128
===> Epoch[29](400/2500): Loss: 0.2229
===> Epoch[29](500/2500): Loss: 0.2256
===> Epoch[29](600/2500): Loss: 0.2226
===> Epoch[29](700/2500): Loss: 0.2225
===> Epoch[29](800/2500): Loss: 0.2186
===> Epoch[29](900/2500): Loss: 0.2021
===> Epoch[29](1000/2500): Loss: 0.2139
===> Epoch[29](1100/2500): Loss: 0.2185
===> Epoch[29](1200/2500): Loss: 0.2277
===> Epoch[29](1300/2500): Loss: 0.2127
===> Epoch[29](1400/2500): Loss: 0.2383
===> Epoch[29](1500/2500): Loss: 0.2351
===> Epoch[29](1600/2500): Loss: 0.2167
===> Epoch[29](1700/2500): Loss: 0.2349
===> Epoch[29](1800/2500): Loss: 0.2444
===> Epoch[29](1900/2500): Loss: 0.2351
===> Epoch[29](2000/2500): Loss: 0.2208
===> Epoch[29](2100/2500): Loss: 0.2173
===> Epoch[29](2200/2500): Loss: 0.2381
===> Epoch[29](2300/2500): Loss: 0.2330
===> Epoch[29](2400/2500): Loss: 0.2330
===> Epoch[29](2500/2500): Loss: 0.2140
===> Epoch 29 Complete: Avg. Loss: 0.2206
===> Timestamp: [2025-08-03 17:33:15]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2319
===> Epoch[29](200/2500): Loss: 0.2191
===> Epoch[29](300/2500): Loss: 0.2128
===> Epoch[29](400/2500): Loss: 0.2229
===> Epoch[29](500/2500): Loss: 0.2256
===> Epoch[29](600/2500): Loss: 0.2226
===> Epoch[29](700/2500): Loss: 0.2225
===> Epoch[29](800/2500): Loss: 0.2186
===> Epoch[29](900/2500): Loss: 0.2021
===> Epoch[29](1000/2500): Loss: 0.2139
===> Epoch[29](1100/2500): Loss: 0.2185
===> Epoch[29](1200/2500): Loss: 0.2277
===> Epoch[29](1300/2500): Loss: 0.2127
===> Epoch[29](1400/2500): Loss: 0.2383
===> Epoch[29](1500/2500): Loss: 0.2351
===> Epoch[29](1600/2500): Loss: 0.2167
===> Epoch[29](1700/2500): Loss: 0.2349
===> Epoch[29](1800/2500): Loss: 0.2444
===> Epoch[29](1900/2500): Loss: 0.2351
===> Epoch[29](2000/2500): Loss: 0.2208
===> Epoch[29](2100/2500): Loss: 0.2173
===> Epoch[29](2200/2500): Loss: 0.2381
===> Epoch[29](2300/2500): Loss: 0.2330
===> Epoch[29](2400/2500): Loss: 0.2330
===> Epoch[29](2500/2500): Loss: 0.2140
===> Epoch 29 Complete: Avg. Loss: 0.2206
===> Timestamp: [2025-08-03 17:33:15]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2319
===> Epoch[29](200/2500): Loss: 0.2191
===> Epoch[29](300/2500): Loss: 0.2128
===> Epoch[29](400/2500): Loss: 0.2229
===> Epoch[29](500/2500): Loss: 0.2256
===> Epoch[29](600/2500): Loss: 0.2226
===> Epoch[29](700/2500): Loss: 0.2225
===> Epoch[29](800/2500): Loss: 0.2186
===> Epoch[29](900/2500): Loss: 0.2021
===> Epoch[29](1000/2500): Loss: 0.2139
===> Epoch[29](1100/2500): Loss: 0.2185
===> Epoch[29](1200/2500): Loss: 0.2277
===> Epoch[29](1300/2500): Loss: 0.2127
===> Epoch[29](1400/2500): Loss: 0.2383
===> Epoch[29](1500/2500): Loss: 0.2351
===> Epoch[29](1600/2500): Loss: 0.2167
===> Epoch[29](1700/2500): Loss: 0.2349
===> Epoch[29](1800/2500): Loss: 0.2444
===> Epoch[29](1900/2500): Loss: 0.2351
===> Epoch[29](2000/2500): Loss: 0.2208
===> Epoch[29](2100/2500): Loss: 0.2173
===> Epoch[29](2200/2500): Loss: 0.2381
===> Epoch[29](2300/2500): Loss: 0.2330
===> Epoch[29](2400/2500): Loss: 0.2330
===> Epoch[29](2500/2500): Loss: 0.2140
===> Epoch 29 Complete: Avg. Loss: 0.2206
===> Timestamp: [2025-08-03 17:33:15]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2319
===> Epoch[29](200/2500): Loss: 0.2191
===> Epoch[29](300/2500): Loss: 0.2128
===> Epoch[29](400/2500): Loss: 0.2229
===> Epoch[29](500/2500): Loss: 0.2256
===> Epoch[29](600/2500): Loss: 0.2226
===> Epoch[29](700/2500): Loss: 0.2225
===> Epoch[29](800/2500): Loss: 0.2186
===> Epoch[29](900/2500): Loss: 0.2021
===> Epoch[29](1000/2500): Loss: 0.2139
===> Epoch[29](1100/2500): Loss: 0.2185
===> Epoch[29](1200/2500): Loss: 0.2277
===> Epoch[29](1300/2500): Loss: 0.2127
===> Epoch[29](1400/2500): Loss: 0.2383
===> Epoch[29](1500/2500): Loss: 0.2351
===> Epoch[29](1600/2500): Loss: 0.2167
===> Epoch[29](1700/2500): Loss: 0.2349
===> Epoch[29](1800/2500): Loss: 0.2444
===> Epoch[29](1900/2500): Loss: 0.2351
===> Epoch[29](2000/2500): Loss: 0.2208
===> Epoch[29](2100/2500): Loss: 0.2173
===> Epoch[29](2200/2500): Loss: 0.2381
===> Epoch[29](2300/2500): Loss: 0.2330
===> Epoch[29](2400/2500): Loss: 0.2330
===> Epoch[29](2500/2500): Loss: 0.2140
===> Epoch 29 Complete: Avg. Loss: 0.2206
===> Timestamp: [2025-08-03 17:33:15]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2319
===> Epoch[29](200/2500): Loss: 0.2191
===> Epoch[29](300/2500): Loss: 0.2128
===> Epoch[29](400/2500): Loss: 0.2229
===> Epoch[29](500/2500): Loss: 0.2256
===> Epoch[29](600/2500): Loss: 0.2226
===> Epoch[29](700/2500): Loss: 0.2225
===> Epoch[29](800/2500): Loss: 0.2186
===> Epoch[29](900/2500): Loss: 0.2021
===> Epoch[29](1000/2500): Loss: 0.2139
===> Epoch[29](1100/2500): Loss: 0.2185
===> Epoch[29](1200/2500): Loss: 0.2277
===> Epoch[29](1300/2500): Loss: 0.2127
===> Epoch[29](1400/2500): Loss: 0.2383
===> Epoch[29](1500/2500): Loss: 0.2351
===> Epoch[29](1600/2500): Loss: 0.2167
===> Epoch[29](1700/2500): Loss: 0.2349
===> Epoch[29](1800/2500): Loss: 0.2444
===> Epoch[29](1900/2500): Loss: 0.2351
===> Epoch[29](2000/2500): Loss: 0.2208
===> Epoch[29](2100/2500): Loss: 0.2173
===> Epoch[29](2200/2500): Loss: 0.2381
===> Epoch[29](2300/2500): Loss: 0.2330
===> Epoch[29](2400/2500): Loss: 0.2330
===> Epoch[29](2500/2500): Loss: 0.2140
===> Epoch 29 Complete: Avg. Loss: 0.2206
===> Timestamp: [2025-08-03 17:33:15]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2319
===> Epoch[29](200/2500): Loss: 0.2191
===> Epoch[29](300/2500): Loss: 0.2128
===> Epoch[29](400/2500): Loss: 0.2229
===> Epoch[29](500/2500): Loss: 0.2256
===> Epoch[29](600/2500): Loss: 0.2226
===> Epoch[29](700/2500): Loss: 0.2225
===> Epoch[29](800/2500): Loss: 0.2186
===> Epoch[29](900/2500): Loss: 0.2021
===> Epoch[29](1000/2500): Loss: 0.2139
===> Epoch[29](1100/2500): Loss: 0.2185
===> Epoch[29](1200/2500): Loss: 0.2277
===> Epoch[29](1300/2500): Loss: 0.2127
===> Epoch[29](1400/2500): Loss: 0.2383
===> Epoch[29](1500/2500): Loss: 0.2351
===> Epoch[29](1600/2500): Loss: 0.2167
===> Epoch[29](1700/2500): Loss: 0.2349
===> Epoch[29](1800/2500): Loss: 0.2444
===> Epoch[29](1900/2500): Loss: 0.2351
===> Epoch[29](2000/2500): Loss: 0.2208
===> Epoch[29](2100/2500): Loss: 0.2173
===> Epoch[29](2200/2500): Loss: 0.2381
===> Epoch[29](2300/2500): Loss: 0.2330
===> Epoch[29](2400/2500): Loss: 0.2330
===> Epoch[29](2500/2500): Loss: 0.2140
===> Epoch 29 Complete: Avg. Loss: 0.2206
===> Timestamp: [2025-08-03 17:33:15]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2319
===> Epoch[29](200/2500): Loss: 0.2191
===> Epoch[29](300/2500): Loss: 0.2128
===> Epoch[29](400/2500): Loss: 0.2229
===> Epoch[29](500/2500): Loss: 0.2256
===> Epoch[29](600/2500): Loss: 0.2226
===> Epoch[29](700/2500): Loss: 0.2225
===> Epoch[29](800/2500): Loss: 0.2186
===> Epoch[29](900/2500): Loss: 0.2021
===> Epoch[29](1000/2500): Loss: 0.2139
===> Epoch[29](1100/2500): Loss: 0.2185
===> Epoch[29](1200/2500): Loss: 0.2277
===> Epoch[29](1300/2500): Loss: 0.2127
===> Epoch[29](1400/2500): Loss: 0.2383
===> Epoch[29](1500/2500): Loss: 0.2351
===> Epoch[29](1600/2500): Loss: 0.2167
===> Epoch[29](1700/2500): Loss: 0.2349
===> Epoch[29](1800/2500): Loss: 0.2444
===> Epoch[29](1900/2500): Loss: 0.2351
===> Epoch[29](2000/2500): Loss: 0.2208
===> Epoch[29](2100/2500): Loss: 0.2173
===> Epoch[29](2200/2500): Loss: 0.2381
===> Epoch[29](2300/2500): Loss: 0.2330
===> Epoch[29](2400/2500): Loss: 0.2330
===> Epoch[29](2500/2500): Loss: 0.2140
===> Epoch 29 Complete: Avg. Loss: 0.2206
===> Timestamp: [2025-08-03 17:33:15]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2319
===> Epoch[29](200/2500): Loss: 0.2191
===> Epoch[29](300/2500): Loss: 0.2128
===> Epoch[29](400/2500): Loss: 0.2229
===> Epoch[29](500/2500): Loss: 0.2256
===> Epoch[29](600/2500): Loss: 0.2226
===> Epoch[29](700/2500): Loss: 0.2225
===> Epoch[29](800/2500): Loss: 0.2186
===> Epoch[29](900/2500): Loss: 0.2021
===> Epoch[29](1000/2500): Loss: 0.2139
===> Epoch[29](1100/2500): Loss: 0.2185
===> Epoch[29](1200/2500): Loss: 0.2277
===> Epoch[29](1300/2500): Loss: 0.2127
===> Epoch[29](1400/2500): Loss: 0.2383
===> Epoch[29](1500/2500): Loss: 0.2351
===> Epoch[29](1600/2500): Loss: 0.2167
===> Epoch[29](1700/2500): Loss: 0.2349
===> Epoch[29](1800/2500): Loss: 0.2444
===> Epoch[29](1900/2500): Loss: 0.2351
===> Epoch[29](2000/2500): Loss: 0.2208
===> Epoch[29](2100/2500): Loss: 0.2173
===> Epoch[29](2200/2500): Loss: 0.2381
===> Epoch[29](2300/2500): Loss: 0.2330
===> Epoch[29](2400/2500): Loss: 0.2330
===> Epoch[29](2500/2500): Loss: 0.2140
===> Epoch 29 Complete: Avg. Loss: 0.2206
===> Timestamp: [2025-08-03 17:33:15]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2319
===> Epoch[29](200/2500): Loss: 0.2191
===> Epoch[29](300/2500): Loss: 0.2128
===> Epoch[29](400/2500): Loss: 0.2229
===> Epoch[29](500/2500): Loss: 0.2256
===> Epoch[29](600/2500): Loss: 0.2226
===> Epoch[29](700/2500): Loss: 0.2225
===> Epoch[29](800/2500): Loss: 0.2186
===> Epoch[29](900/2500): Loss: 0.2021
===> Epoch[29](1000/2500): Loss: 0.2139
===> Epoch[29](1100/2500): Loss: 0.2185
===> Epoch[29](1200/2500): Loss: 0.2277
===> Epoch[29](1300/2500): Loss: 0.2127
===> Epoch[29](1400/2500): Loss: 0.2383
===> Epoch[29](1500/2500): Loss: 0.2351
===> Epoch[29](1600/2500): Loss: 0.2167
===> Epoch[29](1700/2500): Loss: 0.2349
===> Epoch[29](1800/2500): Loss: 0.2444
===> Epoch[29](1900/2500): Loss: 0.2351
===> Epoch[29](2000/2500): Loss: 0.2208
===> Epoch[29](2100/2500): Loss: 0.2173
===> Epoch[29](2200/2500): Loss: 0.2381
===> Epoch[29](2300/2500): Loss: 0.2330
===> Epoch[29](2400/2500): Loss: 0.2330
===> Epoch[29](2500/2500): Loss: 0.2140
===> Epoch 29 Complete: Avg. Loss: 0.2206
===> Timestamp: [2025-08-03 17:33:15]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2319
===> Epoch[29](200/2500): Loss: 0.2191
===> Epoch[29](300/2500): Loss: 0.2128
===> Epoch[29](400/2500): Loss: 0.2229
===> Epoch[29](500/2500): Loss: 0.2256
===> Epoch[29](600/2500): Loss: 0.2226
===> Epoch[29](700/2500): Loss: 0.2225
===> Epoch[29](800/2500): Loss: 0.2186
===> Epoch[29](900/2500): Loss: 0.2021
===> Epoch[29](1000/2500): Loss: 0.2139
===> Epoch[29](1100/2500): Loss: 0.2185
===> Epoch[29](1200/2500): Loss: 0.2277
===> Epoch[29](1300/2500): Loss: 0.2127
===> Epoch[29](1400/2500): Loss: 0.2383
===> Epoch[29](1500/2500): Loss: 0.2351
===> Epoch[29](1600/2500): Loss: 0.2167
===> Epoch[29](1700/2500): Loss: 0.2349
===> Epoch[29](1800/2500): Loss: 0.2444
===> Epoch[29](1900/2500): Loss: 0.2351
===> Epoch[29](2000/2500): Loss: 0.2208
===> Epoch[29](2100/2500): Loss: 0.2173
===> Epoch[29](2200/2500): Loss: 0.2381
===> Epoch[29](2300/2500): Loss: 0.2330
===> Epoch[29](2400/2500): Loss: 0.2330
===> Epoch[29](2500/2500): Loss: 0.2140
===> Epoch 29 Complete: Avg. Loss: 0.2206
===> Timestamp: [2025-08-03 17:33:15]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2319
===> Epoch[29](200/2500): Loss: 0.2191
===> Epoch[29](300/2500): Loss: 0.2128
===> Epoch[29](400/2500): Loss: 0.2229
===> Epoch[29](500/2500): Loss: 0.2256
===> Epoch[29](600/2500): Loss: 0.2226
===> Epoch[29](700/2500): Loss: 0.2225
===> Epoch[29](800/2500): Loss: 0.2186
===> Epoch[29](900/2500): Loss: 0.2021
===> Epoch[29](1000/2500): Loss: 0.2139
===> Epoch[29](1100/2500): Loss: 0.2185
===> Epoch[29](1200/2500): Loss: 0.2277
===> Epoch[29](1300/2500): Loss: 0.2127
===> Epoch[29](1400/2500): Loss: 0.2383
===> Epoch[29](1500/2500): Loss: 0.2351
===> Epoch[29](1600/2500): Loss: 0.2167
===> Epoch[29](1700/2500): Loss: 0.2349
===> Epoch[29](1800/2500): Loss: 0.2444
===> Epoch[29](1900/2500): Loss: 0.2351
===> Epoch[29](2000/2500): Loss: 0.2208
===> Epoch[29](2100/2500): Loss: 0.2173
===> Epoch[29](2200/2500): Loss: 0.2381
===> Epoch[29](2300/2500): Loss: 0.2330
===> Epoch[29](2400/2500): Loss: 0.2330
===> Epoch[29](2500/2500): Loss: 0.2140
===> Epoch 29 Complete: Avg. Loss: 0.2206
===> Timestamp: [2025-08-03 17:33:15]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2319
===> Epoch[29](200/2500): Loss: 0.2191
===> Epoch[29](300/2500): Loss: 0.2128
===> Epoch[29](400/2500): Loss: 0.2229
===> Epoch[29](500/2500): Loss: 0.2256
===> Epoch[29](600/2500): Loss: 0.2226
===> Epoch[29](700/2500): Loss: 0.2225
===> Epoch[29](800/2500): Loss: 0.2186
===> Epoch[29](900/2500): Loss: 0.2021
===> Epoch[29](1000/2500): Loss: 0.2139
===> Epoch[29](1100/2500): Loss: 0.2185
===> Epoch[29](1200/2500): Loss: 0.2277
===> Epoch[29](1300/2500): Loss: 0.2127
===> Epoch[29](1400/2500): Loss: 0.2383
===> Epoch[29](1500/2500): Loss: 0.2351
===> Epoch[29](1600/2500): Loss: 0.2167
===> Epoch[29](1700/2500): Loss: 0.2349
===> Epoch[29](1800/2500): Loss: 0.2444
===> Epoch[29](1900/2500): Loss: 0.2351
===> Epoch[29](2000/2500): Loss: 0.2208
===> Epoch[29](2100/2500): Loss: 0.2173
===> Epoch[29](2200/2500): Loss: 0.2381
===> Epoch[29](2300/2500): Loss: 0.2330
===> Epoch[29](2400/2500): Loss: 0.2330
===> Epoch[29](2500/2500): Loss: 0.2140
===> Epoch 29 Complete: Avg. Loss: 0.2206
===> Timestamp: [2025-08-03 17:33:15]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2319
===> Epoch[29](200/2500): Loss: 0.2191
===> Epoch[29](300/2500): Loss: 0.2128
===> Epoch[29](400/2500): Loss: 0.2229
===> Epoch[29](500/2500): Loss: 0.2256
===> Epoch[29](600/2500): Loss: 0.2226
===> Epoch[29](700/2500): Loss: 0.2225
===> Epoch[29](800/2500): Loss: 0.2186
===> Epoch[29](900/2500): Loss: 0.2021
===> Epoch[29](1000/2500): Loss: 0.2139
===> Epoch[29](1100/2500): Loss: 0.2185
===> Epoch[29](1200/2500): Loss: 0.2277
===> Epoch[29](1300/2500): Loss: 0.2127
===> Epoch[29](1400/2500): Loss: 0.2383
===> Epoch[29](1500/2500): Loss: 0.2351
===> Epoch[29](1600/2500): Loss: 0.2167
===> Epoch[29](1700/2500): Loss: 0.2349
===> Epoch[29](1800/2500): Loss: 0.2444
===> Epoch[29](1900/2500): Loss: 0.2351
===> Epoch[29](2000/2500): Loss: 0.2208
===> Epoch[29](2100/2500): Loss: 0.2173
===> Epoch[29](2200/2500): Loss: 0.2381
===> Epoch[29](2300/2500): Loss: 0.2330
===> Epoch[29](2400/2500): Loss: 0.2330
===> Epoch[29](2500/2500): Loss: 0.2140
===> Epoch 29 Complete: Avg. Loss: 0.2206
===> Timestamp: [2025-08-03 17:33:15]
===> Loading train datasets
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2204
===> Epoch[30](200/2500): Loss: 0.2229
===> Epoch[30](300/2500): Loss: 0.2298
===> Epoch[30](400/2500): Loss: 0.2131
===> Epoch[30](500/2500): Loss: 0.2253
===> Epoch[30](600/2500): Loss: 0.2227
===> Epoch[30](700/2500): Loss: 0.2121
===> Epoch[30](800/2500): Loss: 0.2316
===> Epoch[30](900/2500): Loss: 0.2171
===> Epoch[30](1000/2500): Loss: 0.2346
===> Epoch[30](1100/2500): Loss: 0.2201
===> Epoch[30](1200/2500): Loss: 0.2132
===> Epoch[30](1300/2500): Loss: 0.2126
===> Epoch[30](1400/2500): Loss: 0.2285
===> Epoch[30](1500/2500): Loss: 0.2211
===> Epoch[30](1600/2500): Loss: 0.2122
===> Epoch[30](1700/2500): Loss: 0.2092
===> Epoch[30](1800/2500): Loss: 0.2160
===> Epoch[30](1900/2500): Loss: 0.2083
===> Epoch[30](2000/2500): Loss: 0.2031
===> Epoch[30](2100/2500): Loss: 0.2118
===> Epoch[30](2200/2500): Loss: 0.2123
===> Epoch[30](2300/2500): Loss: 0.2287
===> Epoch[30](2400/2500): Loss: 0.2215
===> Epoch[30](2500/2500): Loss: 0.2090
===> Epoch 30 Complete: Avg. Loss: 0.2180
===> Timestamp: [2025-08-03 17:37:49]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2204
===> Epoch[30](200/2500): Loss: 0.2229
===> Epoch[30](300/2500): Loss: 0.2298
===> Epoch[30](400/2500): Loss: 0.2131
===> Epoch[30](500/2500): Loss: 0.2253
===> Epoch[30](600/2500): Loss: 0.2227
===> Epoch[30](700/2500): Loss: 0.2121
===> Epoch[30](800/2500): Loss: 0.2316
===> Epoch[30](900/2500): Loss: 0.2171
===> Epoch[30](1000/2500): Loss: 0.2346
===> Epoch[30](1100/2500): Loss: 0.2201
===> Epoch[30](1200/2500): Loss: 0.2132
===> Epoch[30](1300/2500): Loss: 0.2126
===> Epoch[30](1400/2500): Loss: 0.2285
===> Epoch[30](1500/2500): Loss: 0.2211
===> Epoch[30](1600/2500): Loss: 0.2122
===> Epoch[30](1700/2500): Loss: 0.2092
===> Epoch[30](1800/2500): Loss: 0.2160
===> Epoch[30](1900/2500): Loss: 0.2083
===> Epoch[30](2000/2500): Loss: 0.2031
===> Epoch[30](2100/2500): Loss: 0.2118
===> Epoch[30](2200/2500): Loss: 0.2123
===> Epoch[30](2300/2500): Loss: 0.2287
===> Epoch[30](2400/2500): Loss: 0.2215
===> Epoch[30](2500/2500): Loss: 0.2090
===> Epoch 30 Complete: Avg. Loss: 0.2180
===> Timestamp: [2025-08-03 17:37:49]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2204
===> Epoch[30](200/2500): Loss: 0.2229
===> Epoch[30](300/2500): Loss: 0.2298
===> Epoch[30](400/2500): Loss: 0.2131
===> Epoch[30](500/2500): Loss: 0.2253
===> Epoch[30](600/2500): Loss: 0.2227
===> Epoch[30](700/2500): Loss: 0.2121
===> Epoch[30](800/2500): Loss: 0.2316
===> Epoch[30](900/2500): Loss: 0.2171
===> Epoch[30](1000/2500): Loss: 0.2346
===> Epoch[30](1100/2500): Loss: 0.2201
===> Epoch[30](1200/2500): Loss: 0.2132
===> Epoch[30](1300/2500): Loss: 0.2126
===> Epoch[30](1400/2500): Loss: 0.2285
===> Epoch[30](1500/2500): Loss: 0.2211
===> Epoch[30](1600/2500): Loss: 0.2122
===> Epoch[30](1700/2500): Loss: 0.2092
===> Epoch[30](1800/2500): Loss: 0.2160
===> Epoch[30](1900/2500): Loss: 0.2083
===> Epoch[30](2000/2500): Loss: 0.2031
===> Epoch[30](2100/2500): Loss: 0.2118
===> Epoch[30](2200/2500): Loss: 0.2123
===> Epoch[30](2300/2500): Loss: 0.2287
===> Epoch[30](2400/2500): Loss: 0.2215
===> Epoch[30](2500/2500): Loss: 0.2090
===> Epoch 30 Complete: Avg. Loss: 0.2180
===> Timestamp: [2025-08-03 17:37:49]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2204
===> Epoch[30](200/2500): Loss: 0.2229
===> Epoch[30](300/2500): Loss: 0.2298
===> Epoch[30](400/2500): Loss: 0.2131
===> Epoch[30](500/2500): Loss: 0.2253
===> Epoch[30](600/2500): Loss: 0.2227
===> Epoch[30](700/2500): Loss: 0.2121
===> Epoch[30](800/2500): Loss: 0.2316
===> Epoch[30](900/2500): Loss: 0.2171
===> Epoch[30](1000/2500): Loss: 0.2346
===> Epoch[30](1100/2500): Loss: 0.2201
===> Epoch[30](1200/2500): Loss: 0.2132
===> Epoch[30](1300/2500): Loss: 0.2126
===> Epoch[30](1400/2500): Loss: 0.2285
===> Epoch[30](1500/2500): Loss: 0.2211
===> Epoch[30](1600/2500): Loss: 0.2122
===> Epoch[30](1700/2500): Loss: 0.2092
===> Epoch[30](1800/2500): Loss: 0.2160
===> Epoch[30](1900/2500): Loss: 0.2083
===> Epoch[30](2000/2500): Loss: 0.2031
===> Epoch[30](2100/2500): Loss: 0.2118
===> Epoch[30](2200/2500): Loss: 0.2123
===> Epoch[30](2300/2500): Loss: 0.2287
===> Epoch[30](2400/2500): Loss: 0.2215
===> Epoch[30](2500/2500): Loss: 0.2090
===> Epoch 30 Complete: Avg. Loss: 0.2180
===> Timestamp: [2025-08-03 17:37:49]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2204
===> Epoch[30](200/2500): Loss: 0.2229
===> Epoch[30](300/2500): Loss: 0.2298
===> Epoch[30](400/2500): Loss: 0.2131
===> Epoch[30](500/2500): Loss: 0.2253
===> Epoch[30](600/2500): Loss: 0.2227
===> Epoch[30](700/2500): Loss: 0.2121
===> Epoch[30](800/2500): Loss: 0.2316
===> Epoch[30](900/2500): Loss: 0.2171
===> Epoch[30](1000/2500): Loss: 0.2346
===> Epoch[30](1100/2500): Loss: 0.2201
===> Epoch[30](1200/2500): Loss: 0.2132
===> Epoch[30](1300/2500): Loss: 0.2126
===> Epoch[30](1400/2500): Loss: 0.2285
===> Epoch[30](1500/2500): Loss: 0.2211
===> Epoch[30](1600/2500): Loss: 0.2122
===> Epoch[30](1700/2500): Loss: 0.2092
===> Epoch[30](1800/2500): Loss: 0.2160
===> Epoch[30](1900/2500): Loss: 0.2083
===> Epoch[30](2000/2500): Loss: 0.2031
===> Epoch[30](2100/2500): Loss: 0.2118
===> Epoch[30](2200/2500): Loss: 0.2123
===> Epoch[30](2300/2500): Loss: 0.2287
===> Epoch[30](2400/2500): Loss: 0.2215
===> Epoch[30](2500/2500): Loss: 0.2090
===> Epoch 30 Complete: Avg. Loss: 0.2180
===> Timestamp: [2025-08-03 17:37:49]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2204
===> Epoch[30](200/2500): Loss: 0.2229
===> Epoch[30](300/2500): Loss: 0.2298
===> Epoch[30](400/2500): Loss: 0.2131
===> Epoch[30](500/2500): Loss: 0.2253
===> Epoch[30](600/2500): Loss: 0.2227
===> Epoch[30](700/2500): Loss: 0.2121
===> Epoch[30](800/2500): Loss: 0.2316
===> Epoch[30](900/2500): Loss: 0.2171
===> Epoch[30](1000/2500): Loss: 0.2346
===> Epoch[30](1100/2500): Loss: 0.2201
===> Epoch[30](1200/2500): Loss: 0.2132
===> Epoch[30](1300/2500): Loss: 0.2126
===> Epoch[30](1400/2500): Loss: 0.2285
===> Epoch[30](1500/2500): Loss: 0.2211
===> Epoch[30](1600/2500): Loss: 0.2122
===> Epoch[30](1700/2500): Loss: 0.2092
===> Epoch[30](1800/2500): Loss: 0.2160
===> Epoch[30](1900/2500): Loss: 0.2083
===> Epoch[30](2000/2500): Loss: 0.2031
===> Epoch[30](2100/2500): Loss: 0.2118
===> Epoch[30](2200/2500): Loss: 0.2123
===> Epoch[30](2300/2500): Loss: 0.2287
===> Epoch[30](2400/2500): Loss: 0.2215
===> Epoch[30](2500/2500): Loss: 0.2090
===> Epoch 30 Complete: Avg. Loss: 0.2180
===> Timestamp: [2025-08-03 17:37:49]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2204
===> Epoch[30](200/2500): Loss: 0.2229
===> Epoch[30](300/2500): Loss: 0.2298
===> Epoch[30](400/2500): Loss: 0.2131
===> Epoch[30](500/2500): Loss: 0.2253
===> Epoch[30](600/2500): Loss: 0.2227
===> Epoch[30](700/2500): Loss: 0.2121
===> Epoch[30](800/2500): Loss: 0.2316
===> Epoch[30](900/2500): Loss: 0.2171
===> Epoch[30](1000/2500): Loss: 0.2346
===> Epoch[30](1100/2500): Loss: 0.2201
===> Epoch[30](1200/2500): Loss: 0.2132
===> Epoch[30](1300/2500): Loss: 0.2126
===> Epoch[30](1400/2500): Loss: 0.2285
===> Epoch[30](1500/2500): Loss: 0.2211
===> Epoch[30](1600/2500): Loss: 0.2122
===> Epoch[30](1700/2500): Loss: 0.2092
===> Epoch[30](1800/2500): Loss: 0.2160
===> Epoch[30](1900/2500): Loss: 0.2083
===> Epoch[30](2000/2500): Loss: 0.2031
===> Epoch[30](2100/2500): Loss: 0.2118
===> Epoch[30](2200/2500): Loss: 0.2123
===> Epoch[30](2300/2500): Loss: 0.2287
===> Epoch[30](2400/2500): Loss: 0.2215
===> Epoch[30](2500/2500): Loss: 0.2090
===> Epoch 30 Complete: Avg. Loss: 0.2180
===> Timestamp: [2025-08-03 17:37:49]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2204
===> Epoch[30](200/2500): Loss: 0.2229
===> Epoch[30](300/2500): Loss: 0.2298
===> Epoch[30](400/2500): Loss: 0.2131
===> Epoch[30](500/2500): Loss: 0.2253
===> Epoch[30](600/2500): Loss: 0.2227
===> Epoch[30](700/2500): Loss: 0.2121
===> Epoch[30](800/2500): Loss: 0.2316
===> Epoch[30](900/2500): Loss: 0.2171
===> Epoch[30](1000/2500): Loss: 0.2346
===> Epoch[30](1100/2500): Loss: 0.2201
===> Epoch[30](1200/2500): Loss: 0.2132
===> Epoch[30](1300/2500): Loss: 0.2126
===> Epoch[30](1400/2500): Loss: 0.2285
===> Epoch[30](1500/2500): Loss: 0.2211
===> Epoch[30](1600/2500): Loss: 0.2122
===> Epoch[30](1700/2500): Loss: 0.2092
===> Epoch[30](1800/2500): Loss: 0.2160
===> Epoch[30](1900/2500): Loss: 0.2083
===> Epoch[30](2000/2500): Loss: 0.2031
===> Epoch[30](2100/2500): Loss: 0.2118
===> Epoch[30](2200/2500): Loss: 0.2123
===> Epoch[30](2300/2500): Loss: 0.2287
===> Epoch[30](2400/2500): Loss: 0.2215
===> Epoch[30](2500/2500): Loss: 0.2090
===> Epoch 30 Complete: Avg. Loss: 0.2180
===> Timestamp: [2025-08-03 17:37:49]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2204
===> Epoch[30](200/2500): Loss: 0.2229
===> Epoch[30](300/2500): Loss: 0.2298
===> Epoch[30](400/2500): Loss: 0.2131
===> Epoch[30](500/2500): Loss: 0.2253
===> Epoch[30](600/2500): Loss: 0.2227
===> Epoch[30](700/2500): Loss: 0.2121
===> Epoch[30](800/2500): Loss: 0.2316
===> Epoch[30](900/2500): Loss: 0.2171
===> Epoch[30](1000/2500): Loss: 0.2346
===> Epoch[30](1100/2500): Loss: 0.2201
===> Epoch[30](1200/2500): Loss: 0.2132
===> Epoch[30](1300/2500): Loss: 0.2126
===> Epoch[30](1400/2500): Loss: 0.2285
===> Epoch[30](1500/2500): Loss: 0.2211
===> Epoch[30](1600/2500): Loss: 0.2122
===> Epoch[30](1700/2500): Loss: 0.2092
===> Epoch[30](1800/2500): Loss: 0.2160
===> Epoch[30](1900/2500): Loss: 0.2083
===> Epoch[30](2000/2500): Loss: 0.2031
===> Epoch[30](2100/2500): Loss: 0.2118
===> Epoch[30](2200/2500): Loss: 0.2123
===> Epoch[30](2300/2500): Loss: 0.2287
===> Epoch[30](2400/2500): Loss: 0.2215
===> Epoch[30](2500/2500): Loss: 0.2090
===> Epoch 30 Complete: Avg. Loss: 0.2180
===> Timestamp: [2025-08-03 17:37:49]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2204
===> Epoch[30](200/2500): Loss: 0.2229
===> Epoch[30](300/2500): Loss: 0.2298
===> Epoch[30](400/2500): Loss: 0.2131
===> Epoch[30](500/2500): Loss: 0.2253
===> Epoch[30](600/2500): Loss: 0.2227
===> Epoch[30](700/2500): Loss: 0.2121
===> Epoch[30](800/2500): Loss: 0.2316
===> Epoch[30](900/2500): Loss: 0.2171
===> Epoch[30](1000/2500): Loss: 0.2346
===> Epoch[30](1100/2500): Loss: 0.2201
===> Epoch[30](1200/2500): Loss: 0.2132
===> Epoch[30](1300/2500): Loss: 0.2126
===> Epoch[30](1400/2500): Loss: 0.2285
===> Epoch[30](1500/2500): Loss: 0.2211
===> Epoch[30](1600/2500): Loss: 0.2122
===> Epoch[30](1700/2500): Loss: 0.2092
===> Epoch[30](1800/2500): Loss: 0.2160
===> Epoch[30](1900/2500): Loss: 0.2083
===> Epoch[30](2000/2500): Loss: 0.2031
===> Epoch[30](2100/2500): Loss: 0.2118
===> Epoch[30](2200/2500): Loss: 0.2123
===> Epoch[30](2300/2500): Loss: 0.2287
===> Epoch[30](2400/2500): Loss: 0.2215
===> Epoch[30](2500/2500): Loss: 0.2090
===> Epoch 30 Complete: Avg. Loss: 0.2180
===> Timestamp: [2025-08-03 17:37:49]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2204
===> Epoch[30](200/2500): Loss: 0.2229
===> Epoch[30](300/2500): Loss: 0.2298
===> Epoch[30](400/2500): Loss: 0.2131
===> Epoch[30](500/2500): Loss: 0.2253
===> Epoch[30](600/2500): Loss: 0.2227
===> Epoch[30](700/2500): Loss: 0.2121
===> Epoch[30](800/2500): Loss: 0.2316
===> Epoch[30](900/2500): Loss: 0.2171
===> Epoch[30](1000/2500): Loss: 0.2346
===> Epoch[30](1100/2500): Loss: 0.2201
===> Epoch[30](1200/2500): Loss: 0.2132
===> Epoch[30](1300/2500): Loss: 0.2126
===> Epoch[30](1400/2500): Loss: 0.2285
===> Epoch[30](1500/2500): Loss: 0.2211
===> Epoch[30](1600/2500): Loss: 0.2122
===> Epoch[30](1700/2500): Loss: 0.2092
===> Epoch[30](1800/2500): Loss: 0.2160
===> Epoch[30](1900/2500): Loss: 0.2083
===> Epoch[30](2000/2500): Loss: 0.2031
===> Epoch[30](2100/2500): Loss: 0.2118
===> Epoch[30](2200/2500): Loss: 0.2123
===> Epoch[30](2300/2500): Loss: 0.2287
===> Epoch[30](2400/2500): Loss: 0.2215
===> Epoch[30](2500/2500): Loss: 0.2090
===> Epoch 30 Complete: Avg. Loss: 0.2180
===> Timestamp: [2025-08-03 17:37:49]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2204
===> Epoch[30](200/2500): Loss: 0.2229
===> Epoch[30](300/2500): Loss: 0.2298
===> Epoch[30](400/2500): Loss: 0.2131
===> Epoch[30](500/2500): Loss: 0.2253
===> Epoch[30](600/2500): Loss: 0.2227
===> Epoch[30](700/2500): Loss: 0.2121
===> Epoch[30](800/2500): Loss: 0.2316
===> Epoch[30](900/2500): Loss: 0.2171
===> Epoch[30](1000/2500): Loss: 0.2346
===> Epoch[30](1100/2500): Loss: 0.2201
===> Epoch[30](1200/2500): Loss: 0.2132
===> Epoch[30](1300/2500): Loss: 0.2126
===> Epoch[30](1400/2500): Loss: 0.2285
===> Epoch[30](1500/2500): Loss: 0.2211
===> Epoch[30](1600/2500): Loss: 0.2122
===> Epoch[30](1700/2500): Loss: 0.2092
===> Epoch[30](1800/2500): Loss: 0.2160
===> Epoch[30](1900/2500): Loss: 0.2083
===> Epoch[30](2000/2500): Loss: 0.2031
===> Epoch[30](2100/2500): Loss: 0.2118
===> Epoch[30](2200/2500): Loss: 0.2123
===> Epoch[30](2300/2500): Loss: 0.2287
===> Epoch[30](2400/2500): Loss: 0.2215
===> Epoch[30](2500/2500): Loss: 0.2090
===> Epoch 30 Complete: Avg. Loss: 0.2180
===> Timestamp: [2025-08-03 17:37:49]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2204
===> Epoch[30](200/2500): Loss: 0.2229
===> Epoch[30](300/2500): Loss: 0.2298
===> Epoch[30](400/2500): Loss: 0.2131
===> Epoch[30](500/2500): Loss: 0.2253
===> Epoch[30](600/2500): Loss: 0.2227
===> Epoch[30](700/2500): Loss: 0.2121
===> Epoch[30](800/2500): Loss: 0.2316
===> Epoch[30](900/2500): Loss: 0.2171
===> Epoch[30](1000/2500): Loss: 0.2346
===> Epoch[30](1100/2500): Loss: 0.2201
===> Epoch[30](1200/2500): Loss: 0.2132
===> Epoch[30](1300/2500): Loss: 0.2126
===> Epoch[30](1400/2500): Loss: 0.2285
===> Epoch[30](1500/2500): Loss: 0.2211
===> Epoch[30](1600/2500): Loss: 0.2122
===> Epoch[30](1700/2500): Loss: 0.2092
===> Epoch[30](1800/2500): Loss: 0.2160
===> Epoch[30](1900/2500): Loss: 0.2083
===> Epoch[30](2000/2500): Loss: 0.2031
===> Epoch[30](2100/2500): Loss: 0.2118
===> Epoch[30](2200/2500): Loss: 0.2123
===> Epoch[30](2300/2500): Loss: 0.2287
===> Epoch[30](2400/2500): Loss: 0.2215
===> Epoch[30](2500/2500): Loss: 0.2090
===> Epoch 30 Complete: Avg. Loss: 0.2180
===> Timestamp: [2025-08-03 17:37:49]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2204
===> Epoch[30](200/2500): Loss: 0.2229
===> Epoch[30](300/2500): Loss: 0.2298
===> Epoch[30](400/2500): Loss: 0.2131
===> Epoch[30](500/2500): Loss: 0.2253
===> Epoch[30](600/2500): Loss: 0.2227
===> Epoch[30](700/2500): Loss: 0.2121
===> Epoch[30](800/2500): Loss: 0.2316
===> Epoch[30](900/2500): Loss: 0.2171
===> Epoch[30](1000/2500): Loss: 0.2346
===> Epoch[30](1100/2500): Loss: 0.2201
===> Epoch[30](1200/2500): Loss: 0.2132
===> Epoch[30](1300/2500): Loss: 0.2126
===> Epoch[30](1400/2500): Loss: 0.2285
===> Epoch[30](1500/2500): Loss: 0.2211
===> Epoch[30](1600/2500): Loss: 0.2122
===> Epoch[30](1700/2500): Loss: 0.2092
===> Epoch[30](1800/2500): Loss: 0.2160
===> Epoch[30](1900/2500): Loss: 0.2083
===> Epoch[30](2000/2500): Loss: 0.2031
===> Epoch[30](2100/2500): Loss: 0.2118
===> Epoch[30](2200/2500): Loss: 0.2123
===> Epoch[30](2300/2500): Loss: 0.2287
===> Epoch[30](2400/2500): Loss: 0.2215
===> Epoch[30](2500/2500): Loss: 0.2090
===> Epoch 30 Complete: Avg. Loss: 0.2180
===> Timestamp: [2025-08-03 17:37:49]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2204
===> Epoch[30](200/2500): Loss: 0.2229
===> Epoch[30](300/2500): Loss: 0.2298
===> Epoch[30](400/2500): Loss: 0.2131
===> Epoch[30](500/2500): Loss: 0.2253
===> Epoch[30](600/2500): Loss: 0.2227
===> Epoch[30](700/2500): Loss: 0.2121
===> Epoch[30](800/2500): Loss: 0.2316
===> Epoch[30](900/2500): Loss: 0.2171
===> Epoch[30](1000/2500): Loss: 0.2346
===> Epoch[30](1100/2500): Loss: 0.2201
===> Epoch[30](1200/2500): Loss: 0.2132
===> Epoch[30](1300/2500): Loss: 0.2126
===> Epoch[30](1400/2500): Loss: 0.2285
===> Epoch[30](1500/2500): Loss: 0.2211
===> Epoch[30](1600/2500): Loss: 0.2122
===> Epoch[30](1700/2500): Loss: 0.2092
===> Epoch[30](1800/2500): Loss: 0.2160
===> Epoch[30](1900/2500): Loss: 0.2083
===> Epoch[30](2000/2500): Loss: 0.2031
===> Epoch[30](2100/2500): Loss: 0.2118
===> Epoch[30](2200/2500): Loss: 0.2123
===> Epoch[30](2300/2500): Loss: 0.2287
===> Epoch[30](2400/2500): Loss: 0.2215
===> Epoch[30](2500/2500): Loss: 0.2090
===> Epoch 30 Complete: Avg. Loss: 0.2180
===> Timestamp: [2025-08-03 17:37:49]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2204
===> Epoch[30](200/2500): Loss: 0.2229
===> Epoch[30](300/2500): Loss: 0.2298
===> Epoch[30](400/2500): Loss: 0.2131
===> Epoch[30](500/2500): Loss: 0.2253
===> Epoch[30](600/2500): Loss: 0.2227
===> Epoch[30](700/2500): Loss: 0.2121
===> Epoch[30](800/2500): Loss: 0.2316
===> Epoch[30](900/2500): Loss: 0.2171
===> Epoch[30](1000/2500): Loss: 0.2346
===> Epoch[30](1100/2500): Loss: 0.2201
===> Epoch[30](1200/2500): Loss: 0.2132
===> Epoch[30](1300/2500): Loss: 0.2126
===> Epoch[30](1400/2500): Loss: 0.2285
===> Epoch[30](1500/2500): Loss: 0.2211
===> Epoch[30](1600/2500): Loss: 0.2122
===> Epoch[30](1700/2500): Loss: 0.2092
===> Epoch[30](1800/2500): Loss: 0.2160
===> Epoch[30](1900/2500): Loss: 0.2083
===> Epoch[30](2000/2500): Loss: 0.2031
===> Epoch[30](2100/2500): Loss: 0.2118
===> Epoch[30](2200/2500): Loss: 0.2123
===> Epoch[30](2300/2500): Loss: 0.2287
===> Epoch[30](2400/2500): Loss: 0.2215
===> Epoch[30](2500/2500): Loss: 0.2090
===> Epoch 30 Complete: Avg. Loss: 0.2180
===> Timestamp: [2025-08-03 17:37:49]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2204
===> Epoch[30](200/2500): Loss: 0.2229
===> Epoch[30](300/2500): Loss: 0.2298
===> Epoch[30](400/2500): Loss: 0.2131
===> Epoch[30](500/2500): Loss: 0.2253
===> Epoch[30](600/2500): Loss: 0.2227
===> Epoch[30](700/2500): Loss: 0.2121
===> Epoch[30](800/2500): Loss: 0.2316
===> Epoch[30](900/2500): Loss: 0.2171
===> Epoch[30](1000/2500): Loss: 0.2346
===> Epoch[30](1100/2500): Loss: 0.2201
===> Epoch[30](1200/2500): Loss: 0.2132
===> Epoch[30](1300/2500): Loss: 0.2126
===> Epoch[30](1400/2500): Loss: 0.2285
===> Epoch[30](1500/2500): Loss: 0.2211
===> Epoch[30](1600/2500): Loss: 0.2122
===> Epoch[30](1700/2500): Loss: 0.2092
===> Epoch[30](1800/2500): Loss: 0.2160
===> Epoch[30](1900/2500): Loss: 0.2083
===> Epoch[30](2000/2500): Loss: 0.2031
===> Epoch[30](2100/2500): Loss: 0.2118
===> Epoch[30](2200/2500): Loss: 0.2123
===> Epoch[30](2300/2500): Loss: 0.2287
===> Epoch[30](2400/2500): Loss: 0.2215
===> Epoch[30](2500/2500): Loss: 0.2090
===> Epoch 30 Complete: Avg. Loss: 0.2180
===> Timestamp: [2025-08-03 17:37:49]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2204
===> Epoch[30](200/2500): Loss: 0.2229
===> Epoch[30](300/2500): Loss: 0.2298
===> Epoch[30](400/2500): Loss: 0.2131
===> Epoch[30](500/2500): Loss: 0.2253
===> Epoch[30](600/2500): Loss: 0.2227
===> Epoch[30](700/2500): Loss: 0.2121
===> Epoch[30](800/2500): Loss: 0.2316
===> Epoch[30](900/2500): Loss: 0.2171
===> Epoch[30](1000/2500): Loss: 0.2346
===> Epoch[30](1100/2500): Loss: 0.2201
===> Epoch[30](1200/2500): Loss: 0.2132
===> Epoch[30](1300/2500): Loss: 0.2126
===> Epoch[30](1400/2500): Loss: 0.2285
===> Epoch[30](1500/2500): Loss: 0.2211
===> Epoch[30](1600/2500): Loss: 0.2122
===> Epoch[30](1700/2500): Loss: 0.2092
===> Epoch[30](1800/2500): Loss: 0.2160
===> Epoch[30](1900/2500): Loss: 0.2083
===> Epoch[30](2000/2500): Loss: 0.2031
===> Epoch[30](2100/2500): Loss: 0.2118
===> Epoch[30](2200/2500): Loss: 0.2123
===> Epoch[30](2300/2500): Loss: 0.2287
===> Epoch[30](2400/2500): Loss: 0.2215
===> Epoch[30](2500/2500): Loss: 0.2090
===> Epoch 30 Complete: Avg. Loss: 0.2180
===> Timestamp: [2025-08-03 17:37:49]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2204
===> Epoch[30](200/2500): Loss: 0.2229
===> Epoch[30](300/2500): Loss: 0.2298
===> Epoch[30](400/2500): Loss: 0.2131
===> Epoch[30](500/2500): Loss: 0.2253
===> Epoch[30](600/2500): Loss: 0.2227
===> Epoch[30](700/2500): Loss: 0.2121
===> Epoch[30](800/2500): Loss: 0.2316
===> Epoch[30](900/2500): Loss: 0.2171
===> Epoch[30](1000/2500): Loss: 0.2346
===> Epoch[30](1100/2500): Loss: 0.2201
===> Epoch[30](1200/2500): Loss: 0.2132
===> Epoch[30](1300/2500): Loss: 0.2126
===> Epoch[30](1400/2500): Loss: 0.2285
===> Epoch[30](1500/2500): Loss: 0.2211
===> Epoch[30](1600/2500): Loss: 0.2122
===> Epoch[30](1700/2500): Loss: 0.2092
===> Epoch[30](1800/2500): Loss: 0.2160
===> Epoch[30](1900/2500): Loss: 0.2083
===> Epoch[30](2000/2500): Loss: 0.2031
===> Epoch[30](2100/2500): Loss: 0.2118
===> Epoch[30](2200/2500): Loss: 0.2123
===> Epoch[30](2300/2500): Loss: 0.2287
===> Epoch[30](2400/2500): Loss: 0.2215
===> Epoch[30](2500/2500): Loss: 0.2090
===> Epoch 30 Complete: Avg. Loss: 0.2180
===> Timestamp: [2025-08-03 17:37:49]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2204
===> Epoch[30](200/2500): Loss: 0.2229
===> Epoch[30](300/2500): Loss: 0.2298
===> Epoch[30](400/2500): Loss: 0.2131
===> Epoch[30](500/2500): Loss: 0.2253
===> Epoch[30](600/2500): Loss: 0.2227
===> Epoch[30](700/2500): Loss: 0.2121
===> Epoch[30](800/2500): Loss: 0.2316
===> Epoch[30](900/2500): Loss: 0.2171
===> Epoch[30](1000/2500): Loss: 0.2346
===> Epoch[30](1100/2500): Loss: 0.2201
===> Epoch[30](1200/2500): Loss: 0.2132
===> Epoch[30](1300/2500): Loss: 0.2126
===> Epoch[30](1400/2500): Loss: 0.2285
===> Epoch[30](1500/2500): Loss: 0.2211
===> Epoch[30](1600/2500): Loss: 0.2122
===> Epoch[30](1700/2500): Loss: 0.2092
===> Epoch[30](1800/2500): Loss: 0.2160
===> Epoch[30](1900/2500): Loss: 0.2083
===> Epoch[30](2000/2500): Loss: 0.2031
===> Epoch[30](2100/2500): Loss: 0.2118
===> Epoch[30](2200/2500): Loss: 0.2123
===> Epoch[30](2300/2500): Loss: 0.2287
===> Epoch[30](2400/2500): Loss: 0.2215
===> Epoch[30](2500/2500): Loss: 0.2090
===> Epoch 30 Complete: Avg. Loss: 0.2180
===> Timestamp: [2025-08-03 17:37:49]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2204
===> Epoch[30](200/2500): Loss: 0.2229
===> Epoch[30](300/2500): Loss: 0.2298
===> Epoch[30](400/2500): Loss: 0.2131
===> Epoch[30](500/2500): Loss: 0.2253
===> Epoch[30](600/2500): Loss: 0.2227
===> Epoch[30](700/2500): Loss: 0.2121
===> Epoch[30](800/2500): Loss: 0.2316
===> Epoch[30](900/2500): Loss: 0.2171
===> Epoch[30](1000/2500): Loss: 0.2346
===> Epoch[30](1100/2500): Loss: 0.2201
===> Epoch[30](1200/2500): Loss: 0.2132
===> Epoch[30](1300/2500): Loss: 0.2126
===> Epoch[30](1400/2500): Loss: 0.2285
===> Epoch[30](1500/2500): Loss: 0.2211
===> Epoch[30](1600/2500): Loss: 0.2122
===> Epoch[30](1700/2500): Loss: 0.2092
===> Epoch[30](1800/2500): Loss: 0.2160
===> Epoch[30](1900/2500): Loss: 0.2083
===> Epoch[30](2000/2500): Loss: 0.2031
===> Epoch[30](2100/2500): Loss: 0.2118
===> Epoch[30](2200/2500): Loss: 0.2123
===> Epoch[30](2300/2500): Loss: 0.2287
===> Epoch[30](2400/2500): Loss: 0.2215
===> Epoch[30](2500/2500): Loss: 0.2090
===> Epoch 30 Complete: Avg. Loss: 0.2180
===> Timestamp: [2025-08-03 17:37:49]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2204
===> Epoch[30](200/2500): Loss: 0.2229
===> Epoch[30](300/2500): Loss: 0.2298
===> Epoch[30](400/2500): Loss: 0.2131
===> Epoch[30](500/2500): Loss: 0.2253
===> Epoch[30](600/2500): Loss: 0.2227
===> Epoch[30](700/2500): Loss: 0.2121
===> Epoch[30](800/2500): Loss: 0.2316
===> Epoch[30](900/2500): Loss: 0.2171
===> Epoch[30](1000/2500): Loss: 0.2346
===> Epoch[30](1100/2500): Loss: 0.2201
===> Epoch[30](1200/2500): Loss: 0.2132
===> Epoch[30](1300/2500): Loss: 0.2126
===> Epoch[30](1400/2500): Loss: 0.2285
===> Epoch[30](1500/2500): Loss: 0.2211
===> Epoch[30](1600/2500): Loss: 0.2122
===> Epoch[30](1700/2500): Loss: 0.2092
===> Epoch[30](1800/2500): Loss: 0.2160
===> Epoch[30](1900/2500): Loss: 0.2083
===> Epoch[30](2000/2500): Loss: 0.2031
===> Epoch[30](2100/2500): Loss: 0.2118
===> Epoch[30](2200/2500): Loss: 0.2123
===> Epoch[30](2300/2500): Loss: 0.2287
===> Epoch[30](2400/2500): Loss: 0.2215
===> Epoch[30](2500/2500): Loss: 0.2090
===> Epoch 30 Complete: Avg. Loss: 0.2180
===> Timestamp: [2025-08-03 17:37:49]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2204
===> Epoch[30](200/2500): Loss: 0.2229
===> Epoch[30](300/2500): Loss: 0.2298
===> Epoch[30](400/2500): Loss: 0.2131
===> Epoch[30](500/2500): Loss: 0.2253
===> Epoch[30](600/2500): Loss: 0.2227
===> Epoch[30](700/2500): Loss: 0.2121
===> Epoch[30](800/2500): Loss: 0.2316
===> Epoch[30](900/2500): Loss: 0.2171
===> Epoch[30](1000/2500): Loss: 0.2346
===> Epoch[30](1100/2500): Loss: 0.2201
===> Epoch[30](1200/2500): Loss: 0.2132
===> Epoch[30](1300/2500): Loss: 0.2126
===> Epoch[30](1400/2500): Loss: 0.2285
===> Epoch[30](1500/2500): Loss: 0.2211
===> Epoch[30](1600/2500): Loss: 0.2122
===> Epoch[30](1700/2500): Loss: 0.2092
===> Epoch[30](1800/2500): Loss: 0.2160
===> Epoch[30](1900/2500): Loss: 0.2083
===> Epoch[30](2000/2500): Loss: 0.2031
===> Epoch[30](2100/2500): Loss: 0.2118
===> Epoch[30](2200/2500): Loss: 0.2123
===> Epoch[30](2300/2500): Loss: 0.2287
===> Epoch[30](2400/2500): Loss: 0.2215
===> Epoch[30](2500/2500): Loss: 0.2090
===> Epoch 30 Complete: Avg. Loss: 0.2180
===> Timestamp: [2025-08-03 17:37:49]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2204
===> Epoch[30](200/2500): Loss: 0.2229
===> Epoch[30](300/2500): Loss: 0.2298
===> Epoch[30](400/2500): Loss: 0.2131
===> Epoch[30](500/2500): Loss: 0.2253
===> Epoch[30](600/2500): Loss: 0.2227
===> Epoch[30](700/2500): Loss: 0.2121
===> Epoch[30](800/2500): Loss: 0.2316
===> Epoch[30](900/2500): Loss: 0.2171
===> Epoch[30](1000/2500): Loss: 0.2346
===> Epoch[30](1100/2500): Loss: 0.2201
===> Epoch[30](1200/2500): Loss: 0.2132
===> Epoch[30](1300/2500): Loss: 0.2126
===> Epoch[30](1400/2500): Loss: 0.2285
===> Epoch[30](1500/2500): Loss: 0.2211
===> Epoch[30](1600/2500): Loss: 0.2122
===> Epoch[30](1700/2500): Loss: 0.2092
===> Epoch[30](1800/2500): Loss: 0.2160
===> Epoch[30](1900/2500): Loss: 0.2083
===> Epoch[30](2000/2500): Loss: 0.2031
===> Epoch[30](2100/2500): Loss: 0.2118
===> Epoch[30](2200/2500): Loss: 0.2123
===> Epoch[30](2300/2500): Loss: 0.2287
===> Epoch[30](2400/2500): Loss: 0.2215
===> Epoch[30](2500/2500): Loss: 0.2090
===> Epoch 30 Complete: Avg. Loss: 0.2180
===> Timestamp: [2025-08-03 17:37:49]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2204
===> Epoch[30](200/2500): Loss: 0.2229
===> Epoch[30](300/2500): Loss: 0.2298
===> Epoch[30](400/2500): Loss: 0.2131
===> Epoch[30](500/2500): Loss: 0.2253
===> Epoch[30](600/2500): Loss: 0.2227
===> Epoch[30](700/2500): Loss: 0.2121
===> Epoch[30](800/2500): Loss: 0.2316
===> Epoch[30](900/2500): Loss: 0.2171
===> Epoch[30](1000/2500): Loss: 0.2346
===> Epoch[30](1100/2500): Loss: 0.2201
===> Epoch[30](1200/2500): Loss: 0.2132
===> Epoch[30](1300/2500): Loss: 0.2126
===> Epoch[30](1400/2500): Loss: 0.2285
===> Epoch[30](1500/2500): Loss: 0.2211
===> Epoch[30](1600/2500): Loss: 0.2122
===> Epoch[30](1700/2500): Loss: 0.2092
===> Epoch[30](1800/2500): Loss: 0.2160
===> Epoch[30](1900/2500): Loss: 0.2083
===> Epoch[30](2000/2500): Loss: 0.2031
===> Epoch[30](2100/2500): Loss: 0.2118
===> Epoch[30](2200/2500): Loss: 0.2123
===> Epoch[30](2300/2500): Loss: 0.2287
===> Epoch[30](2400/2500): Loss: 0.2215
===> Epoch[30](2500/2500): Loss: 0.2090
===> Epoch 30 Complete: Avg. Loss: 0.2180
===> Timestamp: [2025-08-03 17:37:49]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2204
===> Epoch[30](200/2500): Loss: 0.2229
===> Epoch[30](300/2500): Loss: 0.2298
===> Epoch[30](400/2500): Loss: 0.2131
===> Epoch[30](500/2500): Loss: 0.2253
===> Epoch[30](600/2500): Loss: 0.2227
===> Epoch[30](700/2500): Loss: 0.2121
===> Epoch[30](800/2500): Loss: 0.2316
===> Epoch[30](900/2500): Loss: 0.2171
===> Epoch[30](1000/2500): Loss: 0.2346
===> Epoch[30](1100/2500): Loss: 0.2201
===> Epoch[30](1200/2500): Loss: 0.2132
===> Epoch[30](1300/2500): Loss: 0.2126
===> Epoch[30](1400/2500): Loss: 0.2285
===> Epoch[30](1500/2500): Loss: 0.2211
===> Epoch[30](1600/2500): Loss: 0.2122
===> Epoch[30](1700/2500): Loss: 0.2092
===> Epoch[30](1800/2500): Loss: 0.2160
===> Epoch[30](1900/2500): Loss: 0.2083
===> Epoch[30](2000/2500): Loss: 0.2031
===> Epoch[30](2100/2500): Loss: 0.2118
===> Epoch[30](2200/2500): Loss: 0.2123
===> Epoch[30](2300/2500): Loss: 0.2287
===> Epoch[30](2400/2500): Loss: 0.2215
===> Epoch[30](2500/2500): Loss: 0.2090
===> Epoch 30 Complete: Avg. Loss: 0.2180
===> Timestamp: [2025-08-03 17:37:49]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2204
===> Epoch[30](200/2500): Loss: 0.2229
===> Epoch[30](300/2500): Loss: 0.2298
===> Epoch[30](400/2500): Loss: 0.2131
===> Epoch[30](500/2500): Loss: 0.2253
===> Epoch[30](600/2500): Loss: 0.2227
===> Epoch[30](700/2500): Loss: 0.2121
===> Epoch[30](800/2500): Loss: 0.2316
===> Epoch[30](900/2500): Loss: 0.2171
===> Epoch[30](1000/2500): Loss: 0.2346
===> Epoch[30](1100/2500): Loss: 0.2201
===> Epoch[30](1200/2500): Loss: 0.2132
===> Epoch[30](1300/2500): Loss: 0.2126
===> Epoch[30](1400/2500): Loss: 0.2285
===> Epoch[30](1500/2500): Loss: 0.2211
===> Epoch[30](1600/2500): Loss: 0.2122
===> Epoch[30](1700/2500): Loss: 0.2092
===> Epoch[30](1800/2500): Loss: 0.2160
===> Epoch[30](1900/2500): Loss: 0.2083
===> Epoch[30](2000/2500): Loss: 0.2031
===> Epoch[30](2100/2500): Loss: 0.2118
===> Epoch[30](2200/2500): Loss: 0.2123
===> Epoch[30](2300/2500): Loss: 0.2287
===> Epoch[30](2400/2500): Loss: 0.2215
===> Epoch[30](2500/2500): Loss: 0.2090
===> Epoch 30 Complete: Avg. Loss: 0.2180
===> Timestamp: [2025-08-03 17:37:49]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2204
===> Epoch[30](200/2500): Loss: 0.2229
===> Epoch[30](300/2500): Loss: 0.2298
===> Epoch[30](400/2500): Loss: 0.2131
===> Epoch[30](500/2500): Loss: 0.2253
===> Epoch[30](600/2500): Loss: 0.2227
===> Epoch[30](700/2500): Loss: 0.2121
===> Epoch[30](800/2500): Loss: 0.2316
===> Epoch[30](900/2500): Loss: 0.2171
===> Epoch[30](1000/2500): Loss: 0.2346
===> Epoch[30](1100/2500): Loss: 0.2201
===> Epoch[30](1200/2500): Loss: 0.2132
===> Epoch[30](1300/2500): Loss: 0.2126
===> Epoch[30](1400/2500): Loss: 0.2285
===> Epoch[30](1500/2500): Loss: 0.2211
===> Epoch[30](1600/2500): Loss: 0.2122
===> Epoch[30](1700/2500): Loss: 0.2092
===> Epoch[30](1800/2500): Loss: 0.2160
===> Epoch[30](1900/2500): Loss: 0.2083
===> Epoch[30](2000/2500): Loss: 0.2031
===> Epoch[30](2100/2500): Loss: 0.2118
===> Epoch[30](2200/2500): Loss: 0.2123
===> Epoch[30](2300/2500): Loss: 0.2287
===> Epoch[30](2400/2500): Loss: 0.2215
===> Epoch[30](2500/2500): Loss: 0.2090
===> Epoch 30 Complete: Avg. Loss: 0.2180
===> Timestamp: [2025-08-03 17:37:49]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2204
===> Epoch[30](200/2500): Loss: 0.2229
===> Epoch[30](300/2500): Loss: 0.2298
===> Epoch[30](400/2500): Loss: 0.2131
===> Epoch[30](500/2500): Loss: 0.2253
===> Epoch[30](600/2500): Loss: 0.2227
===> Epoch[30](700/2500): Loss: 0.2121
===> Epoch[30](800/2500): Loss: 0.2316
===> Epoch[30](900/2500): Loss: 0.2171
===> Epoch[30](1000/2500): Loss: 0.2346
===> Epoch[30](1100/2500): Loss: 0.2201
===> Epoch[30](1200/2500): Loss: 0.2132
===> Epoch[30](1300/2500): Loss: 0.2126
===> Epoch[30](1400/2500): Loss: 0.2285
===> Epoch[30](1500/2500): Loss: 0.2211
===> Epoch[30](1600/2500): Loss: 0.2122
===> Epoch[30](1700/2500): Loss: 0.2092
===> Epoch[30](1800/2500): Loss: 0.2160
===> Epoch[30](1900/2500): Loss: 0.2083
===> Epoch[30](2000/2500): Loss: 0.2031
===> Epoch[30](2100/2500): Loss: 0.2118
===> Epoch[30](2200/2500): Loss: 0.2123
===> Epoch[30](2300/2500): Loss: 0.2287
===> Epoch[30](2400/2500): Loss: 0.2215
===> Epoch[30](2500/2500): Loss: 0.2090
===> Epoch 30 Complete: Avg. Loss: 0.2180
===> Timestamp: [2025-08-03 17:37:49]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2204
===> Epoch[30](200/2500): Loss: 0.2229
===> Epoch[30](300/2500): Loss: 0.2298
===> Epoch[30](400/2500): Loss: 0.2131
===> Epoch[30](500/2500): Loss: 0.2253
===> Epoch[30](600/2500): Loss: 0.2227
===> Epoch[30](700/2500): Loss: 0.2121
===> Epoch[30](800/2500): Loss: 0.2316
===> Epoch[30](900/2500): Loss: 0.2171
===> Epoch[30](1000/2500): Loss: 0.2346
===> Epoch[30](1100/2500): Loss: 0.2201
===> Epoch[30](1200/2500): Loss: 0.2132
===> Epoch[30](1300/2500): Loss: 0.2126
===> Epoch[30](1400/2500): Loss: 0.2285
===> Epoch[30](1500/2500): Loss: 0.2211
===> Epoch[30](1600/2500): Loss: 0.2122
===> Epoch[30](1700/2500): Loss: 0.2092
===> Epoch[30](1800/2500): Loss: 0.2160
===> Epoch[30](1900/2500): Loss: 0.2083
===> Epoch[30](2000/2500): Loss: 0.2031
===> Epoch[30](2100/2500): Loss: 0.2118
===> Epoch[30](2200/2500): Loss: 0.2123
===> Epoch[30](2300/2500): Loss: 0.2287
===> Epoch[30](2400/2500): Loss: 0.2215
===> Epoch[30](2500/2500): Loss: 0.2090
===> Epoch 30 Complete: Avg. Loss: 0.2180
===> Timestamp: [2025-08-03 17:37:49]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2070
===> Epoch[31](200/2500): Loss: 0.2323
===> Epoch[31](300/2500): Loss: 0.2235
===> Epoch[31](400/2500): Loss: 0.2296
===> Epoch[31](500/2500): Loss: 0.2323
===> Epoch[31](600/2500): Loss: 0.2044
===> Epoch[31](700/2500): Loss: 0.2167
===> Epoch[31](800/2500): Loss: 0.2251
===> Epoch[31](900/2500): Loss: 0.2116
===> Epoch[31](1000/2500): Loss: 0.2123
===> Epoch[31](1100/2500): Loss: 0.2296
===> Epoch[31](1200/2500): Loss: 0.2096
===> Epoch[31](1300/2500): Loss: 0.2110
===> Epoch[31](1400/2500): Loss: 0.2102
===> Epoch[31](1500/2500): Loss: 0.1993
===> Epoch[31](1600/2500): Loss: 0.2071
===> Epoch[31](1700/2500): Loss: 0.2047
===> Epoch[31](1800/2500): Loss: 0.2126
===> Epoch[31](1900/2500): Loss: 0.2288
===> Epoch[31](2000/2500): Loss: 0.2008
===> Epoch[31](2100/2500): Loss: 0.2227
===> Epoch[31](2200/2500): Loss: 0.2010
===> Epoch[31](2300/2500): Loss: 0.2071
===> Epoch[31](2400/2500): Loss: 0.2131
===> Epoch[31](2500/2500): Loss: 0.2038
===> Epoch 31 Complete: Avg. Loss: 0.2157
===> Timestamp: [2025-08-03 17:42:23]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2070
===> Epoch[31](200/2500): Loss: 0.2323
===> Epoch[31](300/2500): Loss: 0.2235
===> Epoch[31](400/2500): Loss: 0.2296
===> Epoch[31](500/2500): Loss: 0.2323
===> Epoch[31](600/2500): Loss: 0.2044
===> Epoch[31](700/2500): Loss: 0.2167
===> Epoch[31](800/2500): Loss: 0.2251
===> Epoch[31](900/2500): Loss: 0.2116
===> Epoch[31](1000/2500): Loss: 0.2123
===> Epoch[31](1100/2500): Loss: 0.2296
===> Epoch[31](1200/2500): Loss: 0.2096
===> Epoch[31](1300/2500): Loss: 0.2110
===> Epoch[31](1400/2500): Loss: 0.2102
===> Epoch[31](1500/2500): Loss: 0.1993
===> Epoch[31](1600/2500): Loss: 0.2071
===> Epoch[31](1700/2500): Loss: 0.2047
===> Epoch[31](1800/2500): Loss: 0.2126
===> Epoch[31](1900/2500): Loss: 0.2288
===> Epoch[31](2000/2500): Loss: 0.2008
===> Epoch[31](2100/2500): Loss: 0.2227
===> Epoch[31](2200/2500): Loss: 0.2010
===> Epoch[31](2300/2500): Loss: 0.2071
===> Epoch[31](2400/2500): Loss: 0.2131
===> Epoch[31](2500/2500): Loss: 0.2038
===> Epoch 31 Complete: Avg. Loss: 0.2157
===> Timestamp: [2025-08-03 17:42:23]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2070
===> Epoch[31](200/2500): Loss: 0.2323
===> Epoch[31](300/2500): Loss: 0.2235
===> Epoch[31](400/2500): Loss: 0.2296
===> Epoch[31](500/2500): Loss: 0.2323
===> Epoch[31](600/2500): Loss: 0.2044
===> Epoch[31](700/2500): Loss: 0.2167
===> Epoch[31](800/2500): Loss: 0.2251
===> Epoch[31](900/2500): Loss: 0.2116
===> Epoch[31](1000/2500): Loss: 0.2123
===> Epoch[31](1100/2500): Loss: 0.2296
===> Epoch[31](1200/2500): Loss: 0.2096
===> Epoch[31](1300/2500): Loss: 0.2110
===> Epoch[31](1400/2500): Loss: 0.2102
===> Epoch[31](1500/2500): Loss: 0.1993
===> Epoch[31](1600/2500): Loss: 0.2071
===> Epoch[31](1700/2500): Loss: 0.2047
===> Epoch[31](1800/2500): Loss: 0.2126
===> Epoch[31](1900/2500): Loss: 0.2288
===> Epoch[31](2000/2500): Loss: 0.2008
===> Epoch[31](2100/2500): Loss: 0.2227
===> Epoch[31](2200/2500): Loss: 0.2010
===> Epoch[31](2300/2500): Loss: 0.2071
===> Epoch[31](2400/2500): Loss: 0.2131
===> Epoch[31](2500/2500): Loss: 0.2038
===> Epoch 31 Complete: Avg. Loss: 0.2157
===> Timestamp: [2025-08-03 17:42:23]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2070
===> Epoch[31](200/2500): Loss: 0.2323
===> Epoch[31](300/2500): Loss: 0.2235
===> Epoch[31](400/2500): Loss: 0.2296
===> Epoch[31](500/2500): Loss: 0.2323
===> Epoch[31](600/2500): Loss: 0.2044
===> Epoch[31](700/2500): Loss: 0.2167
===> Epoch[31](800/2500): Loss: 0.2251
===> Epoch[31](900/2500): Loss: 0.2116
===> Epoch[31](1000/2500): Loss: 0.2123
===> Epoch[31](1100/2500): Loss: 0.2296
===> Epoch[31](1200/2500): Loss: 0.2096
===> Epoch[31](1300/2500): Loss: 0.2110
===> Epoch[31](1400/2500): Loss: 0.2102
===> Epoch[31](1500/2500): Loss: 0.1993
===> Epoch[31](1600/2500): Loss: 0.2071
===> Epoch[31](1700/2500): Loss: 0.2047
===> Epoch[31](1800/2500): Loss: 0.2126
===> Epoch[31](1900/2500): Loss: 0.2288
===> Epoch[31](2000/2500): Loss: 0.2008
===> Epoch[31](2100/2500): Loss: 0.2227
===> Epoch[31](2200/2500): Loss: 0.2010
===> Epoch[31](2300/2500): Loss: 0.2071
===> Epoch[31](2400/2500): Loss: 0.2131
===> Epoch[31](2500/2500): Loss: 0.2038
===> Epoch 31 Complete: Avg. Loss: 0.2157
===> Timestamp: [2025-08-03 17:42:23]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2070
===> Epoch[31](200/2500): Loss: 0.2323
===> Epoch[31](300/2500): Loss: 0.2235
===> Epoch[31](400/2500): Loss: 0.2296
===> Epoch[31](500/2500): Loss: 0.2323
===> Epoch[31](600/2500): Loss: 0.2044
===> Epoch[31](700/2500): Loss: 0.2167
===> Epoch[31](800/2500): Loss: 0.2251
===> Epoch[31](900/2500): Loss: 0.2116
===> Epoch[31](1000/2500): Loss: 0.2123
===> Epoch[31](1100/2500): Loss: 0.2296
===> Epoch[31](1200/2500): Loss: 0.2096
===> Epoch[31](1300/2500): Loss: 0.2110
===> Epoch[31](1400/2500): Loss: 0.2102
===> Epoch[31](1500/2500): Loss: 0.1993
===> Epoch[31](1600/2500): Loss: 0.2071
===> Epoch[31](1700/2500): Loss: 0.2047
===> Epoch[31](1800/2500): Loss: 0.2126
===> Epoch[31](1900/2500): Loss: 0.2288
===> Epoch[31](2000/2500): Loss: 0.2008
===> Epoch[31](2100/2500): Loss: 0.2227
===> Epoch[31](2200/2500): Loss: 0.2010
===> Epoch[31](2300/2500): Loss: 0.2071
===> Epoch[31](2400/2500): Loss: 0.2131
===> Epoch[31](2500/2500): Loss: 0.2038
===> Epoch 31 Complete: Avg. Loss: 0.2157
===> Timestamp: [2025-08-03 17:42:23]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2070
===> Epoch[31](200/2500): Loss: 0.2323
===> Epoch[31](300/2500): Loss: 0.2235
===> Epoch[31](400/2500): Loss: 0.2296
===> Epoch[31](500/2500): Loss: 0.2323
===> Epoch[31](600/2500): Loss: 0.2044
===> Epoch[31](700/2500): Loss: 0.2167
===> Epoch[31](800/2500): Loss: 0.2251
===> Epoch[31](900/2500): Loss: 0.2116
===> Epoch[31](1000/2500): Loss: 0.2123
===> Epoch[31](1100/2500): Loss: 0.2296
===> Epoch[31](1200/2500): Loss: 0.2096
===> Epoch[31](1300/2500): Loss: 0.2110
===> Epoch[31](1400/2500): Loss: 0.2102
===> Epoch[31](1500/2500): Loss: 0.1993
===> Epoch[31](1600/2500): Loss: 0.2071
===> Epoch[31](1700/2500): Loss: 0.2047
===> Epoch[31](1800/2500): Loss: 0.2126
===> Epoch[31](1900/2500): Loss: 0.2288
===> Epoch[31](2000/2500): Loss: 0.2008
===> Epoch[31](2100/2500): Loss: 0.2227
===> Epoch[31](2200/2500): Loss: 0.2010
===> Epoch[31](2300/2500): Loss: 0.2071
===> Epoch[31](2400/2500): Loss: 0.2131
===> Epoch[31](2500/2500): Loss: 0.2038
===> Epoch 31 Complete: Avg. Loss: 0.2157
===> Timestamp: [2025-08-03 17:42:23]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2070
===> Epoch[31](200/2500): Loss: 0.2323
===> Epoch[31](300/2500): Loss: 0.2235
===> Epoch[31](400/2500): Loss: 0.2296
===> Epoch[31](500/2500): Loss: 0.2323
===> Epoch[31](600/2500): Loss: 0.2044
===> Epoch[31](700/2500): Loss: 0.2167
===> Epoch[31](800/2500): Loss: 0.2251
===> Epoch[31](900/2500): Loss: 0.2116
===> Epoch[31](1000/2500): Loss: 0.2123
===> Epoch[31](1100/2500): Loss: 0.2296
===> Epoch[31](1200/2500): Loss: 0.2096
===> Epoch[31](1300/2500): Loss: 0.2110
===> Epoch[31](1400/2500): Loss: 0.2102
===> Epoch[31](1500/2500): Loss: 0.1993
===> Epoch[31](1600/2500): Loss: 0.2071
===> Epoch[31](1700/2500): Loss: 0.2047
===> Epoch[31](1800/2500): Loss: 0.2126
===> Epoch[31](1900/2500): Loss: 0.2288
===> Epoch[31](2000/2500): Loss: 0.2008
===> Epoch[31](2100/2500): Loss: 0.2227
===> Epoch[31](2200/2500): Loss: 0.2010
===> Epoch[31](2300/2500): Loss: 0.2071
===> Epoch[31](2400/2500): Loss: 0.2131
===> Epoch[31](2500/2500): Loss: 0.2038
===> Epoch 31 Complete: Avg. Loss: 0.2157
===> Timestamp: [2025-08-03 17:42:23]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2070
===> Epoch[31](200/2500): Loss: 0.2323
===> Epoch[31](300/2500): Loss: 0.2235
===> Epoch[31](400/2500): Loss: 0.2296
===> Epoch[31](500/2500): Loss: 0.2323
===> Epoch[31](600/2500): Loss: 0.2044
===> Epoch[31](700/2500): Loss: 0.2167
===> Epoch[31](800/2500): Loss: 0.2251
===> Epoch[31](900/2500): Loss: 0.2116
===> Epoch[31](1000/2500): Loss: 0.2123
===> Epoch[31](1100/2500): Loss: 0.2296
===> Epoch[31](1200/2500): Loss: 0.2096
===> Epoch[31](1300/2500): Loss: 0.2110
===> Epoch[31](1400/2500): Loss: 0.2102
===> Epoch[31](1500/2500): Loss: 0.1993
===> Epoch[31](1600/2500): Loss: 0.2071
===> Epoch[31](1700/2500): Loss: 0.2047
===> Epoch[31](1800/2500): Loss: 0.2126
===> Epoch[31](1900/2500): Loss: 0.2288
===> Epoch[31](2000/2500): Loss: 0.2008
===> Epoch[31](2100/2500): Loss: 0.2227
===> Epoch[31](2200/2500): Loss: 0.2010
===> Epoch[31](2300/2500): Loss: 0.2071
===> Epoch[31](2400/2500): Loss: 0.2131
===> Epoch[31](2500/2500): Loss: 0.2038
===> Epoch 31 Complete: Avg. Loss: 0.2157
===> Timestamp: [2025-08-03 17:42:23]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2070
===> Epoch[31](200/2500): Loss: 0.2323
===> Epoch[31](300/2500): Loss: 0.2235
===> Epoch[31](400/2500): Loss: 0.2296
===> Epoch[31](500/2500): Loss: 0.2323
===> Epoch[31](600/2500): Loss: 0.2044
===> Epoch[31](700/2500): Loss: 0.2167
===> Epoch[31](800/2500): Loss: 0.2251
===> Epoch[31](900/2500): Loss: 0.2116
===> Epoch[31](1000/2500): Loss: 0.2123
===> Epoch[31](1100/2500): Loss: 0.2296
===> Epoch[31](1200/2500): Loss: 0.2096
===> Epoch[31](1300/2500): Loss: 0.2110
===> Epoch[31](1400/2500): Loss: 0.2102
===> Epoch[31](1500/2500): Loss: 0.1993
===> Epoch[31](1600/2500): Loss: 0.2071
===> Epoch[31](1700/2500): Loss: 0.2047
===> Epoch[31](1800/2500): Loss: 0.2126
===> Epoch[31](1900/2500): Loss: 0.2288
===> Epoch[31](2000/2500): Loss: 0.2008
===> Epoch[31](2100/2500): Loss: 0.2227
===> Epoch[31](2200/2500): Loss: 0.2010
===> Epoch[31](2300/2500): Loss: 0.2071
===> Epoch[31](2400/2500): Loss: 0.2131
===> Epoch[31](2500/2500): Loss: 0.2038
===> Epoch 31 Complete: Avg. Loss: 0.2157
===> Timestamp: [2025-08-03 17:42:23]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2070
===> Epoch[31](200/2500): Loss: 0.2323
===> Epoch[31](300/2500): Loss: 0.2235
===> Epoch[31](400/2500): Loss: 0.2296
===> Epoch[31](500/2500): Loss: 0.2323
===> Epoch[31](600/2500): Loss: 0.2044
===> Epoch[31](700/2500): Loss: 0.2167
===> Epoch[31](800/2500): Loss: 0.2251
===> Epoch[31](900/2500): Loss: 0.2116
===> Epoch[31](1000/2500): Loss: 0.2123
===> Epoch[31](1100/2500): Loss: 0.2296
===> Epoch[31](1200/2500): Loss: 0.2096
===> Epoch[31](1300/2500): Loss: 0.2110
===> Epoch[31](1400/2500): Loss: 0.2102
===> Epoch[31](1500/2500): Loss: 0.1993
===> Epoch[31](1600/2500): Loss: 0.2071
===> Epoch[31](1700/2500): Loss: 0.2047
===> Epoch[31](1800/2500): Loss: 0.2126
===> Epoch[31](1900/2500): Loss: 0.2288
===> Epoch[31](2000/2500): Loss: 0.2008
===> Epoch[31](2100/2500): Loss: 0.2227
===> Epoch[31](2200/2500): Loss: 0.2010
===> Epoch[31](2300/2500): Loss: 0.2071
===> Epoch[31](2400/2500): Loss: 0.2131
===> Epoch[31](2500/2500): Loss: 0.2038
===> Epoch 31 Complete: Avg. Loss: 0.2157
===> Timestamp: [2025-08-03 17:42:23]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2070
===> Epoch[31](200/2500): Loss: 0.2323
===> Epoch[31](300/2500): Loss: 0.2235
===> Epoch[31](400/2500): Loss: 0.2296
===> Epoch[31](500/2500): Loss: 0.2323
===> Epoch[31](600/2500): Loss: 0.2044
===> Epoch[31](700/2500): Loss: 0.2167
===> Epoch[31](800/2500): Loss: 0.2251
===> Epoch[31](900/2500): Loss: 0.2116
===> Epoch[31](1000/2500): Loss: 0.2123
===> Epoch[31](1100/2500): Loss: 0.2296
===> Epoch[31](1200/2500): Loss: 0.2096
===> Epoch[31](1300/2500): Loss: 0.2110
===> Epoch[31](1400/2500): Loss: 0.2102
===> Epoch[31](1500/2500): Loss: 0.1993
===> Epoch[31](1600/2500): Loss: 0.2071
===> Epoch[31](1700/2500): Loss: 0.2047
===> Epoch[31](1800/2500): Loss: 0.2126
===> Epoch[31](1900/2500): Loss: 0.2288
===> Epoch[31](2000/2500): Loss: 0.2008
===> Epoch[31](2100/2500): Loss: 0.2227
===> Epoch[31](2200/2500): Loss: 0.2010
===> Epoch[31](2300/2500): Loss: 0.2071
===> Epoch[31](2400/2500): Loss: 0.2131
===> Epoch[31](2500/2500): Loss: 0.2038
===> Epoch 31 Complete: Avg. Loss: 0.2157
===> Timestamp: [2025-08-03 17:42:23]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2070
===> Epoch[31](200/2500): Loss: 0.2323
===> Epoch[31](300/2500): Loss: 0.2235
===> Epoch[31](400/2500): Loss: 0.2296
===> Epoch[31](500/2500): Loss: 0.2323
===> Epoch[31](600/2500): Loss: 0.2044
===> Epoch[31](700/2500): Loss: 0.2167
===> Epoch[31](800/2500): Loss: 0.2251
===> Epoch[31](900/2500): Loss: 0.2116
===> Epoch[31](1000/2500): Loss: 0.2123
===> Epoch[31](1100/2500): Loss: 0.2296
===> Epoch[31](1200/2500): Loss: 0.2096
===> Epoch[31](1300/2500): Loss: 0.2110
===> Epoch[31](1400/2500): Loss: 0.2102
===> Epoch[31](1500/2500): Loss: 0.1993
===> Epoch[31](1600/2500): Loss: 0.2071
===> Epoch[31](1700/2500): Loss: 0.2047
===> Epoch[31](1800/2500): Loss: 0.2126
===> Epoch[31](1900/2500): Loss: 0.2288
===> Epoch[31](2000/2500): Loss: 0.2008
===> Epoch[31](2100/2500): Loss: 0.2227
===> Epoch[31](2200/2500): Loss: 0.2010
===> Epoch[31](2300/2500): Loss: 0.2071
===> Epoch[31](2400/2500): Loss: 0.2131
===> Epoch[31](2500/2500): Loss: 0.2038
===> Epoch 31 Complete: Avg. Loss: 0.2157
===> Timestamp: [2025-08-03 17:42:23]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2070
===> Epoch[31](200/2500): Loss: 0.2323
===> Epoch[31](300/2500): Loss: 0.2235
===> Epoch[31](400/2500): Loss: 0.2296
===> Epoch[31](500/2500): Loss: 0.2323
===> Epoch[31](600/2500): Loss: 0.2044
===> Epoch[31](700/2500): Loss: 0.2167
===> Epoch[31](800/2500): Loss: 0.2251
===> Epoch[31](900/2500): Loss: 0.2116
===> Epoch[31](1000/2500): Loss: 0.2123
===> Epoch[31](1100/2500): Loss: 0.2296
===> Epoch[31](1200/2500): Loss: 0.2096
===> Epoch[31](1300/2500): Loss: 0.2110
===> Epoch[31](1400/2500): Loss: 0.2102
===> Epoch[31](1500/2500): Loss: 0.1993
===> Epoch[31](1600/2500): Loss: 0.2071
===> Epoch[31](1700/2500): Loss: 0.2047
===> Epoch[31](1800/2500): Loss: 0.2126
===> Epoch[31](1900/2500): Loss: 0.2288
===> Epoch[31](2000/2500): Loss: 0.2008
===> Epoch[31](2100/2500): Loss: 0.2227
===> Epoch[31](2200/2500): Loss: 0.2010
===> Epoch[31](2300/2500): Loss: 0.2071
===> Epoch[31](2400/2500): Loss: 0.2131
===> Epoch[31](2500/2500): Loss: 0.2038
===> Epoch 31 Complete: Avg. Loss: 0.2157
===> Timestamp: [2025-08-03 17:42:23]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2070
===> Epoch[31](200/2500): Loss: 0.2323
===> Epoch[31](300/2500): Loss: 0.2235
===> Epoch[31](400/2500): Loss: 0.2296
===> Epoch[31](500/2500): Loss: 0.2323
===> Epoch[31](600/2500): Loss: 0.2044
===> Epoch[31](700/2500): Loss: 0.2167
===> Epoch[31](800/2500): Loss: 0.2251
===> Epoch[31](900/2500): Loss: 0.2116
===> Epoch[31](1000/2500): Loss: 0.2123
===> Epoch[31](1100/2500): Loss: 0.2296
===> Epoch[31](1200/2500): Loss: 0.2096
===> Epoch[31](1300/2500): Loss: 0.2110
===> Epoch[31](1400/2500): Loss: 0.2102
===> Epoch[31](1500/2500): Loss: 0.1993
===> Epoch[31](1600/2500): Loss: 0.2071
===> Epoch[31](1700/2500): Loss: 0.2047
===> Epoch[31](1800/2500): Loss: 0.2126
===> Epoch[31](1900/2500): Loss: 0.2288
===> Epoch[31](2000/2500): Loss: 0.2008
===> Epoch[31](2100/2500): Loss: 0.2227
===> Epoch[31](2200/2500): Loss: 0.2010
===> Epoch[31](2300/2500): Loss: 0.2071
===> Epoch[31](2400/2500): Loss: 0.2131
===> Epoch[31](2500/2500): Loss: 0.2038
===> Epoch 31 Complete: Avg. Loss: 0.2157
===> Timestamp: [2025-08-03 17:42:23]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2070
===> Epoch[31](200/2500): Loss: 0.2323
===> Epoch[31](300/2500): Loss: 0.2235
===> Epoch[31](400/2500): Loss: 0.2296
===> Epoch[31](500/2500): Loss: 0.2323
===> Epoch[31](600/2500): Loss: 0.2044
===> Epoch[31](700/2500): Loss: 0.2167
===> Epoch[31](800/2500): Loss: 0.2251
===> Epoch[31](900/2500): Loss: 0.2116
===> Epoch[31](1000/2500): Loss: 0.2123
===> Epoch[31](1100/2500): Loss: 0.2296
===> Epoch[31](1200/2500): Loss: 0.2096
===> Epoch[31](1300/2500): Loss: 0.2110
===> Epoch[31](1400/2500): Loss: 0.2102
===> Epoch[31](1500/2500): Loss: 0.1993
===> Epoch[31](1600/2500): Loss: 0.2071
===> Epoch[31](1700/2500): Loss: 0.2047
===> Epoch[31](1800/2500): Loss: 0.2126
===> Epoch[31](1900/2500): Loss: 0.2288
===> Epoch[31](2000/2500): Loss: 0.2008
===> Epoch[31](2100/2500): Loss: 0.2227
===> Epoch[31](2200/2500): Loss: 0.2010
===> Epoch[31](2300/2500): Loss: 0.2071
===> Epoch[31](2400/2500): Loss: 0.2131
===> Epoch[31](2500/2500): Loss: 0.2038
===> Epoch 31 Complete: Avg. Loss: 0.2157
===> Timestamp: [2025-08-03 17:42:23]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2070
===> Epoch[31](200/2500): Loss: 0.2323
===> Epoch[31](300/2500): Loss: 0.2235
===> Epoch[31](400/2500): Loss: 0.2296
===> Epoch[31](500/2500): Loss: 0.2323
===> Epoch[31](600/2500): Loss: 0.2044
===> Epoch[31](700/2500): Loss: 0.2167
===> Epoch[31](800/2500): Loss: 0.2251
===> Epoch[31](900/2500): Loss: 0.2116
===> Epoch[31](1000/2500): Loss: 0.2123
===> Epoch[31](1100/2500): Loss: 0.2296
===> Epoch[31](1200/2500): Loss: 0.2096
===> Epoch[31](1300/2500): Loss: 0.2110
===> Epoch[31](1400/2500): Loss: 0.2102
===> Epoch[31](1500/2500): Loss: 0.1993
===> Epoch[31](1600/2500): Loss: 0.2071
===> Epoch[31](1700/2500): Loss: 0.2047
===> Epoch[31](1800/2500): Loss: 0.2126
===> Epoch[31](1900/2500): Loss: 0.2288
===> Epoch[31](2000/2500): Loss: 0.2008
===> Epoch[31](2100/2500): Loss: 0.2227
===> Epoch[31](2200/2500): Loss: 0.2010
===> Epoch[31](2300/2500): Loss: 0.2071
===> Epoch[31](2400/2500): Loss: 0.2131
===> Epoch[31](2500/2500): Loss: 0.2038
===> Epoch 31 Complete: Avg. Loss: 0.2157
===> Timestamp: [2025-08-03 17:42:23]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2070
===> Epoch[31](200/2500): Loss: 0.2323
===> Epoch[31](300/2500): Loss: 0.2235
===> Epoch[31](400/2500): Loss: 0.2296
===> Epoch[31](500/2500): Loss: 0.2323
===> Epoch[31](600/2500): Loss: 0.2044
===> Epoch[31](700/2500): Loss: 0.2167
===> Epoch[31](800/2500): Loss: 0.2251
===> Epoch[31](900/2500): Loss: 0.2116
===> Epoch[31](1000/2500): Loss: 0.2123
===> Epoch[31](1100/2500): Loss: 0.2296
===> Epoch[31](1200/2500): Loss: 0.2096
===> Epoch[31](1300/2500): Loss: 0.2110
===> Epoch[31](1400/2500): Loss: 0.2102
===> Epoch[31](1500/2500): Loss: 0.1993
===> Epoch[31](1600/2500): Loss: 0.2071
===> Epoch[31](1700/2500): Loss: 0.2047
===> Epoch[31](1800/2500): Loss: 0.2126
===> Epoch[31](1900/2500): Loss: 0.2288
===> Epoch[31](2000/2500): Loss: 0.2008
===> Epoch[31](2100/2500): Loss: 0.2227
===> Epoch[31](2200/2500): Loss: 0.2010
===> Epoch[31](2300/2500): Loss: 0.2071
===> Epoch[31](2400/2500): Loss: 0.2131
===> Epoch[31](2500/2500): Loss: 0.2038
===> Epoch 31 Complete: Avg. Loss: 0.2157
===> Timestamp: [2025-08-03 17:42:23]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2070
===> Epoch[31](200/2500): Loss: 0.2323
===> Epoch[31](300/2500): Loss: 0.2235
===> Epoch[31](400/2500): Loss: 0.2296
===> Epoch[31](500/2500): Loss: 0.2323
===> Epoch[31](600/2500): Loss: 0.2044
===> Epoch[31](700/2500): Loss: 0.2167
===> Epoch[31](800/2500): Loss: 0.2251
===> Epoch[31](900/2500): Loss: 0.2116
===> Epoch[31](1000/2500): Loss: 0.2123
===> Epoch[31](1100/2500): Loss: 0.2296
===> Epoch[31](1200/2500): Loss: 0.2096
===> Epoch[31](1300/2500): Loss: 0.2110
===> Epoch[31](1400/2500): Loss: 0.2102
===> Epoch[31](1500/2500): Loss: 0.1993
===> Epoch[31](1600/2500): Loss: 0.2071
===> Epoch[31](1700/2500): Loss: 0.2047
===> Epoch[31](1800/2500): Loss: 0.2126
===> Epoch[31](1900/2500): Loss: 0.2288
===> Epoch[31](2000/2500): Loss: 0.2008
===> Epoch[31](2100/2500): Loss: 0.2227
===> Epoch[31](2200/2500): Loss: 0.2010
===> Epoch[31](2300/2500): Loss: 0.2071
===> Epoch[31](2400/2500): Loss: 0.2131
===> Epoch[31](2500/2500): Loss: 0.2038
===> Epoch 31 Complete: Avg. Loss: 0.2157
===> Timestamp: [2025-08-03 17:42:23]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2070
===> Epoch[31](200/2500): Loss: 0.2323
===> Epoch[31](300/2500): Loss: 0.2235
===> Epoch[31](400/2500): Loss: 0.2296
===> Epoch[31](500/2500): Loss: 0.2323
===> Epoch[31](600/2500): Loss: 0.2044
===> Epoch[31](700/2500): Loss: 0.2167
===> Epoch[31](800/2500): Loss: 0.2251
===> Epoch[31](900/2500): Loss: 0.2116
===> Epoch[31](1000/2500): Loss: 0.2123
===> Epoch[31](1100/2500): Loss: 0.2296
===> Epoch[31](1200/2500): Loss: 0.2096
===> Epoch[31](1300/2500): Loss: 0.2110
===> Epoch[31](1400/2500): Loss: 0.2102
===> Epoch[31](1500/2500): Loss: 0.1993
===> Epoch[31](1600/2500): Loss: 0.2071
===> Epoch[31](1700/2500): Loss: 0.2047
===> Epoch[31](1800/2500): Loss: 0.2126
===> Epoch[31](1900/2500): Loss: 0.2288
===> Epoch[31](2000/2500): Loss: 0.2008
===> Epoch[31](2100/2500): Loss: 0.2227
===> Epoch[31](2200/2500): Loss: 0.2010
===> Epoch[31](2300/2500): Loss: 0.2071
===> Epoch[31](2400/2500): Loss: 0.2131
===> Epoch[31](2500/2500): Loss: 0.2038
===> Epoch 31 Complete: Avg. Loss: 0.2157
===> Timestamp: [2025-08-03 17:42:23]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2070
===> Epoch[31](200/2500): Loss: 0.2323
===> Epoch[31](300/2500): Loss: 0.2235
===> Epoch[31](400/2500): Loss: 0.2296
===> Epoch[31](500/2500): Loss: 0.2323
===> Epoch[31](600/2500): Loss: 0.2044
===> Epoch[31](700/2500): Loss: 0.2167
===> Epoch[31](800/2500): Loss: 0.2251
===> Epoch[31](900/2500): Loss: 0.2116
===> Epoch[31](1000/2500): Loss: 0.2123
===> Epoch[31](1100/2500): Loss: 0.2296
===> Epoch[31](1200/2500): Loss: 0.2096
===> Epoch[31](1300/2500): Loss: 0.2110
===> Epoch[31](1400/2500): Loss: 0.2102
===> Epoch[31](1500/2500): Loss: 0.1993
===> Epoch[31](1600/2500): Loss: 0.2071
===> Epoch[31](1700/2500): Loss: 0.2047
===> Epoch[31](1800/2500): Loss: 0.2126
===> Epoch[31](1900/2500): Loss: 0.2288
===> Epoch[31](2000/2500): Loss: 0.2008
===> Epoch[31](2100/2500): Loss: 0.2227
===> Epoch[31](2200/2500): Loss: 0.2010
===> Epoch[31](2300/2500): Loss: 0.2071
===> Epoch[31](2400/2500): Loss: 0.2131
===> Epoch[31](2500/2500): Loss: 0.2038
===> Epoch 31 Complete: Avg. Loss: 0.2157
===> Timestamp: [2025-08-03 17:42:23]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2070
===> Epoch[31](200/2500): Loss: 0.2323
===> Epoch[31](300/2500): Loss: 0.2235
===> Epoch[31](400/2500): Loss: 0.2296
===> Epoch[31](500/2500): Loss: 0.2323
===> Epoch[31](600/2500): Loss: 0.2044
===> Epoch[31](700/2500): Loss: 0.2167
===> Epoch[31](800/2500): Loss: 0.2251
===> Epoch[31](900/2500): Loss: 0.2116
===> Epoch[31](1000/2500): Loss: 0.2123
===> Epoch[31](1100/2500): Loss: 0.2296
===> Epoch[31](1200/2500): Loss: 0.2096
===> Epoch[31](1300/2500): Loss: 0.2110
===> Epoch[31](1400/2500): Loss: 0.2102
===> Epoch[31](1500/2500): Loss: 0.1993
===> Epoch[31](1600/2500): Loss: 0.2071
===> Epoch[31](1700/2500): Loss: 0.2047
===> Epoch[31](1800/2500): Loss: 0.2126
===> Epoch[31](1900/2500): Loss: 0.2288
===> Epoch[31](2000/2500): Loss: 0.2008
===> Epoch[31](2100/2500): Loss: 0.2227
===> Epoch[31](2200/2500): Loss: 0.2010
===> Epoch[31](2300/2500): Loss: 0.2071
===> Epoch[31](2400/2500): Loss: 0.2131
===> Epoch[31](2500/2500): Loss: 0.2038
===> Epoch 31 Complete: Avg. Loss: 0.2157
===> Timestamp: [2025-08-03 17:42:23]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2070
===> Epoch[31](200/2500): Loss: 0.2323
===> Epoch[31](300/2500): Loss: 0.2235
===> Epoch[31](400/2500): Loss: 0.2296
===> Epoch[31](500/2500): Loss: 0.2323
===> Epoch[31](600/2500): Loss: 0.2044
===> Epoch[31](700/2500): Loss: 0.2167
===> Epoch[31](800/2500): Loss: 0.2251
===> Epoch[31](900/2500): Loss: 0.2116
===> Epoch[31](1000/2500): Loss: 0.2123
===> Epoch[31](1100/2500): Loss: 0.2296
===> Epoch[31](1200/2500): Loss: 0.2096
===> Epoch[31](1300/2500): Loss: 0.2110
===> Epoch[31](1400/2500): Loss: 0.2102
===> Epoch[31](1500/2500): Loss: 0.1993
===> Epoch[31](1600/2500): Loss: 0.2071
===> Epoch[31](1700/2500): Loss: 0.2047
===> Epoch[31](1800/2500): Loss: 0.2126
===> Epoch[31](1900/2500): Loss: 0.2288
===> Epoch[31](2000/2500): Loss: 0.2008
===> Epoch[31](2100/2500): Loss: 0.2227
===> Epoch[31](2200/2500): Loss: 0.2010
===> Epoch[31](2300/2500): Loss: 0.2071
===> Epoch[31](2400/2500): Loss: 0.2131
===> Epoch[31](2500/2500): Loss: 0.2038
===> Epoch 31 Complete: Avg. Loss: 0.2157
===> Timestamp: [2025-08-03 17:42:23]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2070
===> Epoch[31](200/2500): Loss: 0.2323
===> Epoch[31](300/2500): Loss: 0.2235
===> Epoch[31](400/2500): Loss: 0.2296
===> Epoch[31](500/2500): Loss: 0.2323
===> Epoch[31](600/2500): Loss: 0.2044
===> Epoch[31](700/2500): Loss: 0.2167
===> Epoch[31](800/2500): Loss: 0.2251
===> Epoch[31](900/2500): Loss: 0.2116
===> Epoch[31](1000/2500): Loss: 0.2123
===> Epoch[31](1100/2500): Loss: 0.2296
===> Epoch[31](1200/2500): Loss: 0.2096
===> Epoch[31](1300/2500): Loss: 0.2110
===> Epoch[31](1400/2500): Loss: 0.2102
===> Epoch[31](1500/2500): Loss: 0.1993
===> Epoch[31](1600/2500): Loss: 0.2071
===> Epoch[31](1700/2500): Loss: 0.2047
===> Epoch[31](1800/2500): Loss: 0.2126
===> Epoch[31](1900/2500): Loss: 0.2288
===> Epoch[31](2000/2500): Loss: 0.2008
===> Epoch[31](2100/2500): Loss: 0.2227
===> Epoch[31](2200/2500): Loss: 0.2010
===> Epoch[31](2300/2500): Loss: 0.2071
===> Epoch[31](2400/2500): Loss: 0.2131
===> Epoch[31](2500/2500): Loss: 0.2038
===> Epoch 31 Complete: Avg. Loss: 0.2157
===> Timestamp: [2025-08-03 17:42:23]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2070
===> Epoch[31](200/2500): Loss: 0.2323
===> Epoch[31](300/2500): Loss: 0.2235
===> Epoch[31](400/2500): Loss: 0.2296
===> Epoch[31](500/2500): Loss: 0.2323
===> Epoch[31](600/2500): Loss: 0.2044
===> Epoch[31](700/2500): Loss: 0.2167
===> Epoch[31](800/2500): Loss: 0.2251
===> Epoch[31](900/2500): Loss: 0.2116
===> Epoch[31](1000/2500): Loss: 0.2123
===> Epoch[31](1100/2500): Loss: 0.2296
===> Epoch[31](1200/2500): Loss: 0.2096
===> Epoch[31](1300/2500): Loss: 0.2110
===> Epoch[31](1400/2500): Loss: 0.2102
===> Epoch[31](1500/2500): Loss: 0.1993
===> Epoch[31](1600/2500): Loss: 0.2071
===> Epoch[31](1700/2500): Loss: 0.2047
===> Epoch[31](1800/2500): Loss: 0.2126
===> Epoch[31](1900/2500): Loss: 0.2288
===> Epoch[31](2000/2500): Loss: 0.2008
===> Epoch[31](2100/2500): Loss: 0.2227
===> Epoch[31](2200/2500): Loss: 0.2010
===> Epoch[31](2300/2500): Loss: 0.2071
===> Epoch[31](2400/2500): Loss: 0.2131
===> Epoch[31](2500/2500): Loss: 0.2038
===> Epoch 31 Complete: Avg. Loss: 0.2157
===> Timestamp: [2025-08-03 17:42:23]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2070
===> Epoch[31](200/2500): Loss: 0.2323
===> Epoch[31](300/2500): Loss: 0.2235
===> Epoch[31](400/2500): Loss: 0.2296
===> Epoch[31](500/2500): Loss: 0.2323
===> Epoch[31](600/2500): Loss: 0.2044
===> Epoch[31](700/2500): Loss: 0.2167
===> Epoch[31](800/2500): Loss: 0.2251
===> Epoch[31](900/2500): Loss: 0.2116
===> Epoch[31](1000/2500): Loss: 0.2123
===> Epoch[31](1100/2500): Loss: 0.2296
===> Epoch[31](1200/2500): Loss: 0.2096
===> Epoch[31](1300/2500): Loss: 0.2110
===> Epoch[31](1400/2500): Loss: 0.2102
===> Epoch[31](1500/2500): Loss: 0.1993
===> Epoch[31](1600/2500): Loss: 0.2071
===> Epoch[31](1700/2500): Loss: 0.2047
===> Epoch[31](1800/2500): Loss: 0.2126
===> Epoch[31](1900/2500): Loss: 0.2288
===> Epoch[31](2000/2500): Loss: 0.2008
===> Epoch[31](2100/2500): Loss: 0.2227
===> Epoch[31](2200/2500): Loss: 0.2010
===> Epoch[31](2300/2500): Loss: 0.2071
===> Epoch[31](2400/2500): Loss: 0.2131
===> Epoch[31](2500/2500): Loss: 0.2038
===> Epoch 31 Complete: Avg. Loss: 0.2157
===> Timestamp: [2025-08-03 17:42:23]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2070
===> Epoch[31](200/2500): Loss: 0.2323
===> Epoch[31](300/2500): Loss: 0.2235
===> Epoch[31](400/2500): Loss: 0.2296
===> Epoch[31](500/2500): Loss: 0.2323
===> Epoch[31](600/2500): Loss: 0.2044
===> Epoch[31](700/2500): Loss: 0.2167
===> Epoch[31](800/2500): Loss: 0.2251
===> Epoch[31](900/2500): Loss: 0.2116
===> Epoch[31](1000/2500): Loss: 0.2123
===> Epoch[31](1100/2500): Loss: 0.2296
===> Epoch[31](1200/2500): Loss: 0.2096
===> Epoch[31](1300/2500): Loss: 0.2110
===> Epoch[31](1400/2500): Loss: 0.2102
===> Epoch[31](1500/2500): Loss: 0.1993
===> Epoch[31](1600/2500): Loss: 0.2071
===> Epoch[31](1700/2500): Loss: 0.2047
===> Epoch[31](1800/2500): Loss: 0.2126
===> Epoch[31](1900/2500): Loss: 0.2288
===> Epoch[31](2000/2500): Loss: 0.2008
===> Epoch[31](2100/2500): Loss: 0.2227
===> Epoch[31](2200/2500): Loss: 0.2010
===> Epoch[31](2300/2500): Loss: 0.2071
===> Epoch[31](2400/2500): Loss: 0.2131
===> Epoch[31](2500/2500): Loss: 0.2038
===> Epoch 31 Complete: Avg. Loss: 0.2157
===> Timestamp: [2025-08-03 17:42:23]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2070
===> Epoch[31](200/2500): Loss: 0.2323
===> Epoch[31](300/2500): Loss: 0.2235
===> Epoch[31](400/2500): Loss: 0.2296
===> Epoch[31](500/2500): Loss: 0.2323
===> Epoch[31](600/2500): Loss: 0.2044
===> Epoch[31](700/2500): Loss: 0.2167
===> Epoch[31](800/2500): Loss: 0.2251
===> Epoch[31](900/2500): Loss: 0.2116
===> Epoch[31](1000/2500): Loss: 0.2123
===> Epoch[31](1100/2500): Loss: 0.2296
===> Epoch[31](1200/2500): Loss: 0.2096
===> Epoch[31](1300/2500): Loss: 0.2110
===> Epoch[31](1400/2500): Loss: 0.2102
===> Epoch[31](1500/2500): Loss: 0.1993
===> Epoch[31](1600/2500): Loss: 0.2071
===> Epoch[31](1700/2500): Loss: 0.2047
===> Epoch[31](1800/2500): Loss: 0.2126
===> Epoch[31](1900/2500): Loss: 0.2288
===> Epoch[31](2000/2500): Loss: 0.2008
===> Epoch[31](2100/2500): Loss: 0.2227
===> Epoch[31](2200/2500): Loss: 0.2010
===> Epoch[31](2300/2500): Loss: 0.2071
===> Epoch[31](2400/2500): Loss: 0.2131
===> Epoch[31](2500/2500): Loss: 0.2038
===> Epoch 31 Complete: Avg. Loss: 0.2157
===> Timestamp: [2025-08-03 17:42:23]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2070
===> Epoch[31](200/2500): Loss: 0.2323
===> Epoch[31](300/2500): Loss: 0.2235
===> Epoch[31](400/2500): Loss: 0.2296
===> Epoch[31](500/2500): Loss: 0.2323
===> Epoch[31](600/2500): Loss: 0.2044
===> Epoch[31](700/2500): Loss: 0.2167
===> Epoch[31](800/2500): Loss: 0.2251
===> Epoch[31](900/2500): Loss: 0.2116
===> Epoch[31](1000/2500): Loss: 0.2123
===> Epoch[31](1100/2500): Loss: 0.2296
===> Epoch[31](1200/2500): Loss: 0.2096
===> Epoch[31](1300/2500): Loss: 0.2110
===> Epoch[31](1400/2500): Loss: 0.2102
===> Epoch[31](1500/2500): Loss: 0.1993
===> Epoch[31](1600/2500): Loss: 0.2071
===> Epoch[31](1700/2500): Loss: 0.2047
===> Epoch[31](1800/2500): Loss: 0.2126
===> Epoch[31](1900/2500): Loss: 0.2288
===> Epoch[31](2000/2500): Loss: 0.2008
===> Epoch[31](2100/2500): Loss: 0.2227
===> Epoch[31](2200/2500): Loss: 0.2010
===> Epoch[31](2300/2500): Loss: 0.2071
===> Epoch[31](2400/2500): Loss: 0.2131
===> Epoch[31](2500/2500): Loss: 0.2038
===> Epoch 31 Complete: Avg. Loss: 0.2157
===> Timestamp: [2025-08-03 17:42:23]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2070
===> Epoch[31](200/2500): Loss: 0.2323
===> Epoch[31](300/2500): Loss: 0.2235
===> Epoch[31](400/2500): Loss: 0.2296
===> Epoch[31](500/2500): Loss: 0.2323
===> Epoch[31](600/2500): Loss: 0.2044
===> Epoch[31](700/2500): Loss: 0.2167
===> Epoch[31](800/2500): Loss: 0.2251
===> Epoch[31](900/2500): Loss: 0.2116
===> Epoch[31](1000/2500): Loss: 0.2123
===> Epoch[31](1100/2500): Loss: 0.2296
===> Epoch[31](1200/2500): Loss: 0.2096
===> Epoch[31](1300/2500): Loss: 0.2110
===> Epoch[31](1400/2500): Loss: 0.2102
===> Epoch[31](1500/2500): Loss: 0.1993
===> Epoch[31](1600/2500): Loss: 0.2071
===> Epoch[31](1700/2500): Loss: 0.2047
===> Epoch[31](1800/2500): Loss: 0.2126
===> Epoch[31](1900/2500): Loss: 0.2288
===> Epoch[31](2000/2500): Loss: 0.2008
===> Epoch[31](2100/2500): Loss: 0.2227
===> Epoch[31](2200/2500): Loss: 0.2010
===> Epoch[31](2300/2500): Loss: 0.2071
===> Epoch[31](2400/2500): Loss: 0.2131
===> Epoch[31](2500/2500): Loss: 0.2038
===> Epoch 31 Complete: Avg. Loss: 0.2157
===> Timestamp: [2025-08-03 17:42:23]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2070
===> Epoch[31](200/2500): Loss: 0.2323
===> Epoch[31](300/2500): Loss: 0.2235
===> Epoch[31](400/2500): Loss: 0.2296
===> Epoch[31](500/2500): Loss: 0.2323
===> Epoch[31](600/2500): Loss: 0.2044
===> Epoch[31](700/2500): Loss: 0.2167
===> Epoch[31](800/2500): Loss: 0.2251
===> Epoch[31](900/2500): Loss: 0.2116
===> Epoch[31](1000/2500): Loss: 0.2123
===> Epoch[31](1100/2500): Loss: 0.2296
===> Epoch[31](1200/2500): Loss: 0.2096
===> Epoch[31](1300/2500): Loss: 0.2110
===> Epoch[31](1400/2500): Loss: 0.2102
===> Epoch[31](1500/2500): Loss: 0.1993
===> Epoch[31](1600/2500): Loss: 0.2071
===> Epoch[31](1700/2500): Loss: 0.2047
===> Epoch[31](1800/2500): Loss: 0.2126
===> Epoch[31](1900/2500): Loss: 0.2288
===> Epoch[31](2000/2500): Loss: 0.2008
===> Epoch[31](2100/2500): Loss: 0.2227
===> Epoch[31](2200/2500): Loss: 0.2010
===> Epoch[31](2300/2500): Loss: 0.2071
===> Epoch[31](2400/2500): Loss: 0.2131
===> Epoch[31](2500/2500): Loss: 0.2038
===> Epoch 31 Complete: Avg. Loss: 0.2157
===> Timestamp: [2025-08-03 17:42:23]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2070
===> Epoch[31](200/2500): Loss: 0.2323
===> Epoch[31](300/2500): Loss: 0.2235
===> Epoch[31](400/2500): Loss: 0.2296
===> Epoch[31](500/2500): Loss: 0.2323
===> Epoch[31](600/2500): Loss: 0.2044
===> Epoch[31](700/2500): Loss: 0.2167
===> Epoch[31](800/2500): Loss: 0.2251
===> Epoch[31](900/2500): Loss: 0.2116
===> Epoch[31](1000/2500): Loss: 0.2123
===> Epoch[31](1100/2500): Loss: 0.2296
===> Epoch[31](1200/2500): Loss: 0.2096
===> Epoch[31](1300/2500): Loss: 0.2110
===> Epoch[31](1400/2500): Loss: 0.2102
===> Epoch[31](1500/2500): Loss: 0.1993
===> Epoch[31](1600/2500): Loss: 0.2071
===> Epoch[31](1700/2500): Loss: 0.2047
===> Epoch[31](1800/2500): Loss: 0.2126
===> Epoch[31](1900/2500): Loss: 0.2288
===> Epoch[31](2000/2500): Loss: 0.2008
===> Epoch[31](2100/2500): Loss: 0.2227
===> Epoch[31](2200/2500): Loss: 0.2010
===> Epoch[31](2300/2500): Loss: 0.2071
===> Epoch[31](2400/2500): Loss: 0.2131
===> Epoch[31](2500/2500): Loss: 0.2038
===> Epoch 31 Complete: Avg. Loss: 0.2157
===> Timestamp: [2025-08-03 17:42:23]
===> Loading train datasets
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.2253
===> Epoch[32](200/2500): Loss: 0.2090
===> Epoch[32](300/2500): Loss: 0.2253
===> Epoch[32](400/2500): Loss: 0.2372
===> Epoch[32](500/2500): Loss: 0.2098
===> Epoch[32](600/2500): Loss: 0.2166
===> Epoch[32](700/2500): Loss: 0.2147
===> Epoch[32](800/2500): Loss: 0.2098
===> Epoch[32](900/2500): Loss: 0.2025
===> Epoch[32](1000/2500): Loss: 0.2346
===> Epoch[32](1100/2500): Loss: 0.2066
===> Epoch[32](1200/2500): Loss: 0.2196
===> Epoch[32](1300/2500): Loss: 0.2254
===> Epoch[32](1400/2500): Loss: 0.2281
===> Epoch[32](1500/2500): Loss: 0.2049
===> Epoch[32](1600/2500): Loss: 0.2225
===> Epoch[32](1700/2500): Loss: 0.2161
===> Epoch[32](1800/2500): Loss: 0.2109
===> Epoch[32](1900/2500): Loss: 0.2102
===> Epoch[32](2000/2500): Loss: 0.2319
===> Epoch[32](2100/2500): Loss: 0.2212
===> Epoch[32](2200/2500): Loss: 0.2228
===> Epoch[32](2300/2500): Loss: 0.1822
===> Epoch[32](2400/2500): Loss: 0.2258
===> Epoch[32](2500/2500): Loss: 0.2129
===> Epoch 32 Complete: Avg. Loss: 0.2154
===> Timestamp: [2025-08-03 17:46:57]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.2253
===> Epoch[32](200/2500): Loss: 0.2090
===> Epoch[32](300/2500): Loss: 0.2253
===> Epoch[32](400/2500): Loss: 0.2372
===> Epoch[32](500/2500): Loss: 0.2098
===> Epoch[32](600/2500): Loss: 0.2166
===> Epoch[32](700/2500): Loss: 0.2147
===> Epoch[32](800/2500): Loss: 0.2098
===> Epoch[32](900/2500): Loss: 0.2025
===> Epoch[32](1000/2500): Loss: 0.2346
===> Epoch[32](1100/2500): Loss: 0.2066
===> Epoch[32](1200/2500): Loss: 0.2196
===> Epoch[32](1300/2500): Loss: 0.2254
===> Epoch[32](1400/2500): Loss: 0.2281
===> Epoch[32](1500/2500): Loss: 0.2049
===> Epoch[32](1600/2500): Loss: 0.2225
===> Epoch[32](1700/2500): Loss: 0.2161
===> Epoch[32](1800/2500): Loss: 0.2109
===> Epoch[32](1900/2500): Loss: 0.2102
===> Epoch[32](2000/2500): Loss: 0.2319
===> Epoch[32](2100/2500): Loss: 0.2212
===> Epoch[32](2200/2500): Loss: 0.2228
===> Epoch[32](2300/2500): Loss: 0.1822
===> Epoch[32](2400/2500): Loss: 0.2258
===> Epoch[32](2500/2500): Loss: 0.2129
===> Epoch 32 Complete: Avg. Loss: 0.2154
===> Timestamp: [2025-08-03 17:46:57]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.2253
===> Epoch[32](200/2500): Loss: 0.2090
===> Epoch[32](300/2500): Loss: 0.2253
===> Epoch[32](400/2500): Loss: 0.2372
===> Epoch[32](500/2500): Loss: 0.2098
===> Epoch[32](600/2500): Loss: 0.2166
===> Epoch[32](700/2500): Loss: 0.2147
===> Epoch[32](800/2500): Loss: 0.2098
===> Epoch[32](900/2500): Loss: 0.2025
===> Epoch[32](1000/2500): Loss: 0.2346
===> Epoch[32](1100/2500): Loss: 0.2066
===> Epoch[32](1200/2500): Loss: 0.2196
===> Epoch[32](1300/2500): Loss: 0.2254
===> Epoch[32](1400/2500): Loss: 0.2281
===> Epoch[32](1500/2500): Loss: 0.2049
===> Epoch[32](1600/2500): Loss: 0.2225
===> Epoch[32](1700/2500): Loss: 0.2161
===> Epoch[32](1800/2500): Loss: 0.2109
===> Epoch[32](1900/2500): Loss: 0.2102
===> Epoch[32](2000/2500): Loss: 0.2319
===> Epoch[32](2100/2500): Loss: 0.2212
===> Epoch[32](2200/2500): Loss: 0.2228
===> Epoch[32](2300/2500): Loss: 0.1822
===> Epoch[32](2400/2500): Loss: 0.2258
===> Epoch[32](2500/2500): Loss: 0.2129
===> Epoch 32 Complete: Avg. Loss: 0.2154
===> Timestamp: [2025-08-03 17:46:57]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.2253
===> Epoch[32](200/2500): Loss: 0.2090
===> Epoch[32](300/2500): Loss: 0.2253
===> Epoch[32](400/2500): Loss: 0.2372
===> Epoch[32](500/2500): Loss: 0.2098
===> Epoch[32](600/2500): Loss: 0.2166
===> Epoch[32](700/2500): Loss: 0.2147
===> Epoch[32](800/2500): Loss: 0.2098
===> Epoch[32](900/2500): Loss: 0.2025
===> Epoch[32](1000/2500): Loss: 0.2346
===> Epoch[32](1100/2500): Loss: 0.2066
===> Epoch[32](1200/2500): Loss: 0.2196
===> Epoch[32](1300/2500): Loss: 0.2254
===> Epoch[32](1400/2500): Loss: 0.2281
===> Epoch[32](1500/2500): Loss: 0.2049
===> Epoch[32](1600/2500): Loss: 0.2225
===> Epoch[32](1700/2500): Loss: 0.2161
===> Epoch[32](1800/2500): Loss: 0.2109
===> Epoch[32](1900/2500): Loss: 0.2102
===> Epoch[32](2000/2500): Loss: 0.2319
===> Epoch[32](2100/2500): Loss: 0.2212
===> Epoch[32](2200/2500): Loss: 0.2228
===> Epoch[32](2300/2500): Loss: 0.1822
===> Epoch[32](2400/2500): Loss: 0.2258
===> Epoch[32](2500/2500): Loss: 0.2129
===> Epoch 32 Complete: Avg. Loss: 0.2154
===> Timestamp: [2025-08-03 17:46:57]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.2253
===> Epoch[32](200/2500): Loss: 0.2090
===> Epoch[32](300/2500): Loss: 0.2253
===> Epoch[32](400/2500): Loss: 0.2372
===> Epoch[32](500/2500): Loss: 0.2098
===> Epoch[32](600/2500): Loss: 0.2166
===> Epoch[32](700/2500): Loss: 0.2147
===> Epoch[32](800/2500): Loss: 0.2098
===> Epoch[32](900/2500): Loss: 0.2025
===> Epoch[32](1000/2500): Loss: 0.2346
===> Epoch[32](1100/2500): Loss: 0.2066
===> Epoch[32](1200/2500): Loss: 0.2196
===> Epoch[32](1300/2500): Loss: 0.2254
===> Epoch[32](1400/2500): Loss: 0.2281
===> Epoch[32](1500/2500): Loss: 0.2049
===> Epoch[32](1600/2500): Loss: 0.2225
===> Epoch[32](1700/2500): Loss: 0.2161
===> Epoch[32](1800/2500): Loss: 0.2109
===> Epoch[32](1900/2500): Loss: 0.2102
===> Epoch[32](2000/2500): Loss: 0.2319
===> Epoch[32](2100/2500): Loss: 0.2212
===> Epoch[32](2200/2500): Loss: 0.2228
===> Epoch[32](2300/2500): Loss: 0.1822
===> Epoch[32](2400/2500): Loss: 0.2258
===> Epoch[32](2500/2500): Loss: 0.2129
===> Epoch 32 Complete: Avg. Loss: 0.2154
===> Timestamp: [2025-08-03 17:46:57]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.2253
===> Epoch[32](200/2500): Loss: 0.2090
===> Epoch[32](300/2500): Loss: 0.2253
===> Epoch[32](400/2500): Loss: 0.2372
===> Epoch[32](500/2500): Loss: 0.2098
===> Epoch[32](600/2500): Loss: 0.2166
===> Epoch[32](700/2500): Loss: 0.2147
===> Epoch[32](800/2500): Loss: 0.2098
===> Epoch[32](900/2500): Loss: 0.2025
===> Epoch[32](1000/2500): Loss: 0.2346
===> Epoch[32](1100/2500): Loss: 0.2066
===> Epoch[32](1200/2500): Loss: 0.2196
===> Epoch[32](1300/2500): Loss: 0.2254
===> Epoch[32](1400/2500): Loss: 0.2281
===> Epoch[32](1500/2500): Loss: 0.2049
===> Epoch[32](1600/2500): Loss: 0.2225
===> Epoch[32](1700/2500): Loss: 0.2161
===> Epoch[32](1800/2500): Loss: 0.2109
===> Epoch[32](1900/2500): Loss: 0.2102
===> Epoch[32](2000/2500): Loss: 0.2319
===> Epoch[32](2100/2500): Loss: 0.2212
===> Epoch[32](2200/2500): Loss: 0.2228
===> Epoch[32](2300/2500): Loss: 0.1822
===> Epoch[32](2400/2500): Loss: 0.2258
===> Epoch[32](2500/2500): Loss: 0.2129
===> Epoch 32 Complete: Avg. Loss: 0.2154
===> Timestamp: [2025-08-03 17:46:57]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.2253
===> Epoch[32](200/2500): Loss: 0.2090
===> Epoch[32](300/2500): Loss: 0.2253
===> Epoch[32](400/2500): Loss: 0.2372
===> Epoch[32](500/2500): Loss: 0.2098
===> Epoch[32](600/2500): Loss: 0.2166
===> Epoch[32](700/2500): Loss: 0.2147
===> Epoch[32](800/2500): Loss: 0.2098
===> Epoch[32](900/2500): Loss: 0.2025
===> Epoch[32](1000/2500): Loss: 0.2346
===> Epoch[32](1100/2500): Loss: 0.2066
===> Epoch[32](1200/2500): Loss: 0.2196
===> Epoch[32](1300/2500): Loss: 0.2254
===> Epoch[32](1400/2500): Loss: 0.2281
===> Epoch[32](1500/2500): Loss: 0.2049
===> Epoch[32](1600/2500): Loss: 0.2225
===> Epoch[32](1700/2500): Loss: 0.2161
===> Epoch[32](1800/2500): Loss: 0.2109
===> Epoch[32](1900/2500): Loss: 0.2102
===> Epoch[32](2000/2500): Loss: 0.2319
===> Epoch[32](2100/2500): Loss: 0.2212
===> Epoch[32](2200/2500): Loss: 0.2228
===> Epoch[32](2300/2500): Loss: 0.1822
===> Epoch[32](2400/2500): Loss: 0.2258
===> Epoch[32](2500/2500): Loss: 0.2129
===> Epoch 32 Complete: Avg. Loss: 0.2154
===> Timestamp: [2025-08-03 17:46:57]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.2253
===> Epoch[32](200/2500): Loss: 0.2090
===> Epoch[32](300/2500): Loss: 0.2253
===> Epoch[32](400/2500): Loss: 0.2372
===> Epoch[32](500/2500): Loss: 0.2098
===> Epoch[32](600/2500): Loss: 0.2166
===> Epoch[32](700/2500): Loss: 0.2147
===> Epoch[32](800/2500): Loss: 0.2098
===> Epoch[32](900/2500): Loss: 0.2025
===> Epoch[32](1000/2500): Loss: 0.2346
===> Epoch[32](1100/2500): Loss: 0.2066
===> Epoch[32](1200/2500): Loss: 0.2196
===> Epoch[32](1300/2500): Loss: 0.2254
===> Epoch[32](1400/2500): Loss: 0.2281
===> Epoch[32](1500/2500): Loss: 0.2049
===> Epoch[32](1600/2500): Loss: 0.2225
===> Epoch[32](1700/2500): Loss: 0.2161
===> Epoch[32](1800/2500): Loss: 0.2109
===> Epoch[32](1900/2500): Loss: 0.2102
===> Epoch[32](2000/2500): Loss: 0.2319
===> Epoch[32](2100/2500): Loss: 0.2212
===> Epoch[32](2200/2500): Loss: 0.2228
===> Epoch[32](2300/2500): Loss: 0.1822
===> Epoch[32](2400/2500): Loss: 0.2258
===> Epoch[32](2500/2500): Loss: 0.2129
===> Epoch 32 Complete: Avg. Loss: 0.2154
===> Timestamp: [2025-08-03 17:46:57]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.2253
===> Epoch[32](200/2500): Loss: 0.2090
===> Epoch[32](300/2500): Loss: 0.2253
===> Epoch[32](400/2500): Loss: 0.2372
===> Epoch[32](500/2500): Loss: 0.2098
===> Epoch[32](600/2500): Loss: 0.2166
===> Epoch[32](700/2500): Loss: 0.2147
===> Epoch[32](800/2500): Loss: 0.2098
===> Epoch[32](900/2500): Loss: 0.2025
===> Epoch[32](1000/2500): Loss: 0.2346
===> Epoch[32](1100/2500): Loss: 0.2066
===> Epoch[32](1200/2500): Loss: 0.2196
===> Epoch[32](1300/2500): Loss: 0.2254
===> Epoch[32](1400/2500): Loss: 0.2281
===> Epoch[32](1500/2500): Loss: 0.2049
===> Epoch[32](1600/2500): Loss: 0.2225
===> Epoch[32](1700/2500): Loss: 0.2161
===> Epoch[32](1800/2500): Loss: 0.2109
===> Epoch[32](1900/2500): Loss: 0.2102
===> Epoch[32](2000/2500): Loss: 0.2319
===> Epoch[32](2100/2500): Loss: 0.2212
===> Epoch[32](2200/2500): Loss: 0.2228
===> Epoch[32](2300/2500): Loss: 0.1822
===> Epoch[32](2400/2500): Loss: 0.2258
===> Epoch[32](2500/2500): Loss: 0.2129
===> Epoch 32 Complete: Avg. Loss: 0.2154
===> Timestamp: [2025-08-03 17:46:57]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.2253
===> Epoch[32](200/2500): Loss: 0.2090
===> Epoch[32](300/2500): Loss: 0.2253
===> Epoch[32](400/2500): Loss: 0.2372
===> Epoch[32](500/2500): Loss: 0.2098
===> Epoch[32](600/2500): Loss: 0.2166
===> Epoch[32](700/2500): Loss: 0.2147
===> Epoch[32](800/2500): Loss: 0.2098
===> Epoch[32](900/2500): Loss: 0.2025
===> Epoch[32](1000/2500): Loss: 0.2346
===> Epoch[32](1100/2500): Loss: 0.2066
===> Epoch[32](1200/2500): Loss: 0.2196
===> Epoch[32](1300/2500): Loss: 0.2254
===> Epoch[32](1400/2500): Loss: 0.2281
===> Epoch[32](1500/2500): Loss: 0.2049
===> Epoch[32](1600/2500): Loss: 0.2225
===> Epoch[32](1700/2500): Loss: 0.2161
===> Epoch[32](1800/2500): Loss: 0.2109
===> Epoch[32](1900/2500): Loss: 0.2102
===> Epoch[32](2000/2500): Loss: 0.2319
===> Epoch[32](2100/2500): Loss: 0.2212
===> Epoch[32](2200/2500): Loss: 0.2228
===> Epoch[32](2300/2500): Loss: 0.1822
===> Epoch[32](2400/2500): Loss: 0.2258
===> Epoch[32](2500/2500): Loss: 0.2129
===> Epoch 32 Complete: Avg. Loss: 0.2154
===> Timestamp: [2025-08-03 17:46:57]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.2253
===> Epoch[32](200/2500): Loss: 0.2090
===> Epoch[32](300/2500): Loss: 0.2253
===> Epoch[32](400/2500): Loss: 0.2372
===> Epoch[32](500/2500): Loss: 0.2098
===> Epoch[32](600/2500): Loss: 0.2166
===> Epoch[32](700/2500): Loss: 0.2147
===> Epoch[32](800/2500): Loss: 0.2098
===> Epoch[32](900/2500): Loss: 0.2025
===> Epoch[32](1000/2500): Loss: 0.2346
===> Epoch[32](1100/2500): Loss: 0.2066
===> Epoch[32](1200/2500): Loss: 0.2196
===> Epoch[32](1300/2500): Loss: 0.2254
===> Epoch[32](1400/2500): Loss: 0.2281
===> Epoch[32](1500/2500): Loss: 0.2049
===> Epoch[32](1600/2500): Loss: 0.2225
===> Epoch[32](1700/2500): Loss: 0.2161
===> Epoch[32](1800/2500): Loss: 0.2109
===> Epoch[32](1900/2500): Loss: 0.2102
===> Epoch[32](2000/2500): Loss: 0.2319
===> Epoch[32](2100/2500): Loss: 0.2212
===> Epoch[32](2200/2500): Loss: 0.2228
===> Epoch[32](2300/2500): Loss: 0.1822
===> Epoch[32](2400/2500): Loss: 0.2258
===> Epoch[32](2500/2500): Loss: 0.2129
===> Epoch 32 Complete: Avg. Loss: 0.2154
===> Timestamp: [2025-08-03 17:46:57]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.2253
===> Epoch[32](200/2500): Loss: 0.2090
===> Epoch[32](300/2500): Loss: 0.2253
===> Epoch[32](400/2500): Loss: 0.2372
===> Epoch[32](500/2500): Loss: 0.2098
===> Epoch[32](600/2500): Loss: 0.2166
===> Epoch[32](700/2500): Loss: 0.2147
===> Epoch[32](800/2500): Loss: 0.2098
===> Epoch[32](900/2500): Loss: 0.2025
===> Epoch[32](1000/2500): Loss: 0.2346
===> Epoch[32](1100/2500): Loss: 0.2066
===> Epoch[32](1200/2500): Loss: 0.2196
===> Epoch[32](1300/2500): Loss: 0.2254
===> Epoch[32](1400/2500): Loss: 0.2281
===> Epoch[32](1500/2500): Loss: 0.2049
===> Epoch[32](1600/2500): Loss: 0.2225
===> Epoch[32](1700/2500): Loss: 0.2161
===> Epoch[32](1800/2500): Loss: 0.2109
===> Epoch[32](1900/2500): Loss: 0.2102
===> Epoch[32](2000/2500): Loss: 0.2319
===> Epoch[32](2100/2500): Loss: 0.2212
===> Epoch[32](2200/2500): Loss: 0.2228
===> Epoch[32](2300/2500): Loss: 0.1822
===> Epoch[32](2400/2500): Loss: 0.2258
===> Epoch[32](2500/2500): Loss: 0.2129
===> Epoch 32 Complete: Avg. Loss: 0.2154
===> Timestamp: [2025-08-03 17:46:57]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.2253
===> Epoch[32](200/2500): Loss: 0.2090
===> Epoch[32](300/2500): Loss: 0.2253
===> Epoch[32](400/2500): Loss: 0.2372
===> Epoch[32](500/2500): Loss: 0.2098
===> Epoch[32](600/2500): Loss: 0.2166
===> Epoch[32](700/2500): Loss: 0.2147
===> Epoch[32](800/2500): Loss: 0.2098
===> Epoch[32](900/2500): Loss: 0.2025
===> Epoch[32](1000/2500): Loss: 0.2346
===> Epoch[32](1100/2500): Loss: 0.2066
===> Epoch[32](1200/2500): Loss: 0.2196
===> Epoch[32](1300/2500): Loss: 0.2254
===> Epoch[32](1400/2500): Loss: 0.2281
===> Epoch[32](1500/2500): Loss: 0.2049
===> Epoch[32](1600/2500): Loss: 0.2225
===> Epoch[32](1700/2500): Loss: 0.2161
===> Epoch[32](1800/2500): Loss: 0.2109
===> Epoch[32](1900/2500): Loss: 0.2102
===> Epoch[32](2000/2500): Loss: 0.2319
===> Epoch[32](2100/2500): Loss: 0.2212
===> Epoch[32](2200/2500): Loss: 0.2228
===> Epoch[32](2300/2500): Loss: 0.1822
===> Epoch[32](2400/2500): Loss: 0.2258
===> Epoch[32](2500/2500): Loss: 0.2129
===> Epoch 32 Complete: Avg. Loss: 0.2154
===> Timestamp: [2025-08-03 17:46:57]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.2253
===> Epoch[32](200/2500): Loss: 0.2090
===> Epoch[32](300/2500): Loss: 0.2253
===> Epoch[32](400/2500): Loss: 0.2372
===> Epoch[32](500/2500): Loss: 0.2098
===> Epoch[32](600/2500): Loss: 0.2166
===> Epoch[32](700/2500): Loss: 0.2147
===> Epoch[32](800/2500): Loss: 0.2098
===> Epoch[32](900/2500): Loss: 0.2025
===> Epoch[32](1000/2500): Loss: 0.2346
===> Epoch[32](1100/2500): Loss: 0.2066
===> Epoch[32](1200/2500): Loss: 0.2196
===> Epoch[32](1300/2500): Loss: 0.2254
===> Epoch[32](1400/2500): Loss: 0.2281
===> Epoch[32](1500/2500): Loss: 0.2049
===> Epoch[32](1600/2500): Loss: 0.2225
===> Epoch[32](1700/2500): Loss: 0.2161
===> Epoch[32](1800/2500): Loss: 0.2109
===> Epoch[32](1900/2500): Loss: 0.2102
===> Epoch[32](2000/2500): Loss: 0.2319
===> Epoch[32](2100/2500): Loss: 0.2212
===> Epoch[32](2200/2500): Loss: 0.2228
===> Epoch[32](2300/2500): Loss: 0.1822
===> Epoch[32](2400/2500): Loss: 0.2258
===> Epoch[32](2500/2500): Loss: 0.2129
===> Epoch 32 Complete: Avg. Loss: 0.2154
===> Timestamp: [2025-08-03 17:46:57]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.2253
===> Epoch[32](200/2500): Loss: 0.2090
===> Epoch[32](300/2500): Loss: 0.2253
===> Epoch[32](400/2500): Loss: 0.2372
===> Epoch[32](500/2500): Loss: 0.2098
===> Epoch[32](600/2500): Loss: 0.2166
===> Epoch[32](700/2500): Loss: 0.2147
===> Epoch[32](800/2500): Loss: 0.2098
===> Epoch[32](900/2500): Loss: 0.2025
===> Epoch[32](1000/2500): Loss: 0.2346
===> Epoch[32](1100/2500): Loss: 0.2066
===> Epoch[32](1200/2500): Loss: 0.2196
===> Epoch[32](1300/2500): Loss: 0.2254
===> Epoch[32](1400/2500): Loss: 0.2281
===> Epoch[32](1500/2500): Loss: 0.2049
===> Epoch[32](1600/2500): Loss: 0.2225
===> Epoch[32](1700/2500): Loss: 0.2161
===> Epoch[32](1800/2500): Loss: 0.2109
===> Epoch[32](1900/2500): Loss: 0.2102
===> Epoch[32](2000/2500): Loss: 0.2319
===> Epoch[32](2100/2500): Loss: 0.2212
===> Epoch[32](2200/2500): Loss: 0.2228
===> Epoch[32](2300/2500): Loss: 0.1822
===> Epoch[32](2400/2500): Loss: 0.2258
===> Epoch[32](2500/2500): Loss: 0.2129
===> Epoch 32 Complete: Avg. Loss: 0.2154
===> Timestamp: [2025-08-03 17:46:57]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.2253
===> Epoch[32](200/2500): Loss: 0.2090
===> Epoch[32](300/2500): Loss: 0.2253
===> Epoch[32](400/2500): Loss: 0.2372
===> Epoch[32](500/2500): Loss: 0.2098
===> Epoch[32](600/2500): Loss: 0.2166
===> Epoch[32](700/2500): Loss: 0.2147
===> Epoch[32](800/2500): Loss: 0.2098
===> Epoch[32](900/2500): Loss: 0.2025
===> Epoch[32](1000/2500): Loss: 0.2346
===> Epoch[32](1100/2500): Loss: 0.2066
===> Epoch[32](1200/2500): Loss: 0.2196
===> Epoch[32](1300/2500): Loss: 0.2254
===> Epoch[32](1400/2500): Loss: 0.2281
===> Epoch[32](1500/2500): Loss: 0.2049
===> Epoch[32](1600/2500): Loss: 0.2225
===> Epoch[32](1700/2500): Loss: 0.2161
===> Epoch[32](1800/2500): Loss: 0.2109
===> Epoch[32](1900/2500): Loss: 0.2102
===> Epoch[32](2000/2500): Loss: 0.2319
===> Epoch[32](2100/2500): Loss: 0.2212
===> Epoch[32](2200/2500): Loss: 0.2228
===> Epoch[32](2300/2500): Loss: 0.1822
===> Epoch[32](2400/2500): Loss: 0.2258
===> Epoch[32](2500/2500): Loss: 0.2129
===> Epoch 32 Complete: Avg. Loss: 0.2154
===> Timestamp: [2025-08-03 17:46:57]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.2253
===> Epoch[32](200/2500): Loss: 0.2090
===> Epoch[32](300/2500): Loss: 0.2253
===> Epoch[32](400/2500): Loss: 0.2372
===> Epoch[32](500/2500): Loss: 0.2098
===> Epoch[32](600/2500): Loss: 0.2166
===> Epoch[32](700/2500): Loss: 0.2147
===> Epoch[32](800/2500): Loss: 0.2098
===> Epoch[32](900/2500): Loss: 0.2025
===> Epoch[32](1000/2500): Loss: 0.2346
===> Epoch[32](1100/2500): Loss: 0.2066
===> Epoch[32](1200/2500): Loss: 0.2196
===> Epoch[32](1300/2500): Loss: 0.2254
===> Epoch[32](1400/2500): Loss: 0.2281
===> Epoch[32](1500/2500): Loss: 0.2049
===> Epoch[32](1600/2500): Loss: 0.2225
===> Epoch[32](1700/2500): Loss: 0.2161
===> Epoch[32](1800/2500): Loss: 0.2109
===> Epoch[32](1900/2500): Loss: 0.2102
===> Epoch[32](2000/2500): Loss: 0.2319
===> Epoch[32](2100/2500): Loss: 0.2212
===> Epoch[32](2200/2500): Loss: 0.2228
===> Epoch[32](2300/2500): Loss: 0.1822
===> Epoch[32](2400/2500): Loss: 0.2258
===> Epoch[32](2500/2500): Loss: 0.2129
===> Epoch 32 Complete: Avg. Loss: 0.2154
===> Timestamp: [2025-08-03 17:46:57]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.2253
===> Epoch[32](200/2500): Loss: 0.2090
===> Epoch[32](300/2500): Loss: 0.2253
===> Epoch[32](400/2500): Loss: 0.2372
===> Epoch[32](500/2500): Loss: 0.2098
===> Epoch[32](600/2500): Loss: 0.2166
===> Epoch[32](700/2500): Loss: 0.2147
===> Epoch[32](800/2500): Loss: 0.2098
===> Epoch[32](900/2500): Loss: 0.2025
===> Epoch[32](1000/2500): Loss: 0.2346
===> Epoch[32](1100/2500): Loss: 0.2066
===> Epoch[32](1200/2500): Loss: 0.2196
===> Epoch[32](1300/2500): Loss: 0.2254
===> Epoch[32](1400/2500): Loss: 0.2281
===> Epoch[32](1500/2500): Loss: 0.2049
===> Epoch[32](1600/2500): Loss: 0.2225
===> Epoch[32](1700/2500): Loss: 0.2161
===> Epoch[32](1800/2500): Loss: 0.2109
===> Epoch[32](1900/2500): Loss: 0.2102
===> Epoch[32](2000/2500): Loss: 0.2319
===> Epoch[32](2100/2500): Loss: 0.2212
===> Epoch[32](2200/2500): Loss: 0.2228
===> Epoch[32](2300/2500): Loss: 0.1822
===> Epoch[32](2400/2500): Loss: 0.2258
===> Epoch[32](2500/2500): Loss: 0.2129
===> Epoch 32 Complete: Avg. Loss: 0.2154
===> Timestamp: [2025-08-03 17:46:57]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.2253
===> Epoch[32](200/2500): Loss: 0.2090
===> Epoch[32](300/2500): Loss: 0.2253
===> Epoch[32](400/2500): Loss: 0.2372
===> Epoch[32](500/2500): Loss: 0.2098
===> Epoch[32](600/2500): Loss: 0.2166
===> Epoch[32](700/2500): Loss: 0.2147
===> Epoch[32](800/2500): Loss: 0.2098
===> Epoch[32](900/2500): Loss: 0.2025
===> Epoch[32](1000/2500): Loss: 0.2346
===> Epoch[32](1100/2500): Loss: 0.2066
===> Epoch[32](1200/2500): Loss: 0.2196
===> Epoch[32](1300/2500): Loss: 0.2254
===> Epoch[32](1400/2500): Loss: 0.2281
===> Epoch[32](1500/2500): Loss: 0.2049
===> Epoch[32](1600/2500): Loss: 0.2225
===> Epoch[32](1700/2500): Loss: 0.2161
===> Epoch[32](1800/2500): Loss: 0.2109
===> Epoch[32](1900/2500): Loss: 0.2102
===> Epoch[32](2000/2500): Loss: 0.2319
===> Epoch[32](2100/2500): Loss: 0.2212
===> Epoch[32](2200/2500): Loss: 0.2228
===> Epoch[32](2300/2500): Loss: 0.1822
===> Epoch[32](2400/2500): Loss: 0.2258
===> Epoch[32](2500/2500): Loss: 0.2129
===> Epoch 32 Complete: Avg. Loss: 0.2154
===> Timestamp: [2025-08-03 17:46:57]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.2253
===> Epoch[32](200/2500): Loss: 0.2090
===> Epoch[32](300/2500): Loss: 0.2253
===> Epoch[32](400/2500): Loss: 0.2372
===> Epoch[32](500/2500): Loss: 0.2098
===> Epoch[32](600/2500): Loss: 0.2166
===> Epoch[32](700/2500): Loss: 0.2147
===> Epoch[32](800/2500): Loss: 0.2098
===> Epoch[32](900/2500): Loss: 0.2025
===> Epoch[32](1000/2500): Loss: 0.2346
===> Epoch[32](1100/2500): Loss: 0.2066
===> Epoch[32](1200/2500): Loss: 0.2196
===> Epoch[32](1300/2500): Loss: 0.2254
===> Epoch[32](1400/2500): Loss: 0.2281
===> Epoch[32](1500/2500): Loss: 0.2049
===> Epoch[32](1600/2500): Loss: 0.2225
===> Epoch[32](1700/2500): Loss: 0.2161
===> Epoch[32](1800/2500): Loss: 0.2109
===> Epoch[32](1900/2500): Loss: 0.2102
===> Epoch[32](2000/2500): Loss: 0.2319
===> Epoch[32](2100/2500): Loss: 0.2212
===> Epoch[32](2200/2500): Loss: 0.2228
===> Epoch[32](2300/2500): Loss: 0.1822
===> Epoch[32](2400/2500): Loss: 0.2258
===> Epoch[32](2500/2500): Loss: 0.2129
===> Epoch 32 Complete: Avg. Loss: 0.2154
===> Timestamp: [2025-08-03 17:46:57]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.2253
===> Epoch[32](200/2500): Loss: 0.2090
===> Epoch[32](300/2500): Loss: 0.2253
===> Epoch[32](400/2500): Loss: 0.2372
===> Epoch[32](500/2500): Loss: 0.2098
===> Epoch[32](600/2500): Loss: 0.2166
===> Epoch[32](700/2500): Loss: 0.2147
===> Epoch[32](800/2500): Loss: 0.2098
===> Epoch[32](900/2500): Loss: 0.2025
===> Epoch[32](1000/2500): Loss: 0.2346
===> Epoch[32](1100/2500): Loss: 0.2066
===> Epoch[32](1200/2500): Loss: 0.2196
===> Epoch[32](1300/2500): Loss: 0.2254
===> Epoch[32](1400/2500): Loss: 0.2281
===> Epoch[32](1500/2500): Loss: 0.2049
===> Epoch[32](1600/2500): Loss: 0.2225
===> Epoch[32](1700/2500): Loss: 0.2161
===> Epoch[32](1800/2500): Loss: 0.2109
===> Epoch[32](1900/2500): Loss: 0.2102
===> Epoch[32](2000/2500): Loss: 0.2319
===> Epoch[32](2100/2500): Loss: 0.2212
===> Epoch[32](2200/2500): Loss: 0.2228
===> Epoch[32](2300/2500): Loss: 0.1822
===> Epoch[32](2400/2500): Loss: 0.2258
===> Epoch[32](2500/2500): Loss: 0.2129
===> Epoch 32 Complete: Avg. Loss: 0.2154
===> Timestamp: [2025-08-03 17:46:57]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.2253
===> Epoch[32](200/2500): Loss: 0.2090
===> Epoch[32](300/2500): Loss: 0.2253
===> Epoch[32](400/2500): Loss: 0.2372
===> Epoch[32](500/2500): Loss: 0.2098
===> Epoch[32](600/2500): Loss: 0.2166
===> Epoch[32](700/2500): Loss: 0.2147
===> Epoch[32](800/2500): Loss: 0.2098
===> Epoch[32](900/2500): Loss: 0.2025
===> Epoch[32](1000/2500): Loss: 0.2346
===> Epoch[32](1100/2500): Loss: 0.2066
===> Epoch[32](1200/2500): Loss: 0.2196
===> Epoch[32](1300/2500): Loss: 0.2254
===> Epoch[32](1400/2500): Loss: 0.2281
===> Epoch[32](1500/2500): Loss: 0.2049
===> Epoch[32](1600/2500): Loss: 0.2225
===> Epoch[32](1700/2500): Loss: 0.2161
===> Epoch[32](1800/2500): Loss: 0.2109
===> Epoch[32](1900/2500): Loss: 0.2102
===> Epoch[32](2000/2500): Loss: 0.2319
===> Epoch[32](2100/2500): Loss: 0.2212
===> Epoch[32](2200/2500): Loss: 0.2228
===> Epoch[32](2300/2500): Loss: 0.1822
===> Epoch[32](2400/2500): Loss: 0.2258
===> Epoch[32](2500/2500): Loss: 0.2129
===> Epoch 32 Complete: Avg. Loss: 0.2154
===> Timestamp: [2025-08-03 17:46:57]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.2253
===> Epoch[32](200/2500): Loss: 0.2090
===> Epoch[32](300/2500): Loss: 0.2253
===> Epoch[32](400/2500): Loss: 0.2372
===> Epoch[32](500/2500): Loss: 0.2098
===> Epoch[32](600/2500): Loss: 0.2166
===> Epoch[32](700/2500): Loss: 0.2147
===> Epoch[32](800/2500): Loss: 0.2098
===> Epoch[32](900/2500): Loss: 0.2025
===> Epoch[32](1000/2500): Loss: 0.2346
===> Epoch[32](1100/2500): Loss: 0.2066
===> Epoch[32](1200/2500): Loss: 0.2196
===> Epoch[32](1300/2500): Loss: 0.2254
===> Epoch[32](1400/2500): Loss: 0.2281
===> Epoch[32](1500/2500): Loss: 0.2049
===> Epoch[32](1600/2500): Loss: 0.2225
===> Epoch[32](1700/2500): Loss: 0.2161
===> Epoch[32](1800/2500): Loss: 0.2109
===> Epoch[32](1900/2500): Loss: 0.2102
===> Epoch[32](2000/2500): Loss: 0.2319
===> Epoch[32](2100/2500): Loss: 0.2212
===> Epoch[32](2200/2500): Loss: 0.2228
===> Epoch[32](2300/2500): Loss: 0.1822
===> Epoch[32](2400/2500): Loss: 0.2258
===> Epoch[32](2500/2500): Loss: 0.2129
===> Epoch 32 Complete: Avg. Loss: 0.2154
===> Timestamp: [2025-08-03 17:46:57]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.2253
===> Epoch[32](200/2500): Loss: 0.2090
===> Epoch[32](300/2500): Loss: 0.2253
===> Epoch[32](400/2500): Loss: 0.2372
===> Epoch[32](500/2500): Loss: 0.2098
===> Epoch[32](600/2500): Loss: 0.2166
===> Epoch[32](700/2500): Loss: 0.2147
===> Epoch[32](800/2500): Loss: 0.2098
===> Epoch[32](900/2500): Loss: 0.2025
===> Epoch[32](1000/2500): Loss: 0.2346
===> Epoch[32](1100/2500): Loss: 0.2066
===> Epoch[32](1200/2500): Loss: 0.2196
===> Epoch[32](1300/2500): Loss: 0.2254
===> Epoch[32](1400/2500): Loss: 0.2281
===> Epoch[32](1500/2500): Loss: 0.2049
===> Epoch[32](1600/2500): Loss: 0.2225
===> Epoch[32](1700/2500): Loss: 0.2161
===> Epoch[32](1800/2500): Loss: 0.2109
===> Epoch[32](1900/2500): Loss: 0.2102
===> Epoch[32](2000/2500): Loss: 0.2319
===> Epoch[32](2100/2500): Loss: 0.2212
===> Epoch[32](2200/2500): Loss: 0.2228
===> Epoch[32](2300/2500): Loss: 0.1822
===> Epoch[32](2400/2500): Loss: 0.2258
===> Epoch[32](2500/2500): Loss: 0.2129
===> Epoch 32 Complete: Avg. Loss: 0.2154
===> Timestamp: [2025-08-03 17:46:57]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.2253
===> Epoch[32](200/2500): Loss: 0.2090
===> Epoch[32](300/2500): Loss: 0.2253
===> Epoch[32](400/2500): Loss: 0.2372
===> Epoch[32](500/2500): Loss: 0.2098
===> Epoch[32](600/2500): Loss: 0.2166
===> Epoch[32](700/2500): Loss: 0.2147
===> Epoch[32](800/2500): Loss: 0.2098
===> Epoch[32](900/2500): Loss: 0.2025
===> Epoch[32](1000/2500): Loss: 0.2346
===> Epoch[32](1100/2500): Loss: 0.2066
===> Epoch[32](1200/2500): Loss: 0.2196
===> Epoch[32](1300/2500): Loss: 0.2254
===> Epoch[32](1400/2500): Loss: 0.2281
===> Epoch[32](1500/2500): Loss: 0.2049
===> Epoch[32](1600/2500): Loss: 0.2225
===> Epoch[32](1700/2500): Loss: 0.2161
===> Epoch[32](1800/2500): Loss: 0.2109
===> Epoch[32](1900/2500): Loss: 0.2102
===> Epoch[32](2000/2500): Loss: 0.2319
===> Epoch[32](2100/2500): Loss: 0.2212
===> Epoch[32](2200/2500): Loss: 0.2228
===> Epoch[32](2300/2500): Loss: 0.1822
===> Epoch[32](2400/2500): Loss: 0.2258
===> Epoch[32](2500/2500): Loss: 0.2129
===> Epoch 32 Complete: Avg. Loss: 0.2154
===> Timestamp: [2025-08-03 17:46:57]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.2253
===> Epoch[32](200/2500): Loss: 0.2090
===> Epoch[32](300/2500): Loss: 0.2253
===> Epoch[32](400/2500): Loss: 0.2372
===> Epoch[32](500/2500): Loss: 0.2098
===> Epoch[32](600/2500): Loss: 0.2166
===> Epoch[32](700/2500): Loss: 0.2147
===> Epoch[32](800/2500): Loss: 0.2098
===> Epoch[32](900/2500): Loss: 0.2025
===> Epoch[32](1000/2500): Loss: 0.2346
===> Epoch[32](1100/2500): Loss: 0.2066
===> Epoch[32](1200/2500): Loss: 0.2196
===> Epoch[32](1300/2500): Loss: 0.2254
===> Epoch[32](1400/2500): Loss: 0.2281
===> Epoch[32](1500/2500): Loss: 0.2049
===> Epoch[32](1600/2500): Loss: 0.2225
===> Epoch[32](1700/2500): Loss: 0.2161
===> Epoch[32](1800/2500): Loss: 0.2109
===> Epoch[32](1900/2500): Loss: 0.2102
===> Epoch[32](2000/2500): Loss: 0.2319
===> Epoch[32](2100/2500): Loss: 0.2212
===> Epoch[32](2200/2500): Loss: 0.2228
===> Epoch[32](2300/2500): Loss: 0.1822
===> Epoch[32](2400/2500): Loss: 0.2258
===> Epoch[32](2500/2500): Loss: 0.2129
===> Epoch 32 Complete: Avg. Loss: 0.2154
===> Timestamp: [2025-08-03 17:46:57]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.2253
===> Epoch[32](200/2500): Loss: 0.2090
===> Epoch[32](300/2500): Loss: 0.2253
===> Epoch[32](400/2500): Loss: 0.2372
===> Epoch[32](500/2500): Loss: 0.2098
===> Epoch[32](600/2500): Loss: 0.2166
===> Epoch[32](700/2500): Loss: 0.2147
===> Epoch[32](800/2500): Loss: 0.2098
===> Epoch[32](900/2500): Loss: 0.2025
===> Epoch[32](1000/2500): Loss: 0.2346
===> Epoch[32](1100/2500): Loss: 0.2066
===> Epoch[32](1200/2500): Loss: 0.2196
===> Epoch[32](1300/2500): Loss: 0.2254
===> Epoch[32](1400/2500): Loss: 0.2281
===> Epoch[32](1500/2500): Loss: 0.2049
===> Epoch[32](1600/2500): Loss: 0.2225
===> Epoch[32](1700/2500): Loss: 0.2161
===> Epoch[32](1800/2500): Loss: 0.2109
===> Epoch[32](1900/2500): Loss: 0.2102
===> Epoch[32](2000/2500): Loss: 0.2319
===> Epoch[32](2100/2500): Loss: 0.2212
===> Epoch[32](2200/2500): Loss: 0.2228
===> Epoch[32](2300/2500): Loss: 0.1822
===> Epoch[32](2400/2500): Loss: 0.2258
===> Epoch[32](2500/2500): Loss: 0.2129
===> Epoch 32 Complete: Avg. Loss: 0.2154
===> Timestamp: [2025-08-03 17:46:57]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.2253
===> Epoch[32](200/2500): Loss: 0.2090
===> Epoch[32](300/2500): Loss: 0.2253
===> Epoch[32](400/2500): Loss: 0.2372
===> Epoch[32](500/2500): Loss: 0.2098
===> Epoch[32](600/2500): Loss: 0.2166
===> Epoch[32](700/2500): Loss: 0.2147
===> Epoch[32](800/2500): Loss: 0.2098
===> Epoch[32](900/2500): Loss: 0.2025
===> Epoch[32](1000/2500): Loss: 0.2346
===> Epoch[32](1100/2500): Loss: 0.2066
===> Epoch[32](1200/2500): Loss: 0.2196
===> Epoch[32](1300/2500): Loss: 0.2254
===> Epoch[32](1400/2500): Loss: 0.2281
===> Epoch[32](1500/2500): Loss: 0.2049
===> Epoch[32](1600/2500): Loss: 0.2225
===> Epoch[32](1700/2500): Loss: 0.2161
===> Epoch[32](1800/2500): Loss: 0.2109
===> Epoch[32](1900/2500): Loss: 0.2102
===> Epoch[32](2000/2500): Loss: 0.2319
===> Epoch[32](2100/2500): Loss: 0.2212
===> Epoch[32](2200/2500): Loss: 0.2228
===> Epoch[32](2300/2500): Loss: 0.1822
===> Epoch[32](2400/2500): Loss: 0.2258
===> Epoch[32](2500/2500): Loss: 0.2129
===> Epoch 32 Complete: Avg. Loss: 0.2154
===> Timestamp: [2025-08-03 17:46:57]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.2253
===> Epoch[32](200/2500): Loss: 0.2090
===> Epoch[32](300/2500): Loss: 0.2253
===> Epoch[32](400/2500): Loss: 0.2372
===> Epoch[32](500/2500): Loss: 0.2098
===> Epoch[32](600/2500): Loss: 0.2166
===> Epoch[32](700/2500): Loss: 0.2147
===> Epoch[32](800/2500): Loss: 0.2098
===> Epoch[32](900/2500): Loss: 0.2025
===> Epoch[32](1000/2500): Loss: 0.2346
===> Epoch[32](1100/2500): Loss: 0.2066
===> Epoch[32](1200/2500): Loss: 0.2196
===> Epoch[32](1300/2500): Loss: 0.2254
===> Epoch[32](1400/2500): Loss: 0.2281
===> Epoch[32](1500/2500): Loss: 0.2049
===> Epoch[32](1600/2500): Loss: 0.2225
===> Epoch[32](1700/2500): Loss: 0.2161
===> Epoch[32](1800/2500): Loss: 0.2109
===> Epoch[32](1900/2500): Loss: 0.2102
===> Epoch[32](2000/2500): Loss: 0.2319
===> Epoch[32](2100/2500): Loss: 0.2212
===> Epoch[32](2200/2500): Loss: 0.2228
===> Epoch[32](2300/2500): Loss: 0.1822
===> Epoch[32](2400/2500): Loss: 0.2258
===> Epoch[32](2500/2500): Loss: 0.2129
===> Epoch 32 Complete: Avg. Loss: 0.2154
===> Timestamp: [2025-08-03 17:46:57]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.2253
===> Epoch[32](200/2500): Loss: 0.2090
===> Epoch[32](300/2500): Loss: 0.2253
===> Epoch[32](400/2500): Loss: 0.2372
===> Epoch[32](500/2500): Loss: 0.2098
===> Epoch[32](600/2500): Loss: 0.2166
===> Epoch[32](700/2500): Loss: 0.2147
===> Epoch[32](800/2500): Loss: 0.2098
===> Epoch[32](900/2500): Loss: 0.2025
===> Epoch[32](1000/2500): Loss: 0.2346
===> Epoch[32](1100/2500): Loss: 0.2066
===> Epoch[32](1200/2500): Loss: 0.2196
===> Epoch[32](1300/2500): Loss: 0.2254
===> Epoch[32](1400/2500): Loss: 0.2281
===> Epoch[32](1500/2500): Loss: 0.2049
===> Epoch[32](1600/2500): Loss: 0.2225
===> Epoch[32](1700/2500): Loss: 0.2161
===> Epoch[32](1800/2500): Loss: 0.2109
===> Epoch[32](1900/2500): Loss: 0.2102
===> Epoch[32](2000/2500): Loss: 0.2319
===> Epoch[32](2100/2500): Loss: 0.2212
===> Epoch[32](2200/2500): Loss: 0.2228
===> Epoch[32](2300/2500): Loss: 0.1822
===> Epoch[32](2400/2500): Loss: 0.2258
===> Epoch[32](2500/2500): Loss: 0.2129
===> Epoch 32 Complete: Avg. Loss: 0.2154
===> Timestamp: [2025-08-03 17:46:57]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.2253
===> Epoch[32](200/2500): Loss: 0.2090
===> Epoch[32](300/2500): Loss: 0.2253
===> Epoch[32](400/2500): Loss: 0.2372
===> Epoch[32](500/2500): Loss: 0.2098
===> Epoch[32](600/2500): Loss: 0.2166
===> Epoch[32](700/2500): Loss: 0.2147
===> Epoch[32](800/2500): Loss: 0.2098
===> Epoch[32](900/2500): Loss: 0.2025
===> Epoch[32](1000/2500): Loss: 0.2346
===> Epoch[32](1100/2500): Loss: 0.2066
===> Epoch[32](1200/2500): Loss: 0.2196
===> Epoch[32](1300/2500): Loss: 0.2254
===> Epoch[32](1400/2500): Loss: 0.2281
===> Epoch[32](1500/2500): Loss: 0.2049
===> Epoch[32](1600/2500): Loss: 0.2225
===> Epoch[32](1700/2500): Loss: 0.2161
===> Epoch[32](1800/2500): Loss: 0.2109
===> Epoch[32](1900/2500): Loss: 0.2102
===> Epoch[32](2000/2500): Loss: 0.2319
===> Epoch[32](2100/2500): Loss: 0.2212
===> Epoch[32](2200/2500): Loss: 0.2228
===> Epoch[32](2300/2500): Loss: 0.1822
===> Epoch[32](2400/2500): Loss: 0.2258
===> Epoch[32](2500/2500): Loss: 0.2129
===> Epoch 32 Complete: Avg. Loss: 0.2154
===> Timestamp: [2025-08-03 17:46:57]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.2253
===> Epoch[32](200/2500): Loss: 0.2090
===> Epoch[32](300/2500): Loss: 0.2253
===> Epoch[32](400/2500): Loss: 0.2372
===> Epoch[32](500/2500): Loss: 0.2098
===> Epoch[32](600/2500): Loss: 0.2166
===> Epoch[32](700/2500): Loss: 0.2147
===> Epoch[32](800/2500): Loss: 0.2098
===> Epoch[32](900/2500): Loss: 0.2025
===> Epoch[32](1000/2500): Loss: 0.2346
===> Epoch[32](1100/2500): Loss: 0.2066
===> Epoch[32](1200/2500): Loss: 0.2196
===> Epoch[32](1300/2500): Loss: 0.2254
===> Epoch[32](1400/2500): Loss: 0.2281
===> Epoch[32](1500/2500): Loss: 0.2049
===> Epoch[32](1600/2500): Loss: 0.2225
===> Epoch[32](1700/2500): Loss: 0.2161
===> Epoch[32](1800/2500): Loss: 0.2109
===> Epoch[32](1900/2500): Loss: 0.2102
===> Epoch[32](2000/2500): Loss: 0.2319
===> Epoch[32](2100/2500): Loss: 0.2212
===> Epoch[32](2200/2500): Loss: 0.2228
===> Epoch[32](2300/2500): Loss: 0.1822
===> Epoch[32](2400/2500): Loss: 0.2258
===> Epoch[32](2500/2500): Loss: 0.2129
===> Epoch 32 Complete: Avg. Loss: 0.2154
===> Timestamp: [2025-08-03 17:46:57]
===> Loading train datasets
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2204
===> Epoch[33](200/2500): Loss: 0.1955
===> Epoch[33](300/2500): Loss: 0.2108
===> Epoch[33](400/2500): Loss: 0.2317
===> Epoch[33](500/2500): Loss: 0.2291
===> Epoch[33](600/2500): Loss: 0.2202
===> Epoch[33](700/2500): Loss: 0.2191
===> Epoch[33](800/2500): Loss: 0.2034
===> Epoch[33](900/2500): Loss: 0.2143
===> Epoch[33](1000/2500): Loss: 0.2159
===> Epoch[33](1100/2500): Loss: 0.2160
===> Epoch[33](1200/2500): Loss: 0.2099
===> Epoch[33](1300/2500): Loss: 0.2312
===> Epoch[33](1400/2500): Loss: 0.2188
===> Epoch[33](1500/2500): Loss: 0.2155
===> Epoch[33](1600/2500): Loss: 0.2222
===> Epoch[33](1700/2500): Loss: 0.2254
===> Epoch[33](1800/2500): Loss: 0.2032
===> Epoch[33](1900/2500): Loss: 0.2007
===> Epoch[33](2000/2500): Loss: 0.2042
===> Epoch[33](2100/2500): Loss: 0.1917
===> Epoch[33](2200/2500): Loss: 0.2313
===> Epoch[33](2300/2500): Loss: 0.2192
===> Epoch[33](2400/2500): Loss: 0.2162
===> Epoch[33](2500/2500): Loss: 0.2133
===> Epoch 33 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 17:51:31]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2204
===> Epoch[33](200/2500): Loss: 0.1955
===> Epoch[33](300/2500): Loss: 0.2108
===> Epoch[33](400/2500): Loss: 0.2317
===> Epoch[33](500/2500): Loss: 0.2291
===> Epoch[33](600/2500): Loss: 0.2202
===> Epoch[33](700/2500): Loss: 0.2191
===> Epoch[33](800/2500): Loss: 0.2034
===> Epoch[33](900/2500): Loss: 0.2143
===> Epoch[33](1000/2500): Loss: 0.2159
===> Epoch[33](1100/2500): Loss: 0.2160
===> Epoch[33](1200/2500): Loss: 0.2099
===> Epoch[33](1300/2500): Loss: 0.2312
===> Epoch[33](1400/2500): Loss: 0.2188
===> Epoch[33](1500/2500): Loss: 0.2155
===> Epoch[33](1600/2500): Loss: 0.2222
===> Epoch[33](1700/2500): Loss: 0.2254
===> Epoch[33](1800/2500): Loss: 0.2032
===> Epoch[33](1900/2500): Loss: 0.2007
===> Epoch[33](2000/2500): Loss: 0.2042
===> Epoch[33](2100/2500): Loss: 0.1917
===> Epoch[33](2200/2500): Loss: 0.2313
===> Epoch[33](2300/2500): Loss: 0.2192
===> Epoch[33](2400/2500): Loss: 0.2162
===> Epoch[33](2500/2500): Loss: 0.2133
===> Epoch 33 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 17:51:31]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2204
===> Epoch[33](200/2500): Loss: 0.1955
===> Epoch[33](300/2500): Loss: 0.2108
===> Epoch[33](400/2500): Loss: 0.2317
===> Epoch[33](500/2500): Loss: 0.2291
===> Epoch[33](600/2500): Loss: 0.2202
===> Epoch[33](700/2500): Loss: 0.2191
===> Epoch[33](800/2500): Loss: 0.2034
===> Epoch[33](900/2500): Loss: 0.2143
===> Epoch[33](1000/2500): Loss: 0.2159
===> Epoch[33](1100/2500): Loss: 0.2160
===> Epoch[33](1200/2500): Loss: 0.2099
===> Epoch[33](1300/2500): Loss: 0.2312
===> Epoch[33](1400/2500): Loss: 0.2188
===> Epoch[33](1500/2500): Loss: 0.2155
===> Epoch[33](1600/2500): Loss: 0.2222
===> Epoch[33](1700/2500): Loss: 0.2254
===> Epoch[33](1800/2500): Loss: 0.2032
===> Epoch[33](1900/2500): Loss: 0.2007
===> Epoch[33](2000/2500): Loss: 0.2042
===> Epoch[33](2100/2500): Loss: 0.1917
===> Epoch[33](2200/2500): Loss: 0.2313
===> Epoch[33](2300/2500): Loss: 0.2192
===> Epoch[33](2400/2500): Loss: 0.2162
===> Epoch[33](2500/2500): Loss: 0.2133
===> Epoch 33 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 17:51:31]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2204
===> Epoch[33](200/2500): Loss: 0.1955
===> Epoch[33](300/2500): Loss: 0.2108
===> Epoch[33](400/2500): Loss: 0.2317
===> Epoch[33](500/2500): Loss: 0.2291
===> Epoch[33](600/2500): Loss: 0.2202
===> Epoch[33](700/2500): Loss: 0.2191
===> Epoch[33](800/2500): Loss: 0.2034
===> Epoch[33](900/2500): Loss: 0.2143
===> Epoch[33](1000/2500): Loss: 0.2159
===> Epoch[33](1100/2500): Loss: 0.2160
===> Epoch[33](1200/2500): Loss: 0.2099
===> Epoch[33](1300/2500): Loss: 0.2312
===> Epoch[33](1400/2500): Loss: 0.2188
===> Epoch[33](1500/2500): Loss: 0.2155
===> Epoch[33](1600/2500): Loss: 0.2222
===> Epoch[33](1700/2500): Loss: 0.2254
===> Epoch[33](1800/2500): Loss: 0.2032
===> Epoch[33](1900/2500): Loss: 0.2007
===> Epoch[33](2000/2500): Loss: 0.2042
===> Epoch[33](2100/2500): Loss: 0.1917
===> Epoch[33](2200/2500): Loss: 0.2313
===> Epoch[33](2300/2500): Loss: 0.2192
===> Epoch[33](2400/2500): Loss: 0.2162
===> Epoch[33](2500/2500): Loss: 0.2133
===> Epoch 33 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 17:51:31]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2204
===> Epoch[33](200/2500): Loss: 0.1955
===> Epoch[33](300/2500): Loss: 0.2108
===> Epoch[33](400/2500): Loss: 0.2317
===> Epoch[33](500/2500): Loss: 0.2291
===> Epoch[33](600/2500): Loss: 0.2202
===> Epoch[33](700/2500): Loss: 0.2191
===> Epoch[33](800/2500): Loss: 0.2034
===> Epoch[33](900/2500): Loss: 0.2143
===> Epoch[33](1000/2500): Loss: 0.2159
===> Epoch[33](1100/2500): Loss: 0.2160
===> Epoch[33](1200/2500): Loss: 0.2099
===> Epoch[33](1300/2500): Loss: 0.2312
===> Epoch[33](1400/2500): Loss: 0.2188
===> Epoch[33](1500/2500): Loss: 0.2155
===> Epoch[33](1600/2500): Loss: 0.2222
===> Epoch[33](1700/2500): Loss: 0.2254
===> Epoch[33](1800/2500): Loss: 0.2032
===> Epoch[33](1900/2500): Loss: 0.2007
===> Epoch[33](2000/2500): Loss: 0.2042
===> Epoch[33](2100/2500): Loss: 0.1917
===> Epoch[33](2200/2500): Loss: 0.2313
===> Epoch[33](2300/2500): Loss: 0.2192
===> Epoch[33](2400/2500): Loss: 0.2162
===> Epoch[33](2500/2500): Loss: 0.2133
===> Epoch 33 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 17:51:31]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2204
===> Epoch[33](200/2500): Loss: 0.1955
===> Epoch[33](300/2500): Loss: 0.2108
===> Epoch[33](400/2500): Loss: 0.2317
===> Epoch[33](500/2500): Loss: 0.2291
===> Epoch[33](600/2500): Loss: 0.2202
===> Epoch[33](700/2500): Loss: 0.2191
===> Epoch[33](800/2500): Loss: 0.2034
===> Epoch[33](900/2500): Loss: 0.2143
===> Epoch[33](1000/2500): Loss: 0.2159
===> Epoch[33](1100/2500): Loss: 0.2160
===> Epoch[33](1200/2500): Loss: 0.2099
===> Epoch[33](1300/2500): Loss: 0.2312
===> Epoch[33](1400/2500): Loss: 0.2188
===> Epoch[33](1500/2500): Loss: 0.2155
===> Epoch[33](1600/2500): Loss: 0.2222
===> Epoch[33](1700/2500): Loss: 0.2254
===> Epoch[33](1800/2500): Loss: 0.2032
===> Epoch[33](1900/2500): Loss: 0.2007
===> Epoch[33](2000/2500): Loss: 0.2042
===> Epoch[33](2100/2500): Loss: 0.1917
===> Epoch[33](2200/2500): Loss: 0.2313
===> Epoch[33](2300/2500): Loss: 0.2192
===> Epoch[33](2400/2500): Loss: 0.2162
===> Epoch[33](2500/2500): Loss: 0.2133
===> Epoch 33 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 17:51:31]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2204
===> Epoch[33](200/2500): Loss: 0.1955
===> Epoch[33](300/2500): Loss: 0.2108
===> Epoch[33](400/2500): Loss: 0.2317
===> Epoch[33](500/2500): Loss: 0.2291
===> Epoch[33](600/2500): Loss: 0.2202
===> Epoch[33](700/2500): Loss: 0.2191
===> Epoch[33](800/2500): Loss: 0.2034
===> Epoch[33](900/2500): Loss: 0.2143
===> Epoch[33](1000/2500): Loss: 0.2159
===> Epoch[33](1100/2500): Loss: 0.2160
===> Epoch[33](1200/2500): Loss: 0.2099
===> Epoch[33](1300/2500): Loss: 0.2312
===> Epoch[33](1400/2500): Loss: 0.2188
===> Epoch[33](1500/2500): Loss: 0.2155
===> Epoch[33](1600/2500): Loss: 0.2222
===> Epoch[33](1700/2500): Loss: 0.2254
===> Epoch[33](1800/2500): Loss: 0.2032
===> Epoch[33](1900/2500): Loss: 0.2007
===> Epoch[33](2000/2500): Loss: 0.2042
===> Epoch[33](2100/2500): Loss: 0.1917
===> Epoch[33](2200/2500): Loss: 0.2313
===> Epoch[33](2300/2500): Loss: 0.2192
===> Epoch[33](2400/2500): Loss: 0.2162
===> Epoch[33](2500/2500): Loss: 0.2133
===> Epoch 33 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 17:51:31]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2204
===> Epoch[33](200/2500): Loss: 0.1955
===> Epoch[33](300/2500): Loss: 0.2108
===> Epoch[33](400/2500): Loss: 0.2317
===> Epoch[33](500/2500): Loss: 0.2291
===> Epoch[33](600/2500): Loss: 0.2202
===> Epoch[33](700/2500): Loss: 0.2191
===> Epoch[33](800/2500): Loss: 0.2034
===> Epoch[33](900/2500): Loss: 0.2143
===> Epoch[33](1000/2500): Loss: 0.2159
===> Epoch[33](1100/2500): Loss: 0.2160
===> Epoch[33](1200/2500): Loss: 0.2099
===> Epoch[33](1300/2500): Loss: 0.2312
===> Epoch[33](1400/2500): Loss: 0.2188
===> Epoch[33](1500/2500): Loss: 0.2155
===> Epoch[33](1600/2500): Loss: 0.2222
===> Epoch[33](1700/2500): Loss: 0.2254
===> Epoch[33](1800/2500): Loss: 0.2032
===> Epoch[33](1900/2500): Loss: 0.2007
===> Epoch[33](2000/2500): Loss: 0.2042
===> Epoch[33](2100/2500): Loss: 0.1917
===> Epoch[33](2200/2500): Loss: 0.2313
===> Epoch[33](2300/2500): Loss: 0.2192
===> Epoch[33](2400/2500): Loss: 0.2162
===> Epoch[33](2500/2500): Loss: 0.2133
===> Epoch 33 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 17:51:31]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2204
===> Epoch[33](200/2500): Loss: 0.1955
===> Epoch[33](300/2500): Loss: 0.2108
===> Epoch[33](400/2500): Loss: 0.2317
===> Epoch[33](500/2500): Loss: 0.2291
===> Epoch[33](600/2500): Loss: 0.2202
===> Epoch[33](700/2500): Loss: 0.2191
===> Epoch[33](800/2500): Loss: 0.2034
===> Epoch[33](900/2500): Loss: 0.2143
===> Epoch[33](1000/2500): Loss: 0.2159
===> Epoch[33](1100/2500): Loss: 0.2160
===> Epoch[33](1200/2500): Loss: 0.2099
===> Epoch[33](1300/2500): Loss: 0.2312
===> Epoch[33](1400/2500): Loss: 0.2188
===> Epoch[33](1500/2500): Loss: 0.2155
===> Epoch[33](1600/2500): Loss: 0.2222
===> Epoch[33](1700/2500): Loss: 0.2254
===> Epoch[33](1800/2500): Loss: 0.2032
===> Epoch[33](1900/2500): Loss: 0.2007
===> Epoch[33](2000/2500): Loss: 0.2042
===> Epoch[33](2100/2500): Loss: 0.1917
===> Epoch[33](2200/2500): Loss: 0.2313
===> Epoch[33](2300/2500): Loss: 0.2192
===> Epoch[33](2400/2500): Loss: 0.2162
===> Epoch[33](2500/2500): Loss: 0.2133
===> Epoch 33 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 17:51:31]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2204
===> Epoch[33](200/2500): Loss: 0.1955
===> Epoch[33](300/2500): Loss: 0.2108
===> Epoch[33](400/2500): Loss: 0.2317
===> Epoch[33](500/2500): Loss: 0.2291
===> Epoch[33](600/2500): Loss: 0.2202
===> Epoch[33](700/2500): Loss: 0.2191
===> Epoch[33](800/2500): Loss: 0.2034
===> Epoch[33](900/2500): Loss: 0.2143
===> Epoch[33](1000/2500): Loss: 0.2159
===> Epoch[33](1100/2500): Loss: 0.2160
===> Epoch[33](1200/2500): Loss: 0.2099
===> Epoch[33](1300/2500): Loss: 0.2312
===> Epoch[33](1400/2500): Loss: 0.2188
===> Epoch[33](1500/2500): Loss: 0.2155
===> Epoch[33](1600/2500): Loss: 0.2222
===> Epoch[33](1700/2500): Loss: 0.2254
===> Epoch[33](1800/2500): Loss: 0.2032
===> Epoch[33](1900/2500): Loss: 0.2007
===> Epoch[33](2000/2500): Loss: 0.2042
===> Epoch[33](2100/2500): Loss: 0.1917
===> Epoch[33](2200/2500): Loss: 0.2313
===> Epoch[33](2300/2500): Loss: 0.2192
===> Epoch[33](2400/2500): Loss: 0.2162
===> Epoch[33](2500/2500): Loss: 0.2133
===> Epoch 33 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 17:51:31]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2204
===> Epoch[33](200/2500): Loss: 0.1955
===> Epoch[33](300/2500): Loss: 0.2108
===> Epoch[33](400/2500): Loss: 0.2317
===> Epoch[33](500/2500): Loss: 0.2291
===> Epoch[33](600/2500): Loss: 0.2202
===> Epoch[33](700/2500): Loss: 0.2191
===> Epoch[33](800/2500): Loss: 0.2034
===> Epoch[33](900/2500): Loss: 0.2143
===> Epoch[33](1000/2500): Loss: 0.2159
===> Epoch[33](1100/2500): Loss: 0.2160
===> Epoch[33](1200/2500): Loss: 0.2099
===> Epoch[33](1300/2500): Loss: 0.2312
===> Epoch[33](1400/2500): Loss: 0.2188
===> Epoch[33](1500/2500): Loss: 0.2155
===> Epoch[33](1600/2500): Loss: 0.2222
===> Epoch[33](1700/2500): Loss: 0.2254
===> Epoch[33](1800/2500): Loss: 0.2032
===> Epoch[33](1900/2500): Loss: 0.2007
===> Epoch[33](2000/2500): Loss: 0.2042
===> Epoch[33](2100/2500): Loss: 0.1917
===> Epoch[33](2200/2500): Loss: 0.2313
===> Epoch[33](2300/2500): Loss: 0.2192
===> Epoch[33](2400/2500): Loss: 0.2162
===> Epoch[33](2500/2500): Loss: 0.2133
===> Epoch 33 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 17:51:31]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2204
===> Epoch[33](200/2500): Loss: 0.1955
===> Epoch[33](300/2500): Loss: 0.2108
===> Epoch[33](400/2500): Loss: 0.2317
===> Epoch[33](500/2500): Loss: 0.2291
===> Epoch[33](600/2500): Loss: 0.2202
===> Epoch[33](700/2500): Loss: 0.2191
===> Epoch[33](800/2500): Loss: 0.2034
===> Epoch[33](900/2500): Loss: 0.2143
===> Epoch[33](1000/2500): Loss: 0.2159
===> Epoch[33](1100/2500): Loss: 0.2160
===> Epoch[33](1200/2500): Loss: 0.2099
===> Epoch[33](1300/2500): Loss: 0.2312
===> Epoch[33](1400/2500): Loss: 0.2188
===> Epoch[33](1500/2500): Loss: 0.2155
===> Epoch[33](1600/2500): Loss: 0.2222
===> Epoch[33](1700/2500): Loss: 0.2254
===> Epoch[33](1800/2500): Loss: 0.2032
===> Epoch[33](1900/2500): Loss: 0.2007
===> Epoch[33](2000/2500): Loss: 0.2042
===> Epoch[33](2100/2500): Loss: 0.1917
===> Epoch[33](2200/2500): Loss: 0.2313
===> Epoch[33](2300/2500): Loss: 0.2192
===> Epoch[33](2400/2500): Loss: 0.2162
===> Epoch[33](2500/2500): Loss: 0.2133
===> Epoch 33 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 17:51:31]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2204
===> Epoch[33](200/2500): Loss: 0.1955
===> Epoch[33](300/2500): Loss: 0.2108
===> Epoch[33](400/2500): Loss: 0.2317
===> Epoch[33](500/2500): Loss: 0.2291
===> Epoch[33](600/2500): Loss: 0.2202
===> Epoch[33](700/2500): Loss: 0.2191
===> Epoch[33](800/2500): Loss: 0.2034
===> Epoch[33](900/2500): Loss: 0.2143
===> Epoch[33](1000/2500): Loss: 0.2159
===> Epoch[33](1100/2500): Loss: 0.2160
===> Epoch[33](1200/2500): Loss: 0.2099
===> Epoch[33](1300/2500): Loss: 0.2312
===> Epoch[33](1400/2500): Loss: 0.2188
===> Epoch[33](1500/2500): Loss: 0.2155
===> Epoch[33](1600/2500): Loss: 0.2222
===> Epoch[33](1700/2500): Loss: 0.2254
===> Epoch[33](1800/2500): Loss: 0.2032
===> Epoch[33](1900/2500): Loss: 0.2007
===> Epoch[33](2000/2500): Loss: 0.2042
===> Epoch[33](2100/2500): Loss: 0.1917
===> Epoch[33](2200/2500): Loss: 0.2313
===> Epoch[33](2300/2500): Loss: 0.2192
===> Epoch[33](2400/2500): Loss: 0.2162
===> Epoch[33](2500/2500): Loss: 0.2133
===> Epoch 33 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 17:51:31]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2204
===> Epoch[33](200/2500): Loss: 0.1955
===> Epoch[33](300/2500): Loss: 0.2108
===> Epoch[33](400/2500): Loss: 0.2317
===> Epoch[33](500/2500): Loss: 0.2291
===> Epoch[33](600/2500): Loss: 0.2202
===> Epoch[33](700/2500): Loss: 0.2191
===> Epoch[33](800/2500): Loss: 0.2034
===> Epoch[33](900/2500): Loss: 0.2143
===> Epoch[33](1000/2500): Loss: 0.2159
===> Epoch[33](1100/2500): Loss: 0.2160
===> Epoch[33](1200/2500): Loss: 0.2099
===> Epoch[33](1300/2500): Loss: 0.2312
===> Epoch[33](1400/2500): Loss: 0.2188
===> Epoch[33](1500/2500): Loss: 0.2155
===> Epoch[33](1600/2500): Loss: 0.2222
===> Epoch[33](1700/2500): Loss: 0.2254
===> Epoch[33](1800/2500): Loss: 0.2032
===> Epoch[33](1900/2500): Loss: 0.2007
===> Epoch[33](2000/2500): Loss: 0.2042
===> Epoch[33](2100/2500): Loss: 0.1917
===> Epoch[33](2200/2500): Loss: 0.2313
===> Epoch[33](2300/2500): Loss: 0.2192
===> Epoch[33](2400/2500): Loss: 0.2162
===> Epoch[33](2500/2500): Loss: 0.2133
===> Epoch 33 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 17:51:31]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2204
===> Epoch[33](200/2500): Loss: 0.1955
===> Epoch[33](300/2500): Loss: 0.2108
===> Epoch[33](400/2500): Loss: 0.2317
===> Epoch[33](500/2500): Loss: 0.2291
===> Epoch[33](600/2500): Loss: 0.2202
===> Epoch[33](700/2500): Loss: 0.2191
===> Epoch[33](800/2500): Loss: 0.2034
===> Epoch[33](900/2500): Loss: 0.2143
===> Epoch[33](1000/2500): Loss: 0.2159
===> Epoch[33](1100/2500): Loss: 0.2160
===> Epoch[33](1200/2500): Loss: 0.2099
===> Epoch[33](1300/2500): Loss: 0.2312
===> Epoch[33](1400/2500): Loss: 0.2188
===> Epoch[33](1500/2500): Loss: 0.2155
===> Epoch[33](1600/2500): Loss: 0.2222
===> Epoch[33](1700/2500): Loss: 0.2254
===> Epoch[33](1800/2500): Loss: 0.2032
===> Epoch[33](1900/2500): Loss: 0.2007
===> Epoch[33](2000/2500): Loss: 0.2042
===> Epoch[33](2100/2500): Loss: 0.1917
===> Epoch[33](2200/2500): Loss: 0.2313
===> Epoch[33](2300/2500): Loss: 0.2192
===> Epoch[33](2400/2500): Loss: 0.2162
===> Epoch[33](2500/2500): Loss: 0.2133
===> Epoch 33 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 17:51:31]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2204
===> Epoch[33](200/2500): Loss: 0.1955
===> Epoch[33](300/2500): Loss: 0.2108
===> Epoch[33](400/2500): Loss: 0.2317
===> Epoch[33](500/2500): Loss: 0.2291
===> Epoch[33](600/2500): Loss: 0.2202
===> Epoch[33](700/2500): Loss: 0.2191
===> Epoch[33](800/2500): Loss: 0.2034
===> Epoch[33](900/2500): Loss: 0.2143
===> Epoch[33](1000/2500): Loss: 0.2159
===> Epoch[33](1100/2500): Loss: 0.2160
===> Epoch[33](1200/2500): Loss: 0.2099
===> Epoch[33](1300/2500): Loss: 0.2312
===> Epoch[33](1400/2500): Loss: 0.2188
===> Epoch[33](1500/2500): Loss: 0.2155
===> Epoch[33](1600/2500): Loss: 0.2222
===> Epoch[33](1700/2500): Loss: 0.2254
===> Epoch[33](1800/2500): Loss: 0.2032
===> Epoch[33](1900/2500): Loss: 0.2007
===> Epoch[33](2000/2500): Loss: 0.2042
===> Epoch[33](2100/2500): Loss: 0.1917
===> Epoch[33](2200/2500): Loss: 0.2313
===> Epoch[33](2300/2500): Loss: 0.2192
===> Epoch[33](2400/2500): Loss: 0.2162
===> Epoch[33](2500/2500): Loss: 0.2133
===> Epoch 33 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 17:51:31]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2204
===> Epoch[33](200/2500): Loss: 0.1955
===> Epoch[33](300/2500): Loss: 0.2108
===> Epoch[33](400/2500): Loss: 0.2317
===> Epoch[33](500/2500): Loss: 0.2291
===> Epoch[33](600/2500): Loss: 0.2202
===> Epoch[33](700/2500): Loss: 0.2191
===> Epoch[33](800/2500): Loss: 0.2034
===> Epoch[33](900/2500): Loss: 0.2143
===> Epoch[33](1000/2500): Loss: 0.2159
===> Epoch[33](1100/2500): Loss: 0.2160
===> Epoch[33](1200/2500): Loss: 0.2099
===> Epoch[33](1300/2500): Loss: 0.2312
===> Epoch[33](1400/2500): Loss: 0.2188
===> Epoch[33](1500/2500): Loss: 0.2155
===> Epoch[33](1600/2500): Loss: 0.2222
===> Epoch[33](1700/2500): Loss: 0.2254
===> Epoch[33](1800/2500): Loss: 0.2032
===> Epoch[33](1900/2500): Loss: 0.2007
===> Epoch[33](2000/2500): Loss: 0.2042
===> Epoch[33](2100/2500): Loss: 0.1917
===> Epoch[33](2200/2500): Loss: 0.2313
===> Epoch[33](2300/2500): Loss: 0.2192
===> Epoch[33](2400/2500): Loss: 0.2162
===> Epoch[33](2500/2500): Loss: 0.2133
===> Epoch 33 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 17:51:31]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2204
===> Epoch[33](200/2500): Loss: 0.1955
===> Epoch[33](300/2500): Loss: 0.2108
===> Epoch[33](400/2500): Loss: 0.2317
===> Epoch[33](500/2500): Loss: 0.2291
===> Epoch[33](600/2500): Loss: 0.2202
===> Epoch[33](700/2500): Loss: 0.2191
===> Epoch[33](800/2500): Loss: 0.2034
===> Epoch[33](900/2500): Loss: 0.2143
===> Epoch[33](1000/2500): Loss: 0.2159
===> Epoch[33](1100/2500): Loss: 0.2160
===> Epoch[33](1200/2500): Loss: 0.2099
===> Epoch[33](1300/2500): Loss: 0.2312
===> Epoch[33](1400/2500): Loss: 0.2188
===> Epoch[33](1500/2500): Loss: 0.2155
===> Epoch[33](1600/2500): Loss: 0.2222
===> Epoch[33](1700/2500): Loss: 0.2254
===> Epoch[33](1800/2500): Loss: 0.2032
===> Epoch[33](1900/2500): Loss: 0.2007
===> Epoch[33](2000/2500): Loss: 0.2042
===> Epoch[33](2100/2500): Loss: 0.1917
===> Epoch[33](2200/2500): Loss: 0.2313
===> Epoch[33](2300/2500): Loss: 0.2192
===> Epoch[33](2400/2500): Loss: 0.2162
===> Epoch[33](2500/2500): Loss: 0.2133
===> Epoch 33 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 17:51:31]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2204
===> Epoch[33](200/2500): Loss: 0.1955
===> Epoch[33](300/2500): Loss: 0.2108
===> Epoch[33](400/2500): Loss: 0.2317
===> Epoch[33](500/2500): Loss: 0.2291
===> Epoch[33](600/2500): Loss: 0.2202
===> Epoch[33](700/2500): Loss: 0.2191
===> Epoch[33](800/2500): Loss: 0.2034
===> Epoch[33](900/2500): Loss: 0.2143
===> Epoch[33](1000/2500): Loss: 0.2159
===> Epoch[33](1100/2500): Loss: 0.2160
===> Epoch[33](1200/2500): Loss: 0.2099
===> Epoch[33](1300/2500): Loss: 0.2312
===> Epoch[33](1400/2500): Loss: 0.2188
===> Epoch[33](1500/2500): Loss: 0.2155
===> Epoch[33](1600/2500): Loss: 0.2222
===> Epoch[33](1700/2500): Loss: 0.2254
===> Epoch[33](1800/2500): Loss: 0.2032
===> Epoch[33](1900/2500): Loss: 0.2007
===> Epoch[33](2000/2500): Loss: 0.2042
===> Epoch[33](2100/2500): Loss: 0.1917
===> Epoch[33](2200/2500): Loss: 0.2313
===> Epoch[33](2300/2500): Loss: 0.2192
===> Epoch[33](2400/2500): Loss: 0.2162
===> Epoch[33](2500/2500): Loss: 0.2133
===> Epoch 33 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 17:51:31]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2204
===> Epoch[33](200/2500): Loss: 0.1955
===> Epoch[33](300/2500): Loss: 0.2108
===> Epoch[33](400/2500): Loss: 0.2317
===> Epoch[33](500/2500): Loss: 0.2291
===> Epoch[33](600/2500): Loss: 0.2202
===> Epoch[33](700/2500): Loss: 0.2191
===> Epoch[33](800/2500): Loss: 0.2034
===> Epoch[33](900/2500): Loss: 0.2143
===> Epoch[33](1000/2500): Loss: 0.2159
===> Epoch[33](1100/2500): Loss: 0.2160
===> Epoch[33](1200/2500): Loss: 0.2099
===> Epoch[33](1300/2500): Loss: 0.2312
===> Epoch[33](1400/2500): Loss: 0.2188
===> Epoch[33](1500/2500): Loss: 0.2155
===> Epoch[33](1600/2500): Loss: 0.2222
===> Epoch[33](1700/2500): Loss: 0.2254
===> Epoch[33](1800/2500): Loss: 0.2032
===> Epoch[33](1900/2500): Loss: 0.2007
===> Epoch[33](2000/2500): Loss: 0.2042
===> Epoch[33](2100/2500): Loss: 0.1917
===> Epoch[33](2200/2500): Loss: 0.2313
===> Epoch[33](2300/2500): Loss: 0.2192
===> Epoch[33](2400/2500): Loss: 0.2162
===> Epoch[33](2500/2500): Loss: 0.2133
===> Epoch 33 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 17:51:31]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2204
===> Epoch[33](200/2500): Loss: 0.1955
===> Epoch[33](300/2500): Loss: 0.2108
===> Epoch[33](400/2500): Loss: 0.2317
===> Epoch[33](500/2500): Loss: 0.2291
===> Epoch[33](600/2500): Loss: 0.2202
===> Epoch[33](700/2500): Loss: 0.2191
===> Epoch[33](800/2500): Loss: 0.2034
===> Epoch[33](900/2500): Loss: 0.2143
===> Epoch[33](1000/2500): Loss: 0.2159
===> Epoch[33](1100/2500): Loss: 0.2160
===> Epoch[33](1200/2500): Loss: 0.2099
===> Epoch[33](1300/2500): Loss: 0.2312
===> Epoch[33](1400/2500): Loss: 0.2188
===> Epoch[33](1500/2500): Loss: 0.2155
===> Epoch[33](1600/2500): Loss: 0.2222
===> Epoch[33](1700/2500): Loss: 0.2254
===> Epoch[33](1800/2500): Loss: 0.2032
===> Epoch[33](1900/2500): Loss: 0.2007
===> Epoch[33](2000/2500): Loss: 0.2042
===> Epoch[33](2100/2500): Loss: 0.1917
===> Epoch[33](2200/2500): Loss: 0.2313
===> Epoch[33](2300/2500): Loss: 0.2192
===> Epoch[33](2400/2500): Loss: 0.2162
===> Epoch[33](2500/2500): Loss: 0.2133
===> Epoch 33 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 17:51:31]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2204
===> Epoch[33](200/2500): Loss: 0.1955
===> Epoch[33](300/2500): Loss: 0.2108
===> Epoch[33](400/2500): Loss: 0.2317
===> Epoch[33](500/2500): Loss: 0.2291
===> Epoch[33](600/2500): Loss: 0.2202
===> Epoch[33](700/2500): Loss: 0.2191
===> Epoch[33](800/2500): Loss: 0.2034
===> Epoch[33](900/2500): Loss: 0.2143
===> Epoch[33](1000/2500): Loss: 0.2159
===> Epoch[33](1100/2500): Loss: 0.2160
===> Epoch[33](1200/2500): Loss: 0.2099
===> Epoch[33](1300/2500): Loss: 0.2312
===> Epoch[33](1400/2500): Loss: 0.2188
===> Epoch[33](1500/2500): Loss: 0.2155
===> Epoch[33](1600/2500): Loss: 0.2222
===> Epoch[33](1700/2500): Loss: 0.2254
===> Epoch[33](1800/2500): Loss: 0.2032
===> Epoch[33](1900/2500): Loss: 0.2007
===> Epoch[33](2000/2500): Loss: 0.2042
===> Epoch[33](2100/2500): Loss: 0.1917
===> Epoch[33](2200/2500): Loss: 0.2313
===> Epoch[33](2300/2500): Loss: 0.2192
===> Epoch[33](2400/2500): Loss: 0.2162
===> Epoch[33](2500/2500): Loss: 0.2133
===> Epoch 33 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 17:51:31]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2204
===> Epoch[33](200/2500): Loss: 0.1955
===> Epoch[33](300/2500): Loss: 0.2108
===> Epoch[33](400/2500): Loss: 0.2317
===> Epoch[33](500/2500): Loss: 0.2291
===> Epoch[33](600/2500): Loss: 0.2202
===> Epoch[33](700/2500): Loss: 0.2191
===> Epoch[33](800/2500): Loss: 0.2034
===> Epoch[33](900/2500): Loss: 0.2143
===> Epoch[33](1000/2500): Loss: 0.2159
===> Epoch[33](1100/2500): Loss: 0.2160
===> Epoch[33](1200/2500): Loss: 0.2099
===> Epoch[33](1300/2500): Loss: 0.2312
===> Epoch[33](1400/2500): Loss: 0.2188
===> Epoch[33](1500/2500): Loss: 0.2155
===> Epoch[33](1600/2500): Loss: 0.2222
===> Epoch[33](1700/2500): Loss: 0.2254
===> Epoch[33](1800/2500): Loss: 0.2032
===> Epoch[33](1900/2500): Loss: 0.2007
===> Epoch[33](2000/2500): Loss: 0.2042
===> Epoch[33](2100/2500): Loss: 0.1917
===> Epoch[33](2200/2500): Loss: 0.2313
===> Epoch[33](2300/2500): Loss: 0.2192
===> Epoch[33](2400/2500): Loss: 0.2162
===> Epoch[33](2500/2500): Loss: 0.2133
===> Epoch 33 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 17:51:31]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2204
===> Epoch[33](200/2500): Loss: 0.1955
===> Epoch[33](300/2500): Loss: 0.2108
===> Epoch[33](400/2500): Loss: 0.2317
===> Epoch[33](500/2500): Loss: 0.2291
===> Epoch[33](600/2500): Loss: 0.2202
===> Epoch[33](700/2500): Loss: 0.2191
===> Epoch[33](800/2500): Loss: 0.2034
===> Epoch[33](900/2500): Loss: 0.2143
===> Epoch[33](1000/2500): Loss: 0.2159
===> Epoch[33](1100/2500): Loss: 0.2160
===> Epoch[33](1200/2500): Loss: 0.2099
===> Epoch[33](1300/2500): Loss: 0.2312
===> Epoch[33](1400/2500): Loss: 0.2188
===> Epoch[33](1500/2500): Loss: 0.2155
===> Epoch[33](1600/2500): Loss: 0.2222
===> Epoch[33](1700/2500): Loss: 0.2254
===> Epoch[33](1800/2500): Loss: 0.2032
===> Epoch[33](1900/2500): Loss: 0.2007
===> Epoch[33](2000/2500): Loss: 0.2042
===> Epoch[33](2100/2500): Loss: 0.1917
===> Epoch[33](2200/2500): Loss: 0.2313
===> Epoch[33](2300/2500): Loss: 0.2192
===> Epoch[33](2400/2500): Loss: 0.2162
===> Epoch[33](2500/2500): Loss: 0.2133
===> Epoch 33 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 17:51:31]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2204
===> Epoch[33](200/2500): Loss: 0.1955
===> Epoch[33](300/2500): Loss: 0.2108
===> Epoch[33](400/2500): Loss: 0.2317
===> Epoch[33](500/2500): Loss: 0.2291
===> Epoch[33](600/2500): Loss: 0.2202
===> Epoch[33](700/2500): Loss: 0.2191
===> Epoch[33](800/2500): Loss: 0.2034
===> Epoch[33](900/2500): Loss: 0.2143
===> Epoch[33](1000/2500): Loss: 0.2159
===> Epoch[33](1100/2500): Loss: 0.2160
===> Epoch[33](1200/2500): Loss: 0.2099
===> Epoch[33](1300/2500): Loss: 0.2312
===> Epoch[33](1400/2500): Loss: 0.2188
===> Epoch[33](1500/2500): Loss: 0.2155
===> Epoch[33](1600/2500): Loss: 0.2222
===> Epoch[33](1700/2500): Loss: 0.2254
===> Epoch[33](1800/2500): Loss: 0.2032
===> Epoch[33](1900/2500): Loss: 0.2007
===> Epoch[33](2000/2500): Loss: 0.2042
===> Epoch[33](2100/2500): Loss: 0.1917
===> Epoch[33](2200/2500): Loss: 0.2313
===> Epoch[33](2300/2500): Loss: 0.2192
===> Epoch[33](2400/2500): Loss: 0.2162
===> Epoch[33](2500/2500): Loss: 0.2133
===> Epoch 33 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 17:51:31]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2204
===> Epoch[33](200/2500): Loss: 0.1955
===> Epoch[33](300/2500): Loss: 0.2108
===> Epoch[33](400/2500): Loss: 0.2317
===> Epoch[33](500/2500): Loss: 0.2291
===> Epoch[33](600/2500): Loss: 0.2202
===> Epoch[33](700/2500): Loss: 0.2191
===> Epoch[33](800/2500): Loss: 0.2034
===> Epoch[33](900/2500): Loss: 0.2143
===> Epoch[33](1000/2500): Loss: 0.2159
===> Epoch[33](1100/2500): Loss: 0.2160
===> Epoch[33](1200/2500): Loss: 0.2099
===> Epoch[33](1300/2500): Loss: 0.2312
===> Epoch[33](1400/2500): Loss: 0.2188
===> Epoch[33](1500/2500): Loss: 0.2155
===> Epoch[33](1600/2500): Loss: 0.2222
===> Epoch[33](1700/2500): Loss: 0.2254
===> Epoch[33](1800/2500): Loss: 0.2032
===> Epoch[33](1900/2500): Loss: 0.2007
===> Epoch[33](2000/2500): Loss: 0.2042
===> Epoch[33](2100/2500): Loss: 0.1917
===> Epoch[33](2200/2500): Loss: 0.2313
===> Epoch[33](2300/2500): Loss: 0.2192
===> Epoch[33](2400/2500): Loss: 0.2162
===> Epoch[33](2500/2500): Loss: 0.2133
===> Epoch 33 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 17:51:31]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2204
===> Epoch[33](200/2500): Loss: 0.1955
===> Epoch[33](300/2500): Loss: 0.2108
===> Epoch[33](400/2500): Loss: 0.2317
===> Epoch[33](500/2500): Loss: 0.2291
===> Epoch[33](600/2500): Loss: 0.2202
===> Epoch[33](700/2500): Loss: 0.2191
===> Epoch[33](800/2500): Loss: 0.2034
===> Epoch[33](900/2500): Loss: 0.2143
===> Epoch[33](1000/2500): Loss: 0.2159
===> Epoch[33](1100/2500): Loss: 0.2160
===> Epoch[33](1200/2500): Loss: 0.2099
===> Epoch[33](1300/2500): Loss: 0.2312
===> Epoch[33](1400/2500): Loss: 0.2188
===> Epoch[33](1500/2500): Loss: 0.2155
===> Epoch[33](1600/2500): Loss: 0.2222
===> Epoch[33](1700/2500): Loss: 0.2254
===> Epoch[33](1800/2500): Loss: 0.2032
===> Epoch[33](1900/2500): Loss: 0.2007
===> Epoch[33](2000/2500): Loss: 0.2042
===> Epoch[33](2100/2500): Loss: 0.1917
===> Epoch[33](2200/2500): Loss: 0.2313
===> Epoch[33](2300/2500): Loss: 0.2192
===> Epoch[33](2400/2500): Loss: 0.2162
===> Epoch[33](2500/2500): Loss: 0.2133
===> Epoch 33 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 17:51:31]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2204
===> Epoch[33](200/2500): Loss: 0.1955
===> Epoch[33](300/2500): Loss: 0.2108
===> Epoch[33](400/2500): Loss: 0.2317
===> Epoch[33](500/2500): Loss: 0.2291
===> Epoch[33](600/2500): Loss: 0.2202
===> Epoch[33](700/2500): Loss: 0.2191
===> Epoch[33](800/2500): Loss: 0.2034
===> Epoch[33](900/2500): Loss: 0.2143
===> Epoch[33](1000/2500): Loss: 0.2159
===> Epoch[33](1100/2500): Loss: 0.2160
===> Epoch[33](1200/2500): Loss: 0.2099
===> Epoch[33](1300/2500): Loss: 0.2312
===> Epoch[33](1400/2500): Loss: 0.2188
===> Epoch[33](1500/2500): Loss: 0.2155
===> Epoch[33](1600/2500): Loss: 0.2222
===> Epoch[33](1700/2500): Loss: 0.2254
===> Epoch[33](1800/2500): Loss: 0.2032
===> Epoch[33](1900/2500): Loss: 0.2007
===> Epoch[33](2000/2500): Loss: 0.2042
===> Epoch[33](2100/2500): Loss: 0.1917
===> Epoch[33](2200/2500): Loss: 0.2313
===> Epoch[33](2300/2500): Loss: 0.2192
===> Epoch[33](2400/2500): Loss: 0.2162
===> Epoch[33](2500/2500): Loss: 0.2133
===> Epoch 33 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 17:51:31]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2204
===> Epoch[33](200/2500): Loss: 0.1955
===> Epoch[33](300/2500): Loss: 0.2108
===> Epoch[33](400/2500): Loss: 0.2317
===> Epoch[33](500/2500): Loss: 0.2291
===> Epoch[33](600/2500): Loss: 0.2202
===> Epoch[33](700/2500): Loss: 0.2191
===> Epoch[33](800/2500): Loss: 0.2034
===> Epoch[33](900/2500): Loss: 0.2143
===> Epoch[33](1000/2500): Loss: 0.2159
===> Epoch[33](1100/2500): Loss: 0.2160
===> Epoch[33](1200/2500): Loss: 0.2099
===> Epoch[33](1300/2500): Loss: 0.2312
===> Epoch[33](1400/2500): Loss: 0.2188
===> Epoch[33](1500/2500): Loss: 0.2155
===> Epoch[33](1600/2500): Loss: 0.2222
===> Epoch[33](1700/2500): Loss: 0.2254
===> Epoch[33](1800/2500): Loss: 0.2032
===> Epoch[33](1900/2500): Loss: 0.2007
===> Epoch[33](2000/2500): Loss: 0.2042
===> Epoch[33](2100/2500): Loss: 0.1917
===> Epoch[33](2200/2500): Loss: 0.2313
===> Epoch[33](2300/2500): Loss: 0.2192
===> Epoch[33](2400/2500): Loss: 0.2162
===> Epoch[33](2500/2500): Loss: 0.2133
===> Epoch 33 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 17:51:31]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2204
===> Epoch[33](200/2500): Loss: 0.1955
===> Epoch[33](300/2500): Loss: 0.2108
===> Epoch[33](400/2500): Loss: 0.2317
===> Epoch[33](500/2500): Loss: 0.2291
===> Epoch[33](600/2500): Loss: 0.2202
===> Epoch[33](700/2500): Loss: 0.2191
===> Epoch[33](800/2500): Loss: 0.2034
===> Epoch[33](900/2500): Loss: 0.2143
===> Epoch[33](1000/2500): Loss: 0.2159
===> Epoch[33](1100/2500): Loss: 0.2160
===> Epoch[33](1200/2500): Loss: 0.2099
===> Epoch[33](1300/2500): Loss: 0.2312
===> Epoch[33](1400/2500): Loss: 0.2188
===> Epoch[33](1500/2500): Loss: 0.2155
===> Epoch[33](1600/2500): Loss: 0.2222
===> Epoch[33](1700/2500): Loss: 0.2254
===> Epoch[33](1800/2500): Loss: 0.2032
===> Epoch[33](1900/2500): Loss: 0.2007
===> Epoch[33](2000/2500): Loss: 0.2042
===> Epoch[33](2100/2500): Loss: 0.1917
===> Epoch[33](2200/2500): Loss: 0.2313
===> Epoch[33](2300/2500): Loss: 0.2192
===> Epoch[33](2400/2500): Loss: 0.2162
===> Epoch[33](2500/2500): Loss: 0.2133
===> Epoch 33 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 17:51:31]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2204
===> Epoch[33](200/2500): Loss: 0.1955
===> Epoch[33](300/2500): Loss: 0.2108
===> Epoch[33](400/2500): Loss: 0.2317
===> Epoch[33](500/2500): Loss: 0.2291
===> Epoch[33](600/2500): Loss: 0.2202
===> Epoch[33](700/2500): Loss: 0.2191
===> Epoch[33](800/2500): Loss: 0.2034
===> Epoch[33](900/2500): Loss: 0.2143
===> Epoch[33](1000/2500): Loss: 0.2159
===> Epoch[33](1100/2500): Loss: 0.2160
===> Epoch[33](1200/2500): Loss: 0.2099
===> Epoch[33](1300/2500): Loss: 0.2312
===> Epoch[33](1400/2500): Loss: 0.2188
===> Epoch[33](1500/2500): Loss: 0.2155
===> Epoch[33](1600/2500): Loss: 0.2222
===> Epoch[33](1700/2500): Loss: 0.2254
===> Epoch[33](1800/2500): Loss: 0.2032
===> Epoch[33](1900/2500): Loss: 0.2007
===> Epoch[33](2000/2500): Loss: 0.2042
===> Epoch[33](2100/2500): Loss: 0.1917
===> Epoch[33](2200/2500): Loss: 0.2313
===> Epoch[33](2300/2500): Loss: 0.2192
===> Epoch[33](2400/2500): Loss: 0.2162
===> Epoch[33](2500/2500): Loss: 0.2133
===> Epoch 33 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 17:51:31]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2204
===> Epoch[33](200/2500): Loss: 0.1955
===> Epoch[33](300/2500): Loss: 0.2108
===> Epoch[33](400/2500): Loss: 0.2317
===> Epoch[33](500/2500): Loss: 0.2291
===> Epoch[33](600/2500): Loss: 0.2202
===> Epoch[33](700/2500): Loss: 0.2191
===> Epoch[33](800/2500): Loss: 0.2034
===> Epoch[33](900/2500): Loss: 0.2143
===> Epoch[33](1000/2500): Loss: 0.2159
===> Epoch[33](1100/2500): Loss: 0.2160
===> Epoch[33](1200/2500): Loss: 0.2099
===> Epoch[33](1300/2500): Loss: 0.2312
===> Epoch[33](1400/2500): Loss: 0.2188
===> Epoch[33](1500/2500): Loss: 0.2155
===> Epoch[33](1600/2500): Loss: 0.2222
===> Epoch[33](1700/2500): Loss: 0.2254
===> Epoch[33](1800/2500): Loss: 0.2032
===> Epoch[33](1900/2500): Loss: 0.2007
===> Epoch[33](2000/2500): Loss: 0.2042
===> Epoch[33](2100/2500): Loss: 0.1917
===> Epoch[33](2200/2500): Loss: 0.2313
===> Epoch[33](2300/2500): Loss: 0.2192
===> Epoch[33](2400/2500): Loss: 0.2162
===> Epoch[33](2500/2500): Loss: 0.2133
===> Epoch 33 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 17:51:31]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2204
===> Epoch[33](200/2500): Loss: 0.1955
===> Epoch[33](300/2500): Loss: 0.2108
===> Epoch[33](400/2500): Loss: 0.2317
===> Epoch[33](500/2500): Loss: 0.2291
===> Epoch[33](600/2500): Loss: 0.2202
===> Epoch[33](700/2500): Loss: 0.2191
===> Epoch[33](800/2500): Loss: 0.2034
===> Epoch[33](900/2500): Loss: 0.2143
===> Epoch[33](1000/2500): Loss: 0.2159
===> Epoch[33](1100/2500): Loss: 0.2160
===> Epoch[33](1200/2500): Loss: 0.2099
===> Epoch[33](1300/2500): Loss: 0.2312
===> Epoch[33](1400/2500): Loss: 0.2188
===> Epoch[33](1500/2500): Loss: 0.2155
===> Epoch[33](1600/2500): Loss: 0.2222
===> Epoch[33](1700/2500): Loss: 0.2254
===> Epoch[33](1800/2500): Loss: 0.2032
===> Epoch[33](1900/2500): Loss: 0.2007
===> Epoch[33](2000/2500): Loss: 0.2042
===> Epoch[33](2100/2500): Loss: 0.1917
===> Epoch[33](2200/2500): Loss: 0.2313
===> Epoch[33](2300/2500): Loss: 0.2192
===> Epoch[33](2400/2500): Loss: 0.2162
===> Epoch[33](2500/2500): Loss: 0.2133
===> Epoch 33 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 17:51:31]
===> Loading train datasets
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2137
===> Epoch[34](200/2500): Loss: 0.2033
===> Epoch[34](300/2500): Loss: 0.2002
===> Epoch[34](400/2500): Loss: 0.2350
===> Epoch[34](500/2500): Loss: 0.2281
===> Epoch[34](600/2500): Loss: 0.2123
===> Epoch[34](700/2500): Loss: 0.2132
===> Epoch[34](800/2500): Loss: 0.1916
===> Epoch[34](900/2500): Loss: 0.2043
===> Epoch[34](1000/2500): Loss: 0.2066
===> Epoch[34](1100/2500): Loss: 0.2124
===> Epoch[34](1200/2500): Loss: 0.1851
===> Epoch[34](1300/2500): Loss: 0.2150
===> Epoch[34](1400/2500): Loss: 0.2095
===> Epoch[34](1500/2500): Loss: 0.2135
===> Epoch[34](1600/2500): Loss: 0.2235
===> Epoch[34](1700/2500): Loss: 0.2004
===> Epoch[34](1800/2500): Loss: 0.2149
===> Epoch[34](1900/2500): Loss: 0.2029
===> Epoch[34](2000/2500): Loss: 0.2221
===> Epoch[34](2100/2500): Loss: 0.2072
===> Epoch[34](2200/2500): Loss: 0.2308
===> Epoch[34](2300/2500): Loss: 0.2252
===> Epoch[34](2400/2500): Loss: 0.2161
===> Epoch[34](2500/2500): Loss: 0.2170
===> Epoch 34 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 17:56:04]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2137
===> Epoch[34](200/2500): Loss: 0.2033
===> Epoch[34](300/2500): Loss: 0.2002
===> Epoch[34](400/2500): Loss: 0.2350
===> Epoch[34](500/2500): Loss: 0.2281
===> Epoch[34](600/2500): Loss: 0.2123
===> Epoch[34](700/2500): Loss: 0.2132
===> Epoch[34](800/2500): Loss: 0.1916
===> Epoch[34](900/2500): Loss: 0.2043
===> Epoch[34](1000/2500): Loss: 0.2066
===> Epoch[34](1100/2500): Loss: 0.2124
===> Epoch[34](1200/2500): Loss: 0.1851
===> Epoch[34](1300/2500): Loss: 0.2150
===> Epoch[34](1400/2500): Loss: 0.2095
===> Epoch[34](1500/2500): Loss: 0.2135
===> Epoch[34](1600/2500): Loss: 0.2235
===> Epoch[34](1700/2500): Loss: 0.2004
===> Epoch[34](1800/2500): Loss: 0.2149
===> Epoch[34](1900/2500): Loss: 0.2029
===> Epoch[34](2000/2500): Loss: 0.2221
===> Epoch[34](2100/2500): Loss: 0.2072
===> Epoch[34](2200/2500): Loss: 0.2308
===> Epoch[34](2300/2500): Loss: 0.2252
===> Epoch[34](2400/2500): Loss: 0.2161
===> Epoch[34](2500/2500): Loss: 0.2170
===> Epoch 34 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 17:56:04]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2137
===> Epoch[34](200/2500): Loss: 0.2033
===> Epoch[34](300/2500): Loss: 0.2002
===> Epoch[34](400/2500): Loss: 0.2350
===> Epoch[34](500/2500): Loss: 0.2281
===> Epoch[34](600/2500): Loss: 0.2123
===> Epoch[34](700/2500): Loss: 0.2132
===> Epoch[34](800/2500): Loss: 0.1916
===> Epoch[34](900/2500): Loss: 0.2043
===> Epoch[34](1000/2500): Loss: 0.2066
===> Epoch[34](1100/2500): Loss: 0.2124
===> Epoch[34](1200/2500): Loss: 0.1851
===> Epoch[34](1300/2500): Loss: 0.2150
===> Epoch[34](1400/2500): Loss: 0.2095
===> Epoch[34](1500/2500): Loss: 0.2135
===> Epoch[34](1600/2500): Loss: 0.2235
===> Epoch[34](1700/2500): Loss: 0.2004
===> Epoch[34](1800/2500): Loss: 0.2149
===> Epoch[34](1900/2500): Loss: 0.2029
===> Epoch[34](2000/2500): Loss: 0.2221
===> Epoch[34](2100/2500): Loss: 0.2072
===> Epoch[34](2200/2500): Loss: 0.2308
===> Epoch[34](2300/2500): Loss: 0.2252
===> Epoch[34](2400/2500): Loss: 0.2161
===> Epoch[34](2500/2500): Loss: 0.2170
===> Epoch 34 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 17:56:04]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2137
===> Epoch[34](200/2500): Loss: 0.2033
===> Epoch[34](300/2500): Loss: 0.2002
===> Epoch[34](400/2500): Loss: 0.2350
===> Epoch[34](500/2500): Loss: 0.2281
===> Epoch[34](600/2500): Loss: 0.2123
===> Epoch[34](700/2500): Loss: 0.2132
===> Epoch[34](800/2500): Loss: 0.1916
===> Epoch[34](900/2500): Loss: 0.2043
===> Epoch[34](1000/2500): Loss: 0.2066
===> Epoch[34](1100/2500): Loss: 0.2124
===> Epoch[34](1200/2500): Loss: 0.1851
===> Epoch[34](1300/2500): Loss: 0.2150
===> Epoch[34](1400/2500): Loss: 0.2095
===> Epoch[34](1500/2500): Loss: 0.2135
===> Epoch[34](1600/2500): Loss: 0.2235
===> Epoch[34](1700/2500): Loss: 0.2004
===> Epoch[34](1800/2500): Loss: 0.2149
===> Epoch[34](1900/2500): Loss: 0.2029
===> Epoch[34](2000/2500): Loss: 0.2221
===> Epoch[34](2100/2500): Loss: 0.2072
===> Epoch[34](2200/2500): Loss: 0.2308
===> Epoch[34](2300/2500): Loss: 0.2252
===> Epoch[34](2400/2500): Loss: 0.2161
===> Epoch[34](2500/2500): Loss: 0.2170
===> Epoch 34 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 17:56:04]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2137
===> Epoch[34](200/2500): Loss: 0.2033
===> Epoch[34](300/2500): Loss: 0.2002
===> Epoch[34](400/2500): Loss: 0.2350
===> Epoch[34](500/2500): Loss: 0.2281
===> Epoch[34](600/2500): Loss: 0.2123
===> Epoch[34](700/2500): Loss: 0.2132
===> Epoch[34](800/2500): Loss: 0.1916
===> Epoch[34](900/2500): Loss: 0.2043
===> Epoch[34](1000/2500): Loss: 0.2066
===> Epoch[34](1100/2500): Loss: 0.2124
===> Epoch[34](1200/2500): Loss: 0.1851
===> Epoch[34](1300/2500): Loss: 0.2150
===> Epoch[34](1400/2500): Loss: 0.2095
===> Epoch[34](1500/2500): Loss: 0.2135
===> Epoch[34](1600/2500): Loss: 0.2235
===> Epoch[34](1700/2500): Loss: 0.2004
===> Epoch[34](1800/2500): Loss: 0.2149
===> Epoch[34](1900/2500): Loss: 0.2029
===> Epoch[34](2000/2500): Loss: 0.2221
===> Epoch[34](2100/2500): Loss: 0.2072
===> Epoch[34](2200/2500): Loss: 0.2308
===> Epoch[34](2300/2500): Loss: 0.2252
===> Epoch[34](2400/2500): Loss: 0.2161
===> Epoch[34](2500/2500): Loss: 0.2170
===> Epoch 34 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 17:56:04]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2137
===> Epoch[34](200/2500): Loss: 0.2033
===> Epoch[34](300/2500): Loss: 0.2002
===> Epoch[34](400/2500): Loss: 0.2350
===> Epoch[34](500/2500): Loss: 0.2281
===> Epoch[34](600/2500): Loss: 0.2123
===> Epoch[34](700/2500): Loss: 0.2132
===> Epoch[34](800/2500): Loss: 0.1916
===> Epoch[34](900/2500): Loss: 0.2043
===> Epoch[34](1000/2500): Loss: 0.2066
===> Epoch[34](1100/2500): Loss: 0.2124
===> Epoch[34](1200/2500): Loss: 0.1851
===> Epoch[34](1300/2500): Loss: 0.2150
===> Epoch[34](1400/2500): Loss: 0.2095
===> Epoch[34](1500/2500): Loss: 0.2135
===> Epoch[34](1600/2500): Loss: 0.2235
===> Epoch[34](1700/2500): Loss: 0.2004
===> Epoch[34](1800/2500): Loss: 0.2149
===> Epoch[34](1900/2500): Loss: 0.2029
===> Epoch[34](2000/2500): Loss: 0.2221
===> Epoch[34](2100/2500): Loss: 0.2072
===> Epoch[34](2200/2500): Loss: 0.2308
===> Epoch[34](2300/2500): Loss: 0.2252
===> Epoch[34](2400/2500): Loss: 0.2161
===> Epoch[34](2500/2500): Loss: 0.2170
===> Epoch 34 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 17:56:04]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2137
===> Epoch[34](200/2500): Loss: 0.2033
===> Epoch[34](300/2500): Loss: 0.2002
===> Epoch[34](400/2500): Loss: 0.2350
===> Epoch[34](500/2500): Loss: 0.2281
===> Epoch[34](600/2500): Loss: 0.2123
===> Epoch[34](700/2500): Loss: 0.2132
===> Epoch[34](800/2500): Loss: 0.1916
===> Epoch[34](900/2500): Loss: 0.2043
===> Epoch[34](1000/2500): Loss: 0.2066
===> Epoch[34](1100/2500): Loss: 0.2124
===> Epoch[34](1200/2500): Loss: 0.1851
===> Epoch[34](1300/2500): Loss: 0.2150
===> Epoch[34](1400/2500): Loss: 0.2095
===> Epoch[34](1500/2500): Loss: 0.2135
===> Epoch[34](1600/2500): Loss: 0.2235
===> Epoch[34](1700/2500): Loss: 0.2004
===> Epoch[34](1800/2500): Loss: 0.2149
===> Epoch[34](1900/2500): Loss: 0.2029
===> Epoch[34](2000/2500): Loss: 0.2221
===> Epoch[34](2100/2500): Loss: 0.2072
===> Epoch[34](2200/2500): Loss: 0.2308
===> Epoch[34](2300/2500): Loss: 0.2252
===> Epoch[34](2400/2500): Loss: 0.2161
===> Epoch[34](2500/2500): Loss: 0.2170
===> Epoch 34 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 17:56:04]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2137
===> Epoch[34](200/2500): Loss: 0.2033
===> Epoch[34](300/2500): Loss: 0.2002
===> Epoch[34](400/2500): Loss: 0.2350
===> Epoch[34](500/2500): Loss: 0.2281
===> Epoch[34](600/2500): Loss: 0.2123
===> Epoch[34](700/2500): Loss: 0.2132
===> Epoch[34](800/2500): Loss: 0.1916
===> Epoch[34](900/2500): Loss: 0.2043
===> Epoch[34](1000/2500): Loss: 0.2066
===> Epoch[34](1100/2500): Loss: 0.2124
===> Epoch[34](1200/2500): Loss: 0.1851
===> Epoch[34](1300/2500): Loss: 0.2150
===> Epoch[34](1400/2500): Loss: 0.2095
===> Epoch[34](1500/2500): Loss: 0.2135
===> Epoch[34](1600/2500): Loss: 0.2235
===> Epoch[34](1700/2500): Loss: 0.2004
===> Epoch[34](1800/2500): Loss: 0.2149
===> Epoch[34](1900/2500): Loss: 0.2029
===> Epoch[34](2000/2500): Loss: 0.2221
===> Epoch[34](2100/2500): Loss: 0.2072
===> Epoch[34](2200/2500): Loss: 0.2308
===> Epoch[34](2300/2500): Loss: 0.2252
===> Epoch[34](2400/2500): Loss: 0.2161
===> Epoch[34](2500/2500): Loss: 0.2170
===> Epoch 34 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 17:56:04]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2137
===> Epoch[34](200/2500): Loss: 0.2033
===> Epoch[34](300/2500): Loss: 0.2002
===> Epoch[34](400/2500): Loss: 0.2350
===> Epoch[34](500/2500): Loss: 0.2281
===> Epoch[34](600/2500): Loss: 0.2123
===> Epoch[34](700/2500): Loss: 0.2132
===> Epoch[34](800/2500): Loss: 0.1916
===> Epoch[34](900/2500): Loss: 0.2043
===> Epoch[34](1000/2500): Loss: 0.2066
===> Epoch[34](1100/2500): Loss: 0.2124
===> Epoch[34](1200/2500): Loss: 0.1851
===> Epoch[34](1300/2500): Loss: 0.2150
===> Epoch[34](1400/2500): Loss: 0.2095
===> Epoch[34](1500/2500): Loss: 0.2135
===> Epoch[34](1600/2500): Loss: 0.2235
===> Epoch[34](1700/2500): Loss: 0.2004
===> Epoch[34](1800/2500): Loss: 0.2149
===> Epoch[34](1900/2500): Loss: 0.2029
===> Epoch[34](2000/2500): Loss: 0.2221
===> Epoch[34](2100/2500): Loss: 0.2072
===> Epoch[34](2200/2500): Loss: 0.2308
===> Epoch[34](2300/2500): Loss: 0.2252
===> Epoch[34](2400/2500): Loss: 0.2161
===> Epoch[34](2500/2500): Loss: 0.2170
===> Epoch 34 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 17:56:04]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2137
===> Epoch[34](200/2500): Loss: 0.2033
===> Epoch[34](300/2500): Loss: 0.2002
===> Epoch[34](400/2500): Loss: 0.2350
===> Epoch[34](500/2500): Loss: 0.2281
===> Epoch[34](600/2500): Loss: 0.2123
===> Epoch[34](700/2500): Loss: 0.2132
===> Epoch[34](800/2500): Loss: 0.1916
===> Epoch[34](900/2500): Loss: 0.2043
===> Epoch[34](1000/2500): Loss: 0.2066
===> Epoch[34](1100/2500): Loss: 0.2124
===> Epoch[34](1200/2500): Loss: 0.1851
===> Epoch[34](1300/2500): Loss: 0.2150
===> Epoch[34](1400/2500): Loss: 0.2095
===> Epoch[34](1500/2500): Loss: 0.2135
===> Epoch[34](1600/2500): Loss: 0.2235
===> Epoch[34](1700/2500): Loss: 0.2004
===> Epoch[34](1800/2500): Loss: 0.2149
===> Epoch[34](1900/2500): Loss: 0.2029
===> Epoch[34](2000/2500): Loss: 0.2221
===> Epoch[34](2100/2500): Loss: 0.2072
===> Epoch[34](2200/2500): Loss: 0.2308
===> Epoch[34](2300/2500): Loss: 0.2252
===> Epoch[34](2400/2500): Loss: 0.2161
===> Epoch[34](2500/2500): Loss: 0.2170
===> Epoch 34 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 17:56:04]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2137
===> Epoch[34](200/2500): Loss: 0.2033
===> Epoch[34](300/2500): Loss: 0.2002
===> Epoch[34](400/2500): Loss: 0.2350
===> Epoch[34](500/2500): Loss: 0.2281
===> Epoch[34](600/2500): Loss: 0.2123
===> Epoch[34](700/2500): Loss: 0.2132
===> Epoch[34](800/2500): Loss: 0.1916
===> Epoch[34](900/2500): Loss: 0.2043
===> Epoch[34](1000/2500): Loss: 0.2066
===> Epoch[34](1100/2500): Loss: 0.2124
===> Epoch[34](1200/2500): Loss: 0.1851
===> Epoch[34](1300/2500): Loss: 0.2150
===> Epoch[34](1400/2500): Loss: 0.2095
===> Epoch[34](1500/2500): Loss: 0.2135
===> Epoch[34](1600/2500): Loss: 0.2235
===> Epoch[34](1700/2500): Loss: 0.2004
===> Epoch[34](1800/2500): Loss: 0.2149
===> Epoch[34](1900/2500): Loss: 0.2029
===> Epoch[34](2000/2500): Loss: 0.2221
===> Epoch[34](2100/2500): Loss: 0.2072
===> Epoch[34](2200/2500): Loss: 0.2308
===> Epoch[34](2300/2500): Loss: 0.2252
===> Epoch[34](2400/2500): Loss: 0.2161
===> Epoch[34](2500/2500): Loss: 0.2170
===> Epoch 34 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 17:56:04]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2137
===> Epoch[34](200/2500): Loss: 0.2033
===> Epoch[34](300/2500): Loss: 0.2002
===> Epoch[34](400/2500): Loss: 0.2350
===> Epoch[34](500/2500): Loss: 0.2281
===> Epoch[34](600/2500): Loss: 0.2123
===> Epoch[34](700/2500): Loss: 0.2132
===> Epoch[34](800/2500): Loss: 0.1916
===> Epoch[34](900/2500): Loss: 0.2043
===> Epoch[34](1000/2500): Loss: 0.2066
===> Epoch[34](1100/2500): Loss: 0.2124
===> Epoch[34](1200/2500): Loss: 0.1851
===> Epoch[34](1300/2500): Loss: 0.2150
===> Epoch[34](1400/2500): Loss: 0.2095
===> Epoch[34](1500/2500): Loss: 0.2135
===> Epoch[34](1600/2500): Loss: 0.2235
===> Epoch[34](1700/2500): Loss: 0.2004
===> Epoch[34](1800/2500): Loss: 0.2149
===> Epoch[34](1900/2500): Loss: 0.2029
===> Epoch[34](2000/2500): Loss: 0.2221
===> Epoch[34](2100/2500): Loss: 0.2072
===> Epoch[34](2200/2500): Loss: 0.2308
===> Epoch[34](2300/2500): Loss: 0.2252
===> Epoch[34](2400/2500): Loss: 0.2161
===> Epoch[34](2500/2500): Loss: 0.2170
===> Epoch 34 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 17:56:04]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2137
===> Epoch[34](200/2500): Loss: 0.2033
===> Epoch[34](300/2500): Loss: 0.2002
===> Epoch[34](400/2500): Loss: 0.2350
===> Epoch[34](500/2500): Loss: 0.2281
===> Epoch[34](600/2500): Loss: 0.2123
===> Epoch[34](700/2500): Loss: 0.2132
===> Epoch[34](800/2500): Loss: 0.1916
===> Epoch[34](900/2500): Loss: 0.2043
===> Epoch[34](1000/2500): Loss: 0.2066
===> Epoch[34](1100/2500): Loss: 0.2124
===> Epoch[34](1200/2500): Loss: 0.1851
===> Epoch[34](1300/2500): Loss: 0.2150
===> Epoch[34](1400/2500): Loss: 0.2095
===> Epoch[34](1500/2500): Loss: 0.2135
===> Epoch[34](1600/2500): Loss: 0.2235
===> Epoch[34](1700/2500): Loss: 0.2004
===> Epoch[34](1800/2500): Loss: 0.2149
===> Epoch[34](1900/2500): Loss: 0.2029
===> Epoch[34](2000/2500): Loss: 0.2221
===> Epoch[34](2100/2500): Loss: 0.2072
===> Epoch[34](2200/2500): Loss: 0.2308
===> Epoch[34](2300/2500): Loss: 0.2252
===> Epoch[34](2400/2500): Loss: 0.2161
===> Epoch[34](2500/2500): Loss: 0.2170
===> Epoch 34 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 17:56:04]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2137
===> Epoch[34](200/2500): Loss: 0.2033
===> Epoch[34](300/2500): Loss: 0.2002
===> Epoch[34](400/2500): Loss: 0.2350
===> Epoch[34](500/2500): Loss: 0.2281
===> Epoch[34](600/2500): Loss: 0.2123
===> Epoch[34](700/2500): Loss: 0.2132
===> Epoch[34](800/2500): Loss: 0.1916
===> Epoch[34](900/2500): Loss: 0.2043
===> Epoch[34](1000/2500): Loss: 0.2066
===> Epoch[34](1100/2500): Loss: 0.2124
===> Epoch[34](1200/2500): Loss: 0.1851
===> Epoch[34](1300/2500): Loss: 0.2150
===> Epoch[34](1400/2500): Loss: 0.2095
===> Epoch[34](1500/2500): Loss: 0.2135
===> Epoch[34](1600/2500): Loss: 0.2235
===> Epoch[34](1700/2500): Loss: 0.2004
===> Epoch[34](1800/2500): Loss: 0.2149
===> Epoch[34](1900/2500): Loss: 0.2029
===> Epoch[34](2000/2500): Loss: 0.2221
===> Epoch[34](2100/2500): Loss: 0.2072
===> Epoch[34](2200/2500): Loss: 0.2308
===> Epoch[34](2300/2500): Loss: 0.2252
===> Epoch[34](2400/2500): Loss: 0.2161
===> Epoch[34](2500/2500): Loss: 0.2170
===> Epoch 34 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 17:56:04]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2137
===> Epoch[34](200/2500): Loss: 0.2033
===> Epoch[34](300/2500): Loss: 0.2002
===> Epoch[34](400/2500): Loss: 0.2350
===> Epoch[34](500/2500): Loss: 0.2281
===> Epoch[34](600/2500): Loss: 0.2123
===> Epoch[34](700/2500): Loss: 0.2132
===> Epoch[34](800/2500): Loss: 0.1916
===> Epoch[34](900/2500): Loss: 0.2043
===> Epoch[34](1000/2500): Loss: 0.2066
===> Epoch[34](1100/2500): Loss: 0.2124
===> Epoch[34](1200/2500): Loss: 0.1851
===> Epoch[34](1300/2500): Loss: 0.2150
===> Epoch[34](1400/2500): Loss: 0.2095
===> Epoch[34](1500/2500): Loss: 0.2135
===> Epoch[34](1600/2500): Loss: 0.2235
===> Epoch[34](1700/2500): Loss: 0.2004
===> Epoch[34](1800/2500): Loss: 0.2149
===> Epoch[34](1900/2500): Loss: 0.2029
===> Epoch[34](2000/2500): Loss: 0.2221
===> Epoch[34](2100/2500): Loss: 0.2072
===> Epoch[34](2200/2500): Loss: 0.2308
===> Epoch[34](2300/2500): Loss: 0.2252
===> Epoch[34](2400/2500): Loss: 0.2161
===> Epoch[34](2500/2500): Loss: 0.2170
===> Epoch 34 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 17:56:04]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2137
===> Epoch[34](200/2500): Loss: 0.2033
===> Epoch[34](300/2500): Loss: 0.2002
===> Epoch[34](400/2500): Loss: 0.2350
===> Epoch[34](500/2500): Loss: 0.2281
===> Epoch[34](600/2500): Loss: 0.2123
===> Epoch[34](700/2500): Loss: 0.2132
===> Epoch[34](800/2500): Loss: 0.1916
===> Epoch[34](900/2500): Loss: 0.2043
===> Epoch[34](1000/2500): Loss: 0.2066
===> Epoch[34](1100/2500): Loss: 0.2124
===> Epoch[34](1200/2500): Loss: 0.1851
===> Epoch[34](1300/2500): Loss: 0.2150
===> Epoch[34](1400/2500): Loss: 0.2095
===> Epoch[34](1500/2500): Loss: 0.2135
===> Epoch[34](1600/2500): Loss: 0.2235
===> Epoch[34](1700/2500): Loss: 0.2004
===> Epoch[34](1800/2500): Loss: 0.2149
===> Epoch[34](1900/2500): Loss: 0.2029
===> Epoch[34](2000/2500): Loss: 0.2221
===> Epoch[34](2100/2500): Loss: 0.2072
===> Epoch[34](2200/2500): Loss: 0.2308
===> Epoch[34](2300/2500): Loss: 0.2252
===> Epoch[34](2400/2500): Loss: 0.2161
===> Epoch[34](2500/2500): Loss: 0.2170
===> Epoch 34 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 17:56:04]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2137
===> Epoch[34](200/2500): Loss: 0.2033
===> Epoch[34](300/2500): Loss: 0.2002
===> Epoch[34](400/2500): Loss: 0.2350
===> Epoch[34](500/2500): Loss: 0.2281
===> Epoch[34](600/2500): Loss: 0.2123
===> Epoch[34](700/2500): Loss: 0.2132
===> Epoch[34](800/2500): Loss: 0.1916
===> Epoch[34](900/2500): Loss: 0.2043
===> Epoch[34](1000/2500): Loss: 0.2066
===> Epoch[34](1100/2500): Loss: 0.2124
===> Epoch[34](1200/2500): Loss: 0.1851
===> Epoch[34](1300/2500): Loss: 0.2150
===> Epoch[34](1400/2500): Loss: 0.2095
===> Epoch[34](1500/2500): Loss: 0.2135
===> Epoch[34](1600/2500): Loss: 0.2235
===> Epoch[34](1700/2500): Loss: 0.2004
===> Epoch[34](1800/2500): Loss: 0.2149
===> Epoch[34](1900/2500): Loss: 0.2029
===> Epoch[34](2000/2500): Loss: 0.2221
===> Epoch[34](2100/2500): Loss: 0.2072
===> Epoch[34](2200/2500): Loss: 0.2308
===> Epoch[34](2300/2500): Loss: 0.2252
===> Epoch[34](2400/2500): Loss: 0.2161
===> Epoch[34](2500/2500): Loss: 0.2170
===> Epoch 34 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 17:56:04]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2137
===> Epoch[34](200/2500): Loss: 0.2033
===> Epoch[34](300/2500): Loss: 0.2002
===> Epoch[34](400/2500): Loss: 0.2350
===> Epoch[34](500/2500): Loss: 0.2281
===> Epoch[34](600/2500): Loss: 0.2123
===> Epoch[34](700/2500): Loss: 0.2132
===> Epoch[34](800/2500): Loss: 0.1916
===> Epoch[34](900/2500): Loss: 0.2043
===> Epoch[34](1000/2500): Loss: 0.2066
===> Epoch[34](1100/2500): Loss: 0.2124
===> Epoch[34](1200/2500): Loss: 0.1851
===> Epoch[34](1300/2500): Loss: 0.2150
===> Epoch[34](1400/2500): Loss: 0.2095
===> Epoch[34](1500/2500): Loss: 0.2135
===> Epoch[34](1600/2500): Loss: 0.2235
===> Epoch[34](1700/2500): Loss: 0.2004
===> Epoch[34](1800/2500): Loss: 0.2149
===> Epoch[34](1900/2500): Loss: 0.2029
===> Epoch[34](2000/2500): Loss: 0.2221
===> Epoch[34](2100/2500): Loss: 0.2072
===> Epoch[34](2200/2500): Loss: 0.2308
===> Epoch[34](2300/2500): Loss: 0.2252
===> Epoch[34](2400/2500): Loss: 0.2161
===> Epoch[34](2500/2500): Loss: 0.2170
===> Epoch 34 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 17:56:04]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2137
===> Epoch[34](200/2500): Loss: 0.2033
===> Epoch[34](300/2500): Loss: 0.2002
===> Epoch[34](400/2500): Loss: 0.2350
===> Epoch[34](500/2500): Loss: 0.2281
===> Epoch[34](600/2500): Loss: 0.2123
===> Epoch[34](700/2500): Loss: 0.2132
===> Epoch[34](800/2500): Loss: 0.1916
===> Epoch[34](900/2500): Loss: 0.2043
===> Epoch[34](1000/2500): Loss: 0.2066
===> Epoch[34](1100/2500): Loss: 0.2124
===> Epoch[34](1200/2500): Loss: 0.1851
===> Epoch[34](1300/2500): Loss: 0.2150
===> Epoch[34](1400/2500): Loss: 0.2095
===> Epoch[34](1500/2500): Loss: 0.2135
===> Epoch[34](1600/2500): Loss: 0.2235
===> Epoch[34](1700/2500): Loss: 0.2004
===> Epoch[34](1800/2500): Loss: 0.2149
===> Epoch[34](1900/2500): Loss: 0.2029
===> Epoch[34](2000/2500): Loss: 0.2221
===> Epoch[34](2100/2500): Loss: 0.2072
===> Epoch[34](2200/2500): Loss: 0.2308
===> Epoch[34](2300/2500): Loss: 0.2252
===> Epoch[34](2400/2500): Loss: 0.2161
===> Epoch[34](2500/2500): Loss: 0.2170
===> Epoch 34 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 17:56:04]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2137
===> Epoch[34](200/2500): Loss: 0.2033
===> Epoch[34](300/2500): Loss: 0.2002
===> Epoch[34](400/2500): Loss: 0.2350
===> Epoch[34](500/2500): Loss: 0.2281
===> Epoch[34](600/2500): Loss: 0.2123
===> Epoch[34](700/2500): Loss: 0.2132
===> Epoch[34](800/2500): Loss: 0.1916
===> Epoch[34](900/2500): Loss: 0.2043
===> Epoch[34](1000/2500): Loss: 0.2066
===> Epoch[34](1100/2500): Loss: 0.2124
===> Epoch[34](1200/2500): Loss: 0.1851
===> Epoch[34](1300/2500): Loss: 0.2150
===> Epoch[34](1400/2500): Loss: 0.2095
===> Epoch[34](1500/2500): Loss: 0.2135
===> Epoch[34](1600/2500): Loss: 0.2235
===> Epoch[34](1700/2500): Loss: 0.2004
===> Epoch[34](1800/2500): Loss: 0.2149
===> Epoch[34](1900/2500): Loss: 0.2029
===> Epoch[34](2000/2500): Loss: 0.2221
===> Epoch[34](2100/2500): Loss: 0.2072
===> Epoch[34](2200/2500): Loss: 0.2308
===> Epoch[34](2300/2500): Loss: 0.2252
===> Epoch[34](2400/2500): Loss: 0.2161
===> Epoch[34](2500/2500): Loss: 0.2170
===> Epoch 34 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 17:56:04]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2137
===> Epoch[34](200/2500): Loss: 0.2033
===> Epoch[34](300/2500): Loss: 0.2002
===> Epoch[34](400/2500): Loss: 0.2350
===> Epoch[34](500/2500): Loss: 0.2281
===> Epoch[34](600/2500): Loss: 0.2123
===> Epoch[34](700/2500): Loss: 0.2132
===> Epoch[34](800/2500): Loss: 0.1916
===> Epoch[34](900/2500): Loss: 0.2043
===> Epoch[34](1000/2500): Loss: 0.2066
===> Epoch[34](1100/2500): Loss: 0.2124
===> Epoch[34](1200/2500): Loss: 0.1851
===> Epoch[34](1300/2500): Loss: 0.2150
===> Epoch[34](1400/2500): Loss: 0.2095
===> Epoch[34](1500/2500): Loss: 0.2135
===> Epoch[34](1600/2500): Loss: 0.2235
===> Epoch[34](1700/2500): Loss: 0.2004
===> Epoch[34](1800/2500): Loss: 0.2149
===> Epoch[34](1900/2500): Loss: 0.2029
===> Epoch[34](2000/2500): Loss: 0.2221
===> Epoch[34](2100/2500): Loss: 0.2072
===> Epoch[34](2200/2500): Loss: 0.2308
===> Epoch[34](2300/2500): Loss: 0.2252
===> Epoch[34](2400/2500): Loss: 0.2161
===> Epoch[34](2500/2500): Loss: 0.2170
===> Epoch 34 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 17:56:04]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2137
===> Epoch[34](200/2500): Loss: 0.2033
===> Epoch[34](300/2500): Loss: 0.2002
===> Epoch[34](400/2500): Loss: 0.2350
===> Epoch[34](500/2500): Loss: 0.2281
===> Epoch[34](600/2500): Loss: 0.2123
===> Epoch[34](700/2500): Loss: 0.2132
===> Epoch[34](800/2500): Loss: 0.1916
===> Epoch[34](900/2500): Loss: 0.2043
===> Epoch[34](1000/2500): Loss: 0.2066
===> Epoch[34](1100/2500): Loss: 0.2124
===> Epoch[34](1200/2500): Loss: 0.1851
===> Epoch[34](1300/2500): Loss: 0.2150
===> Epoch[34](1400/2500): Loss: 0.2095
===> Epoch[34](1500/2500): Loss: 0.2135
===> Epoch[34](1600/2500): Loss: 0.2235
===> Epoch[34](1700/2500): Loss: 0.2004
===> Epoch[34](1800/2500): Loss: 0.2149
===> Epoch[34](1900/2500): Loss: 0.2029
===> Epoch[34](2000/2500): Loss: 0.2221
===> Epoch[34](2100/2500): Loss: 0.2072
===> Epoch[34](2200/2500): Loss: 0.2308
===> Epoch[34](2300/2500): Loss: 0.2252
===> Epoch[34](2400/2500): Loss: 0.2161
===> Epoch[34](2500/2500): Loss: 0.2170
===> Epoch 34 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 17:56:04]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2137
===> Epoch[34](200/2500): Loss: 0.2033
===> Epoch[34](300/2500): Loss: 0.2002
===> Epoch[34](400/2500): Loss: 0.2350
===> Epoch[34](500/2500): Loss: 0.2281
===> Epoch[34](600/2500): Loss: 0.2123
===> Epoch[34](700/2500): Loss: 0.2132
===> Epoch[34](800/2500): Loss: 0.1916
===> Epoch[34](900/2500): Loss: 0.2043
===> Epoch[34](1000/2500): Loss: 0.2066
===> Epoch[34](1100/2500): Loss: 0.2124
===> Epoch[34](1200/2500): Loss: 0.1851
===> Epoch[34](1300/2500): Loss: 0.2150
===> Epoch[34](1400/2500): Loss: 0.2095
===> Epoch[34](1500/2500): Loss: 0.2135
===> Epoch[34](1600/2500): Loss: 0.2235
===> Epoch[34](1700/2500): Loss: 0.2004
===> Epoch[34](1800/2500): Loss: 0.2149
===> Epoch[34](1900/2500): Loss: 0.2029
===> Epoch[34](2000/2500): Loss: 0.2221
===> Epoch[34](2100/2500): Loss: 0.2072
===> Epoch[34](2200/2500): Loss: 0.2308
===> Epoch[34](2300/2500): Loss: 0.2252
===> Epoch[34](2400/2500): Loss: 0.2161
===> Epoch[34](2500/2500): Loss: 0.2170
===> Epoch 34 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 17:56:04]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2137
===> Epoch[34](200/2500): Loss: 0.2033
===> Epoch[34](300/2500): Loss: 0.2002
===> Epoch[34](400/2500): Loss: 0.2350
===> Epoch[34](500/2500): Loss: 0.2281
===> Epoch[34](600/2500): Loss: 0.2123
===> Epoch[34](700/2500): Loss: 0.2132
===> Epoch[34](800/2500): Loss: 0.1916
===> Epoch[34](900/2500): Loss: 0.2043
===> Epoch[34](1000/2500): Loss: 0.2066
===> Epoch[34](1100/2500): Loss: 0.2124
===> Epoch[34](1200/2500): Loss: 0.1851
===> Epoch[34](1300/2500): Loss: 0.2150
===> Epoch[34](1400/2500): Loss: 0.2095
===> Epoch[34](1500/2500): Loss: 0.2135
===> Epoch[34](1600/2500): Loss: 0.2235
===> Epoch[34](1700/2500): Loss: 0.2004
===> Epoch[34](1800/2500): Loss: 0.2149
===> Epoch[34](1900/2500): Loss: 0.2029
===> Epoch[34](2000/2500): Loss: 0.2221
===> Epoch[34](2100/2500): Loss: 0.2072
===> Epoch[34](2200/2500): Loss: 0.2308
===> Epoch[34](2300/2500): Loss: 0.2252
===> Epoch[34](2400/2500): Loss: 0.2161
===> Epoch[34](2500/2500): Loss: 0.2170
===> Epoch 34 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 17:56:04]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2137
===> Epoch[34](200/2500): Loss: 0.2033
===> Epoch[34](300/2500): Loss: 0.2002
===> Epoch[34](400/2500): Loss: 0.2350
===> Epoch[34](500/2500): Loss: 0.2281
===> Epoch[34](600/2500): Loss: 0.2123
===> Epoch[34](700/2500): Loss: 0.2132
===> Epoch[34](800/2500): Loss: 0.1916
===> Epoch[34](900/2500): Loss: 0.2043
===> Epoch[34](1000/2500): Loss: 0.2066
===> Epoch[34](1100/2500): Loss: 0.2124
===> Epoch[34](1200/2500): Loss: 0.1851
===> Epoch[34](1300/2500): Loss: 0.2150
===> Epoch[34](1400/2500): Loss: 0.2095
===> Epoch[34](1500/2500): Loss: 0.2135
===> Epoch[34](1600/2500): Loss: 0.2235
===> Epoch[34](1700/2500): Loss: 0.2004
===> Epoch[34](1800/2500): Loss: 0.2149
===> Epoch[34](1900/2500): Loss: 0.2029
===> Epoch[34](2000/2500): Loss: 0.2221
===> Epoch[34](2100/2500): Loss: 0.2072
===> Epoch[34](2200/2500): Loss: 0.2308
===> Epoch[34](2300/2500): Loss: 0.2252
===> Epoch[34](2400/2500): Loss: 0.2161
===> Epoch[34](2500/2500): Loss: 0.2170
===> Epoch 34 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 17:56:04]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2137
===> Epoch[34](200/2500): Loss: 0.2033
===> Epoch[34](300/2500): Loss: 0.2002
===> Epoch[34](400/2500): Loss: 0.2350
===> Epoch[34](500/2500): Loss: 0.2281
===> Epoch[34](600/2500): Loss: 0.2123
===> Epoch[34](700/2500): Loss: 0.2132
===> Epoch[34](800/2500): Loss: 0.1916
===> Epoch[34](900/2500): Loss: 0.2043
===> Epoch[34](1000/2500): Loss: 0.2066
===> Epoch[34](1100/2500): Loss: 0.2124
===> Epoch[34](1200/2500): Loss: 0.1851
===> Epoch[34](1300/2500): Loss: 0.2150
===> Epoch[34](1400/2500): Loss: 0.2095
===> Epoch[34](1500/2500): Loss: 0.2135
===> Epoch[34](1600/2500): Loss: 0.2235
===> Epoch[34](1700/2500): Loss: 0.2004
===> Epoch[34](1800/2500): Loss: 0.2149
===> Epoch[34](1900/2500): Loss: 0.2029
===> Epoch[34](2000/2500): Loss: 0.2221
===> Epoch[34](2100/2500): Loss: 0.2072
===> Epoch[34](2200/2500): Loss: 0.2308
===> Epoch[34](2300/2500): Loss: 0.2252
===> Epoch[34](2400/2500): Loss: 0.2161
===> Epoch[34](2500/2500): Loss: 0.2170
===> Epoch 34 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 17:56:04]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2137
===> Epoch[34](200/2500): Loss: 0.2033
===> Epoch[34](300/2500): Loss: 0.2002
===> Epoch[34](400/2500): Loss: 0.2350
===> Epoch[34](500/2500): Loss: 0.2281
===> Epoch[34](600/2500): Loss: 0.2123
===> Epoch[34](700/2500): Loss: 0.2132
===> Epoch[34](800/2500): Loss: 0.1916
===> Epoch[34](900/2500): Loss: 0.2043
===> Epoch[34](1000/2500): Loss: 0.2066
===> Epoch[34](1100/2500): Loss: 0.2124
===> Epoch[34](1200/2500): Loss: 0.1851
===> Epoch[34](1300/2500): Loss: 0.2150
===> Epoch[34](1400/2500): Loss: 0.2095
===> Epoch[34](1500/2500): Loss: 0.2135
===> Epoch[34](1600/2500): Loss: 0.2235
===> Epoch[34](1700/2500): Loss: 0.2004
===> Epoch[34](1800/2500): Loss: 0.2149
===> Epoch[34](1900/2500): Loss: 0.2029
===> Epoch[34](2000/2500): Loss: 0.2221
===> Epoch[34](2100/2500): Loss: 0.2072
===> Epoch[34](2200/2500): Loss: 0.2308
===> Epoch[34](2300/2500): Loss: 0.2252
===> Epoch[34](2400/2500): Loss: 0.2161
===> Epoch[34](2500/2500): Loss: 0.2170
===> Epoch 34 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 17:56:04]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2137
===> Epoch[34](200/2500): Loss: 0.2033
===> Epoch[34](300/2500): Loss: 0.2002
===> Epoch[34](400/2500): Loss: 0.2350
===> Epoch[34](500/2500): Loss: 0.2281
===> Epoch[34](600/2500): Loss: 0.2123
===> Epoch[34](700/2500): Loss: 0.2132
===> Epoch[34](800/2500): Loss: 0.1916
===> Epoch[34](900/2500): Loss: 0.2043
===> Epoch[34](1000/2500): Loss: 0.2066
===> Epoch[34](1100/2500): Loss: 0.2124
===> Epoch[34](1200/2500): Loss: 0.1851
===> Epoch[34](1300/2500): Loss: 0.2150
===> Epoch[34](1400/2500): Loss: 0.2095
===> Epoch[34](1500/2500): Loss: 0.2135
===> Epoch[34](1600/2500): Loss: 0.2235
===> Epoch[34](1700/2500): Loss: 0.2004
===> Epoch[34](1800/2500): Loss: 0.2149
===> Epoch[34](1900/2500): Loss: 0.2029
===> Epoch[34](2000/2500): Loss: 0.2221
===> Epoch[34](2100/2500): Loss: 0.2072
===> Epoch[34](2200/2500): Loss: 0.2308
===> Epoch[34](2300/2500): Loss: 0.2252
===> Epoch[34](2400/2500): Loss: 0.2161
===> Epoch[34](2500/2500): Loss: 0.2170
===> Epoch 34 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 17:56:04]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2137
===> Epoch[34](200/2500): Loss: 0.2033
===> Epoch[34](300/2500): Loss: 0.2002
===> Epoch[34](400/2500): Loss: 0.2350
===> Epoch[34](500/2500): Loss: 0.2281
===> Epoch[34](600/2500): Loss: 0.2123
===> Epoch[34](700/2500): Loss: 0.2132
===> Epoch[34](800/2500): Loss: 0.1916
===> Epoch[34](900/2500): Loss: 0.2043
===> Epoch[34](1000/2500): Loss: 0.2066
===> Epoch[34](1100/2500): Loss: 0.2124
===> Epoch[34](1200/2500): Loss: 0.1851
===> Epoch[34](1300/2500): Loss: 0.2150
===> Epoch[34](1400/2500): Loss: 0.2095
===> Epoch[34](1500/2500): Loss: 0.2135
===> Epoch[34](1600/2500): Loss: 0.2235
===> Epoch[34](1700/2500): Loss: 0.2004
===> Epoch[34](1800/2500): Loss: 0.2149
===> Epoch[34](1900/2500): Loss: 0.2029
===> Epoch[34](2000/2500): Loss: 0.2221
===> Epoch[34](2100/2500): Loss: 0.2072
===> Epoch[34](2200/2500): Loss: 0.2308
===> Epoch[34](2300/2500): Loss: 0.2252
===> Epoch[34](2400/2500): Loss: 0.2161
===> Epoch[34](2500/2500): Loss: 0.2170
===> Epoch 34 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 17:56:04]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2137
===> Epoch[34](200/2500): Loss: 0.2033
===> Epoch[34](300/2500): Loss: 0.2002
===> Epoch[34](400/2500): Loss: 0.2350
===> Epoch[34](500/2500): Loss: 0.2281
===> Epoch[34](600/2500): Loss: 0.2123
===> Epoch[34](700/2500): Loss: 0.2132
===> Epoch[34](800/2500): Loss: 0.1916
===> Epoch[34](900/2500): Loss: 0.2043
===> Epoch[34](1000/2500): Loss: 0.2066
===> Epoch[34](1100/2500): Loss: 0.2124
===> Epoch[34](1200/2500): Loss: 0.1851
===> Epoch[34](1300/2500): Loss: 0.2150
===> Epoch[34](1400/2500): Loss: 0.2095
===> Epoch[34](1500/2500): Loss: 0.2135
===> Epoch[34](1600/2500): Loss: 0.2235
===> Epoch[34](1700/2500): Loss: 0.2004
===> Epoch[34](1800/2500): Loss: 0.2149
===> Epoch[34](1900/2500): Loss: 0.2029
===> Epoch[34](2000/2500): Loss: 0.2221
===> Epoch[34](2100/2500): Loss: 0.2072
===> Epoch[34](2200/2500): Loss: 0.2308
===> Epoch[34](2300/2500): Loss: 0.2252
===> Epoch[34](2400/2500): Loss: 0.2161
===> Epoch[34](2500/2500): Loss: 0.2170
===> Epoch 34 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 17:56:04]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2137
===> Epoch[34](200/2500): Loss: 0.2033
===> Epoch[34](300/2500): Loss: 0.2002
===> Epoch[34](400/2500): Loss: 0.2350
===> Epoch[34](500/2500): Loss: 0.2281
===> Epoch[34](600/2500): Loss: 0.2123
===> Epoch[34](700/2500): Loss: 0.2132
===> Epoch[34](800/2500): Loss: 0.1916
===> Epoch[34](900/2500): Loss: 0.2043
===> Epoch[34](1000/2500): Loss: 0.2066
===> Epoch[34](1100/2500): Loss: 0.2124
===> Epoch[34](1200/2500): Loss: 0.1851
===> Epoch[34](1300/2500): Loss: 0.2150
===> Epoch[34](1400/2500): Loss: 0.2095
===> Epoch[34](1500/2500): Loss: 0.2135
===> Epoch[34](1600/2500): Loss: 0.2235
===> Epoch[34](1700/2500): Loss: 0.2004
===> Epoch[34](1800/2500): Loss: 0.2149
===> Epoch[34](1900/2500): Loss: 0.2029
===> Epoch[34](2000/2500): Loss: 0.2221
===> Epoch[34](2100/2500): Loss: 0.2072
===> Epoch[34](2200/2500): Loss: 0.2308
===> Epoch[34](2300/2500): Loss: 0.2252
===> Epoch[34](2400/2500): Loss: 0.2161
===> Epoch[34](2500/2500): Loss: 0.2170
===> Epoch 34 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 17:56:04]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2137
===> Epoch[34](200/2500): Loss: 0.2033
===> Epoch[34](300/2500): Loss: 0.2002
===> Epoch[34](400/2500): Loss: 0.2350
===> Epoch[34](500/2500): Loss: 0.2281
===> Epoch[34](600/2500): Loss: 0.2123
===> Epoch[34](700/2500): Loss: 0.2132
===> Epoch[34](800/2500): Loss: 0.1916
===> Epoch[34](900/2500): Loss: 0.2043
===> Epoch[34](1000/2500): Loss: 0.2066
===> Epoch[34](1100/2500): Loss: 0.2124
===> Epoch[34](1200/2500): Loss: 0.1851
===> Epoch[34](1300/2500): Loss: 0.2150
===> Epoch[34](1400/2500): Loss: 0.2095
===> Epoch[34](1500/2500): Loss: 0.2135
===> Epoch[34](1600/2500): Loss: 0.2235
===> Epoch[34](1700/2500): Loss: 0.2004
===> Epoch[34](1800/2500): Loss: 0.2149
===> Epoch[34](1900/2500): Loss: 0.2029
===> Epoch[34](2000/2500): Loss: 0.2221
===> Epoch[34](2100/2500): Loss: 0.2072
===> Epoch[34](2200/2500): Loss: 0.2308
===> Epoch[34](2300/2500): Loss: 0.2252
===> Epoch[34](2400/2500): Loss: 0.2161
===> Epoch[34](2500/2500): Loss: 0.2170
===> Epoch 34 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 17:56:04]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2137
===> Epoch[34](200/2500): Loss: 0.2033
===> Epoch[34](300/2500): Loss: 0.2002
===> Epoch[34](400/2500): Loss: 0.2350
===> Epoch[34](500/2500): Loss: 0.2281
===> Epoch[34](600/2500): Loss: 0.2123
===> Epoch[34](700/2500): Loss: 0.2132
===> Epoch[34](800/2500): Loss: 0.1916
===> Epoch[34](900/2500): Loss: 0.2043
===> Epoch[34](1000/2500): Loss: 0.2066
===> Epoch[34](1100/2500): Loss: 0.2124
===> Epoch[34](1200/2500): Loss: 0.1851
===> Epoch[34](1300/2500): Loss: 0.2150
===> Epoch[34](1400/2500): Loss: 0.2095
===> Epoch[34](1500/2500): Loss: 0.2135
===> Epoch[34](1600/2500): Loss: 0.2235
===> Epoch[34](1700/2500): Loss: 0.2004
===> Epoch[34](1800/2500): Loss: 0.2149
===> Epoch[34](1900/2500): Loss: 0.2029
===> Epoch[34](2000/2500): Loss: 0.2221
===> Epoch[34](2100/2500): Loss: 0.2072
===> Epoch[34](2200/2500): Loss: 0.2308
===> Epoch[34](2300/2500): Loss: 0.2252
===> Epoch[34](2400/2500): Loss: 0.2161
===> Epoch[34](2500/2500): Loss: 0.2170
===> Epoch 34 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 17:56:04]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2137
===> Epoch[34](200/2500): Loss: 0.2033
===> Epoch[34](300/2500): Loss: 0.2002
===> Epoch[34](400/2500): Loss: 0.2350
===> Epoch[34](500/2500): Loss: 0.2281
===> Epoch[34](600/2500): Loss: 0.2123
===> Epoch[34](700/2500): Loss: 0.2132
===> Epoch[34](800/2500): Loss: 0.1916
===> Epoch[34](900/2500): Loss: 0.2043
===> Epoch[34](1000/2500): Loss: 0.2066
===> Epoch[34](1100/2500): Loss: 0.2124
===> Epoch[34](1200/2500): Loss: 0.1851
===> Epoch[34](1300/2500): Loss: 0.2150
===> Epoch[34](1400/2500): Loss: 0.2095
===> Epoch[34](1500/2500): Loss: 0.2135
===> Epoch[34](1600/2500): Loss: 0.2235
===> Epoch[34](1700/2500): Loss: 0.2004
===> Epoch[34](1800/2500): Loss: 0.2149
===> Epoch[34](1900/2500): Loss: 0.2029
===> Epoch[34](2000/2500): Loss: 0.2221
===> Epoch[34](2100/2500): Loss: 0.2072
===> Epoch[34](2200/2500): Loss: 0.2308
===> Epoch[34](2300/2500): Loss: 0.2252
===> Epoch[34](2400/2500): Loss: 0.2161
===> Epoch[34](2500/2500): Loss: 0.2170
===> Epoch 34 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 17:56:04]
===> Loading train datasets
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2066
===> Epoch[35](200/2500): Loss: 0.2149
===> Epoch[35](300/2500): Loss: 0.2157
===> Epoch[35](400/2500): Loss: 0.2257
===> Epoch[35](500/2500): Loss: 0.2041
===> Epoch[35](600/2500): Loss: 0.2347
===> Epoch[35](700/2500): Loss: 0.2032
===> Epoch[35](800/2500): Loss: 0.2225
===> Epoch[35](900/2500): Loss: 0.2197
===> Epoch[35](1000/2500): Loss: 0.2158
===> Epoch[35](1100/2500): Loss: 0.2161
===> Epoch[35](1200/2500): Loss: 0.2075
===> Epoch[35](1300/2500): Loss: 0.1980
===> Epoch[35](1400/2500): Loss: 0.2158
===> Epoch[35](1500/2500): Loss: 0.2036
===> Epoch[35](1600/2500): Loss: 0.2079
===> Epoch[35](1700/2500): Loss: 0.2000
===> Epoch[35](1800/2500): Loss: 0.2031
===> Epoch[35](1900/2500): Loss: 0.2160
===> Epoch[35](2000/2500): Loss: 0.2256
===> Epoch[35](2100/2500): Loss: 0.2073
===> Epoch[35](2200/2500): Loss: 0.2077
===> Epoch[35](2300/2500): Loss: 0.2167
===> Epoch[35](2400/2500): Loss: 0.1942
===> Epoch[35](2500/2500): Loss: 0.2158
===> Epoch 35 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:00:38]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2102
===> Epoch[36](200/2500): Loss: 0.2220
===> Epoch[36](300/2500): Loss: 0.2035
===> Epoch[36](400/2500): Loss: 0.2220
===> Epoch[36](500/2500): Loss: 0.2166
===> Epoch[36](600/2500): Loss: 0.2096
===> Epoch[36](700/2500): Loss: 0.1948
===> Epoch[36](800/2500): Loss: 0.2096
===> Epoch[36](900/2500): Loss: 0.2253
===> Epoch[36](1000/2500): Loss: 0.2037
===> Epoch[36](1100/2500): Loss: 0.2194
===> Epoch[36](1200/2500): Loss: 0.2377
===> Epoch[36](1300/2500): Loss: 0.2193
===> Epoch[36](1400/2500): Loss: 0.2037
===> Epoch[36](1500/2500): Loss: 0.2258
===> Epoch[36](1600/2500): Loss: 0.2037
===> Epoch[36](1700/2500): Loss: 0.1947
===> Epoch[36](1800/2500): Loss: 0.1980
===> Epoch[36](1900/2500): Loss: 0.2162
===> Epoch[36](2000/2500): Loss: 0.2255
===> Epoch[36](2100/2500): Loss: 0.2159
===> Epoch[36](2200/2500): Loss: 0.2128
===> Epoch[36](2300/2500): Loss: 0.2000
===> Epoch[36](2400/2500): Loss: 0.2225
===> Epoch[36](2500/2500): Loss: 0.2011
===> Epoch 36 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:05:12]
===> Loading train datasets
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2131
===> Epoch[37](200/2500): Loss: 0.2111
===> Epoch[37](300/2500): Loss: 0.2067
===> Epoch[37](400/2500): Loss: 0.2093
===> Epoch[37](500/2500): Loss: 0.2197
===> Epoch[37](600/2500): Loss: 0.2190
===> Epoch[37](700/2500): Loss: 0.2070
===> Epoch[37](800/2500): Loss: 0.2063
===> Epoch[37](900/2500): Loss: 0.2438
===> Epoch[37](1000/2500): Loss: 0.2077
===> Epoch[37](1100/2500): Loss: 0.2099
===> Epoch[37](1200/2500): Loss: 0.2190
===> Epoch[37](1300/2500): Loss: 0.2198
===> Epoch[37](1400/2500): Loss: 0.2257
===> Epoch[37](1500/2500): Loss: 0.2187
===> Epoch[37](1600/2500): Loss: 0.2085
===> Epoch[37](1700/2500): Loss: 0.2099
===> Epoch[37](1800/2500): Loss: 0.2199
===> Epoch[37](1900/2500): Loss: 0.2282
===> Epoch[37](2000/2500): Loss: 0.2235
===> Epoch[37](2100/2500): Loss: 0.2067
===> Epoch[37](2200/2500): Loss: 0.1997
===> Epoch[37](2300/2500): Loss: 0.2018
===> Epoch[37](2400/2500): Loss: 0.2095
===> Epoch[37](2500/2500): Loss: 0.2036
===> Epoch 37 Complete: Avg. Loss: 0.2153
===> Timestamp: [2025-08-03 18:09:46]
===> Loading train datasets
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2075
===> Epoch[38](200/2500): Loss: 0.2140
===> Epoch[38](300/2500): Loss: 0.2094
===> Epoch[38](400/2500): Loss: 0.2174
===> Epoch[38](500/2500): Loss: 0.1986
===> Epoch[38](600/2500): Loss: 0.2089
===> Epoch[38](700/2500): Loss: 0.2032
===> Epoch[38](800/2500): Loss: 0.2105
===> Epoch[38](900/2500): Loss: 0.2155
===> Epoch[38](1000/2500): Loss: 0.2168
===> Epoch[38](1100/2500): Loss: 0.2255
===> Epoch[38](1200/2500): Loss: 0.1999
===> Epoch[38](1300/2500): Loss: 0.2229
===> Epoch[38](1400/2500): Loss: 0.1974
===> Epoch[38](1500/2500): Loss: 0.2192
===> Epoch[38](1600/2500): Loss: 0.2201
===> Epoch[38](1700/2500): Loss: 0.2129
===> Epoch[38](1800/2500): Loss: 0.1915
===> Epoch[38](1900/2500): Loss: 0.2105
===> Epoch[38](2000/2500): Loss: 0.2284
===> Epoch[38](2100/2500): Loss: 0.2393
===> Epoch[38](2200/2500): Loss: 0.2219
===> Epoch[38](2300/2500): Loss: 0.2011
===> Epoch[38](2400/2500): Loss: 0.2247
===> Epoch[38](2500/2500): Loss: 0.2250
===> Epoch 38 Complete: Avg. Loss: 0.2152
===> Timestamp: [2025-08-03 18:14:20]
===> Loading train datasets
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2131
===> Epoch[39](200/2500): Loss: 0.2150
===> Epoch[39](300/2500): Loss: 0.2281
===> Epoch[39](400/2500): Loss: 0.2131
===> Epoch[39](500/2500): Loss: 0.2153
===> Epoch[39](600/2500): Loss: 0.2127
===> Epoch[39](700/2500): Loss: 0.2197
===> Epoch[39](800/2500): Loss: 0.2218
===> Epoch[39](900/2500): Loss: 0.2159
===> Epoch[39](1000/2500): Loss: 0.1976
===> Epoch[39](1100/2500): Loss: 0.2432
===> Epoch[39](1200/2500): Loss: 0.2072
===> Epoch[39](1300/2500): Loss: 0.2098
===> Epoch[39](1400/2500): Loss: 0.2163
===> Epoch[39](1500/2500): Loss: 0.2152
===> Epoch[39](1600/2500): Loss: 0.2107
===> Epoch[39](1700/2500): Loss: 0.2136
===> Epoch[39](1800/2500): Loss: 0.2129
===> Epoch[39](1900/2500): Loss: 0.2187
===> Epoch[39](2000/2500): Loss: 0.2000
===> Epoch[39](2100/2500): Loss: 0.2308
===> Epoch[39](2200/2500): Loss: 0.2282
===> Epoch[39](2300/2500): Loss: 0.2059
===> Epoch[39](2400/2500): Loss: 0.2224
===> Epoch[39](2500/2500): Loss: 0.2065
===> Epoch 39 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:18:53]
===> Loading train datasets
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2162
===> Epoch[40](200/2500): Loss: 0.2211
===> Epoch[40](300/2500): Loss: 0.2255
===> Epoch[40](400/2500): Loss: 0.2169
===> Epoch[40](500/2500): Loss: 0.2184
===> Epoch[40](600/2500): Loss: 0.2173
===> Epoch[40](700/2500): Loss: 0.2213
===> Epoch[40](800/2500): Loss: 0.1942
===> Epoch[40](900/2500): Loss: 0.2122
===> Epoch[40](1000/2500): Loss: 0.2068
===> Epoch[40](1100/2500): Loss: 0.2038
===> Epoch[40](1200/2500): Loss: 0.2057
===> Epoch[40](1300/2500): Loss: 0.2309
===> Epoch[40](1400/2500): Loss: 0.1998
===> Epoch[40](1500/2500): Loss: 0.2186
===> Epoch[40](1600/2500): Loss: 0.2338
===> Epoch[40](1700/2500): Loss: 0.1981
===> Epoch[40](1800/2500): Loss: 0.2218
===> Epoch[40](1900/2500): Loss: 0.2032
===> Epoch[40](2000/2500): Loss: 0.2118
===> Epoch[40](2100/2500): Loss: 0.2157
===> Epoch[40](2200/2500): Loss: 0.2038
===> Epoch[40](2300/2500): Loss: 0.2245
===> Epoch[40](2400/2500): Loss: 0.2185
===> Epoch[40](2500/2500): Loss: 0.2128
===> Epoch 40 Complete: Avg. Loss: 0.2149
===> Timestamp: [2025-08-03 18:23:27]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2252
===> Epoch[41](200/2500): Loss: 0.1977
===> Epoch[41](300/2500): Loss: 0.2009
===> Epoch[41](400/2500): Loss: 0.2279
===> Epoch[41](500/2500): Loss: 0.2130
===> Epoch[41](600/2500): Loss: 0.2158
===> Epoch[41](700/2500): Loss: 0.2221
===> Epoch[41](800/2500): Loss: 0.2125
===> Epoch[41](900/2500): Loss: 0.2279
===> Epoch[41](1000/2500): Loss: 0.2164
===> Epoch[41](1100/2500): Loss: 0.2161
===> Epoch[41](1200/2500): Loss: 0.2167
===> Epoch[41](1300/2500): Loss: 0.2039
===> Epoch[41](1400/2500): Loss: 0.2247
===> Epoch[41](1500/2500): Loss: 0.2139
===> Epoch[41](1600/2500): Loss: 0.2334
===> Epoch[41](1700/2500): Loss: 0.2191
===> Epoch[41](1800/2500): Loss: 0.2058
===> Epoch[41](1900/2500): Loss: 0.2220
===> Epoch[41](2000/2500): Loss: 0.2310
===> Epoch[41](2100/2500): Loss: 0.2065
===> Epoch[41](2200/2500): Loss: 0.2265
===> Epoch[41](2300/2500): Loss: 0.2251
===> Epoch[41](2400/2500): Loss: 0.2248
===> Epoch[41](2500/2500): Loss: 0.2067
===> Epoch 41 Complete: Avg. Loss: 0.2151
===> Timestamp: [2025-08-03 18:28:01]
===> Loading train datasets
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.2281
===> Epoch[42](200/2500): Loss: 0.2407
===> Epoch[42](300/2500): Loss: 0.1967
===> Epoch[42](400/2500): Loss: 0.2280
===> Epoch[42](500/2500): Loss: 0.2152
===> Epoch[42](600/2500): Loss: 0.2217
===> Epoch[42](700/2500): Loss: 0.2188
===> Epoch[42](800/2500): Loss: 0.2132
===> Epoch[42](900/2500): Loss: 0.2247
===> Epoch[42](1000/2500): Loss: 0.2249
===> Epoch[42](1100/2500): Loss: 0.2027
===> Epoch[42](1200/2500): Loss: 0.2309
===> Epoch[42](1300/2500): Loss: 0.2154
===> Epoch[42](1400/2500): Loss: 0.2096
===> Epoch[42](1500/2500): Loss: 0.2000
===> Epoch[42](1600/2500): Loss: 0.2037
===> Epoch[42](1700/2500): Loss: 0.2284
===> Epoch[42](1800/2500): Loss: 0.2161
===> Epoch[42](1900/2500): Loss: 0.2093
===> Epoch[42](2000/2500): Loss: 0.2037
===> Epoch[42](2100/2500): Loss: 0.2219
===> Epoch[42](2200/2500): Loss: 0.2065
===> Epoch[42](2300/2500): Loss: 0.2156
===> Epoch[42](2400/2500): Loss: 0.2246
===> Epoch[42](2500/2500): Loss: 0.2467
===> Epoch 42 Complete: Avg. Loss: 0.2147
===> Timestamp: [2025-08-03 18:32:35]
===> Loading train datasets
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2257
===> Epoch[43](200/2500): Loss: 0.2157
===> Epoch[43](300/2500): Loss: 0.2042
===> Epoch[43](400/2500): Loss: 0.2151
===> Epoch[43](500/2500): Loss: 0.2156
===> Epoch[43](600/2500): Loss: 0.2332
===> Epoch[43](700/2500): Loss: 0.2071
===> Epoch[43](800/2500): Loss: 0.2132
===> Epoch[43](900/2500): Loss: 0.1999
===> Epoch[43](1000/2500): Loss: 0.2249
===> Epoch[43](1100/2500): Loss: 0.2133
===> Epoch[43](1200/2500): Loss: 0.2367
===> Epoch[43](1300/2500): Loss: 0.2064
===> Epoch[43](1400/2500): Loss: 0.2063
===> Epoch[43](1500/2500): Loss: 0.2142
===> Epoch[43](1600/2500): Loss: 0.2124
===> Epoch[43](1700/2500): Loss: 0.2310
===> Epoch[43](1800/2500): Loss: 0.2160
===> Epoch[43](1900/2500): Loss: 0.2185
===> Epoch[43](2000/2500): Loss: 0.2093
===> Epoch[43](2100/2500): Loss: 0.2344
===> Epoch[43](2200/2500): Loss: 0.2239
===> Epoch[43](2300/2500): Loss: 0.1961
===> Epoch[43](2400/2500): Loss: 0.2058
===> Epoch[43](2500/2500): Loss: 0.2214
===> Epoch 43 Complete: Avg. Loss: 0.2148
===> Timestamp: [2025-08-03 18:37:09]
===> Loading train datasets
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2209
===> Epoch[44](200/2500): Loss: 0.2093
===> Epoch[44](300/2500): Loss: 0.2151
===> Epoch[44](400/2500): Loss: 0.2151
===> Epoch[44](500/2500): Loss: 0.2313
===> Epoch[44](600/2500): Loss: 0.2092
===> Epoch[44](700/2500): Loss: 0.2095
===> Epoch[44](800/2500): Loss: 0.2211
===> Epoch[44](900/2500): Loss: 0.2274
===> Epoch[44](1000/2500): Loss: 0.2126
===> Epoch[44](1100/2500): Loss: 0.1966
===> Epoch[44](1200/2500): Loss: 0.2107
===> Epoch[44](1300/2500): Loss: 0.2215
===> Epoch[44](1400/2500): Loss: 0.2089
===> Epoch[44](1500/2500): Loss: 0.2181
===> Epoch[44](1600/2500): Loss: 0.2153
===> Epoch[44](1700/2500): Loss: 0.2026
===> Epoch[44](1800/2500): Loss: 0.1995
===> Epoch[44](1900/2500): Loss: 0.2048
===> Epoch[44](2000/2500): Loss: 0.2085
===> Epoch[44](2100/2500): Loss: 0.1933
===> Epoch[44](2200/2500): Loss: 0.2205
===> Epoch[44](2300/2500): Loss: 0.2152
===> Epoch[44](2400/2500): Loss: 0.2038
===> Epoch[44](2500/2500): Loss: 0.2122
===> Epoch 44 Complete: Avg. Loss: 0.2144
===> Timestamp: [2025-08-03 18:41:42]
===> Loading train datasets
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2156
===> Epoch[45](200/2500): Loss: 0.2087
===> Epoch[45](300/2500): Loss: 0.2123
===> Epoch[45](400/2500): Loss: 0.1998
===> Epoch[45](500/2500): Loss: 0.1939
===> Epoch[45](600/2500): Loss: 0.2082
===> Epoch[45](700/2500): Loss: 0.2301
===> Epoch[45](800/2500): Loss: 0.2086
===> Epoch[45](900/2500): Loss: 0.2151
===> Epoch[45](1000/2500): Loss: 0.2270
===> Epoch[45](1100/2500): Loss: 0.2215
===> Epoch[45](1200/2500): Loss: 0.2021
===> Epoch[45](1300/2500): Loss: 0.1930
===> Epoch[45](1400/2500): Loss: 0.1995
===> Epoch[45](1500/2500): Loss: 0.2206
===> Epoch[45](1600/2500): Loss: 0.2033
===> Epoch[45](1700/2500): Loss: 0.2057
===> Epoch[45](1800/2500): Loss: 0.2147
===> Epoch[45](1900/2500): Loss: 0.2336
===> Epoch[45](2000/2500): Loss: 0.1964
===> Epoch[45](2100/2500): Loss: 0.2136
===> Epoch[45](2200/2500): Loss: 0.2090
===> Epoch[45](2300/2500): Loss: 0.2254
===> Epoch[45](2400/2500): Loss: 0.2238
===> Epoch[45](2500/2500): Loss: 0.2129
===> Epoch 45 Complete: Avg. Loss: 0.2141
===> Timestamp: [2025-08-03 18:46:16]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2147
===> Epoch[46](200/2500): Loss: 0.2245
===> Epoch[46](300/2500): Loss: 0.2260
===> Epoch[46](400/2500): Loss: 0.1998
===> Epoch[46](500/2500): Loss: 0.1945
===> Epoch[46](600/2500): Loss: 0.2115
===> Epoch[46](700/2500): Loss: 0.2079
===> Epoch[46](800/2500): Loss: 0.2177
===> Epoch[46](900/2500): Loss: 0.2332
===> Epoch[46](1000/2500): Loss: 0.2123
===> Epoch[46](1100/2500): Loss: 0.1994
===> Epoch[46](1200/2500): Loss: 0.2188
===> Epoch[46](1300/2500): Loss: 0.2117
===> Epoch[46](1400/2500): Loss: 0.2117
===> Epoch[46](1500/2500): Loss: 0.1966
===> Epoch[46](1600/2500): Loss: 0.2115
===> Epoch[46](1700/2500): Loss: 0.2055
===> Epoch[46](1800/2500): Loss: 0.2212
===> Epoch[46](1900/2500): Loss: 0.1905
===> Epoch[46](2000/2500): Loss: 0.1988
===> Epoch[46](2100/2500): Loss: 0.2080
===> Epoch[46](2200/2500): Loss: 0.2148
===> Epoch[46](2300/2500): Loss: 0.2240
===> Epoch[46](2400/2500): Loss: 0.2214
===> Epoch[46](2500/2500): Loss: 0.2049
===> Epoch 46 Complete: Avg. Loss: 0.2140
===> Timestamp: [2025-08-03 18:50:50]
===> Loading train datasets
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2024
===> Epoch[47](200/2500): Loss: 0.2181
===> Epoch[47](300/2500): Loss: 0.2424
===> Epoch[47](400/2500): Loss: 0.2329
===> Epoch[47](500/2500): Loss: 0.2139
===> Epoch[47](600/2500): Loss: 0.2241
===> Epoch[47](700/2500): Loss: 0.1990
===> Epoch[47](800/2500): Loss: 0.2205
===> Epoch[47](900/2500): Loss: 0.1871
===> Epoch[47](1000/2500): Loss: 0.2110
===> Epoch[47](1100/2500): Loss: 0.2144
===> Epoch[47](1200/2500): Loss: 0.2079
===> Epoch[47](1300/2500): Loss: 0.2147
===> Epoch[47](1400/2500): Loss: 0.2085
===> Epoch[47](1500/2500): Loss: 0.2118
===> Epoch[47](1600/2500): Loss: 0.2200
===> Epoch[47](1700/2500): Loss: 0.1996
===> Epoch[47](1800/2500): Loss: 0.1996
===> Epoch[47](1900/2500): Loss: 0.2266
===> Epoch[47](2000/2500): Loss: 0.2152
===> Epoch[47](2100/2500): Loss: 0.2093
===> Epoch[47](2200/2500): Loss: 0.1924
===> Epoch[47](2300/2500): Loss: 0.2178
===> Epoch[47](2400/2500): Loss: 0.2317
===> Epoch[47](2500/2500): Loss: 0.2263
===> Epoch 47 Complete: Avg. Loss: 0.2138
===> Timestamp: [2025-08-03 18:55:24]
===> Loading train datasets
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2174
===> Epoch[48](200/2500): Loss: 0.2386
===> Epoch[48](300/2500): Loss: 0.2229
===> Epoch[48](400/2500): Loss: 0.2257
===> Epoch[48](500/2500): Loss: 0.2230
===> Epoch[48](600/2500): Loss: 0.2169
===> Epoch[48](700/2500): Loss: 0.2172
===> Epoch[48](800/2500): Loss: 0.2069
===> Epoch[48](900/2500): Loss: 0.2011
===> Epoch[48](1000/2500): Loss: 0.2228
===> Epoch[48](1100/2500): Loss: 0.2170
===> Epoch[48](1200/2500): Loss: 0.2097
===> Epoch[48](1300/2500): Loss: 0.2226
===> Epoch[48](1400/2500): Loss: 0.2140
===> Epoch[48](1500/2500): Loss: 0.2040
===> Epoch[48](1600/2500): Loss: 0.2198
===> Epoch[48](1700/2500): Loss: 0.2199
===> Epoch[48](1800/2500): Loss: 0.2019
===> Epoch[48](1900/2500): Loss: 0.2010
===> Epoch[48](2000/2500): Loss: 0.1977
===> Epoch[48](2100/2500): Loss: 0.2009
===> Epoch[48](2200/2500): Loss: 0.1986
===> Epoch[48](2300/2500): Loss: 0.2165
===> Epoch[48](2400/2500): Loss: 0.2110
===> Epoch[48](2500/2500): Loss: 0.2015
===> Epoch 48 Complete: Avg. Loss: 0.2126
===> Timestamp: [2025-08-03 18:59:58]
===> Loading train datasets
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2015
===> Epoch[49](200/2500): Loss: 0.2198
===> Epoch[49](300/2500): Loss: 0.2199
===> Epoch[49](400/2500): Loss: 0.2068
===> Epoch[49](500/2500): Loss: 0.2098
===> Epoch[49](600/2500): Loss: 0.2217
===> Epoch[49](700/2500): Loss: 0.2225
===> Epoch[49](800/2500): Loss: 0.2072
===> Epoch[49](900/2500): Loss: 0.2162
===> Epoch[49](1000/2500): Loss: 0.2012
===> Epoch[49](1100/2500): Loss: 0.2104
===> Epoch[49](1200/2500): Loss: 0.2038
===> Epoch[49](1300/2500): Loss: 0.2073
===> Epoch[49](1400/2500): Loss: 0.2009
===> Epoch[49](1500/2500): Loss: 0.2159
===> Epoch[49](1600/2500): Loss: 0.2284
===> Epoch[49](1700/2500): Loss: 0.2046
===> Epoch[49](1800/2500): Loss: 0.2163
===> Epoch[49](1900/2500): Loss: 0.2038
===> Epoch[49](2000/2500): Loss: 0.2243
===> Epoch[49](2100/2500): Loss: 0.2138
===> Epoch[49](2200/2500): Loss: 0.2222
===> Epoch[49](2300/2500): Loss: 0.2314
===> Epoch[49](2400/2500): Loss: 0.2232
===> Epoch[49](2500/2500): Loss: 0.1929
===> Epoch 49 Complete: Avg. Loss: 0.2127
===> Timestamp: [2025-08-03 19:04:31]
===> Loading train datasets
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2138
===> Epoch[50](200/2500): Loss: 0.2165
===> Epoch[50](300/2500): Loss: 0.2036
===> Epoch[50](400/2500): Loss: 0.2163
===> Epoch[50](500/2500): Loss: 0.2095
===> Epoch[50](600/2500): Loss: 0.2015
===> Epoch[50](700/2500): Loss: 0.2010
===> Epoch[50](800/2500): Loss: 0.2072
===> Epoch[50](900/2500): Loss: 0.2308
===> Epoch[50](1000/2500): Loss: 0.2070
===> Epoch[50](1100/2500): Loss: 0.2238
===> Epoch[50](1200/2500): Loss: 0.2188
===> Epoch[50](1300/2500): Loss: 0.2039
===> Epoch[50](1400/2500): Loss: 0.2126
===> Epoch[50](1500/2500): Loss: 0.2005
===> Epoch[50](1600/2500): Loss: 0.2189
===> Epoch[50](1700/2500): Loss: 0.2040
===> Epoch[50](1800/2500): Loss: 0.2071
===> Epoch[50](1900/2500): Loss: 0.2137
===> Epoch[50](2000/2500): Loss: 0.2166
===> Epoch[50](2100/2500): Loss: 0.2189
===> Epoch[50](2200/2500): Loss: 0.1982
===> Epoch[50](2300/2500): Loss: 0.2104
===> Epoch[50](2400/2500): Loss: 0.2136
===> Epoch[50](2500/2500): Loss: 0.2105
===> Epoch 50 Complete: Avg. Loss: 0.2124
===> Timestamp: [2025-08-03 19:09:05]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2229
===> Epoch[51](200/2500): Loss: 0.2071
===> Epoch[51](300/2500): Loss: 0.2229
===> Epoch[51](400/2500): Loss: 0.2186
===> Epoch[51](500/2500): Loss: 0.1980
===> Epoch[51](600/2500): Loss: 0.2316
===> Epoch[51](700/2500): Loss: 0.2158
===> Epoch[51](800/2500): Loss: 0.2045
===> Epoch[51](900/2500): Loss: 0.2144
===> Epoch[51](1000/2500): Loss: 0.2202
===> Epoch[51](1100/2500): Loss: 0.2074
===> Epoch[51](1200/2500): Loss: 0.2100
===> Epoch[51](1300/2500): Loss: 0.2068
===> Epoch[51](1400/2500): Loss: 0.2036
===> Epoch[51](1500/2500): Loss: 0.2017
===> Epoch[51](1600/2500): Loss: 0.2049
===> Epoch[51](1700/2500): Loss: 0.2287
===> Epoch[51](1800/2500): Loss: 0.2376
===> Epoch[51](1900/2500): Loss: 0.2174
===> Epoch[51](2000/2500): Loss: 0.1951
===> Epoch[51](2100/2500): Loss: 0.2099
===> Epoch[51](2200/2500): Loss: 0.2137
===> Epoch[51](2300/2500): Loss: 0.2291
===> Epoch[51](2400/2500): Loss: 0.2080
===> Epoch[51](2500/2500): Loss: 0.1974
===> Epoch 51 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:13:39]
===> Loading train datasets
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2193
===> Epoch[52](200/2500): Loss: 0.2129
===> Epoch[52](300/2500): Loss: 0.2237
===> Epoch[52](400/2500): Loss: 0.1914
===> Epoch[52](500/2500): Loss: 0.2099
===> Epoch[52](600/2500): Loss: 0.2074
===> Epoch[52](700/2500): Loss: 0.2006
===> Epoch[52](800/2500): Loss: 0.2072
===> Epoch[52](900/2500): Loss: 0.1884
===> Epoch[52](1000/2500): Loss: 0.1971
===> Epoch[52](1100/2500): Loss: 0.1977
===> Epoch[52](1200/2500): Loss: 0.2138
===> Epoch[52](1300/2500): Loss: 0.2131
===> Epoch[52](1400/2500): Loss: 0.2506
===> Epoch[52](1500/2500): Loss: 0.2222
===> Epoch[52](1600/2500): Loss: 0.2197
===> Epoch[52](1700/2500): Loss: 0.2292
===> Epoch[52](1800/2500): Loss: 0.2179
===> Epoch[52](1900/2500): Loss: 0.2171
===> Epoch[52](2000/2500): Loss: 0.2321
===> Epoch[52](2100/2500): Loss: 0.2041
===> Epoch[52](2200/2500): Loss: 0.2194
===> Epoch[52](2300/2500): Loss: 0.2107
===> Epoch[52](2400/2500): Loss: 0.2135
===> Epoch[52](2500/2500): Loss: 0.1919
===> Epoch 52 Complete: Avg. Loss: 0.2125
===> Timestamp: [2025-08-03 19:18:13]
===> Loading train datasets
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Epoch[53](100/2500): Loss: 0.2411
===> Epoch[53](200/2500): Loss: 0.2135
===> Epoch[53](300/2500): Loss: 0.2073
===> Epoch[53](400/2500): Loss: 0.1984
===> Epoch[53](500/2500): Loss: 0.2132
===> Epoch[53](600/2500): Loss: 0.2134
===> Epoch[53](700/2500): Loss: 0.2039
===> Epoch[53](800/2500): Loss: 0.2163
===> Epoch[53](900/2500): Loss: 0.2011
===> Epoch[53](1000/2500): Loss: 0.2043
===> Epoch[53](1100/2500): Loss: 0.2226
===> Epoch[53](1200/2500): Loss: 0.1974
===> Epoch[53](1300/2500): Loss: 0.2310
===> Loading train datasets
===> Epoch[1](100/2500): Loss: 4.8596
===> Epoch[1](200/2500): Loss: 1.2726
===> Epoch[1](300/2500): Loss: 0.6889
===> Epoch[1](400/2500): Loss: 0.6358
===> Epoch[1](500/2500): Loss: 0.5965
===> Epoch[1](600/2500): Loss: 0.5489
===> Epoch[1](700/2500): Loss: 0.5658
===> Epoch[1](800/2500): Loss: 0.5242
===> Epoch[1](900/2500): Loss: 0.5182
===> Epoch[1](1000/2500): Loss: 0.5293
===> Epoch[1](1100/2500): Loss: 0.5084
===> Epoch[1](1200/2500): Loss: 0.5048
===> Epoch[1](1300/2500): Loss: 0.5081
===> Epoch[1](1400/2500): Loss: 0.5223
===> Epoch[1](1500/2500): Loss: 0.5048
===> Epoch[1](1600/2500): Loss: 0.4958
===> Epoch[1](1700/2500): Loss: 0.4866
===> Epoch[1](1800/2500): Loss: 0.4862
===> Epoch[1](1900/2500): Loss: 0.4768
===> Epoch[1](2000/2500): Loss: 0.5251
===> Epoch[1](2100/2500): Loss: 0.4944
===> Epoch[1](2200/2500): Loss: 0.4879
===> Epoch[1](2300/2500): Loss: 0.5459
===> Epoch[1](2400/2500): Loss: 0.4775
===> Epoch[1](2500/2500): Loss: 0.4415
===> Epoch 1 Complete: Avg. Loss: 24.0839
===> Timestamp: [2025-08-03 19:35:48]
===> Loading train datasets
===> Loading train datasets
===> Epoch[2](100/2500): Loss: 0.5034
===> Epoch[2](200/2500): Loss: 0.4913
===> Epoch[2](300/2500): Loss: 0.4715
===> Epoch[2](400/2500): Loss: 0.4688
===> Epoch[2](500/2500): Loss: 0.4873
===> Epoch[2](600/2500): Loss: 0.5102
===> Epoch[2](700/2500): Loss: 0.4956
===> Epoch[2](800/2500): Loss: 0.5015
===> Epoch[2](900/2500): Loss: 0.4587
===> Epoch[2](1000/2500): Loss: 0.4708
===> Epoch[2](1100/2500): Loss: 0.5352
===> Epoch[2](1200/2500): Loss: 0.4809
===> Epoch[2](1300/2500): Loss: 0.4242
===> Epoch[2](1400/2500): Loss: 0.4337
===> Epoch[2](1500/2500): Loss: 0.4579
===> Epoch[2](1600/2500): Loss: 0.5057
===> Epoch[2](1700/2500): Loss: 0.4605
===> Epoch[2](1800/2500): Loss: 0.4638
===> Epoch[2](1900/2500): Loss: 0.4763
===> Epoch[2](2000/2500): Loss: 0.4430
===> Epoch[2](2100/2500): Loss: 0.4901
===> Epoch[2](2200/2500): Loss: 0.4526
===> Epoch[2](2300/2500): Loss: 0.4743
===> Epoch[2](2400/2500): Loss: 0.4348
===> Epoch[2](2500/2500): Loss: 0.4812
===> Epoch 2 Complete: Avg. Loss: 0.4719
===> Timestamp: [2025-08-03 19:40:22]
===> Loading train datasets
===> Epoch[2](100/2500): Loss: 0.5034
===> Epoch[2](200/2500): Loss: 0.4913
===> Epoch[2](300/2500): Loss: 0.4715
===> Epoch[2](400/2500): Loss: 0.4688
===> Epoch[2](500/2500): Loss: 0.4873
===> Epoch[2](600/2500): Loss: 0.5102
===> Epoch[2](700/2500): Loss: 0.4956
===> Epoch[2](800/2500): Loss: 0.5015
===> Epoch[2](900/2500): Loss: 0.4587
===> Epoch[2](1000/2500): Loss: 0.4708
===> Epoch[2](1100/2500): Loss: 0.5352
===> Epoch[2](1200/2500): Loss: 0.4809
===> Epoch[2](1300/2500): Loss: 0.4242
===> Epoch[2](1400/2500): Loss: 0.4337
===> Epoch[2](1500/2500): Loss: 0.4579
===> Epoch[2](1600/2500): Loss: 0.5057
===> Epoch[2](1700/2500): Loss: 0.4605
===> Epoch[2](1800/2500): Loss: 0.4638
===> Epoch[2](1900/2500): Loss: 0.4763
===> Epoch[2](2000/2500): Loss: 0.4430
===> Epoch[2](2100/2500): Loss: 0.4901
===> Epoch[2](2200/2500): Loss: 0.4526
===> Epoch[2](2300/2500): Loss: 0.4743
===> Epoch[2](2400/2500): Loss: 0.4348
===> Epoch[2](2500/2500): Loss: 0.4812
===> Epoch 2 Complete: Avg. Loss: 0.4719
===> Timestamp: [2025-08-03 19:40:22]
===> Loading train datasets
===> Loading train datasets
===> Epoch[3](100/2500): Loss: 0.4185
===> Epoch[3](200/2500): Loss: 0.4397
===> Epoch[3](300/2500): Loss: 0.4342
===> Epoch[3](400/2500): Loss: 0.4431
===> Epoch[3](500/2500): Loss: 0.4766
===> Epoch[3](600/2500): Loss: 0.4498
===> Epoch[3](700/2500): Loss: 0.4168
===> Epoch[3](800/2500): Loss: 0.4305
===> Epoch[3](900/2500): Loss: 0.4587
===> Epoch[3](1000/2500): Loss: 0.4259
===> Epoch[3](1100/2500): Loss: 0.4066
===> Epoch[3](1200/2500): Loss: 0.4089
===> Epoch[3](1300/2500): Loss: 0.4018
===> Epoch[3](1400/2500): Loss: 0.4296
===> Epoch[3](1500/2500): Loss: 0.4090
===> Epoch[3](1600/2500): Loss: 0.3971
===> Epoch[3](1700/2500): Loss: 0.4123
===> Epoch[3](1800/2500): Loss: 0.4102
===> Epoch[3](1900/2500): Loss: 0.3814
===> Epoch[3](2000/2500): Loss: 0.4037
===> Epoch[3](2100/2500): Loss: 0.4125
===> Epoch[3](2200/2500): Loss: 0.3784
===> Epoch[3](2300/2500): Loss: 0.4222
===> Epoch[3](2400/2500): Loss: 0.3971
===> Epoch[3](2500/2500): Loss: 0.4092
===> Epoch 3 Complete: Avg. Loss: 0.4243
===> Timestamp: [2025-08-03 19:44:56]
===> Loading train datasets
===> Epoch[3](100/2500): Loss: 0.4185
===> Epoch[3](200/2500): Loss: 0.4397
===> Epoch[3](300/2500): Loss: 0.4342
===> Epoch[3](400/2500): Loss: 0.4431
===> Epoch[3](500/2500): Loss: 0.4766
===> Epoch[3](600/2500): Loss: 0.4498
===> Epoch[3](700/2500): Loss: 0.4168
===> Epoch[3](800/2500): Loss: 0.4305
===> Epoch[3](900/2500): Loss: 0.4587
===> Epoch[3](1000/2500): Loss: 0.4259
===> Epoch[3](1100/2500): Loss: 0.4066
===> Epoch[3](1200/2500): Loss: 0.4089
===> Epoch[3](1300/2500): Loss: 0.4018
===> Epoch[3](1400/2500): Loss: 0.4296
===> Epoch[3](1500/2500): Loss: 0.4090
===> Epoch[3](1600/2500): Loss: 0.3971
===> Epoch[3](1700/2500): Loss: 0.4123
===> Epoch[3](1800/2500): Loss: 0.4102
===> Epoch[3](1900/2500): Loss: 0.3814
===> Epoch[3](2000/2500): Loss: 0.4037
===> Epoch[3](2100/2500): Loss: 0.4125
===> Epoch[3](2200/2500): Loss: 0.3784
===> Epoch[3](2300/2500): Loss: 0.4222
===> Epoch[3](2400/2500): Loss: 0.3971
===> Epoch[3](2500/2500): Loss: 0.4092
===> Epoch 3 Complete: Avg. Loss: 0.4243
===> Timestamp: [2025-08-03 19:44:56]
===> Loading train datasets
===> Epoch[3](100/2500): Loss: 0.4185
===> Epoch[3](200/2500): Loss: 0.4397
===> Epoch[3](300/2500): Loss: 0.4342
===> Epoch[3](400/2500): Loss: 0.4431
===> Epoch[3](500/2500): Loss: 0.4766
===> Epoch[3](600/2500): Loss: 0.4498
===> Epoch[3](700/2500): Loss: 0.4168
===> Epoch[3](800/2500): Loss: 0.4305
===> Epoch[3](900/2500): Loss: 0.4587
===> Epoch[3](1000/2500): Loss: 0.4259
===> Epoch[3](1100/2500): Loss: 0.4066
===> Epoch[3](1200/2500): Loss: 0.4089
===> Epoch[3](1300/2500): Loss: 0.4018
===> Epoch[3](1400/2500): Loss: 0.4296
===> Epoch[3](1500/2500): Loss: 0.4090
===> Epoch[3](1600/2500): Loss: 0.3971
===> Epoch[3](1700/2500): Loss: 0.4123
===> Epoch[3](1800/2500): Loss: 0.4102
===> Epoch[3](1900/2500): Loss: 0.3814
===> Epoch[3](2000/2500): Loss: 0.4037
===> Epoch[3](2100/2500): Loss: 0.4125
===> Epoch[3](2200/2500): Loss: 0.3784
===> Epoch[3](2300/2500): Loss: 0.4222
===> Epoch[3](2400/2500): Loss: 0.3971
===> Epoch[3](2500/2500): Loss: 0.4092
===> Epoch 3 Complete: Avg. Loss: 0.4243
===> Timestamp: [2025-08-03 19:44:56]
===> Loading train datasets
===> Loading train datasets
===> Epoch[4](100/2500): Loss: 0.3972
===> Epoch[4](200/2500): Loss: 0.4068
===> Epoch[4](300/2500): Loss: 0.4052
===> Epoch[4](400/2500): Loss: 0.3642
===> Epoch[4](500/2500): Loss: 0.4008
===> Epoch[4](600/2500): Loss: 0.3547
===> Epoch[4](700/2500): Loss: 0.4082
===> Epoch[4](800/2500): Loss: 0.3735
===> Epoch[4](900/2500): Loss: 0.3740
===> Epoch[4](1000/2500): Loss: 0.3654
===> Epoch[4](1100/2500): Loss: 0.4045
===> Epoch[4](1200/2500): Loss: 0.4026
===> Epoch[4](1300/2500): Loss: 0.3891
===> Epoch[4](1400/2500): Loss: 0.3578
===> Epoch[4](1500/2500): Loss: 0.3485
===> Epoch[4](1600/2500): Loss: 0.3764
===> Epoch[4](1700/2500): Loss: 0.3707
===> Epoch[4](1800/2500): Loss: 0.3439
===> Epoch[4](1900/2500): Loss: 0.3669
===> Epoch[4](2000/2500): Loss: 0.3601
===> Epoch[4](2100/2500): Loss: 0.3446
===> Epoch[4](2200/2500): Loss: 0.3876
===> Epoch[4](2300/2500): Loss: 0.3596
===> Epoch[4](2400/2500): Loss: 0.3669
===> Epoch[4](2500/2500): Loss: 0.3259
===> Epoch 4 Complete: Avg. Loss: 0.3796
===> Timestamp: [2025-08-03 19:49:31]
===> Loading train datasets
===> Epoch[4](100/2500): Loss: 0.3972
===> Epoch[4](200/2500): Loss: 0.4068
===> Epoch[4](300/2500): Loss: 0.4052
===> Epoch[4](400/2500): Loss: 0.3642
===> Epoch[4](500/2500): Loss: 0.4008
===> Epoch[4](600/2500): Loss: 0.3547
===> Epoch[4](700/2500): Loss: 0.4082
===> Epoch[4](800/2500): Loss: 0.3735
===> Epoch[4](900/2500): Loss: 0.3740
===> Epoch[4](1000/2500): Loss: 0.3654
===> Epoch[4](1100/2500): Loss: 0.4045
===> Epoch[4](1200/2500): Loss: 0.4026
===> Epoch[4](1300/2500): Loss: 0.3891
===> Epoch[4](1400/2500): Loss: 0.3578
===> Epoch[4](1500/2500): Loss: 0.3485
===> Epoch[4](1600/2500): Loss: 0.3764
===> Epoch[4](1700/2500): Loss: 0.3707
===> Epoch[4](1800/2500): Loss: 0.3439
===> Epoch[4](1900/2500): Loss: 0.3669
===> Epoch[4](2000/2500): Loss: 0.3601
===> Epoch[4](2100/2500): Loss: 0.3446
===> Epoch[4](2200/2500): Loss: 0.3876
===> Epoch[4](2300/2500): Loss: 0.3596
===> Epoch[4](2400/2500): Loss: 0.3669
===> Epoch[4](2500/2500): Loss: 0.3259
===> Epoch 4 Complete: Avg. Loss: 0.3796
===> Timestamp: [2025-08-03 19:49:31]
===> Loading train datasets
===> Epoch[4](100/2500): Loss: 0.3972
===> Epoch[4](200/2500): Loss: 0.4068
===> Epoch[4](300/2500): Loss: 0.4052
===> Epoch[4](400/2500): Loss: 0.3642
===> Epoch[4](500/2500): Loss: 0.4008
===> Epoch[4](600/2500): Loss: 0.3547
===> Epoch[4](700/2500): Loss: 0.4082
===> Epoch[4](800/2500): Loss: 0.3735
===> Epoch[4](900/2500): Loss: 0.3740
===> Epoch[4](1000/2500): Loss: 0.3654
===> Epoch[4](1100/2500): Loss: 0.4045
===> Epoch[4](1200/2500): Loss: 0.4026
===> Epoch[4](1300/2500): Loss: 0.3891
===> Epoch[4](1400/2500): Loss: 0.3578
===> Epoch[4](1500/2500): Loss: 0.3485
===> Epoch[4](1600/2500): Loss: 0.3764
===> Epoch[4](1700/2500): Loss: 0.3707
===> Epoch[4](1800/2500): Loss: 0.3439
===> Epoch[4](1900/2500): Loss: 0.3669
===> Epoch[4](2000/2500): Loss: 0.3601
===> Epoch[4](2100/2500): Loss: 0.3446
===> Epoch[4](2200/2500): Loss: 0.3876
===> Epoch[4](2300/2500): Loss: 0.3596
===> Epoch[4](2400/2500): Loss: 0.3669
===> Epoch[4](2500/2500): Loss: 0.3259
===> Epoch 4 Complete: Avg. Loss: 0.3796
===> Timestamp: [2025-08-03 19:49:31]
===> Loading train datasets
===> Epoch[4](100/2500): Loss: 0.3972
===> Epoch[4](200/2500): Loss: 0.4068
===> Epoch[4](300/2500): Loss: 0.4052
===> Epoch[4](400/2500): Loss: 0.3642
===> Epoch[4](500/2500): Loss: 0.4008
===> Epoch[4](600/2500): Loss: 0.3547
===> Epoch[4](700/2500): Loss: 0.4082
===> Epoch[4](800/2500): Loss: 0.3735
===> Epoch[4](900/2500): Loss: 0.3740
===> Epoch[4](1000/2500): Loss: 0.3654
===> Epoch[4](1100/2500): Loss: 0.4045
===> Epoch[4](1200/2500): Loss: 0.4026
===> Epoch[4](1300/2500): Loss: 0.3891
===> Epoch[4](1400/2500): Loss: 0.3578
===> Epoch[4](1500/2500): Loss: 0.3485
===> Epoch[4](1600/2500): Loss: 0.3764
===> Epoch[4](1700/2500): Loss: 0.3707
===> Epoch[4](1800/2500): Loss: 0.3439
===> Epoch[4](1900/2500): Loss: 0.3669
===> Epoch[4](2000/2500): Loss: 0.3601
===> Epoch[4](2100/2500): Loss: 0.3446
===> Epoch[4](2200/2500): Loss: 0.3876
===> Epoch[4](2300/2500): Loss: 0.3596
===> Epoch[4](2400/2500): Loss: 0.3669
===> Epoch[4](2500/2500): Loss: 0.3259
===> Epoch 4 Complete: Avg. Loss: 0.3796
===> Timestamp: [2025-08-03 19:49:31]
===> Loading train datasets
===> Loading train datasets
===> Epoch[5](100/2500): Loss: 0.3657
===> Epoch[5](200/2500): Loss: 0.3448
===> Epoch[5](300/2500): Loss: 0.3279
===> Epoch[5](400/2500): Loss: 0.3588
===> Epoch[5](500/2500): Loss: 0.3424
===> Epoch[5](600/2500): Loss: 0.3568
===> Epoch[5](700/2500): Loss: 0.3465
===> Epoch[5](800/2500): Loss: 0.3531
===> Epoch[5](900/2500): Loss: 0.3269
===> Epoch[5](1000/2500): Loss: 0.3668
===> Epoch[5](1100/2500): Loss: 0.3829
===> Epoch[5](1200/2500): Loss: 0.3934
===> Epoch[5](1300/2500): Loss: 0.3570
===> Epoch[5](1400/2500): Loss: 0.3667
===> Epoch[5](1500/2500): Loss: 0.3695
===> Epoch[5](1600/2500): Loss: 0.3399
===> Epoch[5](1700/2500): Loss: 0.3646
===> Epoch[5](1800/2500): Loss: 0.3204
===> Epoch[5](1900/2500): Loss: 0.3499
===> Epoch[5](2000/2500): Loss: 0.3542
===> Epoch[5](2100/2500): Loss: 0.3721
===> Epoch[5](2200/2500): Loss: 0.3631
===> Epoch[5](2300/2500): Loss: 0.3380
===> Epoch[5](2400/2500): Loss: 0.3267
===> Epoch[5](2500/2500): Loss: 0.3175
===> Epoch 5 Complete: Avg. Loss: 0.3597
===> Timestamp: [2025-08-03 19:54:05]
Checkpoint saved to TrainedNet/_epoch_5.pth
===> Loading train datasets
===> Epoch[5](100/2500): Loss: 0.3657
===> Epoch[5](200/2500): Loss: 0.3448
===> Epoch[5](300/2500): Loss: 0.3279
===> Epoch[5](400/2500): Loss: 0.3588
===> Epoch[5](500/2500): Loss: 0.3424
===> Epoch[5](600/2500): Loss: 0.3568
===> Epoch[5](700/2500): Loss: 0.3465
===> Epoch[5](800/2500): Loss: 0.3531
===> Epoch[5](900/2500): Loss: 0.3269
===> Epoch[5](1000/2500): Loss: 0.3668
===> Epoch[5](1100/2500): Loss: 0.3829
===> Epoch[5](1200/2500): Loss: 0.3934
===> Epoch[5](1300/2500): Loss: 0.3570
===> Epoch[5](1400/2500): Loss: 0.3667
===> Epoch[5](1500/2500): Loss: 0.3695
===> Epoch[5](1600/2500): Loss: 0.3399
===> Epoch[5](1700/2500): Loss: 0.3646
===> Epoch[5](1800/2500): Loss: 0.3204
===> Epoch[5](1900/2500): Loss: 0.3499
===> Epoch[5](2000/2500): Loss: 0.3542
===> Epoch[5](2100/2500): Loss: 0.3721
===> Epoch[5](2200/2500): Loss: 0.3631
===> Epoch[5](2300/2500): Loss: 0.3380
===> Epoch[5](2400/2500): Loss: 0.3267
===> Epoch[5](2500/2500): Loss: 0.3175
===> Epoch 5 Complete: Avg. Loss: 0.3597
===> Timestamp: [2025-08-03 19:54:05]
Checkpoint saved to TrainedNet/_epoch_5.pth
===> Loading train datasets
===> Epoch[5](100/2500): Loss: 0.3657
===> Epoch[5](200/2500): Loss: 0.3448
===> Epoch[5](300/2500): Loss: 0.3279
===> Epoch[5](400/2500): Loss: 0.3588
===> Epoch[5](500/2500): Loss: 0.3424
===> Epoch[5](600/2500): Loss: 0.3568
===> Epoch[5](700/2500): Loss: 0.3465
===> Epoch[5](800/2500): Loss: 0.3531
===> Epoch[5](900/2500): Loss: 0.3269
===> Epoch[5](1000/2500): Loss: 0.3668
===> Epoch[5](1100/2500): Loss: 0.3829
===> Epoch[5](1200/2500): Loss: 0.3934
===> Epoch[5](1300/2500): Loss: 0.3570
===> Epoch[5](1400/2500): Loss: 0.3667
===> Epoch[5](1500/2500): Loss: 0.3695
===> Epoch[5](1600/2500): Loss: 0.3399
===> Epoch[5](1700/2500): Loss: 0.3646
===> Epoch[5](1800/2500): Loss: 0.3204
===> Epoch[5](1900/2500): Loss: 0.3499
===> Epoch[5](2000/2500): Loss: 0.3542
===> Epoch[5](2100/2500): Loss: 0.3721
===> Epoch[5](2200/2500): Loss: 0.3631
===> Epoch[5](2300/2500): Loss: 0.3380
===> Epoch[5](2400/2500): Loss: 0.3267
===> Epoch[5](2500/2500): Loss: 0.3175
===> Epoch 5 Complete: Avg. Loss: 0.3597
===> Timestamp: [2025-08-03 19:54:05]
Checkpoint saved to TrainedNet/_epoch_5.pth
===> Loading train datasets
===> Epoch[5](100/2500): Loss: 0.3657
===> Epoch[5](200/2500): Loss: 0.3448
===> Epoch[5](300/2500): Loss: 0.3279
===> Epoch[5](400/2500): Loss: 0.3588
===> Epoch[5](500/2500): Loss: 0.3424
===> Epoch[5](600/2500): Loss: 0.3568
===> Epoch[5](700/2500): Loss: 0.3465
===> Epoch[5](800/2500): Loss: 0.3531
===> Epoch[5](900/2500): Loss: 0.3269
===> Epoch[5](1000/2500): Loss: 0.3668
===> Epoch[5](1100/2500): Loss: 0.3829
===> Epoch[5](1200/2500): Loss: 0.3934
===> Epoch[5](1300/2500): Loss: 0.3570
===> Epoch[5](1400/2500): Loss: 0.3667
===> Epoch[5](1500/2500): Loss: 0.3695
===> Epoch[5](1600/2500): Loss: 0.3399
===> Epoch[5](1700/2500): Loss: 0.3646
===> Epoch[5](1800/2500): Loss: 0.3204
===> Epoch[5](1900/2500): Loss: 0.3499
===> Epoch[5](2000/2500): Loss: 0.3542
===> Epoch[5](2100/2500): Loss: 0.3721
===> Epoch[5](2200/2500): Loss: 0.3631
===> Epoch[5](2300/2500): Loss: 0.3380
===> Epoch[5](2400/2500): Loss: 0.3267
===> Epoch[5](2500/2500): Loss: 0.3175
===> Epoch 5 Complete: Avg. Loss: 0.3597
===> Timestamp: [2025-08-03 19:54:05]
Checkpoint saved to TrainedNet/_epoch_5.pth
===> Loading train datasets
===> Epoch[5](100/2500): Loss: 0.3657
===> Epoch[5](200/2500): Loss: 0.3448
===> Epoch[5](300/2500): Loss: 0.3279
===> Epoch[5](400/2500): Loss: 0.3588
===> Epoch[5](500/2500): Loss: 0.3424
===> Epoch[5](600/2500): Loss: 0.3568
===> Epoch[5](700/2500): Loss: 0.3465
===> Epoch[5](800/2500): Loss: 0.3531
===> Epoch[5](900/2500): Loss: 0.3269
===> Epoch[5](1000/2500): Loss: 0.3668
===> Epoch[5](1100/2500): Loss: 0.3829
===> Epoch[5](1200/2500): Loss: 0.3934
===> Epoch[5](1300/2500): Loss: 0.3570
===> Epoch[5](1400/2500): Loss: 0.3667
===> Epoch[5](1500/2500): Loss: 0.3695
===> Epoch[5](1600/2500): Loss: 0.3399
===> Epoch[5](1700/2500): Loss: 0.3646
===> Epoch[5](1800/2500): Loss: 0.3204
===> Epoch[5](1900/2500): Loss: 0.3499
===> Epoch[5](2000/2500): Loss: 0.3542
===> Epoch[5](2100/2500): Loss: 0.3721
===> Epoch[5](2200/2500): Loss: 0.3631
===> Epoch[5](2300/2500): Loss: 0.3380
===> Epoch[5](2400/2500): Loss: 0.3267
===> Epoch[5](2500/2500): Loss: 0.3175
===> Epoch 5 Complete: Avg. Loss: 0.3597
===> Timestamp: [2025-08-03 19:54:05]
Checkpoint saved to TrainedNet/_epoch_5.pth
===> Loading train datasets
===> Loading train datasets
===> Epoch[6](100/2500): Loss: 0.3310
===> Epoch[6](200/2500): Loss: 0.3828
===> Epoch[6](300/2500): Loss: 0.3565
===> Epoch[6](400/2500): Loss: 0.3686
===> Epoch[6](500/2500): Loss: 0.3492
===> Epoch[6](600/2500): Loss: 0.3817
===> Epoch[6](700/2500): Loss: 0.3557
===> Epoch[6](800/2500): Loss: 0.3350
===> Epoch[6](900/2500): Loss: 0.3807
===> Epoch[6](1000/2500): Loss: 0.3691
===> Epoch[6](1100/2500): Loss: 0.3254
===> Epoch[6](1200/2500): Loss: 0.3542
===> Epoch[6](1300/2500): Loss: 0.3509
===> Epoch[6](1400/2500): Loss: 0.3713
===> Epoch[6](1500/2500): Loss: 0.3244
===> Epoch[6](1600/2500): Loss: 0.3329
===> Epoch[6](1700/2500): Loss: 0.3261
===> Epoch[6](1800/2500): Loss: 0.3221
===> Epoch[6](1900/2500): Loss: 0.3525
===> Epoch[6](2000/2500): Loss: 0.3377
===> Epoch[6](2100/2500): Loss: 0.3461
===> Epoch[6](2200/2500): Loss: 0.3164
===> Epoch[6](2300/2500): Loss: 0.3364
===> Epoch[6](2400/2500): Loss: 0.3443
===> Epoch[6](2500/2500): Loss: 0.3403
===> Epoch 6 Complete: Avg. Loss: 0.3519
===> Timestamp: [2025-08-03 19:58:39]
===> Loading train datasets
===> Epoch[6](100/2500): Loss: 0.3310
===> Epoch[6](200/2500): Loss: 0.3828
===> Epoch[6](300/2500): Loss: 0.3565
===> Epoch[6](400/2500): Loss: 0.3686
===> Epoch[6](500/2500): Loss: 0.3492
===> Epoch[6](600/2500): Loss: 0.3817
===> Epoch[6](700/2500): Loss: 0.3557
===> Epoch[6](800/2500): Loss: 0.3350
===> Epoch[6](900/2500): Loss: 0.3807
===> Epoch[6](1000/2500): Loss: 0.3691
===> Epoch[6](1100/2500): Loss: 0.3254
===> Epoch[6](1200/2500): Loss: 0.3542
===> Epoch[6](1300/2500): Loss: 0.3509
===> Epoch[6](1400/2500): Loss: 0.3713
===> Epoch[6](1500/2500): Loss: 0.3244
===> Epoch[6](1600/2500): Loss: 0.3329
===> Epoch[6](1700/2500): Loss: 0.3261
===> Epoch[6](1800/2500): Loss: 0.3221
===> Epoch[6](1900/2500): Loss: 0.3525
===> Epoch[6](2000/2500): Loss: 0.3377
===> Epoch[6](2100/2500): Loss: 0.3461
===> Epoch[6](2200/2500): Loss: 0.3164
===> Epoch[6](2300/2500): Loss: 0.3364
===> Epoch[6](2400/2500): Loss: 0.3443
===> Epoch[6](2500/2500): Loss: 0.3403
===> Epoch 6 Complete: Avg. Loss: 0.3519
===> Timestamp: [2025-08-03 19:58:39]
===> Loading train datasets
===> Epoch[6](100/2500): Loss: 0.3310
===> Epoch[6](200/2500): Loss: 0.3828
===> Epoch[6](300/2500): Loss: 0.3565
===> Epoch[6](400/2500): Loss: 0.3686
===> Epoch[6](500/2500): Loss: 0.3492
===> Epoch[6](600/2500): Loss: 0.3817
===> Epoch[6](700/2500): Loss: 0.3557
===> Epoch[6](800/2500): Loss: 0.3350
===> Epoch[6](900/2500): Loss: 0.3807
===> Epoch[6](1000/2500): Loss: 0.3691
===> Epoch[6](1100/2500): Loss: 0.3254
===> Epoch[6](1200/2500): Loss: 0.3542
===> Epoch[6](1300/2500): Loss: 0.3509
===> Epoch[6](1400/2500): Loss: 0.3713
===> Epoch[6](1500/2500): Loss: 0.3244
===> Epoch[6](1600/2500): Loss: 0.3329
===> Epoch[6](1700/2500): Loss: 0.3261
===> Epoch[6](1800/2500): Loss: 0.3221
===> Epoch[6](1900/2500): Loss: 0.3525
===> Epoch[6](2000/2500): Loss: 0.3377
===> Epoch[6](2100/2500): Loss: 0.3461
===> Epoch[6](2200/2500): Loss: 0.3164
===> Epoch[6](2300/2500): Loss: 0.3364
===> Epoch[6](2400/2500): Loss: 0.3443
===> Epoch[6](2500/2500): Loss: 0.3403
===> Epoch 6 Complete: Avg. Loss: 0.3519
===> Timestamp: [2025-08-03 19:58:39]
===> Loading train datasets
===> Epoch[6](100/2500): Loss: 0.3310
===> Epoch[6](200/2500): Loss: 0.3828
===> Epoch[6](300/2500): Loss: 0.3565
===> Epoch[6](400/2500): Loss: 0.3686
===> Epoch[6](500/2500): Loss: 0.3492
===> Epoch[6](600/2500): Loss: 0.3817
===> Epoch[6](700/2500): Loss: 0.3557
===> Epoch[6](800/2500): Loss: 0.3350
===> Epoch[6](900/2500): Loss: 0.3807
===> Epoch[6](1000/2500): Loss: 0.3691
===> Epoch[6](1100/2500): Loss: 0.3254
===> Epoch[6](1200/2500): Loss: 0.3542
===> Epoch[6](1300/2500): Loss: 0.3509
===> Epoch[6](1400/2500): Loss: 0.3713
===> Epoch[6](1500/2500): Loss: 0.3244
===> Epoch[6](1600/2500): Loss: 0.3329
===> Epoch[6](1700/2500): Loss: 0.3261
===> Epoch[6](1800/2500): Loss: 0.3221
===> Epoch[6](1900/2500): Loss: 0.3525
===> Epoch[6](2000/2500): Loss: 0.3377
===> Epoch[6](2100/2500): Loss: 0.3461
===> Epoch[6](2200/2500): Loss: 0.3164
===> Epoch[6](2300/2500): Loss: 0.3364
===> Epoch[6](2400/2500): Loss: 0.3443
===> Epoch[6](2500/2500): Loss: 0.3403
===> Epoch 6 Complete: Avg. Loss: 0.3519
===> Timestamp: [2025-08-03 19:58:39]
===> Loading train datasets
===> Epoch[6](100/2500): Loss: 0.3310
===> Epoch[6](200/2500): Loss: 0.3828
===> Epoch[6](300/2500): Loss: 0.3565
===> Epoch[6](400/2500): Loss: 0.3686
===> Epoch[6](500/2500): Loss: 0.3492
===> Epoch[6](600/2500): Loss: 0.3817
===> Epoch[6](700/2500): Loss: 0.3557
===> Epoch[6](800/2500): Loss: 0.3350
===> Epoch[6](900/2500): Loss: 0.3807
===> Epoch[6](1000/2500): Loss: 0.3691
===> Epoch[6](1100/2500): Loss: 0.3254
===> Epoch[6](1200/2500): Loss: 0.3542
===> Epoch[6](1300/2500): Loss: 0.3509
===> Epoch[6](1400/2500): Loss: 0.3713
===> Epoch[6](1500/2500): Loss: 0.3244
===> Epoch[6](1600/2500): Loss: 0.3329
===> Epoch[6](1700/2500): Loss: 0.3261
===> Epoch[6](1800/2500): Loss: 0.3221
===> Epoch[6](1900/2500): Loss: 0.3525
===> Epoch[6](2000/2500): Loss: 0.3377
===> Epoch[6](2100/2500): Loss: 0.3461
===> Epoch[6](2200/2500): Loss: 0.3164
===> Epoch[6](2300/2500): Loss: 0.3364
===> Epoch[6](2400/2500): Loss: 0.3443
===> Epoch[6](2500/2500): Loss: 0.3403
===> Epoch 6 Complete: Avg. Loss: 0.3519
===> Timestamp: [2025-08-03 19:58:39]
===> Loading train datasets
===> Epoch[6](100/2500): Loss: 0.3310
===> Epoch[6](200/2500): Loss: 0.3828
===> Epoch[6](300/2500): Loss: 0.3565
===> Epoch[6](400/2500): Loss: 0.3686
===> Epoch[6](500/2500): Loss: 0.3492
===> Epoch[6](600/2500): Loss: 0.3817
===> Epoch[6](700/2500): Loss: 0.3557
===> Epoch[6](800/2500): Loss: 0.3350
===> Epoch[6](900/2500): Loss: 0.3807
===> Epoch[6](1000/2500): Loss: 0.3691
===> Epoch[6](1100/2500): Loss: 0.3254
===> Epoch[6](1200/2500): Loss: 0.3542
===> Epoch[6](1300/2500): Loss: 0.3509
===> Epoch[6](1400/2500): Loss: 0.3713
===> Epoch[6](1500/2500): Loss: 0.3244
===> Epoch[6](1600/2500): Loss: 0.3329
===> Epoch[6](1700/2500): Loss: 0.3261
===> Epoch[6](1800/2500): Loss: 0.3221
===> Epoch[6](1900/2500): Loss: 0.3525
===> Epoch[6](2000/2500): Loss: 0.3377
===> Epoch[6](2100/2500): Loss: 0.3461
===> Epoch[6](2200/2500): Loss: 0.3164
===> Epoch[6](2300/2500): Loss: 0.3364
===> Epoch[6](2400/2500): Loss: 0.3443
===> Epoch[6](2500/2500): Loss: 0.3403
===> Epoch 6 Complete: Avg. Loss: 0.3519
===> Timestamp: [2025-08-03 19:58:39]
===> Loading train datasets
===> Loading train datasets
===> Epoch[7](100/2500): Loss: 0.3112
===> Epoch[7](200/2500): Loss: 0.3449
===> Epoch[7](300/2500): Loss: 0.3502
===> Epoch[7](400/2500): Loss: 0.3532
===> Epoch[7](500/2500): Loss: 0.3348
===> Epoch[7](600/2500): Loss: 0.3377
===> Epoch[7](700/2500): Loss: 0.3189
===> Epoch[7](800/2500): Loss: 0.3494
===> Epoch[7](900/2500): Loss: 0.3569
===> Epoch[7](1000/2500): Loss: 0.3609
===> Epoch[7](1100/2500): Loss: 0.3377
===> Epoch[7](1200/2500): Loss: 0.3322
===> Epoch[7](1300/2500): Loss: 0.3394
===> Epoch[7](1400/2500): Loss: 0.3507
===> Epoch[7](1500/2500): Loss: 0.3232
===> Epoch[7](1600/2500): Loss: 0.3262
===> Epoch[7](1700/2500): Loss: 0.3252
===> Epoch[7](1800/2500): Loss: 0.3253
===> Epoch[7](1900/2500): Loss: 0.3541
===> Epoch[7](2000/2500): Loss: 0.3562
===> Epoch[7](2100/2500): Loss: 0.3087
===> Epoch[7](2200/2500): Loss: 0.3414
===> Epoch[7](2300/2500): Loss: 0.3450
===> Epoch[7](2400/2500): Loss: 0.3262
===> Epoch[7](2500/2500): Loss: 0.3439
===> Epoch 7 Complete: Avg. Loss: 0.3445
===> Timestamp: [2025-08-03 20:03:13]
===> Loading train datasets
===> Epoch[7](100/2500): Loss: 0.3112
===> Epoch[7](200/2500): Loss: 0.3449
===> Epoch[7](300/2500): Loss: 0.3502
===> Epoch[7](400/2500): Loss: 0.3532
===> Epoch[7](500/2500): Loss: 0.3348
===> Epoch[7](600/2500): Loss: 0.3377
===> Epoch[7](700/2500): Loss: 0.3189
===> Epoch[7](800/2500): Loss: 0.3494
===> Epoch[7](900/2500): Loss: 0.3569
===> Epoch[7](1000/2500): Loss: 0.3609
===> Epoch[7](1100/2500): Loss: 0.3377
===> Epoch[7](1200/2500): Loss: 0.3322
===> Epoch[7](1300/2500): Loss: 0.3394
===> Epoch[7](1400/2500): Loss: 0.3507
===> Epoch[7](1500/2500): Loss: 0.3232
===> Epoch[7](1600/2500): Loss: 0.3262
===> Epoch[7](1700/2500): Loss: 0.3252
===> Epoch[7](1800/2500): Loss: 0.3253
===> Epoch[7](1900/2500): Loss: 0.3541
===> Epoch[7](2000/2500): Loss: 0.3562
===> Epoch[7](2100/2500): Loss: 0.3087
===> Epoch[7](2200/2500): Loss: 0.3414
===> Epoch[7](2300/2500): Loss: 0.3450
===> Epoch[7](2400/2500): Loss: 0.3262
===> Epoch[7](2500/2500): Loss: 0.3439
===> Epoch 7 Complete: Avg. Loss: 0.3445
===> Timestamp: [2025-08-03 20:03:13]
===> Loading train datasets
===> Epoch[7](100/2500): Loss: 0.3112
===> Epoch[7](200/2500): Loss: 0.3449
===> Epoch[7](300/2500): Loss: 0.3502
===> Epoch[7](400/2500): Loss: 0.3532
===> Epoch[7](500/2500): Loss: 0.3348
===> Epoch[7](600/2500): Loss: 0.3377
===> Epoch[7](700/2500): Loss: 0.3189
===> Epoch[7](800/2500): Loss: 0.3494
===> Epoch[7](900/2500): Loss: 0.3569
===> Epoch[7](1000/2500): Loss: 0.3609
===> Epoch[7](1100/2500): Loss: 0.3377
===> Epoch[7](1200/2500): Loss: 0.3322
===> Epoch[7](1300/2500): Loss: 0.3394
===> Epoch[7](1400/2500): Loss: 0.3507
===> Epoch[7](1500/2500): Loss: 0.3232
===> Epoch[7](1600/2500): Loss: 0.3262
===> Epoch[7](1700/2500): Loss: 0.3252
===> Epoch[7](1800/2500): Loss: 0.3253
===> Epoch[7](1900/2500): Loss: 0.3541
===> Epoch[7](2000/2500): Loss: 0.3562
===> Epoch[7](2100/2500): Loss: 0.3087
===> Epoch[7](2200/2500): Loss: 0.3414
===> Epoch[7](2300/2500): Loss: 0.3450
===> Epoch[7](2400/2500): Loss: 0.3262
===> Epoch[7](2500/2500): Loss: 0.3439
===> Epoch 7 Complete: Avg. Loss: 0.3445
===> Timestamp: [2025-08-03 20:03:13]
===> Loading train datasets
===> Epoch[7](100/2500): Loss: 0.3112
===> Epoch[7](200/2500): Loss: 0.3449
===> Epoch[7](300/2500): Loss: 0.3502
===> Epoch[7](400/2500): Loss: 0.3532
===> Epoch[7](500/2500): Loss: 0.3348
===> Epoch[7](600/2500): Loss: 0.3377
===> Epoch[7](700/2500): Loss: 0.3189
===> Epoch[7](800/2500): Loss: 0.3494
===> Epoch[7](900/2500): Loss: 0.3569
===> Epoch[7](1000/2500): Loss: 0.3609
===> Epoch[7](1100/2500): Loss: 0.3377
===> Epoch[7](1200/2500): Loss: 0.3322
===> Epoch[7](1300/2500): Loss: 0.3394
===> Epoch[7](1400/2500): Loss: 0.3507
===> Epoch[7](1500/2500): Loss: 0.3232
===> Epoch[7](1600/2500): Loss: 0.3262
===> Epoch[7](1700/2500): Loss: 0.3252
===> Epoch[7](1800/2500): Loss: 0.3253
===> Epoch[7](1900/2500): Loss: 0.3541
===> Epoch[7](2000/2500): Loss: 0.3562
===> Epoch[7](2100/2500): Loss: 0.3087
===> Epoch[7](2200/2500): Loss: 0.3414
===> Epoch[7](2300/2500): Loss: 0.3450
===> Epoch[7](2400/2500): Loss: 0.3262
===> Epoch[7](2500/2500): Loss: 0.3439
===> Epoch 7 Complete: Avg. Loss: 0.3445
===> Timestamp: [2025-08-03 20:03:13]
===> Loading train datasets
===> Epoch[7](100/2500): Loss: 0.3112
===> Epoch[7](200/2500): Loss: 0.3449
===> Epoch[7](300/2500): Loss: 0.3502
===> Epoch[7](400/2500): Loss: 0.3532
===> Epoch[7](500/2500): Loss: 0.3348
===> Epoch[7](600/2500): Loss: 0.3377
===> Epoch[7](700/2500): Loss: 0.3189
===> Epoch[7](800/2500): Loss: 0.3494
===> Epoch[7](900/2500): Loss: 0.3569
===> Epoch[7](1000/2500): Loss: 0.3609
===> Epoch[7](1100/2500): Loss: 0.3377
===> Epoch[7](1200/2500): Loss: 0.3322
===> Epoch[7](1300/2500): Loss: 0.3394
===> Epoch[7](1400/2500): Loss: 0.3507
===> Epoch[7](1500/2500): Loss: 0.3232
===> Epoch[7](1600/2500): Loss: 0.3262
===> Epoch[7](1700/2500): Loss: 0.3252
===> Epoch[7](1800/2500): Loss: 0.3253
===> Epoch[7](1900/2500): Loss: 0.3541
===> Epoch[7](2000/2500): Loss: 0.3562
===> Epoch[7](2100/2500): Loss: 0.3087
===> Epoch[7](2200/2500): Loss: 0.3414
===> Epoch[7](2300/2500): Loss: 0.3450
===> Epoch[7](2400/2500): Loss: 0.3262
===> Epoch[7](2500/2500): Loss: 0.3439
===> Epoch 7 Complete: Avg. Loss: 0.3445
===> Timestamp: [2025-08-03 20:03:13]
===> Loading train datasets
===> Epoch[7](100/2500): Loss: 0.3112
===> Epoch[7](200/2500): Loss: 0.3449
===> Epoch[7](300/2500): Loss: 0.3502
===> Epoch[7](400/2500): Loss: 0.3532
===> Epoch[7](500/2500): Loss: 0.3348
===> Epoch[7](600/2500): Loss: 0.3377
===> Epoch[7](700/2500): Loss: 0.3189
===> Epoch[7](800/2500): Loss: 0.3494
===> Epoch[7](900/2500): Loss: 0.3569
===> Epoch[7](1000/2500): Loss: 0.3609
===> Epoch[7](1100/2500): Loss: 0.3377
===> Epoch[7](1200/2500): Loss: 0.3322
===> Epoch[7](1300/2500): Loss: 0.3394
===> Epoch[7](1400/2500): Loss: 0.3507
===> Epoch[7](1500/2500): Loss: 0.3232
===> Epoch[7](1600/2500): Loss: 0.3262
===> Epoch[7](1700/2500): Loss: 0.3252
===> Epoch[7](1800/2500): Loss: 0.3253
===> Epoch[7](1900/2500): Loss: 0.3541
===> Epoch[7](2000/2500): Loss: 0.3562
===> Epoch[7](2100/2500): Loss: 0.3087
===> Epoch[7](2200/2500): Loss: 0.3414
===> Epoch[7](2300/2500): Loss: 0.3450
===> Epoch[7](2400/2500): Loss: 0.3262
===> Epoch[7](2500/2500): Loss: 0.3439
===> Epoch 7 Complete: Avg. Loss: 0.3445
===> Timestamp: [2025-08-03 20:03:13]
===> Loading train datasets
===> Epoch[7](100/2500): Loss: 0.3112
===> Epoch[7](200/2500): Loss: 0.3449
===> Epoch[7](300/2500): Loss: 0.3502
===> Epoch[7](400/2500): Loss: 0.3532
===> Epoch[7](500/2500): Loss: 0.3348
===> Epoch[7](600/2500): Loss: 0.3377
===> Epoch[7](700/2500): Loss: 0.3189
===> Epoch[7](800/2500): Loss: 0.3494
===> Epoch[7](900/2500): Loss: 0.3569
===> Epoch[7](1000/2500): Loss: 0.3609
===> Epoch[7](1100/2500): Loss: 0.3377
===> Epoch[7](1200/2500): Loss: 0.3322
===> Epoch[7](1300/2500): Loss: 0.3394
===> Epoch[7](1400/2500): Loss: 0.3507
===> Epoch[7](1500/2500): Loss: 0.3232
===> Epoch[7](1600/2500): Loss: 0.3262
===> Epoch[7](1700/2500): Loss: 0.3252
===> Epoch[7](1800/2500): Loss: 0.3253
===> Epoch[7](1900/2500): Loss: 0.3541
===> Epoch[7](2000/2500): Loss: 0.3562
===> Epoch[7](2100/2500): Loss: 0.3087
===> Epoch[7](2200/2500): Loss: 0.3414
===> Epoch[7](2300/2500): Loss: 0.3450
===> Epoch[7](2400/2500): Loss: 0.3262
===> Epoch[7](2500/2500): Loss: 0.3439
===> Epoch 7 Complete: Avg. Loss: 0.3445
===> Timestamp: [2025-08-03 20:03:13]
===> Loading train datasets
===> Loading train datasets
===> Epoch[8](100/2500): Loss: 0.3346
===> Epoch[8](200/2500): Loss: 0.3047
===> Epoch[8](300/2500): Loss: 0.3667
===> Epoch[8](400/2500): Loss: 0.3775
===> Epoch[8](500/2500): Loss: 0.3607
===> Epoch[8](600/2500): Loss: 0.3386
===> Epoch[8](700/2500): Loss: 0.3469
===> Epoch[8](800/2500): Loss: 0.3215
===> Epoch[8](900/2500): Loss: 0.3309
===> Epoch[8](1000/2500): Loss: 0.3511
===> Epoch[8](1100/2500): Loss: 0.3466
===> Epoch[8](1200/2500): Loss: 0.3402
===> Epoch[8](1300/2500): Loss: 0.3343
===> Epoch[8](1400/2500): Loss: 0.3447
===> Epoch[8](1500/2500): Loss: 0.3472
===> Epoch[8](1600/2500): Loss: 0.3428
===> Epoch[8](1700/2500): Loss: 0.3011
===> Epoch[8](1800/2500): Loss: 0.3388
===> Epoch[8](1900/2500): Loss: 0.3293
===> Epoch[8](2000/2500): Loss: 0.3143
===> Epoch[8](2100/2500): Loss: 0.3235
===> Epoch[8](2200/2500): Loss: 0.3307
===> Epoch[8](2300/2500): Loss: 0.3272
===> Epoch[8](2400/2500): Loss: 0.3271
===> Epoch[8](2500/2500): Loss: 0.3144
===> Epoch 8 Complete: Avg. Loss: 0.3350
===> Timestamp: [2025-08-03 20:07:47]
===> Loading train datasets
===> Epoch[8](100/2500): Loss: 0.3346
===> Epoch[8](200/2500): Loss: 0.3047
===> Epoch[8](300/2500): Loss: 0.3667
===> Epoch[8](400/2500): Loss: 0.3775
===> Epoch[8](500/2500): Loss: 0.3607
===> Epoch[8](600/2500): Loss: 0.3386
===> Epoch[8](700/2500): Loss: 0.3469
===> Epoch[8](800/2500): Loss: 0.3215
===> Epoch[8](900/2500): Loss: 0.3309
===> Epoch[8](1000/2500): Loss: 0.3511
===> Epoch[8](1100/2500): Loss: 0.3466
===> Epoch[8](1200/2500): Loss: 0.3402
===> Epoch[8](1300/2500): Loss: 0.3343
===> Epoch[8](1400/2500): Loss: 0.3447
===> Epoch[8](1500/2500): Loss: 0.3472
===> Epoch[8](1600/2500): Loss: 0.3428
===> Epoch[8](1700/2500): Loss: 0.3011
===> Epoch[8](1800/2500): Loss: 0.3388
===> Epoch[8](1900/2500): Loss: 0.3293
===> Epoch[8](2000/2500): Loss: 0.3143
===> Epoch[8](2100/2500): Loss: 0.3235
===> Epoch[8](2200/2500): Loss: 0.3307
===> Epoch[8](2300/2500): Loss: 0.3272
===> Epoch[8](2400/2500): Loss: 0.3271
===> Epoch[8](2500/2500): Loss: 0.3144
===> Epoch 8 Complete: Avg. Loss: 0.3350
===> Timestamp: [2025-08-03 20:07:47]
===> Loading train datasets
===> Epoch[8](100/2500): Loss: 0.3346
===> Epoch[8](200/2500): Loss: 0.3047
===> Epoch[8](300/2500): Loss: 0.3667
===> Epoch[8](400/2500): Loss: 0.3775
===> Epoch[8](500/2500): Loss: 0.3607
===> Epoch[8](600/2500): Loss: 0.3386
===> Epoch[8](700/2500): Loss: 0.3469
===> Epoch[8](800/2500): Loss: 0.3215
===> Epoch[8](900/2500): Loss: 0.3309
===> Epoch[8](1000/2500): Loss: 0.3511
===> Epoch[8](1100/2500): Loss: 0.3466
===> Epoch[8](1200/2500): Loss: 0.3402
===> Epoch[8](1300/2500): Loss: 0.3343
===> Epoch[8](1400/2500): Loss: 0.3447
===> Epoch[8](1500/2500): Loss: 0.3472
===> Epoch[8](1600/2500): Loss: 0.3428
===> Epoch[8](1700/2500): Loss: 0.3011
===> Epoch[8](1800/2500): Loss: 0.3388
===> Epoch[8](1900/2500): Loss: 0.3293
===> Epoch[8](2000/2500): Loss: 0.3143
===> Epoch[8](2100/2500): Loss: 0.3235
===> Epoch[8](2200/2500): Loss: 0.3307
===> Epoch[8](2300/2500): Loss: 0.3272
===> Epoch[8](2400/2500): Loss: 0.3271
===> Epoch[8](2500/2500): Loss: 0.3144
===> Epoch 8 Complete: Avg. Loss: 0.3350
===> Timestamp: [2025-08-03 20:07:47]
===> Loading train datasets
===> Epoch[8](100/2500): Loss: 0.3346
===> Epoch[8](200/2500): Loss: 0.3047
===> Epoch[8](300/2500): Loss: 0.3667
===> Epoch[8](400/2500): Loss: 0.3775
===> Epoch[8](500/2500): Loss: 0.3607
===> Epoch[8](600/2500): Loss: 0.3386
===> Epoch[8](700/2500): Loss: 0.3469
===> Epoch[8](800/2500): Loss: 0.3215
===> Epoch[8](900/2500): Loss: 0.3309
===> Epoch[8](1000/2500): Loss: 0.3511
===> Epoch[8](1100/2500): Loss: 0.3466
===> Epoch[8](1200/2500): Loss: 0.3402
===> Epoch[8](1300/2500): Loss: 0.3343
===> Epoch[8](1400/2500): Loss: 0.3447
===> Epoch[8](1500/2500): Loss: 0.3472
===> Epoch[8](1600/2500): Loss: 0.3428
===> Epoch[8](1700/2500): Loss: 0.3011
===> Epoch[8](1800/2500): Loss: 0.3388
===> Epoch[8](1900/2500): Loss: 0.3293
===> Epoch[8](2000/2500): Loss: 0.3143
===> Epoch[8](2100/2500): Loss: 0.3235
===> Epoch[8](2200/2500): Loss: 0.3307
===> Epoch[8](2300/2500): Loss: 0.3272
===> Epoch[8](2400/2500): Loss: 0.3271
===> Epoch[8](2500/2500): Loss: 0.3144
===> Epoch 8 Complete: Avg. Loss: 0.3350
===> Timestamp: [2025-08-03 20:07:47]
===> Loading train datasets
===> Epoch[8](100/2500): Loss: 0.3346
===> Epoch[8](200/2500): Loss: 0.3047
===> Epoch[8](300/2500): Loss: 0.3667
===> Epoch[8](400/2500): Loss: 0.3775
===> Epoch[8](500/2500): Loss: 0.3607
===> Epoch[8](600/2500): Loss: 0.3386
===> Epoch[8](700/2500): Loss: 0.3469
===> Epoch[8](800/2500): Loss: 0.3215
===> Epoch[8](900/2500): Loss: 0.3309
===> Epoch[8](1000/2500): Loss: 0.3511
===> Epoch[8](1100/2500): Loss: 0.3466
===> Epoch[8](1200/2500): Loss: 0.3402
===> Epoch[8](1300/2500): Loss: 0.3343
===> Epoch[8](1400/2500): Loss: 0.3447
===> Epoch[8](1500/2500): Loss: 0.3472
===> Epoch[8](1600/2500): Loss: 0.3428
===> Epoch[8](1700/2500): Loss: 0.3011
===> Epoch[8](1800/2500): Loss: 0.3388
===> Epoch[8](1900/2500): Loss: 0.3293
===> Epoch[8](2000/2500): Loss: 0.3143
===> Epoch[8](2100/2500): Loss: 0.3235
===> Epoch[8](2200/2500): Loss: 0.3307
===> Epoch[8](2300/2500): Loss: 0.3272
===> Epoch[8](2400/2500): Loss: 0.3271
===> Epoch[8](2500/2500): Loss: 0.3144
===> Epoch 8 Complete: Avg. Loss: 0.3350
===> Timestamp: [2025-08-03 20:07:47]
===> Loading train datasets
===> Epoch[8](100/2500): Loss: 0.3346
===> Epoch[8](200/2500): Loss: 0.3047
===> Epoch[8](300/2500): Loss: 0.3667
===> Epoch[8](400/2500): Loss: 0.3775
===> Epoch[8](500/2500): Loss: 0.3607
===> Epoch[8](600/2500): Loss: 0.3386
===> Epoch[8](700/2500): Loss: 0.3469
===> Epoch[8](800/2500): Loss: 0.3215
===> Epoch[8](900/2500): Loss: 0.3309
===> Epoch[8](1000/2500): Loss: 0.3511
===> Epoch[8](1100/2500): Loss: 0.3466
===> Epoch[8](1200/2500): Loss: 0.3402
===> Epoch[8](1300/2500): Loss: 0.3343
===> Epoch[8](1400/2500): Loss: 0.3447
===> Epoch[8](1500/2500): Loss: 0.3472
===> Epoch[8](1600/2500): Loss: 0.3428
===> Epoch[8](1700/2500): Loss: 0.3011
===> Epoch[8](1800/2500): Loss: 0.3388
===> Epoch[8](1900/2500): Loss: 0.3293
===> Epoch[8](2000/2500): Loss: 0.3143
===> Epoch[8](2100/2500): Loss: 0.3235
===> Epoch[8](2200/2500): Loss: 0.3307
===> Epoch[8](2300/2500): Loss: 0.3272
===> Epoch[8](2400/2500): Loss: 0.3271
===> Epoch[8](2500/2500): Loss: 0.3144
===> Epoch 8 Complete: Avg. Loss: 0.3350
===> Timestamp: [2025-08-03 20:07:47]
===> Loading train datasets
===> Epoch[8](100/2500): Loss: 0.3346
===> Epoch[8](200/2500): Loss: 0.3047
===> Epoch[8](300/2500): Loss: 0.3667
===> Epoch[8](400/2500): Loss: 0.3775
===> Epoch[8](500/2500): Loss: 0.3607
===> Epoch[8](600/2500): Loss: 0.3386
===> Epoch[8](700/2500): Loss: 0.3469
===> Epoch[8](800/2500): Loss: 0.3215
===> Epoch[8](900/2500): Loss: 0.3309
===> Epoch[8](1000/2500): Loss: 0.3511
===> Epoch[8](1100/2500): Loss: 0.3466
===> Epoch[8](1200/2500): Loss: 0.3402
===> Epoch[8](1300/2500): Loss: 0.3343
===> Epoch[8](1400/2500): Loss: 0.3447
===> Epoch[8](1500/2500): Loss: 0.3472
===> Epoch[8](1600/2500): Loss: 0.3428
===> Epoch[8](1700/2500): Loss: 0.3011
===> Epoch[8](1800/2500): Loss: 0.3388
===> Epoch[8](1900/2500): Loss: 0.3293
===> Epoch[8](2000/2500): Loss: 0.3143
===> Epoch[8](2100/2500): Loss: 0.3235
===> Epoch[8](2200/2500): Loss: 0.3307
===> Epoch[8](2300/2500): Loss: 0.3272
===> Epoch[8](2400/2500): Loss: 0.3271
===> Epoch[8](2500/2500): Loss: 0.3144
===> Epoch 8 Complete: Avg. Loss: 0.3350
===> Timestamp: [2025-08-03 20:07:47]
===> Loading train datasets
===> Epoch[8](100/2500): Loss: 0.3346
===> Epoch[8](200/2500): Loss: 0.3047
===> Epoch[8](300/2500): Loss: 0.3667
===> Epoch[8](400/2500): Loss: 0.3775
===> Epoch[8](500/2500): Loss: 0.3607
===> Epoch[8](600/2500): Loss: 0.3386
===> Epoch[8](700/2500): Loss: 0.3469
===> Epoch[8](800/2500): Loss: 0.3215
===> Epoch[8](900/2500): Loss: 0.3309
===> Epoch[8](1000/2500): Loss: 0.3511
===> Epoch[8](1100/2500): Loss: 0.3466
===> Epoch[8](1200/2500): Loss: 0.3402
===> Epoch[8](1300/2500): Loss: 0.3343
===> Epoch[8](1400/2500): Loss: 0.3447
===> Epoch[8](1500/2500): Loss: 0.3472
===> Epoch[8](1600/2500): Loss: 0.3428
===> Epoch[8](1700/2500): Loss: 0.3011
===> Epoch[8](1800/2500): Loss: 0.3388
===> Epoch[8](1900/2500): Loss: 0.3293
===> Epoch[8](2000/2500): Loss: 0.3143
===> Epoch[8](2100/2500): Loss: 0.3235
===> Epoch[8](2200/2500): Loss: 0.3307
===> Epoch[8](2300/2500): Loss: 0.3272
===> Epoch[8](2400/2500): Loss: 0.3271
===> Epoch[8](2500/2500): Loss: 0.3144
===> Epoch 8 Complete: Avg. Loss: 0.3350
===> Timestamp: [2025-08-03 20:07:47]
===> Loading train datasets
===> Loading train datasets
===> Epoch[9](100/2500): Loss: 0.2901
===> Epoch[9](200/2500): Loss: 0.3343
===> Epoch[9](300/2500): Loss: 0.3066
===> Epoch[9](400/2500): Loss: 0.3306
===> Epoch[9](500/2500): Loss: 0.3171
===> Epoch[9](600/2500): Loss: 0.3010
===> Epoch[9](700/2500): Loss: 0.3457
===> Epoch[9](800/2500): Loss: 0.3151
===> Epoch[9](900/2500): Loss: 0.3483
===> Epoch[9](1000/2500): Loss: 0.3109
===> Epoch[9](1100/2500): Loss: 0.3383
===> Epoch[9](1200/2500): Loss: 0.3156
===> Epoch[9](1300/2500): Loss: 0.2988
===> Epoch[9](1400/2500): Loss: 0.3272
===> Epoch[9](1500/2500): Loss: 0.3027
===> Epoch[9](1600/2500): Loss: 0.3547
===> Epoch[9](1700/2500): Loss: 0.3556
===> Epoch[9](1800/2500): Loss: 0.3232
===> Epoch[9](1900/2500): Loss: 0.3273
===> Epoch[9](2000/2500): Loss: 0.3167
===> Epoch[9](2100/2500): Loss: 0.3188
===> Epoch[9](2200/2500): Loss: 0.2923
===> Epoch[9](2300/2500): Loss: 0.3117
===> Epoch[9](2400/2500): Loss: 0.3182
===> Epoch[9](2500/2500): Loss: 0.3138
===> Epoch 9 Complete: Avg. Loss: 0.3245
===> Timestamp: [2025-08-03 20:12:21]
===> Loading train datasets
===> Epoch[9](100/2500): Loss: 0.2901
===> Epoch[9](200/2500): Loss: 0.3343
===> Epoch[9](300/2500): Loss: 0.3066
===> Epoch[9](400/2500): Loss: 0.3306
===> Epoch[9](500/2500): Loss: 0.3171
===> Epoch[9](600/2500): Loss: 0.3010
===> Epoch[9](700/2500): Loss: 0.3457
===> Epoch[9](800/2500): Loss: 0.3151
===> Epoch[9](900/2500): Loss: 0.3483
===> Epoch[9](1000/2500): Loss: 0.3109
===> Epoch[9](1100/2500): Loss: 0.3383
===> Epoch[9](1200/2500): Loss: 0.3156
===> Epoch[9](1300/2500): Loss: 0.2988
===> Epoch[9](1400/2500): Loss: 0.3272
===> Epoch[9](1500/2500): Loss: 0.3027
===> Epoch[9](1600/2500): Loss: 0.3547
===> Epoch[9](1700/2500): Loss: 0.3556
===> Epoch[9](1800/2500): Loss: 0.3232
===> Epoch[9](1900/2500): Loss: 0.3273
===> Epoch[9](2000/2500): Loss: 0.3167
===> Epoch[9](2100/2500): Loss: 0.3188
===> Epoch[9](2200/2500): Loss: 0.2923
===> Epoch[9](2300/2500): Loss: 0.3117
===> Epoch[9](2400/2500): Loss: 0.3182
===> Epoch[9](2500/2500): Loss: 0.3138
===> Epoch 9 Complete: Avg. Loss: 0.3245
===> Timestamp: [2025-08-03 20:12:21]
===> Loading train datasets
===> Epoch[9](100/2500): Loss: 0.2901
===> Epoch[9](200/2500): Loss: 0.3343
===> Epoch[9](300/2500): Loss: 0.3066
===> Epoch[9](400/2500): Loss: 0.3306
===> Epoch[9](500/2500): Loss: 0.3171
===> Epoch[9](600/2500): Loss: 0.3010
===> Epoch[9](700/2500): Loss: 0.3457
===> Epoch[9](800/2500): Loss: 0.3151
===> Epoch[9](900/2500): Loss: 0.3483
===> Epoch[9](1000/2500): Loss: 0.3109
===> Epoch[9](1100/2500): Loss: 0.3383
===> Epoch[9](1200/2500): Loss: 0.3156
===> Epoch[9](1300/2500): Loss: 0.2988
===> Epoch[9](1400/2500): Loss: 0.3272
===> Epoch[9](1500/2500): Loss: 0.3027
===> Epoch[9](1600/2500): Loss: 0.3547
===> Epoch[9](1700/2500): Loss: 0.3556
===> Epoch[9](1800/2500): Loss: 0.3232
===> Epoch[9](1900/2500): Loss: 0.3273
===> Epoch[9](2000/2500): Loss: 0.3167
===> Epoch[9](2100/2500): Loss: 0.3188
===> Epoch[9](2200/2500): Loss: 0.2923
===> Epoch[9](2300/2500): Loss: 0.3117
===> Epoch[9](2400/2500): Loss: 0.3182
===> Epoch[9](2500/2500): Loss: 0.3138
===> Epoch 9 Complete: Avg. Loss: 0.3245
===> Timestamp: [2025-08-03 20:12:21]
===> Loading train datasets
===> Epoch[9](100/2500): Loss: 0.2901
===> Epoch[9](200/2500): Loss: 0.3343
===> Epoch[9](300/2500): Loss: 0.3066
===> Epoch[9](400/2500): Loss: 0.3306
===> Epoch[9](500/2500): Loss: 0.3171
===> Epoch[9](600/2500): Loss: 0.3010
===> Epoch[9](700/2500): Loss: 0.3457
===> Epoch[9](800/2500): Loss: 0.3151
===> Epoch[9](900/2500): Loss: 0.3483
===> Epoch[9](1000/2500): Loss: 0.3109
===> Epoch[9](1100/2500): Loss: 0.3383
===> Epoch[9](1200/2500): Loss: 0.3156
===> Epoch[9](1300/2500): Loss: 0.2988
===> Epoch[9](1400/2500): Loss: 0.3272
===> Epoch[9](1500/2500): Loss: 0.3027
===> Epoch[9](1600/2500): Loss: 0.3547
===> Epoch[9](1700/2500): Loss: 0.3556
===> Epoch[9](1800/2500): Loss: 0.3232
===> Epoch[9](1900/2500): Loss: 0.3273
===> Epoch[9](2000/2500): Loss: 0.3167
===> Epoch[9](2100/2500): Loss: 0.3188
===> Epoch[9](2200/2500): Loss: 0.2923
===> Epoch[9](2300/2500): Loss: 0.3117
===> Epoch[9](2400/2500): Loss: 0.3182
===> Epoch[9](2500/2500): Loss: 0.3138
===> Epoch 9 Complete: Avg. Loss: 0.3245
===> Timestamp: [2025-08-03 20:12:21]
===> Loading train datasets
===> Epoch[9](100/2500): Loss: 0.2901
===> Epoch[9](200/2500): Loss: 0.3343
===> Epoch[9](300/2500): Loss: 0.3066
===> Epoch[9](400/2500): Loss: 0.3306
===> Epoch[9](500/2500): Loss: 0.3171
===> Epoch[9](600/2500): Loss: 0.3010
===> Epoch[9](700/2500): Loss: 0.3457
===> Epoch[9](800/2500): Loss: 0.3151
===> Epoch[9](900/2500): Loss: 0.3483
===> Epoch[9](1000/2500): Loss: 0.3109
===> Epoch[9](1100/2500): Loss: 0.3383
===> Epoch[9](1200/2500): Loss: 0.3156
===> Epoch[9](1300/2500): Loss: 0.2988
===> Epoch[9](1400/2500): Loss: 0.3272
===> Epoch[9](1500/2500): Loss: 0.3027
===> Epoch[9](1600/2500): Loss: 0.3547
===> Epoch[9](1700/2500): Loss: 0.3556
===> Epoch[9](1800/2500): Loss: 0.3232
===> Epoch[9](1900/2500): Loss: 0.3273
===> Epoch[9](2000/2500): Loss: 0.3167
===> Epoch[9](2100/2500): Loss: 0.3188
===> Epoch[9](2200/2500): Loss: 0.2923
===> Epoch[9](2300/2500): Loss: 0.3117
===> Epoch[9](2400/2500): Loss: 0.3182
===> Epoch[9](2500/2500): Loss: 0.3138
===> Epoch 9 Complete: Avg. Loss: 0.3245
===> Timestamp: [2025-08-03 20:12:21]
===> Loading train datasets
===> Epoch[9](100/2500): Loss: 0.2901
===> Epoch[9](200/2500): Loss: 0.3343
===> Epoch[9](300/2500): Loss: 0.3066
===> Epoch[9](400/2500): Loss: 0.3306
===> Epoch[9](500/2500): Loss: 0.3171
===> Epoch[9](600/2500): Loss: 0.3010
===> Epoch[9](700/2500): Loss: 0.3457
===> Epoch[9](800/2500): Loss: 0.3151
===> Epoch[9](900/2500): Loss: 0.3483
===> Epoch[9](1000/2500): Loss: 0.3109
===> Epoch[9](1100/2500): Loss: 0.3383
===> Epoch[9](1200/2500): Loss: 0.3156
===> Epoch[9](1300/2500): Loss: 0.2988
===> Epoch[9](1400/2500): Loss: 0.3272
===> Epoch[9](1500/2500): Loss: 0.3027
===> Epoch[9](1600/2500): Loss: 0.3547
===> Epoch[9](1700/2500): Loss: 0.3556
===> Epoch[9](1800/2500): Loss: 0.3232
===> Epoch[9](1900/2500): Loss: 0.3273
===> Epoch[9](2000/2500): Loss: 0.3167
===> Epoch[9](2100/2500): Loss: 0.3188
===> Epoch[9](2200/2500): Loss: 0.2923
===> Epoch[9](2300/2500): Loss: 0.3117
===> Epoch[9](2400/2500): Loss: 0.3182
===> Epoch[9](2500/2500): Loss: 0.3138
===> Epoch 9 Complete: Avg. Loss: 0.3245
===> Timestamp: [2025-08-03 20:12:21]
===> Loading train datasets
===> Epoch[9](100/2500): Loss: 0.2901
===> Epoch[9](200/2500): Loss: 0.3343
===> Epoch[9](300/2500): Loss: 0.3066
===> Epoch[9](400/2500): Loss: 0.3306
===> Epoch[9](500/2500): Loss: 0.3171
===> Epoch[9](600/2500): Loss: 0.3010
===> Epoch[9](700/2500): Loss: 0.3457
===> Epoch[9](800/2500): Loss: 0.3151
===> Epoch[9](900/2500): Loss: 0.3483
===> Epoch[9](1000/2500): Loss: 0.3109
===> Epoch[9](1100/2500): Loss: 0.3383
===> Epoch[9](1200/2500): Loss: 0.3156
===> Epoch[9](1300/2500): Loss: 0.2988
===> Epoch[9](1400/2500): Loss: 0.3272
===> Epoch[9](1500/2500): Loss: 0.3027
===> Epoch[9](1600/2500): Loss: 0.3547
===> Epoch[9](1700/2500): Loss: 0.3556
===> Epoch[9](1800/2500): Loss: 0.3232
===> Epoch[9](1900/2500): Loss: 0.3273
===> Epoch[9](2000/2500): Loss: 0.3167
===> Epoch[9](2100/2500): Loss: 0.3188
===> Epoch[9](2200/2500): Loss: 0.2923
===> Epoch[9](2300/2500): Loss: 0.3117
===> Epoch[9](2400/2500): Loss: 0.3182
===> Epoch[9](2500/2500): Loss: 0.3138
===> Epoch 9 Complete: Avg. Loss: 0.3245
===> Timestamp: [2025-08-03 20:12:21]
===> Loading train datasets
===> Epoch[9](100/2500): Loss: 0.2901
===> Epoch[9](200/2500): Loss: 0.3343
===> Epoch[9](300/2500): Loss: 0.3066
===> Epoch[9](400/2500): Loss: 0.3306
===> Epoch[9](500/2500): Loss: 0.3171
===> Epoch[9](600/2500): Loss: 0.3010
===> Epoch[9](700/2500): Loss: 0.3457
===> Epoch[9](800/2500): Loss: 0.3151
===> Epoch[9](900/2500): Loss: 0.3483
===> Epoch[9](1000/2500): Loss: 0.3109
===> Epoch[9](1100/2500): Loss: 0.3383
===> Epoch[9](1200/2500): Loss: 0.3156
===> Epoch[9](1300/2500): Loss: 0.2988
===> Epoch[9](1400/2500): Loss: 0.3272
===> Epoch[9](1500/2500): Loss: 0.3027
===> Epoch[9](1600/2500): Loss: 0.3547
===> Epoch[9](1700/2500): Loss: 0.3556
===> Epoch[9](1800/2500): Loss: 0.3232
===> Epoch[9](1900/2500): Loss: 0.3273
===> Epoch[9](2000/2500): Loss: 0.3167
===> Epoch[9](2100/2500): Loss: 0.3188
===> Epoch[9](2200/2500): Loss: 0.2923
===> Epoch[9](2300/2500): Loss: 0.3117
===> Epoch[9](2400/2500): Loss: 0.3182
===> Epoch[9](2500/2500): Loss: 0.3138
===> Epoch 9 Complete: Avg. Loss: 0.3245
===> Timestamp: [2025-08-03 20:12:21]
===> Loading train datasets
===> Epoch[9](100/2500): Loss: 0.2901
===> Epoch[9](200/2500): Loss: 0.3343
===> Epoch[9](300/2500): Loss: 0.3066
===> Epoch[9](400/2500): Loss: 0.3306
===> Epoch[9](500/2500): Loss: 0.3171
===> Epoch[9](600/2500): Loss: 0.3010
===> Epoch[9](700/2500): Loss: 0.3457
===> Epoch[9](800/2500): Loss: 0.3151
===> Epoch[9](900/2500): Loss: 0.3483
===> Epoch[9](1000/2500): Loss: 0.3109
===> Epoch[9](1100/2500): Loss: 0.3383
===> Epoch[9](1200/2500): Loss: 0.3156
===> Epoch[9](1300/2500): Loss: 0.2988
===> Epoch[9](1400/2500): Loss: 0.3272
===> Epoch[9](1500/2500): Loss: 0.3027
===> Epoch[9](1600/2500): Loss: 0.3547
===> Epoch[9](1700/2500): Loss: 0.3556
===> Epoch[9](1800/2500): Loss: 0.3232
===> Epoch[9](1900/2500): Loss: 0.3273
===> Epoch[9](2000/2500): Loss: 0.3167
===> Epoch[9](2100/2500): Loss: 0.3188
===> Epoch[9](2200/2500): Loss: 0.2923
===> Epoch[9](2300/2500): Loss: 0.3117
===> Epoch[9](2400/2500): Loss: 0.3182
===> Epoch[9](2500/2500): Loss: 0.3138
===> Epoch 9 Complete: Avg. Loss: 0.3245
===> Timestamp: [2025-08-03 20:12:21]
===> Loading train datasets
===> Loading train datasets
===> Epoch[10](100/2500): Loss: 0.3023
===> Epoch[10](200/2500): Loss: 0.3006
===> Epoch[10](300/2500): Loss: 0.3274
===> Epoch[10](400/2500): Loss: 0.3033
===> Epoch[10](500/2500): Loss: 0.2822
===> Epoch[10](600/2500): Loss: 0.3082
===> Epoch[10](700/2500): Loss: 0.3215
===> Epoch[10](800/2500): Loss: 0.3101
===> Epoch[10](900/2500): Loss: 0.3591
===> Epoch[10](1000/2500): Loss: 0.3081
===> Epoch[10](1100/2500): Loss: 0.3130
===> Epoch[10](1200/2500): Loss: 0.3232
===> Epoch[10](1300/2500): Loss: 0.3150
===> Epoch[10](1400/2500): Loss: 0.2883
===> Epoch[10](1500/2500): Loss: 0.3054
===> Epoch[10](1600/2500): Loss: 0.3047
===> Epoch[10](1700/2500): Loss: 0.3178
===> Epoch[10](1800/2500): Loss: 0.3135
===> Epoch[10](1900/2500): Loss: 0.3096
===> Epoch[10](2000/2500): Loss: 0.3178
===> Epoch[10](2100/2500): Loss: 0.3293
===> Epoch[10](2200/2500): Loss: 0.2998
===> Epoch[10](2300/2500): Loss: 0.3014
===> Epoch[10](2400/2500): Loss: 0.2912
===> Epoch[10](2500/2500): Loss: 0.2947
===> Epoch 10 Complete: Avg. Loss: 0.3145
===> Timestamp: [2025-08-03 20:16:55]
Checkpoint saved to TrainedNet/_epoch_10.pth
===> Loading train datasets
===> Epoch[10](100/2500): Loss: 0.3023
===> Epoch[10](200/2500): Loss: 0.3006
===> Epoch[10](300/2500): Loss: 0.3274
===> Epoch[10](400/2500): Loss: 0.3033
===> Epoch[10](500/2500): Loss: 0.2822
===> Epoch[10](600/2500): Loss: 0.3082
===> Epoch[10](700/2500): Loss: 0.3215
===> Epoch[10](800/2500): Loss: 0.3101
===> Epoch[10](900/2500): Loss: 0.3591
===> Epoch[10](1000/2500): Loss: 0.3081
===> Epoch[10](1100/2500): Loss: 0.3130
===> Epoch[10](1200/2500): Loss: 0.3232
===> Epoch[10](1300/2500): Loss: 0.3150
===> Epoch[10](1400/2500): Loss: 0.2883
===> Epoch[10](1500/2500): Loss: 0.3054
===> Epoch[10](1600/2500): Loss: 0.3047
===> Epoch[10](1700/2500): Loss: 0.3178
===> Epoch[10](1800/2500): Loss: 0.3135
===> Epoch[10](1900/2500): Loss: 0.3096
===> Epoch[10](2000/2500): Loss: 0.3178
===> Epoch[10](2100/2500): Loss: 0.3293
===> Epoch[10](2200/2500): Loss: 0.2998
===> Epoch[10](2300/2500): Loss: 0.3014
===> Epoch[10](2400/2500): Loss: 0.2912
===> Epoch[10](2500/2500): Loss: 0.2947
===> Epoch 10 Complete: Avg. Loss: 0.3145
===> Timestamp: [2025-08-03 20:16:55]
Checkpoint saved to TrainedNet/_epoch_10.pth
===> Loading train datasets
===> Epoch[10](100/2500): Loss: 0.3023
===> Epoch[10](200/2500): Loss: 0.3006
===> Epoch[10](300/2500): Loss: 0.3274
===> Epoch[10](400/2500): Loss: 0.3033
===> Epoch[10](500/2500): Loss: 0.2822
===> Epoch[10](600/2500): Loss: 0.3082
===> Epoch[10](700/2500): Loss: 0.3215
===> Epoch[10](800/2500): Loss: 0.3101
===> Epoch[10](900/2500): Loss: 0.3591
===> Epoch[10](1000/2500): Loss: 0.3081
===> Epoch[10](1100/2500): Loss: 0.3130
===> Epoch[10](1200/2500): Loss: 0.3232
===> Epoch[10](1300/2500): Loss: 0.3150
===> Epoch[10](1400/2500): Loss: 0.2883
===> Epoch[10](1500/2500): Loss: 0.3054
===> Epoch[10](1600/2500): Loss: 0.3047
===> Epoch[10](1700/2500): Loss: 0.3178
===> Epoch[10](1800/2500): Loss: 0.3135
===> Epoch[10](1900/2500): Loss: 0.3096
===> Epoch[10](2000/2500): Loss: 0.3178
===> Epoch[10](2100/2500): Loss: 0.3293
===> Epoch[10](2200/2500): Loss: 0.2998
===> Epoch[10](2300/2500): Loss: 0.3014
===> Epoch[10](2400/2500): Loss: 0.2912
===> Epoch[10](2500/2500): Loss: 0.2947
===> Epoch 10 Complete: Avg. Loss: 0.3145
===> Timestamp: [2025-08-03 20:16:55]
Checkpoint saved to TrainedNet/_epoch_10.pth
===> Loading train datasets
===> Epoch[10](100/2500): Loss: 0.3023
===> Epoch[10](200/2500): Loss: 0.3006
===> Epoch[10](300/2500): Loss: 0.3274
===> Epoch[10](400/2500): Loss: 0.3033
===> Epoch[10](500/2500): Loss: 0.2822
===> Epoch[10](600/2500): Loss: 0.3082
===> Epoch[10](700/2500): Loss: 0.3215
===> Epoch[10](800/2500): Loss: 0.3101
===> Epoch[10](900/2500): Loss: 0.3591
===> Epoch[10](1000/2500): Loss: 0.3081
===> Epoch[10](1100/2500): Loss: 0.3130
===> Epoch[10](1200/2500): Loss: 0.3232
===> Epoch[10](1300/2500): Loss: 0.3150
===> Epoch[10](1400/2500): Loss: 0.2883
===> Epoch[10](1500/2500): Loss: 0.3054
===> Epoch[10](1600/2500): Loss: 0.3047
===> Epoch[10](1700/2500): Loss: 0.3178
===> Epoch[10](1800/2500): Loss: 0.3135
===> Epoch[10](1900/2500): Loss: 0.3096
===> Epoch[10](2000/2500): Loss: 0.3178
===> Epoch[10](2100/2500): Loss: 0.3293
===> Epoch[10](2200/2500): Loss: 0.2998
===> Epoch[10](2300/2500): Loss: 0.3014
===> Epoch[10](2400/2500): Loss: 0.2912
===> Epoch[10](2500/2500): Loss: 0.2947
===> Epoch 10 Complete: Avg. Loss: 0.3145
===> Timestamp: [2025-08-03 20:16:55]
Checkpoint saved to TrainedNet/_epoch_10.pth
===> Loading train datasets
===> Epoch[10](100/2500): Loss: 0.3023
===> Epoch[10](200/2500): Loss: 0.3006
===> Epoch[10](300/2500): Loss: 0.3274
===> Epoch[10](400/2500): Loss: 0.3033
===> Epoch[10](500/2500): Loss: 0.2822
===> Epoch[10](600/2500): Loss: 0.3082
===> Epoch[10](700/2500): Loss: 0.3215
===> Epoch[10](800/2500): Loss: 0.3101
===> Epoch[10](900/2500): Loss: 0.3591
===> Epoch[10](1000/2500): Loss: 0.3081
===> Epoch[10](1100/2500): Loss: 0.3130
===> Epoch[10](1200/2500): Loss: 0.3232
===> Epoch[10](1300/2500): Loss: 0.3150
===> Epoch[10](1400/2500): Loss: 0.2883
===> Epoch[10](1500/2500): Loss: 0.3054
===> Epoch[10](1600/2500): Loss: 0.3047
===> Epoch[10](1700/2500): Loss: 0.3178
===> Epoch[10](1800/2500): Loss: 0.3135
===> Epoch[10](1900/2500): Loss: 0.3096
===> Epoch[10](2000/2500): Loss: 0.3178
===> Epoch[10](2100/2500): Loss: 0.3293
===> Epoch[10](2200/2500): Loss: 0.2998
===> Epoch[10](2300/2500): Loss: 0.3014
===> Epoch[10](2400/2500): Loss: 0.2912
===> Epoch[10](2500/2500): Loss: 0.2947
===> Epoch 10 Complete: Avg. Loss: 0.3145
===> Timestamp: [2025-08-03 20:16:55]
Checkpoint saved to TrainedNet/_epoch_10.pth
===> Loading train datasets
===> Epoch[10](100/2500): Loss: 0.3023
===> Epoch[10](200/2500): Loss: 0.3006
===> Epoch[10](300/2500): Loss: 0.3274
===> Epoch[10](400/2500): Loss: 0.3033
===> Epoch[10](500/2500): Loss: 0.2822
===> Epoch[10](600/2500): Loss: 0.3082
===> Epoch[10](700/2500): Loss: 0.3215
===> Epoch[10](800/2500): Loss: 0.3101
===> Epoch[10](900/2500): Loss: 0.3591
===> Epoch[10](1000/2500): Loss: 0.3081
===> Epoch[10](1100/2500): Loss: 0.3130
===> Epoch[10](1200/2500): Loss: 0.3232
===> Epoch[10](1300/2500): Loss: 0.3150
===> Epoch[10](1400/2500): Loss: 0.2883
===> Epoch[10](1500/2500): Loss: 0.3054
===> Epoch[10](1600/2500): Loss: 0.3047
===> Epoch[10](1700/2500): Loss: 0.3178
===> Epoch[10](1800/2500): Loss: 0.3135
===> Epoch[10](1900/2500): Loss: 0.3096
===> Epoch[10](2000/2500): Loss: 0.3178
===> Epoch[10](2100/2500): Loss: 0.3293
===> Epoch[10](2200/2500): Loss: 0.2998
===> Epoch[10](2300/2500): Loss: 0.3014
===> Epoch[10](2400/2500): Loss: 0.2912
===> Epoch[10](2500/2500): Loss: 0.2947
===> Epoch 10 Complete: Avg. Loss: 0.3145
===> Timestamp: [2025-08-03 20:16:55]
Checkpoint saved to TrainedNet/_epoch_10.pth
===> Loading train datasets
===> Epoch[10](100/2500): Loss: 0.3023
===> Epoch[10](200/2500): Loss: 0.3006
===> Epoch[10](300/2500): Loss: 0.3274
===> Epoch[10](400/2500): Loss: 0.3033
===> Epoch[10](500/2500): Loss: 0.2822
===> Epoch[10](600/2500): Loss: 0.3082
===> Epoch[10](700/2500): Loss: 0.3215
===> Epoch[10](800/2500): Loss: 0.3101
===> Epoch[10](900/2500): Loss: 0.3591
===> Epoch[10](1000/2500): Loss: 0.3081
===> Epoch[10](1100/2500): Loss: 0.3130
===> Epoch[10](1200/2500): Loss: 0.3232
===> Epoch[10](1300/2500): Loss: 0.3150
===> Epoch[10](1400/2500): Loss: 0.2883
===> Epoch[10](1500/2500): Loss: 0.3054
===> Epoch[10](1600/2500): Loss: 0.3047
===> Epoch[10](1700/2500): Loss: 0.3178
===> Epoch[10](1800/2500): Loss: 0.3135
===> Epoch[10](1900/2500): Loss: 0.3096
===> Epoch[10](2000/2500): Loss: 0.3178
===> Epoch[10](2100/2500): Loss: 0.3293
===> Epoch[10](2200/2500): Loss: 0.2998
===> Epoch[10](2300/2500): Loss: 0.3014
===> Epoch[10](2400/2500): Loss: 0.2912
===> Epoch[10](2500/2500): Loss: 0.2947
===> Epoch 10 Complete: Avg. Loss: 0.3145
===> Timestamp: [2025-08-03 20:16:55]
Checkpoint saved to TrainedNet/_epoch_10.pth
===> Loading train datasets
===> Epoch[10](100/2500): Loss: 0.3023
===> Epoch[10](200/2500): Loss: 0.3006
===> Epoch[10](300/2500): Loss: 0.3274
===> Epoch[10](400/2500): Loss: 0.3033
===> Epoch[10](500/2500): Loss: 0.2822
===> Epoch[10](600/2500): Loss: 0.3082
===> Epoch[10](700/2500): Loss: 0.3215
===> Epoch[10](800/2500): Loss: 0.3101
===> Epoch[10](900/2500): Loss: 0.3591
===> Epoch[10](1000/2500): Loss: 0.3081
===> Epoch[10](1100/2500): Loss: 0.3130
===> Epoch[10](1200/2500): Loss: 0.3232
===> Epoch[10](1300/2500): Loss: 0.3150
===> Epoch[10](1400/2500): Loss: 0.2883
===> Epoch[10](1500/2500): Loss: 0.3054
===> Epoch[10](1600/2500): Loss: 0.3047
===> Epoch[10](1700/2500): Loss: 0.3178
===> Epoch[10](1800/2500): Loss: 0.3135
===> Epoch[10](1900/2500): Loss: 0.3096
===> Epoch[10](2000/2500): Loss: 0.3178
===> Epoch[10](2100/2500): Loss: 0.3293
===> Epoch[10](2200/2500): Loss: 0.2998
===> Epoch[10](2300/2500): Loss: 0.3014
===> Epoch[10](2400/2500): Loss: 0.2912
===> Epoch[10](2500/2500): Loss: 0.2947
===> Epoch 10 Complete: Avg. Loss: 0.3145
===> Timestamp: [2025-08-03 20:16:55]
Checkpoint saved to TrainedNet/_epoch_10.pth
===> Loading train datasets
===> Epoch[10](100/2500): Loss: 0.3023
===> Epoch[10](200/2500): Loss: 0.3006
===> Epoch[10](300/2500): Loss: 0.3274
===> Epoch[10](400/2500): Loss: 0.3033
===> Epoch[10](500/2500): Loss: 0.2822
===> Epoch[10](600/2500): Loss: 0.3082
===> Epoch[10](700/2500): Loss: 0.3215
===> Epoch[10](800/2500): Loss: 0.3101
===> Epoch[10](900/2500): Loss: 0.3591
===> Epoch[10](1000/2500): Loss: 0.3081
===> Epoch[10](1100/2500): Loss: 0.3130
===> Epoch[10](1200/2500): Loss: 0.3232
===> Epoch[10](1300/2500): Loss: 0.3150
===> Epoch[10](1400/2500): Loss: 0.2883
===> Epoch[10](1500/2500): Loss: 0.3054
===> Epoch[10](1600/2500): Loss: 0.3047
===> Epoch[10](1700/2500): Loss: 0.3178
===> Epoch[10](1800/2500): Loss: 0.3135
===> Epoch[10](1900/2500): Loss: 0.3096
===> Epoch[10](2000/2500): Loss: 0.3178
===> Epoch[10](2100/2500): Loss: 0.3293
===> Epoch[10](2200/2500): Loss: 0.2998
===> Epoch[10](2300/2500): Loss: 0.3014
===> Epoch[10](2400/2500): Loss: 0.2912
===> Epoch[10](2500/2500): Loss: 0.2947
===> Epoch 10 Complete: Avg. Loss: 0.3145
===> Timestamp: [2025-08-03 20:16:55]
Checkpoint saved to TrainedNet/_epoch_10.pth
===> Loading train datasets
===> Epoch[10](100/2500): Loss: 0.3023
===> Epoch[10](200/2500): Loss: 0.3006
===> Epoch[10](300/2500): Loss: 0.3274
===> Epoch[10](400/2500): Loss: 0.3033
===> Epoch[10](500/2500): Loss: 0.2822
===> Epoch[10](600/2500): Loss: 0.3082
===> Epoch[10](700/2500): Loss: 0.3215
===> Epoch[10](800/2500): Loss: 0.3101
===> Epoch[10](900/2500): Loss: 0.3591
===> Epoch[10](1000/2500): Loss: 0.3081
===> Epoch[10](1100/2500): Loss: 0.3130
===> Epoch[10](1200/2500): Loss: 0.3232
===> Epoch[10](1300/2500): Loss: 0.3150
===> Epoch[10](1400/2500): Loss: 0.2883
===> Epoch[10](1500/2500): Loss: 0.3054
===> Epoch[10](1600/2500): Loss: 0.3047
===> Epoch[10](1700/2500): Loss: 0.3178
===> Epoch[10](1800/2500): Loss: 0.3135
===> Epoch[10](1900/2500): Loss: 0.3096
===> Epoch[10](2000/2500): Loss: 0.3178
===> Epoch[10](2100/2500): Loss: 0.3293
===> Epoch[10](2200/2500): Loss: 0.2998
===> Epoch[10](2300/2500): Loss: 0.3014
===> Epoch[10](2400/2500): Loss: 0.2912
===> Epoch[10](2500/2500): Loss: 0.2947
===> Epoch 10 Complete: Avg. Loss: 0.3145
===> Timestamp: [2025-08-03 20:16:55]
Checkpoint saved to TrainedNet/_epoch_10.pth
===> Loading train datasets
===> Loading train datasets
===> Epoch[11](100/2500): Loss: 0.3068
===> Epoch[11](200/2500): Loss: 0.2979
===> Epoch[11](300/2500): Loss: 0.3103
===> Epoch[11](400/2500): Loss: 0.2981
===> Epoch[11](500/2500): Loss: 0.3035
===> Epoch[11](600/2500): Loss: 0.3062
===> Epoch[11](700/2500): Loss: 0.2943
===> Epoch[11](800/2500): Loss: 0.3011
===> Epoch[11](900/2500): Loss: 0.3109
===> Epoch[11](1000/2500): Loss: 0.2985
===> Epoch[11](1100/2500): Loss: 0.3068
===> Epoch[11](1200/2500): Loss: 0.3008
===> Epoch[11](1300/2500): Loss: 0.3102
===> Epoch[11](1400/2500): Loss: 0.3273
===> Epoch[11](1500/2500): Loss: 0.3149
===> Epoch[11](1600/2500): Loss: 0.2832
===> Epoch[11](1700/2500): Loss: 0.3097
===> Epoch[11](1800/2500): Loss: 0.3353
===> Epoch[11](1900/2500): Loss: 0.2843
===> Epoch[11](2000/2500): Loss: 0.2913
===> Epoch[11](2100/2500): Loss: 0.3278
===> Epoch[11](2200/2500): Loss: 0.3035
===> Epoch[11](2300/2500): Loss: 0.2996
===> Epoch[11](2400/2500): Loss: 0.2927
===> Epoch[11](2500/2500): Loss: 0.3192
===> Epoch 11 Complete: Avg. Loss: 0.3083
===> Timestamp: [2025-08-03 20:21:29]
===> Loading train datasets
===> Epoch[11](100/2500): Loss: 0.3068
===> Epoch[11](200/2500): Loss: 0.2979
===> Epoch[11](300/2500): Loss: 0.3103
===> Epoch[11](400/2500): Loss: 0.2981
===> Epoch[11](500/2500): Loss: 0.3035
===> Epoch[11](600/2500): Loss: 0.3062
===> Epoch[11](700/2500): Loss: 0.2943
===> Epoch[11](800/2500): Loss: 0.3011
===> Epoch[11](900/2500): Loss: 0.3109
===> Epoch[11](1000/2500): Loss: 0.2985
===> Epoch[11](1100/2500): Loss: 0.3068
===> Epoch[11](1200/2500): Loss: 0.3008
===> Epoch[11](1300/2500): Loss: 0.3102
===> Epoch[11](1400/2500): Loss: 0.3273
===> Epoch[11](1500/2500): Loss: 0.3149
===> Epoch[11](1600/2500): Loss: 0.2832
===> Epoch[11](1700/2500): Loss: 0.3097
===> Epoch[11](1800/2500): Loss: 0.3353
===> Epoch[11](1900/2500): Loss: 0.2843
===> Epoch[11](2000/2500): Loss: 0.2913
===> Epoch[11](2100/2500): Loss: 0.3278
===> Epoch[11](2200/2500): Loss: 0.3035
===> Epoch[11](2300/2500): Loss: 0.2996
===> Epoch[11](2400/2500): Loss: 0.2927
===> Epoch[11](2500/2500): Loss: 0.3192
===> Epoch 11 Complete: Avg. Loss: 0.3083
===> Timestamp: [2025-08-03 20:21:29]
===> Loading train datasets
===> Epoch[11](100/2500): Loss: 0.3068
===> Epoch[11](200/2500): Loss: 0.2979
===> Epoch[11](300/2500): Loss: 0.3103
===> Epoch[11](400/2500): Loss: 0.2981
===> Epoch[11](500/2500): Loss: 0.3035
===> Epoch[11](600/2500): Loss: 0.3062
===> Epoch[11](700/2500): Loss: 0.2943
===> Epoch[11](800/2500): Loss: 0.3011
===> Epoch[11](900/2500): Loss: 0.3109
===> Epoch[11](1000/2500): Loss: 0.2985
===> Epoch[11](1100/2500): Loss: 0.3068
===> Epoch[11](1200/2500): Loss: 0.3008
===> Epoch[11](1300/2500): Loss: 0.3102
===> Epoch[11](1400/2500): Loss: 0.3273
===> Epoch[11](1500/2500): Loss: 0.3149
===> Epoch[11](1600/2500): Loss: 0.2832
===> Epoch[11](1700/2500): Loss: 0.3097
===> Epoch[11](1800/2500): Loss: 0.3353
===> Epoch[11](1900/2500): Loss: 0.2843
===> Epoch[11](2000/2500): Loss: 0.2913
===> Epoch[11](2100/2500): Loss: 0.3278
===> Epoch[11](2200/2500): Loss: 0.3035
===> Epoch[11](2300/2500): Loss: 0.2996
===> Epoch[11](2400/2500): Loss: 0.2927
===> Epoch[11](2500/2500): Loss: 0.3192
===> Epoch 11 Complete: Avg. Loss: 0.3083
===> Timestamp: [2025-08-03 20:21:29]
===> Loading train datasets
===> Epoch[11](100/2500): Loss: 0.3068
===> Epoch[11](200/2500): Loss: 0.2979
===> Epoch[11](300/2500): Loss: 0.3103
===> Epoch[11](400/2500): Loss: 0.2981
===> Epoch[11](500/2500): Loss: 0.3035
===> Epoch[11](600/2500): Loss: 0.3062
===> Epoch[11](700/2500): Loss: 0.2943
===> Epoch[11](800/2500): Loss: 0.3011
===> Epoch[11](900/2500): Loss: 0.3109
===> Epoch[11](1000/2500): Loss: 0.2985
===> Epoch[11](1100/2500): Loss: 0.3068
===> Epoch[11](1200/2500): Loss: 0.3008
===> Epoch[11](1300/2500): Loss: 0.3102
===> Epoch[11](1400/2500): Loss: 0.3273
===> Epoch[11](1500/2500): Loss: 0.3149
===> Epoch[11](1600/2500): Loss: 0.2832
===> Epoch[11](1700/2500): Loss: 0.3097
===> Epoch[11](1800/2500): Loss: 0.3353
===> Epoch[11](1900/2500): Loss: 0.2843
===> Epoch[11](2000/2500): Loss: 0.2913
===> Epoch[11](2100/2500): Loss: 0.3278
===> Epoch[11](2200/2500): Loss: 0.3035
===> Epoch[11](2300/2500): Loss: 0.2996
===> Epoch[11](2400/2500): Loss: 0.2927
===> Epoch[11](2500/2500): Loss: 0.3192
===> Epoch 11 Complete: Avg. Loss: 0.3083
===> Timestamp: [2025-08-03 20:21:29]
===> Loading train datasets
===> Epoch[11](100/2500): Loss: 0.3068
===> Epoch[11](200/2500): Loss: 0.2979
===> Epoch[11](300/2500): Loss: 0.3103
===> Epoch[11](400/2500): Loss: 0.2981
===> Epoch[11](500/2500): Loss: 0.3035
===> Epoch[11](600/2500): Loss: 0.3062
===> Epoch[11](700/2500): Loss: 0.2943
===> Epoch[11](800/2500): Loss: 0.3011
===> Epoch[11](900/2500): Loss: 0.3109
===> Epoch[11](1000/2500): Loss: 0.2985
===> Epoch[11](1100/2500): Loss: 0.3068
===> Epoch[11](1200/2500): Loss: 0.3008
===> Epoch[11](1300/2500): Loss: 0.3102
===> Epoch[11](1400/2500): Loss: 0.3273
===> Epoch[11](1500/2500): Loss: 0.3149
===> Epoch[11](1600/2500): Loss: 0.2832
===> Epoch[11](1700/2500): Loss: 0.3097
===> Epoch[11](1800/2500): Loss: 0.3353
===> Epoch[11](1900/2500): Loss: 0.2843
===> Epoch[11](2000/2500): Loss: 0.2913
===> Epoch[11](2100/2500): Loss: 0.3278
===> Epoch[11](2200/2500): Loss: 0.3035
===> Epoch[11](2300/2500): Loss: 0.2996
===> Epoch[11](2400/2500): Loss: 0.2927
===> Epoch[11](2500/2500): Loss: 0.3192
===> Epoch 11 Complete: Avg. Loss: 0.3083
===> Timestamp: [2025-08-03 20:21:29]
===> Loading train datasets
===> Epoch[11](100/2500): Loss: 0.3068
===> Epoch[11](200/2500): Loss: 0.2979
===> Epoch[11](300/2500): Loss: 0.3103
===> Epoch[11](400/2500): Loss: 0.2981
===> Epoch[11](500/2500): Loss: 0.3035
===> Epoch[11](600/2500): Loss: 0.3062
===> Epoch[11](700/2500): Loss: 0.2943
===> Epoch[11](800/2500): Loss: 0.3011
===> Epoch[11](900/2500): Loss: 0.3109
===> Epoch[11](1000/2500): Loss: 0.2985
===> Epoch[11](1100/2500): Loss: 0.3068
===> Epoch[11](1200/2500): Loss: 0.3008
===> Epoch[11](1300/2500): Loss: 0.3102
===> Epoch[11](1400/2500): Loss: 0.3273
===> Epoch[11](1500/2500): Loss: 0.3149
===> Epoch[11](1600/2500): Loss: 0.2832
===> Epoch[11](1700/2500): Loss: 0.3097
===> Epoch[11](1800/2500): Loss: 0.3353
===> Epoch[11](1900/2500): Loss: 0.2843
===> Epoch[11](2000/2500): Loss: 0.2913
===> Epoch[11](2100/2500): Loss: 0.3278
===> Epoch[11](2200/2500): Loss: 0.3035
===> Epoch[11](2300/2500): Loss: 0.2996
===> Epoch[11](2400/2500): Loss: 0.2927
===> Epoch[11](2500/2500): Loss: 0.3192
===> Epoch 11 Complete: Avg. Loss: 0.3083
===> Timestamp: [2025-08-03 20:21:29]
===> Loading train datasets
===> Epoch[11](100/2500): Loss: 0.3068
===> Epoch[11](200/2500): Loss: 0.2979
===> Epoch[11](300/2500): Loss: 0.3103
===> Epoch[11](400/2500): Loss: 0.2981
===> Epoch[11](500/2500): Loss: 0.3035
===> Epoch[11](600/2500): Loss: 0.3062
===> Epoch[11](700/2500): Loss: 0.2943
===> Epoch[11](800/2500): Loss: 0.3011
===> Epoch[11](900/2500): Loss: 0.3109
===> Epoch[11](1000/2500): Loss: 0.2985
===> Epoch[11](1100/2500): Loss: 0.3068
===> Epoch[11](1200/2500): Loss: 0.3008
===> Epoch[11](1300/2500): Loss: 0.3102
===> Epoch[11](1400/2500): Loss: 0.3273
===> Epoch[11](1500/2500): Loss: 0.3149
===> Epoch[11](1600/2500): Loss: 0.2832
===> Epoch[11](1700/2500): Loss: 0.3097
===> Epoch[11](1800/2500): Loss: 0.3353
===> Epoch[11](1900/2500): Loss: 0.2843
===> Epoch[11](2000/2500): Loss: 0.2913
===> Epoch[11](2100/2500): Loss: 0.3278
===> Epoch[11](2200/2500): Loss: 0.3035
===> Epoch[11](2300/2500): Loss: 0.2996
===> Epoch[11](2400/2500): Loss: 0.2927
===> Epoch[11](2500/2500): Loss: 0.3192
===> Epoch 11 Complete: Avg. Loss: 0.3083
===> Timestamp: [2025-08-03 20:21:29]
===> Loading train datasets
===> Epoch[11](100/2500): Loss: 0.3068
===> Epoch[11](200/2500): Loss: 0.2979
===> Epoch[11](300/2500): Loss: 0.3103
===> Epoch[11](400/2500): Loss: 0.2981
===> Epoch[11](500/2500): Loss: 0.3035
===> Epoch[11](600/2500): Loss: 0.3062
===> Epoch[11](700/2500): Loss: 0.2943
===> Epoch[11](800/2500): Loss: 0.3011
===> Epoch[11](900/2500): Loss: 0.3109
===> Epoch[11](1000/2500): Loss: 0.2985
===> Epoch[11](1100/2500): Loss: 0.3068
===> Epoch[11](1200/2500): Loss: 0.3008
===> Epoch[11](1300/2500): Loss: 0.3102
===> Epoch[11](1400/2500): Loss: 0.3273
===> Epoch[11](1500/2500): Loss: 0.3149
===> Epoch[11](1600/2500): Loss: 0.2832
===> Epoch[11](1700/2500): Loss: 0.3097
===> Epoch[11](1800/2500): Loss: 0.3353
===> Epoch[11](1900/2500): Loss: 0.2843
===> Epoch[11](2000/2500): Loss: 0.2913
===> Epoch[11](2100/2500): Loss: 0.3278
===> Epoch[11](2200/2500): Loss: 0.3035
===> Epoch[11](2300/2500): Loss: 0.2996
===> Epoch[11](2400/2500): Loss: 0.2927
===> Epoch[11](2500/2500): Loss: 0.3192
===> Epoch 11 Complete: Avg. Loss: 0.3083
===> Timestamp: [2025-08-03 20:21:29]
===> Loading train datasets
===> Epoch[11](100/2500): Loss: 0.3068
===> Epoch[11](200/2500): Loss: 0.2979
===> Epoch[11](300/2500): Loss: 0.3103
===> Epoch[11](400/2500): Loss: 0.2981
===> Epoch[11](500/2500): Loss: 0.3035
===> Epoch[11](600/2500): Loss: 0.3062
===> Epoch[11](700/2500): Loss: 0.2943
===> Epoch[11](800/2500): Loss: 0.3011
===> Epoch[11](900/2500): Loss: 0.3109
===> Epoch[11](1000/2500): Loss: 0.2985
===> Epoch[11](1100/2500): Loss: 0.3068
===> Epoch[11](1200/2500): Loss: 0.3008
===> Epoch[11](1300/2500): Loss: 0.3102
===> Epoch[11](1400/2500): Loss: 0.3273
===> Epoch[11](1500/2500): Loss: 0.3149
===> Epoch[11](1600/2500): Loss: 0.2832
===> Epoch[11](1700/2500): Loss: 0.3097
===> Epoch[11](1800/2500): Loss: 0.3353
===> Epoch[11](1900/2500): Loss: 0.2843
===> Epoch[11](2000/2500): Loss: 0.2913
===> Epoch[11](2100/2500): Loss: 0.3278
===> Epoch[11](2200/2500): Loss: 0.3035
===> Epoch[11](2300/2500): Loss: 0.2996
===> Epoch[11](2400/2500): Loss: 0.2927
===> Epoch[11](2500/2500): Loss: 0.3192
===> Epoch 11 Complete: Avg. Loss: 0.3083
===> Timestamp: [2025-08-03 20:21:29]
===> Loading train datasets
===> Epoch[11](100/2500): Loss: 0.3068
===> Epoch[11](200/2500): Loss: 0.2979
===> Epoch[11](300/2500): Loss: 0.3103
===> Epoch[11](400/2500): Loss: 0.2981
===> Epoch[11](500/2500): Loss: 0.3035
===> Epoch[11](600/2500): Loss: 0.3062
===> Epoch[11](700/2500): Loss: 0.2943
===> Epoch[11](800/2500): Loss: 0.3011
===> Epoch[11](900/2500): Loss: 0.3109
===> Epoch[11](1000/2500): Loss: 0.2985
===> Epoch[11](1100/2500): Loss: 0.3068
===> Epoch[11](1200/2500): Loss: 0.3008
===> Epoch[11](1300/2500): Loss: 0.3102
===> Epoch[11](1400/2500): Loss: 0.3273
===> Epoch[11](1500/2500): Loss: 0.3149
===> Epoch[11](1600/2500): Loss: 0.2832
===> Epoch[11](1700/2500): Loss: 0.3097
===> Epoch[11](1800/2500): Loss: 0.3353
===> Epoch[11](1900/2500): Loss: 0.2843
===> Epoch[11](2000/2500): Loss: 0.2913
===> Epoch[11](2100/2500): Loss: 0.3278
===> Epoch[11](2200/2500): Loss: 0.3035
===> Epoch[11](2300/2500): Loss: 0.2996
===> Epoch[11](2400/2500): Loss: 0.2927
===> Epoch[11](2500/2500): Loss: 0.3192
===> Epoch 11 Complete: Avg. Loss: 0.3083
===> Timestamp: [2025-08-03 20:21:29]
===> Loading train datasets
===> Epoch[11](100/2500): Loss: 0.3068
===> Epoch[11](200/2500): Loss: 0.2979
===> Epoch[11](300/2500): Loss: 0.3103
===> Epoch[11](400/2500): Loss: 0.2981
===> Epoch[11](500/2500): Loss: 0.3035
===> Epoch[11](600/2500): Loss: 0.3062
===> Epoch[11](700/2500): Loss: 0.2943
===> Epoch[11](800/2500): Loss: 0.3011
===> Epoch[11](900/2500): Loss: 0.3109
===> Epoch[11](1000/2500): Loss: 0.2985
===> Epoch[11](1100/2500): Loss: 0.3068
===> Epoch[11](1200/2500): Loss: 0.3008
===> Epoch[11](1300/2500): Loss: 0.3102
===> Epoch[11](1400/2500): Loss: 0.3273
===> Epoch[11](1500/2500): Loss: 0.3149
===> Epoch[11](1600/2500): Loss: 0.2832
===> Epoch[11](1700/2500): Loss: 0.3097
===> Epoch[11](1800/2500): Loss: 0.3353
===> Epoch[11](1900/2500): Loss: 0.2843
===> Epoch[11](2000/2500): Loss: 0.2913
===> Epoch[11](2100/2500): Loss: 0.3278
===> Epoch[11](2200/2500): Loss: 0.3035
===> Epoch[11](2300/2500): Loss: 0.2996
===> Epoch[11](2400/2500): Loss: 0.2927
===> Epoch[11](2500/2500): Loss: 0.3192
===> Epoch 11 Complete: Avg. Loss: 0.3083
===> Timestamp: [2025-08-03 20:21:29]
===> Loading train datasets
===> Loading train datasets
===> Epoch[12](100/2500): Loss: 0.3261
===> Epoch[12](200/2500): Loss: 0.3178
===> Epoch[12](300/2500): Loss: 0.3361
===> Epoch[12](400/2500): Loss: 0.3106
===> Epoch[12](500/2500): Loss: 0.3244
===> Epoch[12](600/2500): Loss: 0.2873
===> Epoch[12](700/2500): Loss: 0.2804
===> Epoch[12](800/2500): Loss: 0.2894
===> Epoch[12](900/2500): Loss: 0.2966
===> Epoch[12](1000/2500): Loss: 0.2916
===> Epoch[12](1100/2500): Loss: 0.3343
===> Epoch[12](1200/2500): Loss: 0.2738
===> Epoch[12](1300/2500): Loss: 0.3176
===> Epoch[12](1400/2500): Loss: 0.3003
===> Epoch[12](1500/2500): Loss: 0.3130
===> Epoch[12](1600/2500): Loss: 0.3045
===> Epoch[12](1700/2500): Loss: 0.2875
===> Epoch[12](1800/2500): Loss: 0.3304
===> Epoch[12](1900/2500): Loss: 0.2941
===> Epoch[12](2000/2500): Loss: 0.3302
===> Epoch[12](2100/2500): Loss: 0.3300
===> Epoch[12](2200/2500): Loss: 0.3310
===> Epoch[12](2300/2500): Loss: 0.2962
===> Epoch[12](2400/2500): Loss: 0.3201
===> Epoch[12](2500/2500): Loss: 0.3086
===> Epoch 12 Complete: Avg. Loss: 0.3039
===> Timestamp: [2025-08-03 20:26:03]
===> Loading train datasets
===> Epoch[12](100/2500): Loss: 0.3261
===> Epoch[12](200/2500): Loss: 0.3178
===> Epoch[12](300/2500): Loss: 0.3361
===> Epoch[12](400/2500): Loss: 0.3106
===> Epoch[12](500/2500): Loss: 0.3244
===> Epoch[12](600/2500): Loss: 0.2873
===> Epoch[12](700/2500): Loss: 0.2804
===> Epoch[12](800/2500): Loss: 0.2894
===> Epoch[12](900/2500): Loss: 0.2966
===> Epoch[12](1000/2500): Loss: 0.2916
===> Epoch[12](1100/2500): Loss: 0.3343
===> Epoch[12](1200/2500): Loss: 0.2738
===> Epoch[12](1300/2500): Loss: 0.3176
===> Epoch[12](1400/2500): Loss: 0.3003
===> Epoch[12](1500/2500): Loss: 0.3130
===> Epoch[12](1600/2500): Loss: 0.3045
===> Epoch[12](1700/2500): Loss: 0.2875
===> Epoch[12](1800/2500): Loss: 0.3304
===> Epoch[12](1900/2500): Loss: 0.2941
===> Epoch[12](2000/2500): Loss: 0.3302
===> Epoch[12](2100/2500): Loss: 0.3300
===> Epoch[12](2200/2500): Loss: 0.3310
===> Epoch[12](2300/2500): Loss: 0.2962
===> Epoch[12](2400/2500): Loss: 0.3201
===> Epoch[12](2500/2500): Loss: 0.3086
===> Epoch 12 Complete: Avg. Loss: 0.3039
===> Timestamp: [2025-08-03 20:26:03]
===> Loading train datasets
===> Epoch[12](100/2500): Loss: 0.3261
===> Epoch[12](200/2500): Loss: 0.3178
===> Epoch[12](300/2500): Loss: 0.3361
===> Epoch[12](400/2500): Loss: 0.3106
===> Epoch[12](500/2500): Loss: 0.3244
===> Epoch[12](600/2500): Loss: 0.2873
===> Epoch[12](700/2500): Loss: 0.2804
===> Epoch[12](800/2500): Loss: 0.2894
===> Epoch[12](900/2500): Loss: 0.2966
===> Epoch[12](1000/2500): Loss: 0.2916
===> Epoch[12](1100/2500): Loss: 0.3343
===> Epoch[12](1200/2500): Loss: 0.2738
===> Epoch[12](1300/2500): Loss: 0.3176
===> Epoch[12](1400/2500): Loss: 0.3003
===> Epoch[12](1500/2500): Loss: 0.3130
===> Epoch[12](1600/2500): Loss: 0.3045
===> Epoch[12](1700/2500): Loss: 0.2875
===> Epoch[12](1800/2500): Loss: 0.3304
===> Epoch[12](1900/2500): Loss: 0.2941
===> Epoch[12](2000/2500): Loss: 0.3302
===> Epoch[12](2100/2500): Loss: 0.3300
===> Epoch[12](2200/2500): Loss: 0.3310
===> Epoch[12](2300/2500): Loss: 0.2962
===> Epoch[12](2400/2500): Loss: 0.3201
===> Epoch[12](2500/2500): Loss: 0.3086
===> Epoch 12 Complete: Avg. Loss: 0.3039
===> Timestamp: [2025-08-03 20:26:03]
===> Loading train datasets
===> Epoch[12](100/2500): Loss: 0.3261
===> Epoch[12](200/2500): Loss: 0.3178
===> Epoch[12](300/2500): Loss: 0.3361
===> Epoch[12](400/2500): Loss: 0.3106
===> Epoch[12](500/2500): Loss: 0.3244
===> Epoch[12](600/2500): Loss: 0.2873
===> Epoch[12](700/2500): Loss: 0.2804
===> Epoch[12](800/2500): Loss: 0.2894
===> Epoch[12](900/2500): Loss: 0.2966
===> Epoch[12](1000/2500): Loss: 0.2916
===> Epoch[12](1100/2500): Loss: 0.3343
===> Epoch[12](1200/2500): Loss: 0.2738
===> Epoch[12](1300/2500): Loss: 0.3176
===> Epoch[12](1400/2500): Loss: 0.3003
===> Epoch[12](1500/2500): Loss: 0.3130
===> Epoch[12](1600/2500): Loss: 0.3045
===> Epoch[12](1700/2500): Loss: 0.2875
===> Epoch[12](1800/2500): Loss: 0.3304
===> Epoch[12](1900/2500): Loss: 0.2941
===> Epoch[12](2000/2500): Loss: 0.3302
===> Epoch[12](2100/2500): Loss: 0.3300
===> Epoch[12](2200/2500): Loss: 0.3310
===> Epoch[12](2300/2500): Loss: 0.2962
===> Epoch[12](2400/2500): Loss: 0.3201
===> Epoch[12](2500/2500): Loss: 0.3086
===> Epoch 12 Complete: Avg. Loss: 0.3039
===> Timestamp: [2025-08-03 20:26:03]
===> Loading train datasets
===> Epoch[12](100/2500): Loss: 0.3261
===> Epoch[12](200/2500): Loss: 0.3178
===> Epoch[12](300/2500): Loss: 0.3361
===> Epoch[12](400/2500): Loss: 0.3106
===> Epoch[12](500/2500): Loss: 0.3244
===> Epoch[12](600/2500): Loss: 0.2873
===> Epoch[12](700/2500): Loss: 0.2804
===> Epoch[12](800/2500): Loss: 0.2894
===> Epoch[12](900/2500): Loss: 0.2966
===> Epoch[12](1000/2500): Loss: 0.2916
===> Epoch[12](1100/2500): Loss: 0.3343
===> Epoch[12](1200/2500): Loss: 0.2738
===> Epoch[12](1300/2500): Loss: 0.3176
===> Epoch[12](1400/2500): Loss: 0.3003
===> Epoch[12](1500/2500): Loss: 0.3130
===> Epoch[12](1600/2500): Loss: 0.3045
===> Epoch[12](1700/2500): Loss: 0.2875
===> Epoch[12](1800/2500): Loss: 0.3304
===> Epoch[12](1900/2500): Loss: 0.2941
===> Epoch[12](2000/2500): Loss: 0.3302
===> Epoch[12](2100/2500): Loss: 0.3300
===> Epoch[12](2200/2500): Loss: 0.3310
===> Epoch[12](2300/2500): Loss: 0.2962
===> Epoch[12](2400/2500): Loss: 0.3201
===> Epoch[12](2500/2500): Loss: 0.3086
===> Epoch 12 Complete: Avg. Loss: 0.3039
===> Timestamp: [2025-08-03 20:26:03]
===> Loading train datasets
===> Epoch[12](100/2500): Loss: 0.3261
===> Epoch[12](200/2500): Loss: 0.3178
===> Epoch[12](300/2500): Loss: 0.3361
===> Epoch[12](400/2500): Loss: 0.3106
===> Epoch[12](500/2500): Loss: 0.3244
===> Epoch[12](600/2500): Loss: 0.2873
===> Epoch[12](700/2500): Loss: 0.2804
===> Epoch[12](800/2500): Loss: 0.2894
===> Epoch[12](900/2500): Loss: 0.2966
===> Epoch[12](1000/2500): Loss: 0.2916
===> Epoch[12](1100/2500): Loss: 0.3343
===> Epoch[12](1200/2500): Loss: 0.2738
===> Epoch[12](1300/2500): Loss: 0.3176
===> Epoch[12](1400/2500): Loss: 0.3003
===> Epoch[12](1500/2500): Loss: 0.3130
===> Epoch[12](1600/2500): Loss: 0.3045
===> Epoch[12](1700/2500): Loss: 0.2875
===> Epoch[12](1800/2500): Loss: 0.3304
===> Epoch[12](1900/2500): Loss: 0.2941
===> Epoch[12](2000/2500): Loss: 0.3302
===> Epoch[12](2100/2500): Loss: 0.3300
===> Epoch[12](2200/2500): Loss: 0.3310
===> Epoch[12](2300/2500): Loss: 0.2962
===> Epoch[12](2400/2500): Loss: 0.3201
===> Epoch[12](2500/2500): Loss: 0.3086
===> Epoch 12 Complete: Avg. Loss: 0.3039
===> Timestamp: [2025-08-03 20:26:03]
===> Loading train datasets
===> Epoch[12](100/2500): Loss: 0.3261
===> Epoch[12](200/2500): Loss: 0.3178
===> Epoch[12](300/2500): Loss: 0.3361
===> Epoch[12](400/2500): Loss: 0.3106
===> Epoch[12](500/2500): Loss: 0.3244
===> Epoch[12](600/2500): Loss: 0.2873
===> Epoch[12](700/2500): Loss: 0.2804
===> Epoch[12](800/2500): Loss: 0.2894
===> Epoch[12](900/2500): Loss: 0.2966
===> Epoch[12](1000/2500): Loss: 0.2916
===> Epoch[12](1100/2500): Loss: 0.3343
===> Epoch[12](1200/2500): Loss: 0.2738
===> Epoch[12](1300/2500): Loss: 0.3176
===> Epoch[12](1400/2500): Loss: 0.3003
===> Epoch[12](1500/2500): Loss: 0.3130
===> Epoch[12](1600/2500): Loss: 0.3045
===> Epoch[12](1700/2500): Loss: 0.2875
===> Epoch[12](1800/2500): Loss: 0.3304
===> Epoch[12](1900/2500): Loss: 0.2941
===> Epoch[12](2000/2500): Loss: 0.3302
===> Epoch[12](2100/2500): Loss: 0.3300
===> Epoch[12](2200/2500): Loss: 0.3310
===> Epoch[12](2300/2500): Loss: 0.2962
===> Epoch[12](2400/2500): Loss: 0.3201
===> Epoch[12](2500/2500): Loss: 0.3086
===> Epoch 12 Complete: Avg. Loss: 0.3039
===> Timestamp: [2025-08-03 20:26:03]
===> Loading train datasets
===> Epoch[12](100/2500): Loss: 0.3261
===> Epoch[12](200/2500): Loss: 0.3178
===> Epoch[12](300/2500): Loss: 0.3361
===> Epoch[12](400/2500): Loss: 0.3106
===> Epoch[12](500/2500): Loss: 0.3244
===> Epoch[12](600/2500): Loss: 0.2873
===> Epoch[12](700/2500): Loss: 0.2804
===> Epoch[12](800/2500): Loss: 0.2894
===> Epoch[12](900/2500): Loss: 0.2966
===> Epoch[12](1000/2500): Loss: 0.2916
===> Epoch[12](1100/2500): Loss: 0.3343
===> Epoch[12](1200/2500): Loss: 0.2738
===> Epoch[12](1300/2500): Loss: 0.3176
===> Epoch[12](1400/2500): Loss: 0.3003
===> Epoch[12](1500/2500): Loss: 0.3130
===> Epoch[12](1600/2500): Loss: 0.3045
===> Epoch[12](1700/2500): Loss: 0.2875
===> Epoch[12](1800/2500): Loss: 0.3304
===> Epoch[12](1900/2500): Loss: 0.2941
===> Epoch[12](2000/2500): Loss: 0.3302
===> Epoch[12](2100/2500): Loss: 0.3300
===> Epoch[12](2200/2500): Loss: 0.3310
===> Epoch[12](2300/2500): Loss: 0.2962
===> Epoch[12](2400/2500): Loss: 0.3201
===> Epoch[12](2500/2500): Loss: 0.3086
===> Epoch 12 Complete: Avg. Loss: 0.3039
===> Timestamp: [2025-08-03 20:26:03]
===> Loading train datasets
===> Epoch[12](100/2500): Loss: 0.3261
===> Epoch[12](200/2500): Loss: 0.3178
===> Epoch[12](300/2500): Loss: 0.3361
===> Epoch[12](400/2500): Loss: 0.3106
===> Epoch[12](500/2500): Loss: 0.3244
===> Epoch[12](600/2500): Loss: 0.2873
===> Epoch[12](700/2500): Loss: 0.2804
===> Epoch[12](800/2500): Loss: 0.2894
===> Epoch[12](900/2500): Loss: 0.2966
===> Epoch[12](1000/2500): Loss: 0.2916
===> Epoch[12](1100/2500): Loss: 0.3343
===> Epoch[12](1200/2500): Loss: 0.2738
===> Epoch[12](1300/2500): Loss: 0.3176
===> Epoch[12](1400/2500): Loss: 0.3003
===> Epoch[12](1500/2500): Loss: 0.3130
===> Epoch[12](1600/2500): Loss: 0.3045
===> Epoch[12](1700/2500): Loss: 0.2875
===> Epoch[12](1800/2500): Loss: 0.3304
===> Epoch[12](1900/2500): Loss: 0.2941
===> Epoch[12](2000/2500): Loss: 0.3302
===> Epoch[12](2100/2500): Loss: 0.3300
===> Epoch[12](2200/2500): Loss: 0.3310
===> Epoch[12](2300/2500): Loss: 0.2962
===> Epoch[12](2400/2500): Loss: 0.3201
===> Epoch[12](2500/2500): Loss: 0.3086
===> Epoch 12 Complete: Avg. Loss: 0.3039
===> Timestamp: [2025-08-03 20:26:03]
===> Loading train datasets
===> Epoch[12](100/2500): Loss: 0.3261
===> Epoch[12](200/2500): Loss: 0.3178
===> Epoch[12](300/2500): Loss: 0.3361
===> Epoch[12](400/2500): Loss: 0.3106
===> Epoch[12](500/2500): Loss: 0.3244
===> Epoch[12](600/2500): Loss: 0.2873
===> Epoch[12](700/2500): Loss: 0.2804
===> Epoch[12](800/2500): Loss: 0.2894
===> Epoch[12](900/2500): Loss: 0.2966
===> Epoch[12](1000/2500): Loss: 0.2916
===> Epoch[12](1100/2500): Loss: 0.3343
===> Epoch[12](1200/2500): Loss: 0.2738
===> Epoch[12](1300/2500): Loss: 0.3176
===> Epoch[12](1400/2500): Loss: 0.3003
===> Epoch[12](1500/2500): Loss: 0.3130
===> Epoch[12](1600/2500): Loss: 0.3045
===> Epoch[12](1700/2500): Loss: 0.2875
===> Epoch[12](1800/2500): Loss: 0.3304
===> Epoch[12](1900/2500): Loss: 0.2941
===> Epoch[12](2000/2500): Loss: 0.3302
===> Epoch[12](2100/2500): Loss: 0.3300
===> Epoch[12](2200/2500): Loss: 0.3310
===> Epoch[12](2300/2500): Loss: 0.2962
===> Epoch[12](2400/2500): Loss: 0.3201
===> Epoch[12](2500/2500): Loss: 0.3086
===> Epoch 12 Complete: Avg. Loss: 0.3039
===> Timestamp: [2025-08-03 20:26:03]
===> Loading train datasets
===> Epoch[12](100/2500): Loss: 0.3261
===> Epoch[12](200/2500): Loss: 0.3178
===> Epoch[12](300/2500): Loss: 0.3361
===> Epoch[12](400/2500): Loss: 0.3106
===> Epoch[12](500/2500): Loss: 0.3244
===> Epoch[12](600/2500): Loss: 0.2873
===> Epoch[12](700/2500): Loss: 0.2804
===> Epoch[12](800/2500): Loss: 0.2894
===> Epoch[12](900/2500): Loss: 0.2966
===> Epoch[12](1000/2500): Loss: 0.2916
===> Epoch[12](1100/2500): Loss: 0.3343
===> Epoch[12](1200/2500): Loss: 0.2738
===> Epoch[12](1300/2500): Loss: 0.3176
===> Epoch[12](1400/2500): Loss: 0.3003
===> Epoch[12](1500/2500): Loss: 0.3130
===> Epoch[12](1600/2500): Loss: 0.3045
===> Epoch[12](1700/2500): Loss: 0.2875
===> Epoch[12](1800/2500): Loss: 0.3304
===> Epoch[12](1900/2500): Loss: 0.2941
===> Epoch[12](2000/2500): Loss: 0.3302
===> Epoch[12](2100/2500): Loss: 0.3300
===> Epoch[12](2200/2500): Loss: 0.3310
===> Epoch[12](2300/2500): Loss: 0.2962
===> Epoch[12](2400/2500): Loss: 0.3201
===> Epoch[12](2500/2500): Loss: 0.3086
===> Epoch 12 Complete: Avg. Loss: 0.3039
===> Timestamp: [2025-08-03 20:26:03]
===> Loading train datasets
===> Epoch[12](100/2500): Loss: 0.3261
===> Epoch[12](200/2500): Loss: 0.3178
===> Epoch[12](300/2500): Loss: 0.3361
===> Epoch[12](400/2500): Loss: 0.3106
===> Epoch[12](500/2500): Loss: 0.3244
===> Epoch[12](600/2500): Loss: 0.2873
===> Epoch[12](700/2500): Loss: 0.2804
===> Epoch[12](800/2500): Loss: 0.2894
===> Epoch[12](900/2500): Loss: 0.2966
===> Epoch[12](1000/2500): Loss: 0.2916
===> Epoch[12](1100/2500): Loss: 0.3343
===> Epoch[12](1200/2500): Loss: 0.2738
===> Epoch[12](1300/2500): Loss: 0.3176
===> Epoch[12](1400/2500): Loss: 0.3003
===> Epoch[12](1500/2500): Loss: 0.3130
===> Epoch[12](1600/2500): Loss: 0.3045
===> Epoch[12](1700/2500): Loss: 0.2875
===> Epoch[12](1800/2500): Loss: 0.3304
===> Epoch[12](1900/2500): Loss: 0.2941
===> Epoch[12](2000/2500): Loss: 0.3302
===> Epoch[12](2100/2500): Loss: 0.3300
===> Epoch[12](2200/2500): Loss: 0.3310
===> Epoch[12](2300/2500): Loss: 0.2962
===> Epoch[12](2400/2500): Loss: 0.3201
===> Epoch[12](2500/2500): Loss: 0.3086
===> Epoch 12 Complete: Avg. Loss: 0.3039
===> Timestamp: [2025-08-03 20:26:03]
===> Loading train datasets
===> Loading train datasets
===> Epoch[13](100/2500): Loss: 0.3163
===> Epoch[13](200/2500): Loss: 0.3348
===> Epoch[13](300/2500): Loss: 0.3180
===> Epoch[13](400/2500): Loss: 0.3130
===> Epoch[13](500/2500): Loss: 0.2843
===> Epoch[13](600/2500): Loss: 0.3121
===> Epoch[13](700/2500): Loss: 0.3208
===> Epoch[13](800/2500): Loss: 0.2909
===> Epoch[13](900/2500): Loss: 0.3048
===> Epoch[13](1000/2500): Loss: 0.3248
===> Epoch[13](1100/2500): Loss: 0.3160
===> Epoch[13](1200/2500): Loss: 0.3068
===> Epoch[13](1300/2500): Loss: 0.2921
===> Epoch[13](1400/2500): Loss: 0.3022
===> Epoch[13](1500/2500): Loss: 0.2602
===> Epoch[13](1600/2500): Loss: 0.3164
===> Epoch[13](1700/2500): Loss: 0.2952
===> Epoch[13](1800/2500): Loss: 0.2949
===> Epoch[13](1900/2500): Loss: 0.3107
===> Epoch[13](2000/2500): Loss: 0.2995
===> Epoch[13](2100/2500): Loss: 0.2877
===> Epoch[13](2200/2500): Loss: 0.3155
===> Epoch[13](2300/2500): Loss: 0.2901
===> Epoch[13](2400/2500): Loss: 0.3193
===> Epoch[13](2500/2500): Loss: 0.3036
===> Epoch 13 Complete: Avg. Loss: 0.3025
===> Timestamp: [2025-08-03 20:30:36]
===> Loading train datasets
===> Epoch[13](100/2500): Loss: 0.3163
===> Epoch[13](200/2500): Loss: 0.3348
===> Epoch[13](300/2500): Loss: 0.3180
===> Epoch[13](400/2500): Loss: 0.3130
===> Epoch[13](500/2500): Loss: 0.2843
===> Epoch[13](600/2500): Loss: 0.3121
===> Epoch[13](700/2500): Loss: 0.3208
===> Epoch[13](800/2500): Loss: 0.2909
===> Epoch[13](900/2500): Loss: 0.3048
===> Epoch[13](1000/2500): Loss: 0.3248
===> Epoch[13](1100/2500): Loss: 0.3160
===> Epoch[13](1200/2500): Loss: 0.3068
===> Epoch[13](1300/2500): Loss: 0.2921
===> Epoch[13](1400/2500): Loss: 0.3022
===> Epoch[13](1500/2500): Loss: 0.2602
===> Epoch[13](1600/2500): Loss: 0.3164
===> Epoch[13](1700/2500): Loss: 0.2952
===> Epoch[13](1800/2500): Loss: 0.2949
===> Epoch[13](1900/2500): Loss: 0.3107
===> Epoch[13](2000/2500): Loss: 0.2995
===> Epoch[13](2100/2500): Loss: 0.2877
===> Epoch[13](2200/2500): Loss: 0.3155
===> Epoch[13](2300/2500): Loss: 0.2901
===> Epoch[13](2400/2500): Loss: 0.3193
===> Epoch[13](2500/2500): Loss: 0.3036
===> Epoch 13 Complete: Avg. Loss: 0.3025
===> Timestamp: [2025-08-03 20:30:36]
===> Loading train datasets
===> Epoch[13](100/2500): Loss: 0.3163
===> Epoch[13](200/2500): Loss: 0.3348
===> Epoch[13](300/2500): Loss: 0.3180
===> Epoch[13](400/2500): Loss: 0.3130
===> Epoch[13](500/2500): Loss: 0.2843
===> Epoch[13](600/2500): Loss: 0.3121
===> Epoch[13](700/2500): Loss: 0.3208
===> Epoch[13](800/2500): Loss: 0.2909
===> Epoch[13](900/2500): Loss: 0.3048
===> Epoch[13](1000/2500): Loss: 0.3248
===> Epoch[13](1100/2500): Loss: 0.3160
===> Epoch[13](1200/2500): Loss: 0.3068
===> Epoch[13](1300/2500): Loss: 0.2921
===> Epoch[13](1400/2500): Loss: 0.3022
===> Epoch[13](1500/2500): Loss: 0.2602
===> Epoch[13](1600/2500): Loss: 0.3164
===> Epoch[13](1700/2500): Loss: 0.2952
===> Epoch[13](1800/2500): Loss: 0.2949
===> Epoch[13](1900/2500): Loss: 0.3107
===> Epoch[13](2000/2500): Loss: 0.2995
===> Epoch[13](2100/2500): Loss: 0.2877
===> Epoch[13](2200/2500): Loss: 0.3155
===> Epoch[13](2300/2500): Loss: 0.2901
===> Epoch[13](2400/2500): Loss: 0.3193
===> Epoch[13](2500/2500): Loss: 0.3036
===> Epoch 13 Complete: Avg. Loss: 0.3025
===> Timestamp: [2025-08-03 20:30:36]
===> Loading train datasets
===> Epoch[13](100/2500): Loss: 0.3163
===> Epoch[13](200/2500): Loss: 0.3348
===> Epoch[13](300/2500): Loss: 0.3180
===> Epoch[13](400/2500): Loss: 0.3130
===> Epoch[13](500/2500): Loss: 0.2843
===> Epoch[13](600/2500): Loss: 0.3121
===> Epoch[13](700/2500): Loss: 0.3208
===> Epoch[13](800/2500): Loss: 0.2909
===> Epoch[13](900/2500): Loss: 0.3048
===> Epoch[13](1000/2500): Loss: 0.3248
===> Epoch[13](1100/2500): Loss: 0.3160
===> Epoch[13](1200/2500): Loss: 0.3068
===> Epoch[13](1300/2500): Loss: 0.2921
===> Epoch[13](1400/2500): Loss: 0.3022
===> Epoch[13](1500/2500): Loss: 0.2602
===> Epoch[13](1600/2500): Loss: 0.3164
===> Epoch[13](1700/2500): Loss: 0.2952
===> Epoch[13](1800/2500): Loss: 0.2949
===> Epoch[13](1900/2500): Loss: 0.3107
===> Epoch[13](2000/2500): Loss: 0.2995
===> Epoch[13](2100/2500): Loss: 0.2877
===> Epoch[13](2200/2500): Loss: 0.3155
===> Epoch[13](2300/2500): Loss: 0.2901
===> Epoch[13](2400/2500): Loss: 0.3193
===> Epoch[13](2500/2500): Loss: 0.3036
===> Epoch 13 Complete: Avg. Loss: 0.3025
===> Timestamp: [2025-08-03 20:30:36]
===> Loading train datasets
===> Epoch[13](100/2500): Loss: 0.3163
===> Epoch[13](200/2500): Loss: 0.3348
===> Epoch[13](300/2500): Loss: 0.3180
===> Epoch[13](400/2500): Loss: 0.3130
===> Epoch[13](500/2500): Loss: 0.2843
===> Epoch[13](600/2500): Loss: 0.3121
===> Epoch[13](700/2500): Loss: 0.3208
===> Epoch[13](800/2500): Loss: 0.2909
===> Epoch[13](900/2500): Loss: 0.3048
===> Epoch[13](1000/2500): Loss: 0.3248
===> Epoch[13](1100/2500): Loss: 0.3160
===> Epoch[13](1200/2500): Loss: 0.3068
===> Epoch[13](1300/2500): Loss: 0.2921
===> Epoch[13](1400/2500): Loss: 0.3022
===> Epoch[13](1500/2500): Loss: 0.2602
===> Epoch[13](1600/2500): Loss: 0.3164
===> Epoch[13](1700/2500): Loss: 0.2952
===> Epoch[13](1800/2500): Loss: 0.2949
===> Epoch[13](1900/2500): Loss: 0.3107
===> Epoch[13](2000/2500): Loss: 0.2995
===> Epoch[13](2100/2500): Loss: 0.2877
===> Epoch[13](2200/2500): Loss: 0.3155
===> Epoch[13](2300/2500): Loss: 0.2901
===> Epoch[13](2400/2500): Loss: 0.3193
===> Epoch[13](2500/2500): Loss: 0.3036
===> Epoch 13 Complete: Avg. Loss: 0.3025
===> Timestamp: [2025-08-03 20:30:36]
===> Loading train datasets
===> Epoch[13](100/2500): Loss: 0.3163
===> Epoch[13](200/2500): Loss: 0.3348
===> Epoch[13](300/2500): Loss: 0.3180
===> Epoch[13](400/2500): Loss: 0.3130
===> Epoch[13](500/2500): Loss: 0.2843
===> Epoch[13](600/2500): Loss: 0.3121
===> Epoch[13](700/2500): Loss: 0.3208
===> Epoch[13](800/2500): Loss: 0.2909
===> Epoch[13](900/2500): Loss: 0.3048
===> Epoch[13](1000/2500): Loss: 0.3248
===> Epoch[13](1100/2500): Loss: 0.3160
===> Epoch[13](1200/2500): Loss: 0.3068
===> Epoch[13](1300/2500): Loss: 0.2921
===> Epoch[13](1400/2500): Loss: 0.3022
===> Epoch[13](1500/2500): Loss: 0.2602
===> Epoch[13](1600/2500): Loss: 0.3164
===> Epoch[13](1700/2500): Loss: 0.2952
===> Epoch[13](1800/2500): Loss: 0.2949
===> Epoch[13](1900/2500): Loss: 0.3107
===> Epoch[13](2000/2500): Loss: 0.2995
===> Epoch[13](2100/2500): Loss: 0.2877
===> Epoch[13](2200/2500): Loss: 0.3155
===> Epoch[13](2300/2500): Loss: 0.2901
===> Epoch[13](2400/2500): Loss: 0.3193
===> Epoch[13](2500/2500): Loss: 0.3036
===> Epoch 13 Complete: Avg. Loss: 0.3025
===> Timestamp: [2025-08-03 20:30:36]
===> Loading train datasets
===> Epoch[13](100/2500): Loss: 0.3163
===> Epoch[13](200/2500): Loss: 0.3348
===> Epoch[13](300/2500): Loss: 0.3180
===> Epoch[13](400/2500): Loss: 0.3130
===> Epoch[13](500/2500): Loss: 0.2843
===> Epoch[13](600/2500): Loss: 0.3121
===> Epoch[13](700/2500): Loss: 0.3208
===> Epoch[13](800/2500): Loss: 0.2909
===> Epoch[13](900/2500): Loss: 0.3048
===> Epoch[13](1000/2500): Loss: 0.3248
===> Epoch[13](1100/2500): Loss: 0.3160
===> Epoch[13](1200/2500): Loss: 0.3068
===> Epoch[13](1300/2500): Loss: 0.2921
===> Epoch[13](1400/2500): Loss: 0.3022
===> Epoch[13](1500/2500): Loss: 0.2602
===> Epoch[13](1600/2500): Loss: 0.3164
===> Epoch[13](1700/2500): Loss: 0.2952
===> Epoch[13](1800/2500): Loss: 0.2949
===> Epoch[13](1900/2500): Loss: 0.3107
===> Epoch[13](2000/2500): Loss: 0.2995
===> Epoch[13](2100/2500): Loss: 0.2877
===> Epoch[13](2200/2500): Loss: 0.3155
===> Epoch[13](2300/2500): Loss: 0.2901
===> Epoch[13](2400/2500): Loss: 0.3193
===> Epoch[13](2500/2500): Loss: 0.3036
===> Epoch 13 Complete: Avg. Loss: 0.3025
===> Timestamp: [2025-08-03 20:30:36]
===> Loading train datasets
===> Epoch[13](100/2500): Loss: 0.3163
===> Epoch[13](200/2500): Loss: 0.3348
===> Epoch[13](300/2500): Loss: 0.3180
===> Epoch[13](400/2500): Loss: 0.3130
===> Epoch[13](500/2500): Loss: 0.2843
===> Epoch[13](600/2500): Loss: 0.3121
===> Epoch[13](700/2500): Loss: 0.3208
===> Epoch[13](800/2500): Loss: 0.2909
===> Epoch[13](900/2500): Loss: 0.3048
===> Epoch[13](1000/2500): Loss: 0.3248
===> Epoch[13](1100/2500): Loss: 0.3160
===> Epoch[13](1200/2500): Loss: 0.3068
===> Epoch[13](1300/2500): Loss: 0.2921
===> Epoch[13](1400/2500): Loss: 0.3022
===> Epoch[13](1500/2500): Loss: 0.2602
===> Epoch[13](1600/2500): Loss: 0.3164
===> Epoch[13](1700/2500): Loss: 0.2952
===> Epoch[13](1800/2500): Loss: 0.2949
===> Epoch[13](1900/2500): Loss: 0.3107
===> Epoch[13](2000/2500): Loss: 0.2995
===> Epoch[13](2100/2500): Loss: 0.2877
===> Epoch[13](2200/2500): Loss: 0.3155
===> Epoch[13](2300/2500): Loss: 0.2901
===> Epoch[13](2400/2500): Loss: 0.3193
===> Epoch[13](2500/2500): Loss: 0.3036
===> Epoch 13 Complete: Avg. Loss: 0.3025
===> Timestamp: [2025-08-03 20:30:36]
===> Loading train datasets
===> Epoch[13](100/2500): Loss: 0.3163
===> Epoch[13](200/2500): Loss: 0.3348
===> Epoch[13](300/2500): Loss: 0.3180
===> Epoch[13](400/2500): Loss: 0.3130
===> Epoch[13](500/2500): Loss: 0.2843
===> Epoch[13](600/2500): Loss: 0.3121
===> Epoch[13](700/2500): Loss: 0.3208
===> Epoch[13](800/2500): Loss: 0.2909
===> Epoch[13](900/2500): Loss: 0.3048
===> Epoch[13](1000/2500): Loss: 0.3248
===> Epoch[13](1100/2500): Loss: 0.3160
===> Epoch[13](1200/2500): Loss: 0.3068
===> Epoch[13](1300/2500): Loss: 0.2921
===> Epoch[13](1400/2500): Loss: 0.3022
===> Epoch[13](1500/2500): Loss: 0.2602
===> Epoch[13](1600/2500): Loss: 0.3164
===> Epoch[13](1700/2500): Loss: 0.2952
===> Epoch[13](1800/2500): Loss: 0.2949
===> Epoch[13](1900/2500): Loss: 0.3107
===> Epoch[13](2000/2500): Loss: 0.2995
===> Epoch[13](2100/2500): Loss: 0.2877
===> Epoch[13](2200/2500): Loss: 0.3155
===> Epoch[13](2300/2500): Loss: 0.2901
===> Epoch[13](2400/2500): Loss: 0.3193
===> Epoch[13](2500/2500): Loss: 0.3036
===> Epoch 13 Complete: Avg. Loss: 0.3025
===> Timestamp: [2025-08-03 20:30:36]
===> Loading train datasets
===> Epoch[13](100/2500): Loss: 0.3163
===> Epoch[13](200/2500): Loss: 0.3348
===> Epoch[13](300/2500): Loss: 0.3180
===> Epoch[13](400/2500): Loss: 0.3130
===> Epoch[13](500/2500): Loss: 0.2843
===> Epoch[13](600/2500): Loss: 0.3121
===> Epoch[13](700/2500): Loss: 0.3208
===> Epoch[13](800/2500): Loss: 0.2909
===> Epoch[13](900/2500): Loss: 0.3048
===> Epoch[13](1000/2500): Loss: 0.3248
===> Epoch[13](1100/2500): Loss: 0.3160
===> Epoch[13](1200/2500): Loss: 0.3068
===> Epoch[13](1300/2500): Loss: 0.2921
===> Epoch[13](1400/2500): Loss: 0.3022
===> Epoch[13](1500/2500): Loss: 0.2602
===> Epoch[13](1600/2500): Loss: 0.3164
===> Epoch[13](1700/2500): Loss: 0.2952
===> Epoch[13](1800/2500): Loss: 0.2949
===> Epoch[13](1900/2500): Loss: 0.3107
===> Epoch[13](2000/2500): Loss: 0.2995
===> Epoch[13](2100/2500): Loss: 0.2877
===> Epoch[13](2200/2500): Loss: 0.3155
===> Epoch[13](2300/2500): Loss: 0.2901
===> Epoch[13](2400/2500): Loss: 0.3193
===> Epoch[13](2500/2500): Loss: 0.3036
===> Epoch 13 Complete: Avg. Loss: 0.3025
===> Timestamp: [2025-08-03 20:30:36]
===> Loading train datasets
===> Epoch[13](100/2500): Loss: 0.3163
===> Epoch[13](200/2500): Loss: 0.3348
===> Epoch[13](300/2500): Loss: 0.3180
===> Epoch[13](400/2500): Loss: 0.3130
===> Epoch[13](500/2500): Loss: 0.2843
===> Epoch[13](600/2500): Loss: 0.3121
===> Epoch[13](700/2500): Loss: 0.3208
===> Epoch[13](800/2500): Loss: 0.2909
===> Epoch[13](900/2500): Loss: 0.3048
===> Epoch[13](1000/2500): Loss: 0.3248
===> Epoch[13](1100/2500): Loss: 0.3160
===> Epoch[13](1200/2500): Loss: 0.3068
===> Epoch[13](1300/2500): Loss: 0.2921
===> Epoch[13](1400/2500): Loss: 0.3022
===> Epoch[13](1500/2500): Loss: 0.2602
===> Epoch[13](1600/2500): Loss: 0.3164
===> Epoch[13](1700/2500): Loss: 0.2952
===> Epoch[13](1800/2500): Loss: 0.2949
===> Epoch[13](1900/2500): Loss: 0.3107
===> Epoch[13](2000/2500): Loss: 0.2995
===> Epoch[13](2100/2500): Loss: 0.2877
===> Epoch[13](2200/2500): Loss: 0.3155
===> Epoch[13](2300/2500): Loss: 0.2901
===> Epoch[13](2400/2500): Loss: 0.3193
===> Epoch[13](2500/2500): Loss: 0.3036
===> Epoch 13 Complete: Avg. Loss: 0.3025
===> Timestamp: [2025-08-03 20:30:36]
===> Loading train datasets
===> Epoch[13](100/2500): Loss: 0.3163
===> Epoch[13](200/2500): Loss: 0.3348
===> Epoch[13](300/2500): Loss: 0.3180
===> Epoch[13](400/2500): Loss: 0.3130
===> Epoch[13](500/2500): Loss: 0.2843
===> Epoch[13](600/2500): Loss: 0.3121
===> Epoch[13](700/2500): Loss: 0.3208
===> Epoch[13](800/2500): Loss: 0.2909
===> Epoch[13](900/2500): Loss: 0.3048
===> Epoch[13](1000/2500): Loss: 0.3248
===> Epoch[13](1100/2500): Loss: 0.3160
===> Epoch[13](1200/2500): Loss: 0.3068
===> Epoch[13](1300/2500): Loss: 0.2921
===> Epoch[13](1400/2500): Loss: 0.3022
===> Epoch[13](1500/2500): Loss: 0.2602
===> Epoch[13](1600/2500): Loss: 0.3164
===> Epoch[13](1700/2500): Loss: 0.2952
===> Epoch[13](1800/2500): Loss: 0.2949
===> Epoch[13](1900/2500): Loss: 0.3107
===> Epoch[13](2000/2500): Loss: 0.2995
===> Epoch[13](2100/2500): Loss: 0.2877
===> Epoch[13](2200/2500): Loss: 0.3155
===> Epoch[13](2300/2500): Loss: 0.2901
===> Epoch[13](2400/2500): Loss: 0.3193
===> Epoch[13](2500/2500): Loss: 0.3036
===> Epoch 13 Complete: Avg. Loss: 0.3025
===> Timestamp: [2025-08-03 20:30:36]
===> Loading train datasets
===> Epoch[13](100/2500): Loss: 0.3163
===> Epoch[13](200/2500): Loss: 0.3348
===> Epoch[13](300/2500): Loss: 0.3180
===> Epoch[13](400/2500): Loss: 0.3130
===> Epoch[13](500/2500): Loss: 0.2843
===> Epoch[13](600/2500): Loss: 0.3121
===> Epoch[13](700/2500): Loss: 0.3208
===> Epoch[13](800/2500): Loss: 0.2909
===> Epoch[13](900/2500): Loss: 0.3048
===> Epoch[13](1000/2500): Loss: 0.3248
===> Epoch[13](1100/2500): Loss: 0.3160
===> Epoch[13](1200/2500): Loss: 0.3068
===> Epoch[13](1300/2500): Loss: 0.2921
===> Epoch[13](1400/2500): Loss: 0.3022
===> Epoch[13](1500/2500): Loss: 0.2602
===> Epoch[13](1600/2500): Loss: 0.3164
===> Epoch[13](1700/2500): Loss: 0.2952
===> Epoch[13](1800/2500): Loss: 0.2949
===> Epoch[13](1900/2500): Loss: 0.3107
===> Epoch[13](2000/2500): Loss: 0.2995
===> Epoch[13](2100/2500): Loss: 0.2877
===> Epoch[13](2200/2500): Loss: 0.3155
===> Epoch[13](2300/2500): Loss: 0.2901
===> Epoch[13](2400/2500): Loss: 0.3193
===> Epoch[13](2500/2500): Loss: 0.3036
===> Epoch 13 Complete: Avg. Loss: 0.3025
===> Timestamp: [2025-08-03 20:30:36]
===> Loading train datasets
===> Loading train datasets
===> Epoch[14](100/2500): Loss: 0.2867
===> Epoch[14](200/2500): Loss: 0.3238
===> Epoch[14](300/2500): Loss: 0.2831
===> Epoch[14](400/2500): Loss: 0.3036
===> Epoch[14](500/2500): Loss: 0.2963
===> Epoch[14](600/2500): Loss: 0.2917
===> Epoch[14](700/2500): Loss: 0.2832
===> Epoch[14](800/2500): Loss: 0.3107
===> Epoch[14](900/2500): Loss: 0.2858
===> Epoch[14](1000/2500): Loss: 0.3026
===> Epoch[14](1100/2500): Loss: 0.2874
===> Epoch[14](1200/2500): Loss: 0.3124
===> Epoch[14](1300/2500): Loss: 0.2988
===> Epoch[14](1400/2500): Loss: 0.3107
===> Epoch[14](1500/2500): Loss: 0.3197
===> Epoch[14](1600/2500): Loss: 0.3201
===> Epoch[14](1700/2500): Loss: 0.3071
===> Epoch[14](1800/2500): Loss: 0.2851
===> Epoch[14](1900/2500): Loss: 0.2942
===> Epoch[14](2000/2500): Loss: 0.3270
===> Epoch[14](2100/2500): Loss: 0.2987
===> Epoch[14](2200/2500): Loss: 0.2736
===> Epoch[14](2300/2500): Loss: 0.2992
===> Epoch[14](2400/2500): Loss: 0.3223
===> Epoch[14](2500/2500): Loss: 0.2882
===> Epoch 14 Complete: Avg. Loss: 0.3014
===> Timestamp: [2025-08-03 20:35:10]
===> Loading train datasets
===> Epoch[14](100/2500): Loss: 0.2867
===> Epoch[14](200/2500): Loss: 0.3238
===> Epoch[14](300/2500): Loss: 0.2831
===> Epoch[14](400/2500): Loss: 0.3036
===> Epoch[14](500/2500): Loss: 0.2963
===> Epoch[14](600/2500): Loss: 0.2917
===> Epoch[14](700/2500): Loss: 0.2832
===> Epoch[14](800/2500): Loss: 0.3107
===> Epoch[14](900/2500): Loss: 0.2858
===> Epoch[14](1000/2500): Loss: 0.3026
===> Epoch[14](1100/2500): Loss: 0.2874
===> Epoch[14](1200/2500): Loss: 0.3124
===> Epoch[14](1300/2500): Loss: 0.2988
===> Epoch[14](1400/2500): Loss: 0.3107
===> Epoch[14](1500/2500): Loss: 0.3197
===> Epoch[14](1600/2500): Loss: 0.3201
===> Epoch[14](1700/2500): Loss: 0.3071
===> Epoch[14](1800/2500): Loss: 0.2851
===> Epoch[14](1900/2500): Loss: 0.2942
===> Epoch[14](2000/2500): Loss: 0.3270
===> Epoch[14](2100/2500): Loss: 0.2987
===> Epoch[14](2200/2500): Loss: 0.2736
===> Epoch[14](2300/2500): Loss: 0.2992
===> Epoch[14](2400/2500): Loss: 0.3223
===> Epoch[14](2500/2500): Loss: 0.2882
===> Epoch 14 Complete: Avg. Loss: 0.3014
===> Timestamp: [2025-08-03 20:35:10]
===> Loading train datasets
===> Epoch[14](100/2500): Loss: 0.2867
===> Epoch[14](200/2500): Loss: 0.3238
===> Epoch[14](300/2500): Loss: 0.2831
===> Epoch[14](400/2500): Loss: 0.3036
===> Epoch[14](500/2500): Loss: 0.2963
===> Epoch[14](600/2500): Loss: 0.2917
===> Epoch[14](700/2500): Loss: 0.2832
===> Epoch[14](800/2500): Loss: 0.3107
===> Epoch[14](900/2500): Loss: 0.2858
===> Epoch[14](1000/2500): Loss: 0.3026
===> Epoch[14](1100/2500): Loss: 0.2874
===> Epoch[14](1200/2500): Loss: 0.3124
===> Epoch[14](1300/2500): Loss: 0.2988
===> Epoch[14](1400/2500): Loss: 0.3107
===> Epoch[14](1500/2500): Loss: 0.3197
===> Epoch[14](1600/2500): Loss: 0.3201
===> Epoch[14](1700/2500): Loss: 0.3071
===> Epoch[14](1800/2500): Loss: 0.2851
===> Epoch[14](1900/2500): Loss: 0.2942
===> Epoch[14](2000/2500): Loss: 0.3270
===> Epoch[14](2100/2500): Loss: 0.2987
===> Epoch[14](2200/2500): Loss: 0.2736
===> Epoch[14](2300/2500): Loss: 0.2992
===> Epoch[14](2400/2500): Loss: 0.3223
===> Epoch[14](2500/2500): Loss: 0.2882
===> Epoch 14 Complete: Avg. Loss: 0.3014
===> Timestamp: [2025-08-03 20:35:10]
===> Loading train datasets
===> Epoch[14](100/2500): Loss: 0.2867
===> Epoch[14](200/2500): Loss: 0.3238
===> Epoch[14](300/2500): Loss: 0.2831
===> Epoch[14](400/2500): Loss: 0.3036
===> Epoch[14](500/2500): Loss: 0.2963
===> Epoch[14](600/2500): Loss: 0.2917
===> Epoch[14](700/2500): Loss: 0.2832
===> Epoch[14](800/2500): Loss: 0.3107
===> Epoch[14](900/2500): Loss: 0.2858
===> Epoch[14](1000/2500): Loss: 0.3026
===> Epoch[14](1100/2500): Loss: 0.2874
===> Epoch[14](1200/2500): Loss: 0.3124
===> Epoch[14](1300/2500): Loss: 0.2988
===> Epoch[14](1400/2500): Loss: 0.3107
===> Epoch[14](1500/2500): Loss: 0.3197
===> Epoch[14](1600/2500): Loss: 0.3201
===> Epoch[14](1700/2500): Loss: 0.3071
===> Epoch[14](1800/2500): Loss: 0.2851
===> Epoch[14](1900/2500): Loss: 0.2942
===> Epoch[14](2000/2500): Loss: 0.3270
===> Epoch[14](2100/2500): Loss: 0.2987
===> Epoch[14](2200/2500): Loss: 0.2736
===> Epoch[14](2300/2500): Loss: 0.2992
===> Epoch[14](2400/2500): Loss: 0.3223
===> Epoch[14](2500/2500): Loss: 0.2882
===> Epoch 14 Complete: Avg. Loss: 0.3014
===> Timestamp: [2025-08-03 20:35:10]
===> Loading train datasets
===> Epoch[14](100/2500): Loss: 0.2867
===> Epoch[14](200/2500): Loss: 0.3238
===> Epoch[14](300/2500): Loss: 0.2831
===> Epoch[14](400/2500): Loss: 0.3036
===> Epoch[14](500/2500): Loss: 0.2963
===> Epoch[14](600/2500): Loss: 0.2917
===> Epoch[14](700/2500): Loss: 0.2832
===> Epoch[14](800/2500): Loss: 0.3107
===> Epoch[14](900/2500): Loss: 0.2858
===> Epoch[14](1000/2500): Loss: 0.3026
===> Epoch[14](1100/2500): Loss: 0.2874
===> Epoch[14](1200/2500): Loss: 0.3124
===> Epoch[14](1300/2500): Loss: 0.2988
===> Epoch[14](1400/2500): Loss: 0.3107
===> Epoch[14](1500/2500): Loss: 0.3197
===> Epoch[14](1600/2500): Loss: 0.3201
===> Epoch[14](1700/2500): Loss: 0.3071
===> Epoch[14](1800/2500): Loss: 0.2851
===> Epoch[14](1900/2500): Loss: 0.2942
===> Epoch[14](2000/2500): Loss: 0.3270
===> Epoch[14](2100/2500): Loss: 0.2987
===> Epoch[14](2200/2500): Loss: 0.2736
===> Epoch[14](2300/2500): Loss: 0.2992
===> Epoch[14](2400/2500): Loss: 0.3223
===> Epoch[14](2500/2500): Loss: 0.2882
===> Epoch 14 Complete: Avg. Loss: 0.3014
===> Timestamp: [2025-08-03 20:35:10]
===> Loading train datasets
===> Epoch[14](100/2500): Loss: 0.2867
===> Epoch[14](200/2500): Loss: 0.3238
===> Epoch[14](300/2500): Loss: 0.2831
===> Epoch[14](400/2500): Loss: 0.3036
===> Epoch[14](500/2500): Loss: 0.2963
===> Epoch[14](600/2500): Loss: 0.2917
===> Epoch[14](700/2500): Loss: 0.2832
===> Epoch[14](800/2500): Loss: 0.3107
===> Epoch[14](900/2500): Loss: 0.2858
===> Epoch[14](1000/2500): Loss: 0.3026
===> Epoch[14](1100/2500): Loss: 0.2874
===> Epoch[14](1200/2500): Loss: 0.3124
===> Epoch[14](1300/2500): Loss: 0.2988
===> Epoch[14](1400/2500): Loss: 0.3107
===> Epoch[14](1500/2500): Loss: 0.3197
===> Epoch[14](1600/2500): Loss: 0.3201
===> Epoch[14](1700/2500): Loss: 0.3071
===> Epoch[14](1800/2500): Loss: 0.2851
===> Epoch[14](1900/2500): Loss: 0.2942
===> Epoch[14](2000/2500): Loss: 0.3270
===> Epoch[14](2100/2500): Loss: 0.2987
===> Epoch[14](2200/2500): Loss: 0.2736
===> Epoch[14](2300/2500): Loss: 0.2992
===> Epoch[14](2400/2500): Loss: 0.3223
===> Epoch[14](2500/2500): Loss: 0.2882
===> Epoch 14 Complete: Avg. Loss: 0.3014
===> Timestamp: [2025-08-03 20:35:10]
===> Loading train datasets
===> Epoch[14](100/2500): Loss: 0.2867
===> Epoch[14](200/2500): Loss: 0.3238
===> Epoch[14](300/2500): Loss: 0.2831
===> Epoch[14](400/2500): Loss: 0.3036
===> Epoch[14](500/2500): Loss: 0.2963
===> Epoch[14](600/2500): Loss: 0.2917
===> Epoch[14](700/2500): Loss: 0.2832
===> Epoch[14](800/2500): Loss: 0.3107
===> Epoch[14](900/2500): Loss: 0.2858
===> Epoch[14](1000/2500): Loss: 0.3026
===> Epoch[14](1100/2500): Loss: 0.2874
===> Epoch[14](1200/2500): Loss: 0.3124
===> Epoch[14](1300/2500): Loss: 0.2988
===> Epoch[14](1400/2500): Loss: 0.3107
===> Epoch[14](1500/2500): Loss: 0.3197
===> Epoch[14](1600/2500): Loss: 0.3201
===> Epoch[14](1700/2500): Loss: 0.3071
===> Epoch[14](1800/2500): Loss: 0.2851
===> Epoch[14](1900/2500): Loss: 0.2942
===> Epoch[14](2000/2500): Loss: 0.3270
===> Epoch[14](2100/2500): Loss: 0.2987
===> Epoch[14](2200/2500): Loss: 0.2736
===> Epoch[14](2300/2500): Loss: 0.2992
===> Epoch[14](2400/2500): Loss: 0.3223
===> Epoch[14](2500/2500): Loss: 0.2882
===> Epoch 14 Complete: Avg. Loss: 0.3014
===> Timestamp: [2025-08-03 20:35:10]
===> Loading train datasets
===> Epoch[14](100/2500): Loss: 0.2867
===> Epoch[14](200/2500): Loss: 0.3238
===> Epoch[14](300/2500): Loss: 0.2831
===> Epoch[14](400/2500): Loss: 0.3036
===> Epoch[14](500/2500): Loss: 0.2963
===> Epoch[14](600/2500): Loss: 0.2917
===> Epoch[14](700/2500): Loss: 0.2832
===> Epoch[14](800/2500): Loss: 0.3107
===> Epoch[14](900/2500): Loss: 0.2858
===> Epoch[14](1000/2500): Loss: 0.3026
===> Epoch[14](1100/2500): Loss: 0.2874
===> Epoch[14](1200/2500): Loss: 0.3124
===> Epoch[14](1300/2500): Loss: 0.2988
===> Epoch[14](1400/2500): Loss: 0.3107
===> Epoch[14](1500/2500): Loss: 0.3197
===> Epoch[14](1600/2500): Loss: 0.3201
===> Epoch[14](1700/2500): Loss: 0.3071
===> Epoch[14](1800/2500): Loss: 0.2851
===> Epoch[14](1900/2500): Loss: 0.2942
===> Epoch[14](2000/2500): Loss: 0.3270
===> Epoch[14](2100/2500): Loss: 0.2987
===> Epoch[14](2200/2500): Loss: 0.2736
===> Epoch[14](2300/2500): Loss: 0.2992
===> Epoch[14](2400/2500): Loss: 0.3223
===> Epoch[14](2500/2500): Loss: 0.2882
===> Epoch 14 Complete: Avg. Loss: 0.3014
===> Timestamp: [2025-08-03 20:35:10]
===> Loading train datasets
===> Epoch[14](100/2500): Loss: 0.2867
===> Epoch[14](200/2500): Loss: 0.3238
===> Epoch[14](300/2500): Loss: 0.2831
===> Epoch[14](400/2500): Loss: 0.3036
===> Epoch[14](500/2500): Loss: 0.2963
===> Epoch[14](600/2500): Loss: 0.2917
===> Epoch[14](700/2500): Loss: 0.2832
===> Epoch[14](800/2500): Loss: 0.3107
===> Epoch[14](900/2500): Loss: 0.2858
===> Epoch[14](1000/2500): Loss: 0.3026
===> Epoch[14](1100/2500): Loss: 0.2874
===> Epoch[14](1200/2500): Loss: 0.3124
===> Epoch[14](1300/2500): Loss: 0.2988
===> Epoch[14](1400/2500): Loss: 0.3107
===> Epoch[14](1500/2500): Loss: 0.3197
===> Epoch[14](1600/2500): Loss: 0.3201
===> Epoch[14](1700/2500): Loss: 0.3071
===> Epoch[14](1800/2500): Loss: 0.2851
===> Epoch[14](1900/2500): Loss: 0.2942
===> Epoch[14](2000/2500): Loss: 0.3270
===> Epoch[14](2100/2500): Loss: 0.2987
===> Epoch[14](2200/2500): Loss: 0.2736
===> Epoch[14](2300/2500): Loss: 0.2992
===> Epoch[14](2400/2500): Loss: 0.3223
===> Epoch[14](2500/2500): Loss: 0.2882
===> Epoch 14 Complete: Avg. Loss: 0.3014
===> Timestamp: [2025-08-03 20:35:10]
===> Loading train datasets
===> Epoch[14](100/2500): Loss: 0.2867
===> Epoch[14](200/2500): Loss: 0.3238
===> Epoch[14](300/2500): Loss: 0.2831
===> Epoch[14](400/2500): Loss: 0.3036
===> Epoch[14](500/2500): Loss: 0.2963
===> Epoch[14](600/2500): Loss: 0.2917
===> Epoch[14](700/2500): Loss: 0.2832
===> Epoch[14](800/2500): Loss: 0.3107
===> Epoch[14](900/2500): Loss: 0.2858
===> Epoch[14](1000/2500): Loss: 0.3026
===> Epoch[14](1100/2500): Loss: 0.2874
===> Epoch[14](1200/2500): Loss: 0.3124
===> Epoch[14](1300/2500): Loss: 0.2988
===> Epoch[14](1400/2500): Loss: 0.3107
===> Epoch[14](1500/2500): Loss: 0.3197
===> Epoch[14](1600/2500): Loss: 0.3201
===> Epoch[14](1700/2500): Loss: 0.3071
===> Epoch[14](1800/2500): Loss: 0.2851
===> Epoch[14](1900/2500): Loss: 0.2942
===> Epoch[14](2000/2500): Loss: 0.3270
===> Epoch[14](2100/2500): Loss: 0.2987
===> Epoch[14](2200/2500): Loss: 0.2736
===> Epoch[14](2300/2500): Loss: 0.2992
===> Epoch[14](2400/2500): Loss: 0.3223
===> Epoch[14](2500/2500): Loss: 0.2882
===> Epoch 14 Complete: Avg. Loss: 0.3014
===> Timestamp: [2025-08-03 20:35:10]
===> Loading train datasets
===> Epoch[14](100/2500): Loss: 0.2867
===> Epoch[14](200/2500): Loss: 0.3238
===> Epoch[14](300/2500): Loss: 0.2831
===> Epoch[14](400/2500): Loss: 0.3036
===> Epoch[14](500/2500): Loss: 0.2963
===> Epoch[14](600/2500): Loss: 0.2917
===> Epoch[14](700/2500): Loss: 0.2832
===> Epoch[14](800/2500): Loss: 0.3107
===> Epoch[14](900/2500): Loss: 0.2858
===> Epoch[14](1000/2500): Loss: 0.3026
===> Epoch[14](1100/2500): Loss: 0.2874
===> Epoch[14](1200/2500): Loss: 0.3124
===> Epoch[14](1300/2500): Loss: 0.2988
===> Epoch[14](1400/2500): Loss: 0.3107
===> Epoch[14](1500/2500): Loss: 0.3197
===> Epoch[14](1600/2500): Loss: 0.3201
===> Epoch[14](1700/2500): Loss: 0.3071
===> Epoch[14](1800/2500): Loss: 0.2851
===> Epoch[14](1900/2500): Loss: 0.2942
===> Epoch[14](2000/2500): Loss: 0.3270
===> Epoch[14](2100/2500): Loss: 0.2987
===> Epoch[14](2200/2500): Loss: 0.2736
===> Epoch[14](2300/2500): Loss: 0.2992
===> Epoch[14](2400/2500): Loss: 0.3223
===> Epoch[14](2500/2500): Loss: 0.2882
===> Epoch 14 Complete: Avg. Loss: 0.3014
===> Timestamp: [2025-08-03 20:35:10]
===> Loading train datasets
===> Epoch[14](100/2500): Loss: 0.2867
===> Epoch[14](200/2500): Loss: 0.3238
===> Epoch[14](300/2500): Loss: 0.2831
===> Epoch[14](400/2500): Loss: 0.3036
===> Epoch[14](500/2500): Loss: 0.2963
===> Epoch[14](600/2500): Loss: 0.2917
===> Epoch[14](700/2500): Loss: 0.2832
===> Epoch[14](800/2500): Loss: 0.3107
===> Epoch[14](900/2500): Loss: 0.2858
===> Epoch[14](1000/2500): Loss: 0.3026
===> Epoch[14](1100/2500): Loss: 0.2874
===> Epoch[14](1200/2500): Loss: 0.3124
===> Epoch[14](1300/2500): Loss: 0.2988
===> Epoch[14](1400/2500): Loss: 0.3107
===> Epoch[14](1500/2500): Loss: 0.3197
===> Epoch[14](1600/2500): Loss: 0.3201
===> Epoch[14](1700/2500): Loss: 0.3071
===> Epoch[14](1800/2500): Loss: 0.2851
===> Epoch[14](1900/2500): Loss: 0.2942
===> Epoch[14](2000/2500): Loss: 0.3270
===> Epoch[14](2100/2500): Loss: 0.2987
===> Epoch[14](2200/2500): Loss: 0.2736
===> Epoch[14](2300/2500): Loss: 0.2992
===> Epoch[14](2400/2500): Loss: 0.3223
===> Epoch[14](2500/2500): Loss: 0.2882
===> Epoch 14 Complete: Avg. Loss: 0.3014
===> Timestamp: [2025-08-03 20:35:10]
===> Loading train datasets
===> Epoch[14](100/2500): Loss: 0.2867
===> Epoch[14](200/2500): Loss: 0.3238
===> Epoch[14](300/2500): Loss: 0.2831
===> Epoch[14](400/2500): Loss: 0.3036
===> Epoch[14](500/2500): Loss: 0.2963
===> Epoch[14](600/2500): Loss: 0.2917
===> Epoch[14](700/2500): Loss: 0.2832
===> Epoch[14](800/2500): Loss: 0.3107
===> Epoch[14](900/2500): Loss: 0.2858
===> Epoch[14](1000/2500): Loss: 0.3026
===> Epoch[14](1100/2500): Loss: 0.2874
===> Epoch[14](1200/2500): Loss: 0.3124
===> Epoch[14](1300/2500): Loss: 0.2988
===> Epoch[14](1400/2500): Loss: 0.3107
===> Epoch[14](1500/2500): Loss: 0.3197
===> Epoch[14](1600/2500): Loss: 0.3201
===> Epoch[14](1700/2500): Loss: 0.3071
===> Epoch[14](1800/2500): Loss: 0.2851
===> Epoch[14](1900/2500): Loss: 0.2942
===> Epoch[14](2000/2500): Loss: 0.3270
===> Epoch[14](2100/2500): Loss: 0.2987
===> Epoch[14](2200/2500): Loss: 0.2736
===> Epoch[14](2300/2500): Loss: 0.2992
===> Epoch[14](2400/2500): Loss: 0.3223
===> Epoch[14](2500/2500): Loss: 0.2882
===> Epoch 14 Complete: Avg. Loss: 0.3014
===> Timestamp: [2025-08-03 20:35:10]
===> Loading train datasets
===> Epoch[14](100/2500): Loss: 0.2867
===> Epoch[14](200/2500): Loss: 0.3238
===> Epoch[14](300/2500): Loss: 0.2831
===> Epoch[14](400/2500): Loss: 0.3036
===> Epoch[14](500/2500): Loss: 0.2963
===> Epoch[14](600/2500): Loss: 0.2917
===> Epoch[14](700/2500): Loss: 0.2832
===> Epoch[14](800/2500): Loss: 0.3107
===> Epoch[14](900/2500): Loss: 0.2858
===> Epoch[14](1000/2500): Loss: 0.3026
===> Epoch[14](1100/2500): Loss: 0.2874
===> Epoch[14](1200/2500): Loss: 0.3124
===> Epoch[14](1300/2500): Loss: 0.2988
===> Epoch[14](1400/2500): Loss: 0.3107
===> Epoch[14](1500/2500): Loss: 0.3197
===> Epoch[14](1600/2500): Loss: 0.3201
===> Epoch[14](1700/2500): Loss: 0.3071
===> Epoch[14](1800/2500): Loss: 0.2851
===> Epoch[14](1900/2500): Loss: 0.2942
===> Epoch[14](2000/2500): Loss: 0.3270
===> Epoch[14](2100/2500): Loss: 0.2987
===> Epoch[14](2200/2500): Loss: 0.2736
===> Epoch[14](2300/2500): Loss: 0.2992
===> Epoch[14](2400/2500): Loss: 0.3223
===> Epoch[14](2500/2500): Loss: 0.2882
===> Epoch 14 Complete: Avg. Loss: 0.3014
===> Timestamp: [2025-08-03 20:35:10]
===> Loading train datasets
===> Loading train datasets
===> Epoch[15](100/2500): Loss: 0.3016
===> Epoch[15](200/2500): Loss: 0.2977
===> Epoch[15](300/2500): Loss: 0.3180
===> Epoch[15](400/2500): Loss: 0.3129
===> Epoch[15](500/2500): Loss: 0.2893
===> Epoch[15](600/2500): Loss: 0.2938
===> Epoch[15](700/2500): Loss: 0.3069
===> Epoch[15](800/2500): Loss: 0.3050
===> Epoch[15](900/2500): Loss: 0.3116
===> Epoch[15](1000/2500): Loss: 0.2808
===> Epoch[15](1100/2500): Loss: 0.2975
===> Epoch[15](1200/2500): Loss: 0.2944
===> Epoch[15](1300/2500): Loss: 0.3343
===> Epoch[15](1400/2500): Loss: 0.2850
===> Epoch[15](1500/2500): Loss: 0.2997
===> Epoch[15](1600/2500): Loss: 0.3001
===> Epoch[15](1700/2500): Loss: 0.2895
===> Epoch[15](1800/2500): Loss: 0.2955
===> Epoch[15](1900/2500): Loss: 0.2749
===> Epoch[15](2000/2500): Loss: 0.3118
===> Epoch[15](2100/2500): Loss: 0.3037
===> Epoch[15](2200/2500): Loss: 0.3208
===> Epoch[15](2300/2500): Loss: 0.2936
===> Epoch[15](2400/2500): Loss: 0.2914
===> Epoch[15](2500/2500): Loss: 0.2955
===> Epoch 15 Complete: Avg. Loss: 0.2992
===> Timestamp: [2025-08-03 20:39:44]
Checkpoint saved to TrainedNet/_epoch_15.pth
===> Loading train datasets
===> Epoch[15](100/2500): Loss: 0.3016
===> Epoch[15](200/2500): Loss: 0.2977
===> Epoch[15](300/2500): Loss: 0.3180
===> Epoch[15](400/2500): Loss: 0.3129
===> Epoch[15](500/2500): Loss: 0.2893
===> Epoch[15](600/2500): Loss: 0.2938
===> Epoch[15](700/2500): Loss: 0.3069
===> Epoch[15](800/2500): Loss: 0.3050
===> Epoch[15](900/2500): Loss: 0.3116
===> Epoch[15](1000/2500): Loss: 0.2808
===> Epoch[15](1100/2500): Loss: 0.2975
===> Epoch[15](1200/2500): Loss: 0.2944
===> Epoch[15](1300/2500): Loss: 0.3343
===> Epoch[15](1400/2500): Loss: 0.2850
===> Epoch[15](1500/2500): Loss: 0.2997
===> Epoch[15](1600/2500): Loss: 0.3001
===> Epoch[15](1700/2500): Loss: 0.2895
===> Epoch[15](1800/2500): Loss: 0.2955
===> Epoch[15](1900/2500): Loss: 0.2749
===> Epoch[15](2000/2500): Loss: 0.3118
===> Epoch[15](2100/2500): Loss: 0.3037
===> Epoch[15](2200/2500): Loss: 0.3208
===> Epoch[15](2300/2500): Loss: 0.2936
===> Epoch[15](2400/2500): Loss: 0.2914
===> Epoch[15](2500/2500): Loss: 0.2955
===> Epoch 15 Complete: Avg. Loss: 0.2992
===> Timestamp: [2025-08-03 20:39:44]
Checkpoint saved to TrainedNet/_epoch_15.pth
===> Loading train datasets
===> Epoch[15](100/2500): Loss: 0.3016
===> Epoch[15](200/2500): Loss: 0.2977
===> Epoch[15](300/2500): Loss: 0.3180
===> Epoch[15](400/2500): Loss: 0.3129
===> Epoch[15](500/2500): Loss: 0.2893
===> Epoch[15](600/2500): Loss: 0.2938
===> Epoch[15](700/2500): Loss: 0.3069
===> Epoch[15](800/2500): Loss: 0.3050
===> Epoch[15](900/2500): Loss: 0.3116
===> Epoch[15](1000/2500): Loss: 0.2808
===> Epoch[15](1100/2500): Loss: 0.2975
===> Epoch[15](1200/2500): Loss: 0.2944
===> Epoch[15](1300/2500): Loss: 0.3343
===> Epoch[15](1400/2500): Loss: 0.2850
===> Epoch[15](1500/2500): Loss: 0.2997
===> Epoch[15](1600/2500): Loss: 0.3001
===> Epoch[15](1700/2500): Loss: 0.2895
===> Epoch[15](1800/2500): Loss: 0.2955
===> Epoch[15](1900/2500): Loss: 0.2749
===> Epoch[15](2000/2500): Loss: 0.3118
===> Epoch[15](2100/2500): Loss: 0.3037
===> Epoch[15](2200/2500): Loss: 0.3208
===> Epoch[15](2300/2500): Loss: 0.2936
===> Epoch[15](2400/2500): Loss: 0.2914
===> Epoch[15](2500/2500): Loss: 0.2955
===> Epoch 15 Complete: Avg. Loss: 0.2992
===> Timestamp: [2025-08-03 20:39:44]
Checkpoint saved to TrainedNet/_epoch_15.pth
===> Loading train datasets
===> Epoch[15](100/2500): Loss: 0.3016
===> Epoch[15](200/2500): Loss: 0.2977
===> Epoch[15](300/2500): Loss: 0.3180
===> Epoch[15](400/2500): Loss: 0.3129
===> Epoch[15](500/2500): Loss: 0.2893
===> Epoch[15](600/2500): Loss: 0.2938
===> Epoch[15](700/2500): Loss: 0.3069
===> Epoch[15](800/2500): Loss: 0.3050
===> Epoch[15](900/2500): Loss: 0.3116
===> Epoch[15](1000/2500): Loss: 0.2808
===> Epoch[15](1100/2500): Loss: 0.2975
===> Epoch[15](1200/2500): Loss: 0.2944
===> Epoch[15](1300/2500): Loss: 0.3343
===> Epoch[15](1400/2500): Loss: 0.2850
===> Epoch[15](1500/2500): Loss: 0.2997
===> Epoch[15](1600/2500): Loss: 0.3001
===> Epoch[15](1700/2500): Loss: 0.2895
===> Epoch[15](1800/2500): Loss: 0.2955
===> Epoch[15](1900/2500): Loss: 0.2749
===> Epoch[15](2000/2500): Loss: 0.3118
===> Epoch[15](2100/2500): Loss: 0.3037
===> Epoch[15](2200/2500): Loss: 0.3208
===> Epoch[15](2300/2500): Loss: 0.2936
===> Epoch[15](2400/2500): Loss: 0.2914
===> Epoch[15](2500/2500): Loss: 0.2955
===> Epoch 15 Complete: Avg. Loss: 0.2992
===> Timestamp: [2025-08-03 20:39:44]
Checkpoint saved to TrainedNet/_epoch_15.pth
===> Loading train datasets
===> Epoch[15](100/2500): Loss: 0.3016
===> Epoch[15](200/2500): Loss: 0.2977
===> Epoch[15](300/2500): Loss: 0.3180
===> Epoch[15](400/2500): Loss: 0.3129
===> Epoch[15](500/2500): Loss: 0.2893
===> Epoch[15](600/2500): Loss: 0.2938
===> Epoch[15](700/2500): Loss: 0.3069
===> Epoch[15](800/2500): Loss: 0.3050
===> Epoch[15](900/2500): Loss: 0.3116
===> Epoch[15](1000/2500): Loss: 0.2808
===> Epoch[15](1100/2500): Loss: 0.2975
===> Epoch[15](1200/2500): Loss: 0.2944
===> Epoch[15](1300/2500): Loss: 0.3343
===> Epoch[15](1400/2500): Loss: 0.2850
===> Epoch[15](1500/2500): Loss: 0.2997
===> Epoch[15](1600/2500): Loss: 0.3001
===> Epoch[15](1700/2500): Loss: 0.2895
===> Epoch[15](1800/2500): Loss: 0.2955
===> Epoch[15](1900/2500): Loss: 0.2749
===> Epoch[15](2000/2500): Loss: 0.3118
===> Epoch[15](2100/2500): Loss: 0.3037
===> Epoch[15](2200/2500): Loss: 0.3208
===> Epoch[15](2300/2500): Loss: 0.2936
===> Epoch[15](2400/2500): Loss: 0.2914
===> Epoch[15](2500/2500): Loss: 0.2955
===> Epoch 15 Complete: Avg. Loss: 0.2992
===> Timestamp: [2025-08-03 20:39:44]
Checkpoint saved to TrainedNet/_epoch_15.pth
===> Loading train datasets
===> Epoch[15](100/2500): Loss: 0.3016
===> Epoch[15](200/2500): Loss: 0.2977
===> Epoch[15](300/2500): Loss: 0.3180
===> Epoch[15](400/2500): Loss: 0.3129
===> Epoch[15](500/2500): Loss: 0.2893
===> Epoch[15](600/2500): Loss: 0.2938
===> Epoch[15](700/2500): Loss: 0.3069
===> Epoch[15](800/2500): Loss: 0.3050
===> Epoch[15](900/2500): Loss: 0.3116
===> Epoch[15](1000/2500): Loss: 0.2808
===> Epoch[15](1100/2500): Loss: 0.2975
===> Epoch[15](1200/2500): Loss: 0.2944
===> Epoch[15](1300/2500): Loss: 0.3343
===> Epoch[15](1400/2500): Loss: 0.2850
===> Epoch[15](1500/2500): Loss: 0.2997
===> Epoch[15](1600/2500): Loss: 0.3001
===> Epoch[15](1700/2500): Loss: 0.2895
===> Epoch[15](1800/2500): Loss: 0.2955
===> Epoch[15](1900/2500): Loss: 0.2749
===> Epoch[15](2000/2500): Loss: 0.3118
===> Epoch[15](2100/2500): Loss: 0.3037
===> Epoch[15](2200/2500): Loss: 0.3208
===> Epoch[15](2300/2500): Loss: 0.2936
===> Epoch[15](2400/2500): Loss: 0.2914
===> Epoch[15](2500/2500): Loss: 0.2955
===> Epoch 15 Complete: Avg. Loss: 0.2992
===> Timestamp: [2025-08-03 20:39:44]
Checkpoint saved to TrainedNet/_epoch_15.pth
===> Loading train datasets
===> Epoch[15](100/2500): Loss: 0.3016
===> Epoch[15](200/2500): Loss: 0.2977
===> Epoch[15](300/2500): Loss: 0.3180
===> Epoch[15](400/2500): Loss: 0.3129
===> Epoch[15](500/2500): Loss: 0.2893
===> Epoch[15](600/2500): Loss: 0.2938
===> Epoch[15](700/2500): Loss: 0.3069
===> Epoch[15](800/2500): Loss: 0.3050
===> Epoch[15](900/2500): Loss: 0.3116
===> Epoch[15](1000/2500): Loss: 0.2808
===> Epoch[15](1100/2500): Loss: 0.2975
===> Epoch[15](1200/2500): Loss: 0.2944
===> Epoch[15](1300/2500): Loss: 0.3343
===> Epoch[15](1400/2500): Loss: 0.2850
===> Epoch[15](1500/2500): Loss: 0.2997
===> Epoch[15](1600/2500): Loss: 0.3001
===> Epoch[15](1700/2500): Loss: 0.2895
===> Epoch[15](1800/2500): Loss: 0.2955
===> Epoch[15](1900/2500): Loss: 0.2749
===> Epoch[15](2000/2500): Loss: 0.3118
===> Epoch[15](2100/2500): Loss: 0.3037
===> Epoch[15](2200/2500): Loss: 0.3208
===> Epoch[15](2300/2500): Loss: 0.2936
===> Epoch[15](2400/2500): Loss: 0.2914
===> Epoch[15](2500/2500): Loss: 0.2955
===> Epoch 15 Complete: Avg. Loss: 0.2992
===> Timestamp: [2025-08-03 20:39:44]
Checkpoint saved to TrainedNet/_epoch_15.pth
===> Loading train datasets
===> Epoch[15](100/2500): Loss: 0.3016
===> Epoch[15](200/2500): Loss: 0.2977
===> Epoch[15](300/2500): Loss: 0.3180
===> Epoch[15](400/2500): Loss: 0.3129
===> Epoch[15](500/2500): Loss: 0.2893
===> Epoch[15](600/2500): Loss: 0.2938
===> Epoch[15](700/2500): Loss: 0.3069
===> Epoch[15](800/2500): Loss: 0.3050
===> Epoch[15](900/2500): Loss: 0.3116
===> Epoch[15](1000/2500): Loss: 0.2808
===> Epoch[15](1100/2500): Loss: 0.2975
===> Epoch[15](1200/2500): Loss: 0.2944
===> Epoch[15](1300/2500): Loss: 0.3343
===> Epoch[15](1400/2500): Loss: 0.2850
===> Epoch[15](1500/2500): Loss: 0.2997
===> Epoch[15](1600/2500): Loss: 0.3001
===> Epoch[15](1700/2500): Loss: 0.2895
===> Epoch[15](1800/2500): Loss: 0.2955
===> Epoch[15](1900/2500): Loss: 0.2749
===> Epoch[15](2000/2500): Loss: 0.3118
===> Epoch[15](2100/2500): Loss: 0.3037
===> Epoch[15](2200/2500): Loss: 0.3208
===> Epoch[15](2300/2500): Loss: 0.2936
===> Epoch[15](2400/2500): Loss: 0.2914
===> Epoch[15](2500/2500): Loss: 0.2955
===> Epoch 15 Complete: Avg. Loss: 0.2992
===> Timestamp: [2025-08-03 20:39:44]
Checkpoint saved to TrainedNet/_epoch_15.pth
===> Loading train datasets
===> Epoch[15](100/2500): Loss: 0.3016
===> Epoch[15](200/2500): Loss: 0.2977
===> Epoch[15](300/2500): Loss: 0.3180
===> Epoch[15](400/2500): Loss: 0.3129
===> Epoch[15](500/2500): Loss: 0.2893
===> Epoch[15](600/2500): Loss: 0.2938
===> Epoch[15](700/2500): Loss: 0.3069
===> Epoch[15](800/2500): Loss: 0.3050
===> Epoch[15](900/2500): Loss: 0.3116
===> Epoch[15](1000/2500): Loss: 0.2808
===> Epoch[15](1100/2500): Loss: 0.2975
===> Epoch[15](1200/2500): Loss: 0.2944
===> Epoch[15](1300/2500): Loss: 0.3343
===> Epoch[15](1400/2500): Loss: 0.2850
===> Epoch[15](1500/2500): Loss: 0.2997
===> Epoch[15](1600/2500): Loss: 0.3001
===> Epoch[15](1700/2500): Loss: 0.2895
===> Epoch[15](1800/2500): Loss: 0.2955
===> Epoch[15](1900/2500): Loss: 0.2749
===> Epoch[15](2000/2500): Loss: 0.3118
===> Epoch[15](2100/2500): Loss: 0.3037
===> Epoch[15](2200/2500): Loss: 0.3208
===> Epoch[15](2300/2500): Loss: 0.2936
===> Epoch[15](2400/2500): Loss: 0.2914
===> Epoch[15](2500/2500): Loss: 0.2955
===> Epoch 15 Complete: Avg. Loss: 0.2992
===> Timestamp: [2025-08-03 20:39:44]
Checkpoint saved to TrainedNet/_epoch_15.pth
===> Loading train datasets
===> Epoch[15](100/2500): Loss: 0.3016
===> Epoch[15](200/2500): Loss: 0.2977
===> Epoch[15](300/2500): Loss: 0.3180
===> Epoch[15](400/2500): Loss: 0.3129
===> Epoch[15](500/2500): Loss: 0.2893
===> Epoch[15](600/2500): Loss: 0.2938
===> Epoch[15](700/2500): Loss: 0.3069
===> Epoch[15](800/2500): Loss: 0.3050
===> Epoch[15](900/2500): Loss: 0.3116
===> Epoch[15](1000/2500): Loss: 0.2808
===> Epoch[15](1100/2500): Loss: 0.2975
===> Epoch[15](1200/2500): Loss: 0.2944
===> Epoch[15](1300/2500): Loss: 0.3343
===> Epoch[15](1400/2500): Loss: 0.2850
===> Epoch[15](1500/2500): Loss: 0.2997
===> Epoch[15](1600/2500): Loss: 0.3001
===> Epoch[15](1700/2500): Loss: 0.2895
===> Epoch[15](1800/2500): Loss: 0.2955
===> Epoch[15](1900/2500): Loss: 0.2749
===> Epoch[15](2000/2500): Loss: 0.3118
===> Epoch[15](2100/2500): Loss: 0.3037
===> Epoch[15](2200/2500): Loss: 0.3208
===> Epoch[15](2300/2500): Loss: 0.2936
===> Epoch[15](2400/2500): Loss: 0.2914
===> Epoch[15](2500/2500): Loss: 0.2955
===> Epoch 15 Complete: Avg. Loss: 0.2992
===> Timestamp: [2025-08-03 20:39:44]
Checkpoint saved to TrainedNet/_epoch_15.pth
===> Loading train datasets
===> Epoch[15](100/2500): Loss: 0.3016
===> Epoch[15](200/2500): Loss: 0.2977
===> Epoch[15](300/2500): Loss: 0.3180
===> Epoch[15](400/2500): Loss: 0.3129
===> Epoch[15](500/2500): Loss: 0.2893
===> Epoch[15](600/2500): Loss: 0.2938
===> Epoch[15](700/2500): Loss: 0.3069
===> Epoch[15](800/2500): Loss: 0.3050
===> Epoch[15](900/2500): Loss: 0.3116
===> Epoch[15](1000/2500): Loss: 0.2808
===> Epoch[15](1100/2500): Loss: 0.2975
===> Epoch[15](1200/2500): Loss: 0.2944
===> Epoch[15](1300/2500): Loss: 0.3343
===> Epoch[15](1400/2500): Loss: 0.2850
===> Epoch[15](1500/2500): Loss: 0.2997
===> Epoch[15](1600/2500): Loss: 0.3001
===> Epoch[15](1700/2500): Loss: 0.2895
===> Epoch[15](1800/2500): Loss: 0.2955
===> Epoch[15](1900/2500): Loss: 0.2749
===> Epoch[15](2000/2500): Loss: 0.3118
===> Epoch[15](2100/2500): Loss: 0.3037
===> Epoch[15](2200/2500): Loss: 0.3208
===> Epoch[15](2300/2500): Loss: 0.2936
===> Epoch[15](2400/2500): Loss: 0.2914
===> Epoch[15](2500/2500): Loss: 0.2955
===> Epoch 15 Complete: Avg. Loss: 0.2992
===> Timestamp: [2025-08-03 20:39:44]
Checkpoint saved to TrainedNet/_epoch_15.pth
===> Loading train datasets
===> Epoch[15](100/2500): Loss: 0.3016
===> Epoch[15](200/2500): Loss: 0.2977
===> Epoch[15](300/2500): Loss: 0.3180
===> Epoch[15](400/2500): Loss: 0.3129
===> Epoch[15](500/2500): Loss: 0.2893
===> Epoch[15](600/2500): Loss: 0.2938
===> Epoch[15](700/2500): Loss: 0.3069
===> Epoch[15](800/2500): Loss: 0.3050
===> Epoch[15](900/2500): Loss: 0.3116
===> Epoch[15](1000/2500): Loss: 0.2808
===> Epoch[15](1100/2500): Loss: 0.2975
===> Epoch[15](1200/2500): Loss: 0.2944
===> Epoch[15](1300/2500): Loss: 0.3343
===> Epoch[15](1400/2500): Loss: 0.2850
===> Epoch[15](1500/2500): Loss: 0.2997
===> Epoch[15](1600/2500): Loss: 0.3001
===> Epoch[15](1700/2500): Loss: 0.2895
===> Epoch[15](1800/2500): Loss: 0.2955
===> Epoch[15](1900/2500): Loss: 0.2749
===> Epoch[15](2000/2500): Loss: 0.3118
===> Epoch[15](2100/2500): Loss: 0.3037
===> Epoch[15](2200/2500): Loss: 0.3208
===> Epoch[15](2300/2500): Loss: 0.2936
===> Epoch[15](2400/2500): Loss: 0.2914
===> Epoch[15](2500/2500): Loss: 0.2955
===> Epoch 15 Complete: Avg. Loss: 0.2992
===> Timestamp: [2025-08-03 20:39:44]
Checkpoint saved to TrainedNet/_epoch_15.pth
===> Loading train datasets
===> Epoch[15](100/2500): Loss: 0.3016
===> Epoch[15](200/2500): Loss: 0.2977
===> Epoch[15](300/2500): Loss: 0.3180
===> Epoch[15](400/2500): Loss: 0.3129
===> Epoch[15](500/2500): Loss: 0.2893
===> Epoch[15](600/2500): Loss: 0.2938
===> Epoch[15](700/2500): Loss: 0.3069
===> Epoch[15](800/2500): Loss: 0.3050
===> Epoch[15](900/2500): Loss: 0.3116
===> Epoch[15](1000/2500): Loss: 0.2808
===> Epoch[15](1100/2500): Loss: 0.2975
===> Epoch[15](1200/2500): Loss: 0.2944
===> Epoch[15](1300/2500): Loss: 0.3343
===> Epoch[15](1400/2500): Loss: 0.2850
===> Epoch[15](1500/2500): Loss: 0.2997
===> Epoch[15](1600/2500): Loss: 0.3001
===> Epoch[15](1700/2500): Loss: 0.2895
===> Epoch[15](1800/2500): Loss: 0.2955
===> Epoch[15](1900/2500): Loss: 0.2749
===> Epoch[15](2000/2500): Loss: 0.3118
===> Epoch[15](2100/2500): Loss: 0.3037
===> Epoch[15](2200/2500): Loss: 0.3208
===> Epoch[15](2300/2500): Loss: 0.2936
===> Epoch[15](2400/2500): Loss: 0.2914
===> Epoch[15](2500/2500): Loss: 0.2955
===> Epoch 15 Complete: Avg. Loss: 0.2992
===> Timestamp: [2025-08-03 20:39:44]
Checkpoint saved to TrainedNet/_epoch_15.pth
===> Loading train datasets
===> Epoch[15](100/2500): Loss: 0.3016
===> Epoch[15](200/2500): Loss: 0.2977
===> Epoch[15](300/2500): Loss: 0.3180
===> Epoch[15](400/2500): Loss: 0.3129
===> Epoch[15](500/2500): Loss: 0.2893
===> Epoch[15](600/2500): Loss: 0.2938
===> Epoch[15](700/2500): Loss: 0.3069
===> Epoch[15](800/2500): Loss: 0.3050
===> Epoch[15](900/2500): Loss: 0.3116
===> Epoch[15](1000/2500): Loss: 0.2808
===> Epoch[15](1100/2500): Loss: 0.2975
===> Epoch[15](1200/2500): Loss: 0.2944
===> Epoch[15](1300/2500): Loss: 0.3343
===> Epoch[15](1400/2500): Loss: 0.2850
===> Epoch[15](1500/2500): Loss: 0.2997
===> Epoch[15](1600/2500): Loss: 0.3001
===> Epoch[15](1700/2500): Loss: 0.2895
===> Epoch[15](1800/2500): Loss: 0.2955
===> Epoch[15](1900/2500): Loss: 0.2749
===> Epoch[15](2000/2500): Loss: 0.3118
===> Epoch[15](2100/2500): Loss: 0.3037
===> Epoch[15](2200/2500): Loss: 0.3208
===> Epoch[15](2300/2500): Loss: 0.2936
===> Epoch[15](2400/2500): Loss: 0.2914
===> Epoch[15](2500/2500): Loss: 0.2955
===> Epoch 15 Complete: Avg. Loss: 0.2992
===> Timestamp: [2025-08-03 20:39:44]
Checkpoint saved to TrainedNet/_epoch_15.pth
===> Loading train datasets
===> Epoch[15](100/2500): Loss: 0.3016
===> Epoch[15](200/2500): Loss: 0.2977
===> Epoch[15](300/2500): Loss: 0.3180
===> Epoch[15](400/2500): Loss: 0.3129
===> Epoch[15](500/2500): Loss: 0.2893
===> Epoch[15](600/2500): Loss: 0.2938
===> Epoch[15](700/2500): Loss: 0.3069
===> Epoch[15](800/2500): Loss: 0.3050
===> Epoch[15](900/2500): Loss: 0.3116
===> Epoch[15](1000/2500): Loss: 0.2808
===> Epoch[15](1100/2500): Loss: 0.2975
===> Epoch[15](1200/2500): Loss: 0.2944
===> Epoch[15](1300/2500): Loss: 0.3343
===> Epoch[15](1400/2500): Loss: 0.2850
===> Epoch[15](1500/2500): Loss: 0.2997
===> Epoch[15](1600/2500): Loss: 0.3001
===> Epoch[15](1700/2500): Loss: 0.2895
===> Epoch[15](1800/2500): Loss: 0.2955
===> Epoch[15](1900/2500): Loss: 0.2749
===> Epoch[15](2000/2500): Loss: 0.3118
===> Epoch[15](2100/2500): Loss: 0.3037
===> Epoch[15](2200/2500): Loss: 0.3208
===> Epoch[15](2300/2500): Loss: 0.2936
===> Epoch[15](2400/2500): Loss: 0.2914
===> Epoch[15](2500/2500): Loss: 0.2955
===> Epoch 15 Complete: Avg. Loss: 0.2992
===> Timestamp: [2025-08-03 20:39:44]
Checkpoint saved to TrainedNet/_epoch_15.pth
===> Loading train datasets
===> Loading train datasets
===> Epoch[16](100/2500): Loss: 0.3203
===> Epoch[16](200/2500): Loss: 0.3087
===> Epoch[16](300/2500): Loss: 0.2921
===> Epoch[16](400/2500): Loss: 0.3078
===> Epoch[16](500/2500): Loss: 0.2769
===> Epoch[16](600/2500): Loss: 0.2865
===> Epoch[16](700/2500): Loss: 0.3282
===> Epoch[16](800/2500): Loss: 0.2986
===> Epoch[16](900/2500): Loss: 0.3100
===> Epoch[16](1000/2500): Loss: 0.2738
===> Epoch[16](1100/2500): Loss: 0.2954
===> Epoch[16](1200/2500): Loss: 0.2786
===> Epoch[16](1300/2500): Loss: 0.2945
===> Epoch[16](1400/2500): Loss: 0.3118
===> Epoch[16](1500/2500): Loss: 0.2975
===> Epoch[16](1600/2500): Loss: 0.2819
===> Epoch[16](1700/2500): Loss: 0.3198
===> Epoch[16](1800/2500): Loss: 0.2816
===> Epoch[16](1900/2500): Loss: 0.2975
===> Epoch[16](2000/2500): Loss: 0.2969
===> Epoch[16](2100/2500): Loss: 0.2975
===> Epoch[16](2200/2500): Loss: 0.2853
===> Epoch[16](2300/2500): Loss: 0.2891
===> Epoch[16](2400/2500): Loss: 0.2987
===> Epoch[16](2500/2500): Loss: 0.2785
===> Epoch 16 Complete: Avg. Loss: 0.2974
===> Timestamp: [2025-08-03 20:44:18]
===> Loading train datasets
===> Epoch[16](100/2500): Loss: 0.3203
===> Epoch[16](200/2500): Loss: 0.3087
===> Epoch[16](300/2500): Loss: 0.2921
===> Epoch[16](400/2500): Loss: 0.3078
===> Epoch[16](500/2500): Loss: 0.2769
===> Epoch[16](600/2500): Loss: 0.2865
===> Epoch[16](700/2500): Loss: 0.3282
===> Epoch[16](800/2500): Loss: 0.2986
===> Epoch[16](900/2500): Loss: 0.3100
===> Epoch[16](1000/2500): Loss: 0.2738
===> Epoch[16](1100/2500): Loss: 0.2954
===> Epoch[16](1200/2500): Loss: 0.2786
===> Epoch[16](1300/2500): Loss: 0.2945
===> Epoch[16](1400/2500): Loss: 0.3118
===> Epoch[16](1500/2500): Loss: 0.2975
===> Epoch[16](1600/2500): Loss: 0.2819
===> Epoch[16](1700/2500): Loss: 0.3198
===> Epoch[16](1800/2500): Loss: 0.2816
===> Epoch[16](1900/2500): Loss: 0.2975
===> Epoch[16](2000/2500): Loss: 0.2969
===> Epoch[16](2100/2500): Loss: 0.2975
===> Epoch[16](2200/2500): Loss: 0.2853
===> Epoch[16](2300/2500): Loss: 0.2891
===> Epoch[16](2400/2500): Loss: 0.2987
===> Epoch[16](2500/2500): Loss: 0.2785
===> Epoch 16 Complete: Avg. Loss: 0.2974
===> Timestamp: [2025-08-03 20:44:18]
===> Loading train datasets
===> Epoch[16](100/2500): Loss: 0.3203
===> Epoch[16](200/2500): Loss: 0.3087
===> Epoch[16](300/2500): Loss: 0.2921
===> Epoch[16](400/2500): Loss: 0.3078
===> Epoch[16](500/2500): Loss: 0.2769
===> Epoch[16](600/2500): Loss: 0.2865
===> Epoch[16](700/2500): Loss: 0.3282
===> Epoch[16](800/2500): Loss: 0.2986
===> Epoch[16](900/2500): Loss: 0.3100
===> Epoch[16](1000/2500): Loss: 0.2738
===> Epoch[16](1100/2500): Loss: 0.2954
===> Epoch[16](1200/2500): Loss: 0.2786
===> Epoch[16](1300/2500): Loss: 0.2945
===> Epoch[16](1400/2500): Loss: 0.3118
===> Epoch[16](1500/2500): Loss: 0.2975
===> Epoch[16](1600/2500): Loss: 0.2819
===> Epoch[16](1700/2500): Loss: 0.3198
===> Epoch[16](1800/2500): Loss: 0.2816
===> Epoch[16](1900/2500): Loss: 0.2975
===> Epoch[16](2000/2500): Loss: 0.2969
===> Epoch[16](2100/2500): Loss: 0.2975
===> Epoch[16](2200/2500): Loss: 0.2853
===> Epoch[16](2300/2500): Loss: 0.2891
===> Epoch[16](2400/2500): Loss: 0.2987
===> Epoch[16](2500/2500): Loss: 0.2785
===> Epoch 16 Complete: Avg. Loss: 0.2974
===> Timestamp: [2025-08-03 20:44:18]
===> Loading train datasets
===> Epoch[16](100/2500): Loss: 0.3203
===> Epoch[16](200/2500): Loss: 0.3087
===> Epoch[16](300/2500): Loss: 0.2921
===> Epoch[16](400/2500): Loss: 0.3078
===> Epoch[16](500/2500): Loss: 0.2769
===> Epoch[16](600/2500): Loss: 0.2865
===> Epoch[16](700/2500): Loss: 0.3282
===> Epoch[16](800/2500): Loss: 0.2986
===> Epoch[16](900/2500): Loss: 0.3100
===> Epoch[16](1000/2500): Loss: 0.2738
===> Epoch[16](1100/2500): Loss: 0.2954
===> Epoch[16](1200/2500): Loss: 0.2786
===> Epoch[16](1300/2500): Loss: 0.2945
===> Epoch[16](1400/2500): Loss: 0.3118
===> Epoch[16](1500/2500): Loss: 0.2975
===> Epoch[16](1600/2500): Loss: 0.2819
===> Epoch[16](1700/2500): Loss: 0.3198
===> Epoch[16](1800/2500): Loss: 0.2816
===> Epoch[16](1900/2500): Loss: 0.2975
===> Epoch[16](2000/2500): Loss: 0.2969
===> Epoch[16](2100/2500): Loss: 0.2975
===> Epoch[16](2200/2500): Loss: 0.2853
===> Epoch[16](2300/2500): Loss: 0.2891
===> Epoch[16](2400/2500): Loss: 0.2987
===> Epoch[16](2500/2500): Loss: 0.2785
===> Epoch 16 Complete: Avg. Loss: 0.2974
===> Timestamp: [2025-08-03 20:44:18]
===> Loading train datasets
===> Epoch[16](100/2500): Loss: 0.3203
===> Epoch[16](200/2500): Loss: 0.3087
===> Epoch[16](300/2500): Loss: 0.2921
===> Epoch[16](400/2500): Loss: 0.3078
===> Epoch[16](500/2500): Loss: 0.2769
===> Epoch[16](600/2500): Loss: 0.2865
===> Epoch[16](700/2500): Loss: 0.3282
===> Epoch[16](800/2500): Loss: 0.2986
===> Epoch[16](900/2500): Loss: 0.3100
===> Epoch[16](1000/2500): Loss: 0.2738
===> Epoch[16](1100/2500): Loss: 0.2954
===> Epoch[16](1200/2500): Loss: 0.2786
===> Epoch[16](1300/2500): Loss: 0.2945
===> Epoch[16](1400/2500): Loss: 0.3118
===> Epoch[16](1500/2500): Loss: 0.2975
===> Epoch[16](1600/2500): Loss: 0.2819
===> Epoch[16](1700/2500): Loss: 0.3198
===> Epoch[16](1800/2500): Loss: 0.2816
===> Epoch[16](1900/2500): Loss: 0.2975
===> Epoch[16](2000/2500): Loss: 0.2969
===> Epoch[16](2100/2500): Loss: 0.2975
===> Epoch[16](2200/2500): Loss: 0.2853
===> Epoch[16](2300/2500): Loss: 0.2891
===> Epoch[16](2400/2500): Loss: 0.2987
===> Epoch[16](2500/2500): Loss: 0.2785
===> Epoch 16 Complete: Avg. Loss: 0.2974
===> Timestamp: [2025-08-03 20:44:18]
===> Loading train datasets
===> Epoch[16](100/2500): Loss: 0.3203
===> Epoch[16](200/2500): Loss: 0.3087
===> Epoch[16](300/2500): Loss: 0.2921
===> Epoch[16](400/2500): Loss: 0.3078
===> Epoch[16](500/2500): Loss: 0.2769
===> Epoch[16](600/2500): Loss: 0.2865
===> Epoch[16](700/2500): Loss: 0.3282
===> Epoch[16](800/2500): Loss: 0.2986
===> Epoch[16](900/2500): Loss: 0.3100
===> Epoch[16](1000/2500): Loss: 0.2738
===> Epoch[16](1100/2500): Loss: 0.2954
===> Epoch[16](1200/2500): Loss: 0.2786
===> Epoch[16](1300/2500): Loss: 0.2945
===> Epoch[16](1400/2500): Loss: 0.3118
===> Epoch[16](1500/2500): Loss: 0.2975
===> Epoch[16](1600/2500): Loss: 0.2819
===> Epoch[16](1700/2500): Loss: 0.3198
===> Epoch[16](1800/2500): Loss: 0.2816
===> Epoch[16](1900/2500): Loss: 0.2975
===> Epoch[16](2000/2500): Loss: 0.2969
===> Epoch[16](2100/2500): Loss: 0.2975
===> Epoch[16](2200/2500): Loss: 0.2853
===> Epoch[16](2300/2500): Loss: 0.2891
===> Epoch[16](2400/2500): Loss: 0.2987
===> Epoch[16](2500/2500): Loss: 0.2785
===> Epoch 16 Complete: Avg. Loss: 0.2974
===> Timestamp: [2025-08-03 20:44:18]
===> Loading train datasets
===> Epoch[16](100/2500): Loss: 0.3203
===> Epoch[16](200/2500): Loss: 0.3087
===> Epoch[16](300/2500): Loss: 0.2921
===> Epoch[16](400/2500): Loss: 0.3078
===> Epoch[16](500/2500): Loss: 0.2769
===> Epoch[16](600/2500): Loss: 0.2865
===> Epoch[16](700/2500): Loss: 0.3282
===> Epoch[16](800/2500): Loss: 0.2986
===> Epoch[16](900/2500): Loss: 0.3100
===> Epoch[16](1000/2500): Loss: 0.2738
===> Epoch[16](1100/2500): Loss: 0.2954
===> Epoch[16](1200/2500): Loss: 0.2786
===> Epoch[16](1300/2500): Loss: 0.2945
===> Epoch[16](1400/2500): Loss: 0.3118
===> Epoch[16](1500/2500): Loss: 0.2975
===> Epoch[16](1600/2500): Loss: 0.2819
===> Epoch[16](1700/2500): Loss: 0.3198
===> Epoch[16](1800/2500): Loss: 0.2816
===> Epoch[16](1900/2500): Loss: 0.2975
===> Epoch[16](2000/2500): Loss: 0.2969
===> Epoch[16](2100/2500): Loss: 0.2975
===> Epoch[16](2200/2500): Loss: 0.2853
===> Epoch[16](2300/2500): Loss: 0.2891
===> Epoch[16](2400/2500): Loss: 0.2987
===> Epoch[16](2500/2500): Loss: 0.2785
===> Epoch 16 Complete: Avg. Loss: 0.2974
===> Timestamp: [2025-08-03 20:44:18]
===> Loading train datasets
===> Epoch[16](100/2500): Loss: 0.3203
===> Epoch[16](200/2500): Loss: 0.3087
===> Epoch[16](300/2500): Loss: 0.2921
===> Epoch[16](400/2500): Loss: 0.3078
===> Epoch[16](500/2500): Loss: 0.2769
===> Epoch[16](600/2500): Loss: 0.2865
===> Epoch[16](700/2500): Loss: 0.3282
===> Epoch[16](800/2500): Loss: 0.2986
===> Epoch[16](900/2500): Loss: 0.3100
===> Epoch[16](1000/2500): Loss: 0.2738
===> Epoch[16](1100/2500): Loss: 0.2954
===> Epoch[16](1200/2500): Loss: 0.2786
===> Epoch[16](1300/2500): Loss: 0.2945
===> Epoch[16](1400/2500): Loss: 0.3118
===> Epoch[16](1500/2500): Loss: 0.2975
===> Epoch[16](1600/2500): Loss: 0.2819
===> Epoch[16](1700/2500): Loss: 0.3198
===> Epoch[16](1800/2500): Loss: 0.2816
===> Epoch[16](1900/2500): Loss: 0.2975
===> Epoch[16](2000/2500): Loss: 0.2969
===> Epoch[16](2100/2500): Loss: 0.2975
===> Epoch[16](2200/2500): Loss: 0.2853
===> Epoch[16](2300/2500): Loss: 0.2891
===> Epoch[16](2400/2500): Loss: 0.2987
===> Epoch[16](2500/2500): Loss: 0.2785
===> Epoch 16 Complete: Avg. Loss: 0.2974
===> Timestamp: [2025-08-03 20:44:18]
===> Loading train datasets
===> Epoch[16](100/2500): Loss: 0.3203
===> Epoch[16](200/2500): Loss: 0.3087
===> Epoch[16](300/2500): Loss: 0.2921
===> Epoch[16](400/2500): Loss: 0.3078
===> Epoch[16](500/2500): Loss: 0.2769
===> Epoch[16](600/2500): Loss: 0.2865
===> Epoch[16](700/2500): Loss: 0.3282
===> Epoch[16](800/2500): Loss: 0.2986
===> Epoch[16](900/2500): Loss: 0.3100
===> Epoch[16](1000/2500): Loss: 0.2738
===> Epoch[16](1100/2500): Loss: 0.2954
===> Epoch[16](1200/2500): Loss: 0.2786
===> Epoch[16](1300/2500): Loss: 0.2945
===> Epoch[16](1400/2500): Loss: 0.3118
===> Epoch[16](1500/2500): Loss: 0.2975
===> Epoch[16](1600/2500): Loss: 0.2819
===> Epoch[16](1700/2500): Loss: 0.3198
===> Epoch[16](1800/2500): Loss: 0.2816
===> Epoch[16](1900/2500): Loss: 0.2975
===> Epoch[16](2000/2500): Loss: 0.2969
===> Epoch[16](2100/2500): Loss: 0.2975
===> Epoch[16](2200/2500): Loss: 0.2853
===> Epoch[16](2300/2500): Loss: 0.2891
===> Epoch[16](2400/2500): Loss: 0.2987
===> Epoch[16](2500/2500): Loss: 0.2785
===> Epoch 16 Complete: Avg. Loss: 0.2974
===> Timestamp: [2025-08-03 20:44:18]
===> Loading train datasets
===> Epoch[16](100/2500): Loss: 0.3203
===> Epoch[16](200/2500): Loss: 0.3087
===> Epoch[16](300/2500): Loss: 0.2921
===> Epoch[16](400/2500): Loss: 0.3078
===> Epoch[16](500/2500): Loss: 0.2769
===> Epoch[16](600/2500): Loss: 0.2865
===> Epoch[16](700/2500): Loss: 0.3282
===> Epoch[16](800/2500): Loss: 0.2986
===> Epoch[16](900/2500): Loss: 0.3100
===> Epoch[16](1000/2500): Loss: 0.2738
===> Epoch[16](1100/2500): Loss: 0.2954
===> Epoch[16](1200/2500): Loss: 0.2786
===> Epoch[16](1300/2500): Loss: 0.2945
===> Epoch[16](1400/2500): Loss: 0.3118
===> Epoch[16](1500/2500): Loss: 0.2975
===> Epoch[16](1600/2500): Loss: 0.2819
===> Epoch[16](1700/2500): Loss: 0.3198
===> Epoch[16](1800/2500): Loss: 0.2816
===> Epoch[16](1900/2500): Loss: 0.2975
===> Epoch[16](2000/2500): Loss: 0.2969
===> Epoch[16](2100/2500): Loss: 0.2975
===> Epoch[16](2200/2500): Loss: 0.2853
===> Epoch[16](2300/2500): Loss: 0.2891
===> Epoch[16](2400/2500): Loss: 0.2987
===> Epoch[16](2500/2500): Loss: 0.2785
===> Epoch 16 Complete: Avg. Loss: 0.2974
===> Timestamp: [2025-08-03 20:44:18]
===> Loading train datasets
===> Epoch[16](100/2500): Loss: 0.3203
===> Epoch[16](200/2500): Loss: 0.3087
===> Epoch[16](300/2500): Loss: 0.2921
===> Epoch[16](400/2500): Loss: 0.3078
===> Epoch[16](500/2500): Loss: 0.2769
===> Epoch[16](600/2500): Loss: 0.2865
===> Epoch[16](700/2500): Loss: 0.3282
===> Epoch[16](800/2500): Loss: 0.2986
===> Epoch[16](900/2500): Loss: 0.3100
===> Epoch[16](1000/2500): Loss: 0.2738
===> Epoch[16](1100/2500): Loss: 0.2954
===> Epoch[16](1200/2500): Loss: 0.2786
===> Epoch[16](1300/2500): Loss: 0.2945
===> Epoch[16](1400/2500): Loss: 0.3118
===> Epoch[16](1500/2500): Loss: 0.2975
===> Epoch[16](1600/2500): Loss: 0.2819
===> Epoch[16](1700/2500): Loss: 0.3198
===> Epoch[16](1800/2500): Loss: 0.2816
===> Epoch[16](1900/2500): Loss: 0.2975
===> Epoch[16](2000/2500): Loss: 0.2969
===> Epoch[16](2100/2500): Loss: 0.2975
===> Epoch[16](2200/2500): Loss: 0.2853
===> Epoch[16](2300/2500): Loss: 0.2891
===> Epoch[16](2400/2500): Loss: 0.2987
===> Epoch[16](2500/2500): Loss: 0.2785
===> Epoch 16 Complete: Avg. Loss: 0.2974
===> Timestamp: [2025-08-03 20:44:18]
===> Loading train datasets
===> Epoch[16](100/2500): Loss: 0.3203
===> Epoch[16](200/2500): Loss: 0.3087
===> Epoch[16](300/2500): Loss: 0.2921
===> Epoch[16](400/2500): Loss: 0.3078
===> Epoch[16](500/2500): Loss: 0.2769
===> Epoch[16](600/2500): Loss: 0.2865
===> Epoch[16](700/2500): Loss: 0.3282
===> Epoch[16](800/2500): Loss: 0.2986
===> Epoch[16](900/2500): Loss: 0.3100
===> Epoch[16](1000/2500): Loss: 0.2738
===> Epoch[16](1100/2500): Loss: 0.2954
===> Epoch[16](1200/2500): Loss: 0.2786
===> Epoch[16](1300/2500): Loss: 0.2945
===> Epoch[16](1400/2500): Loss: 0.3118
===> Epoch[16](1500/2500): Loss: 0.2975
===> Epoch[16](1600/2500): Loss: 0.2819
===> Epoch[16](1700/2500): Loss: 0.3198
===> Epoch[16](1800/2500): Loss: 0.2816
===> Epoch[16](1900/2500): Loss: 0.2975
===> Epoch[16](2000/2500): Loss: 0.2969
===> Epoch[16](2100/2500): Loss: 0.2975
===> Epoch[16](2200/2500): Loss: 0.2853
===> Epoch[16](2300/2500): Loss: 0.2891
===> Epoch[16](2400/2500): Loss: 0.2987
===> Epoch[16](2500/2500): Loss: 0.2785
===> Epoch 16 Complete: Avg. Loss: 0.2974
===> Timestamp: [2025-08-03 20:44:18]
===> Loading train datasets
===> Epoch[16](100/2500): Loss: 0.3203
===> Epoch[16](200/2500): Loss: 0.3087
===> Epoch[16](300/2500): Loss: 0.2921
===> Epoch[16](400/2500): Loss: 0.3078
===> Epoch[16](500/2500): Loss: 0.2769
===> Epoch[16](600/2500): Loss: 0.2865
===> Epoch[16](700/2500): Loss: 0.3282
===> Epoch[16](800/2500): Loss: 0.2986
===> Epoch[16](900/2500): Loss: 0.3100
===> Epoch[16](1000/2500): Loss: 0.2738
===> Epoch[16](1100/2500): Loss: 0.2954
===> Epoch[16](1200/2500): Loss: 0.2786
===> Epoch[16](1300/2500): Loss: 0.2945
===> Epoch[16](1400/2500): Loss: 0.3118
===> Epoch[16](1500/2500): Loss: 0.2975
===> Epoch[16](1600/2500): Loss: 0.2819
===> Epoch[16](1700/2500): Loss: 0.3198
===> Epoch[16](1800/2500): Loss: 0.2816
===> Epoch[16](1900/2500): Loss: 0.2975
===> Epoch[16](2000/2500): Loss: 0.2969
===> Epoch[16](2100/2500): Loss: 0.2975
===> Epoch[16](2200/2500): Loss: 0.2853
===> Epoch[16](2300/2500): Loss: 0.2891
===> Epoch[16](2400/2500): Loss: 0.2987
===> Epoch[16](2500/2500): Loss: 0.2785
===> Epoch 16 Complete: Avg. Loss: 0.2974
===> Timestamp: [2025-08-03 20:44:18]
===> Loading train datasets
===> Epoch[16](100/2500): Loss: 0.3203
===> Epoch[16](200/2500): Loss: 0.3087
===> Epoch[16](300/2500): Loss: 0.2921
===> Epoch[16](400/2500): Loss: 0.3078
===> Epoch[16](500/2500): Loss: 0.2769
===> Epoch[16](600/2500): Loss: 0.2865
===> Epoch[16](700/2500): Loss: 0.3282
===> Epoch[16](800/2500): Loss: 0.2986
===> Epoch[16](900/2500): Loss: 0.3100
===> Epoch[16](1000/2500): Loss: 0.2738
===> Epoch[16](1100/2500): Loss: 0.2954
===> Epoch[16](1200/2500): Loss: 0.2786
===> Epoch[16](1300/2500): Loss: 0.2945
===> Epoch[16](1400/2500): Loss: 0.3118
===> Epoch[16](1500/2500): Loss: 0.2975
===> Epoch[16](1600/2500): Loss: 0.2819
===> Epoch[16](1700/2500): Loss: 0.3198
===> Epoch[16](1800/2500): Loss: 0.2816
===> Epoch[16](1900/2500): Loss: 0.2975
===> Epoch[16](2000/2500): Loss: 0.2969
===> Epoch[16](2100/2500): Loss: 0.2975
===> Epoch[16](2200/2500): Loss: 0.2853
===> Epoch[16](2300/2500): Loss: 0.2891
===> Epoch[16](2400/2500): Loss: 0.2987
===> Epoch[16](2500/2500): Loss: 0.2785
===> Epoch 16 Complete: Avg. Loss: 0.2974
===> Timestamp: [2025-08-03 20:44:18]
===> Loading train datasets
===> Epoch[16](100/2500): Loss: 0.3203
===> Epoch[16](200/2500): Loss: 0.3087
===> Epoch[16](300/2500): Loss: 0.2921
===> Epoch[16](400/2500): Loss: 0.3078
===> Epoch[16](500/2500): Loss: 0.2769
===> Epoch[16](600/2500): Loss: 0.2865
===> Epoch[16](700/2500): Loss: 0.3282
===> Epoch[16](800/2500): Loss: 0.2986
===> Epoch[16](900/2500): Loss: 0.3100
===> Epoch[16](1000/2500): Loss: 0.2738
===> Epoch[16](1100/2500): Loss: 0.2954
===> Epoch[16](1200/2500): Loss: 0.2786
===> Epoch[16](1300/2500): Loss: 0.2945
===> Epoch[16](1400/2500): Loss: 0.3118
===> Epoch[16](1500/2500): Loss: 0.2975
===> Epoch[16](1600/2500): Loss: 0.2819
===> Epoch[16](1700/2500): Loss: 0.3198
===> Epoch[16](1800/2500): Loss: 0.2816
===> Epoch[16](1900/2500): Loss: 0.2975
===> Epoch[16](2000/2500): Loss: 0.2969
===> Epoch[16](2100/2500): Loss: 0.2975
===> Epoch[16](2200/2500): Loss: 0.2853
===> Epoch[16](2300/2500): Loss: 0.2891
===> Epoch[16](2400/2500): Loss: 0.2987
===> Epoch[16](2500/2500): Loss: 0.2785
===> Epoch 16 Complete: Avg. Loss: 0.2974
===> Timestamp: [2025-08-03 20:44:18]
===> Loading train datasets
===> Epoch[16](100/2500): Loss: 0.3203
===> Epoch[16](200/2500): Loss: 0.3087
===> Epoch[16](300/2500): Loss: 0.2921
===> Epoch[16](400/2500): Loss: 0.3078
===> Epoch[16](500/2500): Loss: 0.2769
===> Epoch[16](600/2500): Loss: 0.2865
===> Epoch[16](700/2500): Loss: 0.3282
===> Epoch[16](800/2500): Loss: 0.2986
===> Epoch[16](900/2500): Loss: 0.3100
===> Epoch[16](1000/2500): Loss: 0.2738
===> Epoch[16](1100/2500): Loss: 0.2954
===> Epoch[16](1200/2500): Loss: 0.2786
===> Epoch[16](1300/2500): Loss: 0.2945
===> Epoch[16](1400/2500): Loss: 0.3118
===> Epoch[16](1500/2500): Loss: 0.2975
===> Epoch[16](1600/2500): Loss: 0.2819
===> Epoch[16](1700/2500): Loss: 0.3198
===> Epoch[16](1800/2500): Loss: 0.2816
===> Epoch[16](1900/2500): Loss: 0.2975
===> Epoch[16](2000/2500): Loss: 0.2969
===> Epoch[16](2100/2500): Loss: 0.2975
===> Epoch[16](2200/2500): Loss: 0.2853
===> Epoch[16](2300/2500): Loss: 0.2891
===> Epoch[16](2400/2500): Loss: 0.2987
===> Epoch[16](2500/2500): Loss: 0.2785
===> Epoch 16 Complete: Avg. Loss: 0.2974
===> Timestamp: [2025-08-03 20:44:18]
===> Loading train datasets
===> Loading train datasets
===> Epoch[17](100/2500): Loss: 0.3261
===> Epoch[17](200/2500): Loss: 0.2937
===> Epoch[17](300/2500): Loss: 0.2963
===> Epoch[17](400/2500): Loss: 0.3013
===> Epoch[17](500/2500): Loss: 0.3339
===> Epoch[17](600/2500): Loss: 0.2943
===> Epoch[17](700/2500): Loss: 0.3138
===> Epoch[17](800/2500): Loss: 0.2897
===> Epoch[17](900/2500): Loss: 0.2811
===> Epoch[17](1000/2500): Loss: 0.3163
===> Epoch[17](1100/2500): Loss: 0.3040
===> Epoch[17](1200/2500): Loss: 0.2927
===> Epoch[17](1300/2500): Loss: 0.2977
===> Epoch[17](1400/2500): Loss: 0.2961
===> Epoch[17](1500/2500): Loss: 0.2803
===> Epoch[17](1600/2500): Loss: 0.2920
===> Epoch[17](1700/2500): Loss: 0.2878
===> Epoch[17](1800/2500): Loss: 0.2834
===> Epoch[17](1900/2500): Loss: 0.3117
===> Epoch[17](2000/2500): Loss: 0.3081
===> Epoch[17](2100/2500): Loss: 0.3115
===> Epoch[17](2200/2500): Loss: 0.2672
===> Epoch[17](2300/2500): Loss: 0.2801
===> Epoch[17](2400/2500): Loss: 0.2997
===> Epoch[17](2500/2500): Loss: 0.2798
===> Epoch 17 Complete: Avg. Loss: 0.2952
===> Timestamp: [2025-08-03 20:48:52]
===> Loading train datasets
===> Epoch[17](100/2500): Loss: 0.3261
===> Epoch[17](200/2500): Loss: 0.2937
===> Epoch[17](300/2500): Loss: 0.2963
===> Epoch[17](400/2500): Loss: 0.3013
===> Epoch[17](500/2500): Loss: 0.3339
===> Epoch[17](600/2500): Loss: 0.2943
===> Epoch[17](700/2500): Loss: 0.3138
===> Epoch[17](800/2500): Loss: 0.2897
===> Epoch[17](900/2500): Loss: 0.2811
===> Epoch[17](1000/2500): Loss: 0.3163
===> Epoch[17](1100/2500): Loss: 0.3040
===> Epoch[17](1200/2500): Loss: 0.2927
===> Epoch[17](1300/2500): Loss: 0.2977
===> Epoch[17](1400/2500): Loss: 0.2961
===> Epoch[17](1500/2500): Loss: 0.2803
===> Epoch[17](1600/2500): Loss: 0.2920
===> Epoch[17](1700/2500): Loss: 0.2878
===> Epoch[17](1800/2500): Loss: 0.2834
===> Epoch[17](1900/2500): Loss: 0.3117
===> Epoch[17](2000/2500): Loss: 0.3081
===> Epoch[17](2100/2500): Loss: 0.3115
===> Epoch[17](2200/2500): Loss: 0.2672
===> Epoch[17](2300/2500): Loss: 0.2801
===> Epoch[17](2400/2500): Loss: 0.2997
===> Epoch[17](2500/2500): Loss: 0.2798
===> Epoch 17 Complete: Avg. Loss: 0.2952
===> Timestamp: [2025-08-03 20:48:52]
===> Loading train datasets
===> Epoch[17](100/2500): Loss: 0.3261
===> Epoch[17](200/2500): Loss: 0.2937
===> Epoch[17](300/2500): Loss: 0.2963
===> Epoch[17](400/2500): Loss: 0.3013
===> Epoch[17](500/2500): Loss: 0.3339
===> Epoch[17](600/2500): Loss: 0.2943
===> Epoch[17](700/2500): Loss: 0.3138
===> Epoch[17](800/2500): Loss: 0.2897
===> Epoch[17](900/2500): Loss: 0.2811
===> Epoch[17](1000/2500): Loss: 0.3163
===> Epoch[17](1100/2500): Loss: 0.3040
===> Epoch[17](1200/2500): Loss: 0.2927
===> Epoch[17](1300/2500): Loss: 0.2977
===> Epoch[17](1400/2500): Loss: 0.2961
===> Epoch[17](1500/2500): Loss: 0.2803
===> Epoch[17](1600/2500): Loss: 0.2920
===> Epoch[17](1700/2500): Loss: 0.2878
===> Epoch[17](1800/2500): Loss: 0.2834
===> Epoch[17](1900/2500): Loss: 0.3117
===> Epoch[17](2000/2500): Loss: 0.3081
===> Epoch[17](2100/2500): Loss: 0.3115
===> Epoch[17](2200/2500): Loss: 0.2672
===> Epoch[17](2300/2500): Loss: 0.2801
===> Epoch[17](2400/2500): Loss: 0.2997
===> Epoch[17](2500/2500): Loss: 0.2798
===> Epoch 17 Complete: Avg. Loss: 0.2952
===> Timestamp: [2025-08-03 20:48:52]
===> Loading train datasets
===> Epoch[17](100/2500): Loss: 0.3261
===> Epoch[17](200/2500): Loss: 0.2937
===> Epoch[17](300/2500): Loss: 0.2963
===> Epoch[17](400/2500): Loss: 0.3013
===> Epoch[17](500/2500): Loss: 0.3339
===> Epoch[17](600/2500): Loss: 0.2943
===> Epoch[17](700/2500): Loss: 0.3138
===> Epoch[17](800/2500): Loss: 0.2897
===> Epoch[17](900/2500): Loss: 0.2811
===> Epoch[17](1000/2500): Loss: 0.3163
===> Epoch[17](1100/2500): Loss: 0.3040
===> Epoch[17](1200/2500): Loss: 0.2927
===> Epoch[17](1300/2500): Loss: 0.2977
===> Epoch[17](1400/2500): Loss: 0.2961
===> Epoch[17](1500/2500): Loss: 0.2803
===> Epoch[17](1600/2500): Loss: 0.2920
===> Epoch[17](1700/2500): Loss: 0.2878
===> Epoch[17](1800/2500): Loss: 0.2834
===> Epoch[17](1900/2500): Loss: 0.3117
===> Epoch[17](2000/2500): Loss: 0.3081
===> Epoch[17](2100/2500): Loss: 0.3115
===> Epoch[17](2200/2500): Loss: 0.2672
===> Epoch[17](2300/2500): Loss: 0.2801
===> Epoch[17](2400/2500): Loss: 0.2997
===> Epoch[17](2500/2500): Loss: 0.2798
===> Epoch 17 Complete: Avg. Loss: 0.2952
===> Timestamp: [2025-08-03 20:48:52]
===> Loading train datasets
===> Epoch[17](100/2500): Loss: 0.3261
===> Epoch[17](200/2500): Loss: 0.2937
===> Epoch[17](300/2500): Loss: 0.2963
===> Epoch[17](400/2500): Loss: 0.3013
===> Epoch[17](500/2500): Loss: 0.3339
===> Epoch[17](600/2500): Loss: 0.2943
===> Epoch[17](700/2500): Loss: 0.3138
===> Epoch[17](800/2500): Loss: 0.2897
===> Epoch[17](900/2500): Loss: 0.2811
===> Epoch[17](1000/2500): Loss: 0.3163
===> Epoch[17](1100/2500): Loss: 0.3040
===> Epoch[17](1200/2500): Loss: 0.2927
===> Epoch[17](1300/2500): Loss: 0.2977
===> Epoch[17](1400/2500): Loss: 0.2961
===> Epoch[17](1500/2500): Loss: 0.2803
===> Epoch[17](1600/2500): Loss: 0.2920
===> Epoch[17](1700/2500): Loss: 0.2878
===> Epoch[17](1800/2500): Loss: 0.2834
===> Epoch[17](1900/2500): Loss: 0.3117
===> Epoch[17](2000/2500): Loss: 0.3081
===> Epoch[17](2100/2500): Loss: 0.3115
===> Epoch[17](2200/2500): Loss: 0.2672
===> Epoch[17](2300/2500): Loss: 0.2801
===> Epoch[17](2400/2500): Loss: 0.2997
===> Epoch[17](2500/2500): Loss: 0.2798
===> Epoch 17 Complete: Avg. Loss: 0.2952
===> Timestamp: [2025-08-03 20:48:52]
===> Loading train datasets
===> Epoch[17](100/2500): Loss: 0.3261
===> Epoch[17](200/2500): Loss: 0.2937
===> Epoch[17](300/2500): Loss: 0.2963
===> Epoch[17](400/2500): Loss: 0.3013
===> Epoch[17](500/2500): Loss: 0.3339
===> Epoch[17](600/2500): Loss: 0.2943
===> Epoch[17](700/2500): Loss: 0.3138
===> Epoch[17](800/2500): Loss: 0.2897
===> Epoch[17](900/2500): Loss: 0.2811
===> Epoch[17](1000/2500): Loss: 0.3163
===> Epoch[17](1100/2500): Loss: 0.3040
===> Epoch[17](1200/2500): Loss: 0.2927
===> Epoch[17](1300/2500): Loss: 0.2977
===> Epoch[17](1400/2500): Loss: 0.2961
===> Epoch[17](1500/2500): Loss: 0.2803
===> Epoch[17](1600/2500): Loss: 0.2920
===> Epoch[17](1700/2500): Loss: 0.2878
===> Epoch[17](1800/2500): Loss: 0.2834
===> Epoch[17](1900/2500): Loss: 0.3117
===> Epoch[17](2000/2500): Loss: 0.3081
===> Epoch[17](2100/2500): Loss: 0.3115
===> Epoch[17](2200/2500): Loss: 0.2672
===> Epoch[17](2300/2500): Loss: 0.2801
===> Epoch[17](2400/2500): Loss: 0.2997
===> Epoch[17](2500/2500): Loss: 0.2798
===> Epoch 17 Complete: Avg. Loss: 0.2952
===> Timestamp: [2025-08-03 20:48:52]
===> Loading train datasets
===> Epoch[17](100/2500): Loss: 0.3261
===> Epoch[17](200/2500): Loss: 0.2937
===> Epoch[17](300/2500): Loss: 0.2963
===> Epoch[17](400/2500): Loss: 0.3013
===> Epoch[17](500/2500): Loss: 0.3339
===> Epoch[17](600/2500): Loss: 0.2943
===> Epoch[17](700/2500): Loss: 0.3138
===> Epoch[17](800/2500): Loss: 0.2897
===> Epoch[17](900/2500): Loss: 0.2811
===> Epoch[17](1000/2500): Loss: 0.3163
===> Epoch[17](1100/2500): Loss: 0.3040
===> Epoch[17](1200/2500): Loss: 0.2927
===> Epoch[17](1300/2500): Loss: 0.2977
===> Epoch[17](1400/2500): Loss: 0.2961
===> Epoch[17](1500/2500): Loss: 0.2803
===> Epoch[17](1600/2500): Loss: 0.2920
===> Epoch[17](1700/2500): Loss: 0.2878
===> Epoch[17](1800/2500): Loss: 0.2834
===> Epoch[17](1900/2500): Loss: 0.3117
===> Epoch[17](2000/2500): Loss: 0.3081
===> Epoch[17](2100/2500): Loss: 0.3115
===> Epoch[17](2200/2500): Loss: 0.2672
===> Epoch[17](2300/2500): Loss: 0.2801
===> Epoch[17](2400/2500): Loss: 0.2997
===> Epoch[17](2500/2500): Loss: 0.2798
===> Epoch 17 Complete: Avg. Loss: 0.2952
===> Timestamp: [2025-08-03 20:48:52]
===> Loading train datasets
===> Epoch[17](100/2500): Loss: 0.3261
===> Epoch[17](200/2500): Loss: 0.2937
===> Epoch[17](300/2500): Loss: 0.2963
===> Epoch[17](400/2500): Loss: 0.3013
===> Epoch[17](500/2500): Loss: 0.3339
===> Epoch[17](600/2500): Loss: 0.2943
===> Epoch[17](700/2500): Loss: 0.3138
===> Epoch[17](800/2500): Loss: 0.2897
===> Epoch[17](900/2500): Loss: 0.2811
===> Epoch[17](1000/2500): Loss: 0.3163
===> Epoch[17](1100/2500): Loss: 0.3040
===> Epoch[17](1200/2500): Loss: 0.2927
===> Epoch[17](1300/2500): Loss: 0.2977
===> Epoch[17](1400/2500): Loss: 0.2961
===> Epoch[17](1500/2500): Loss: 0.2803
===> Epoch[17](1600/2500): Loss: 0.2920
===> Epoch[17](1700/2500): Loss: 0.2878
===> Epoch[17](1800/2500): Loss: 0.2834
===> Epoch[17](1900/2500): Loss: 0.3117
===> Epoch[17](2000/2500): Loss: 0.3081
===> Epoch[17](2100/2500): Loss: 0.3115
===> Epoch[17](2200/2500): Loss: 0.2672
===> Epoch[17](2300/2500): Loss: 0.2801
===> Epoch[17](2400/2500): Loss: 0.2997
===> Epoch[17](2500/2500): Loss: 0.2798
===> Epoch 17 Complete: Avg. Loss: 0.2952
===> Timestamp: [2025-08-03 20:48:52]
===> Loading train datasets
===> Epoch[17](100/2500): Loss: 0.3261
===> Epoch[17](200/2500): Loss: 0.2937
===> Epoch[17](300/2500): Loss: 0.2963
===> Epoch[17](400/2500): Loss: 0.3013
===> Epoch[17](500/2500): Loss: 0.3339
===> Epoch[17](600/2500): Loss: 0.2943
===> Epoch[17](700/2500): Loss: 0.3138
===> Epoch[17](800/2500): Loss: 0.2897
===> Epoch[17](900/2500): Loss: 0.2811
===> Epoch[17](1000/2500): Loss: 0.3163
===> Epoch[17](1100/2500): Loss: 0.3040
===> Epoch[17](1200/2500): Loss: 0.2927
===> Epoch[17](1300/2500): Loss: 0.2977
===> Epoch[17](1400/2500): Loss: 0.2961
===> Epoch[17](1500/2500): Loss: 0.2803
===> Epoch[17](1600/2500): Loss: 0.2920
===> Epoch[17](1700/2500): Loss: 0.2878
===> Epoch[17](1800/2500): Loss: 0.2834
===> Epoch[17](1900/2500): Loss: 0.3117
===> Epoch[17](2000/2500): Loss: 0.3081
===> Epoch[17](2100/2500): Loss: 0.3115
===> Epoch[17](2200/2500): Loss: 0.2672
===> Epoch[17](2300/2500): Loss: 0.2801
===> Epoch[17](2400/2500): Loss: 0.2997
===> Epoch[17](2500/2500): Loss: 0.2798
===> Epoch 17 Complete: Avg. Loss: 0.2952
===> Timestamp: [2025-08-03 20:48:52]
===> Loading train datasets
===> Epoch[17](100/2500): Loss: 0.3261
===> Epoch[17](200/2500): Loss: 0.2937
===> Epoch[17](300/2500): Loss: 0.2963
===> Epoch[17](400/2500): Loss: 0.3013
===> Epoch[17](500/2500): Loss: 0.3339
===> Epoch[17](600/2500): Loss: 0.2943
===> Epoch[17](700/2500): Loss: 0.3138
===> Epoch[17](800/2500): Loss: 0.2897
===> Epoch[17](900/2500): Loss: 0.2811
===> Epoch[17](1000/2500): Loss: 0.3163
===> Epoch[17](1100/2500): Loss: 0.3040
===> Epoch[17](1200/2500): Loss: 0.2927
===> Epoch[17](1300/2500): Loss: 0.2977
===> Epoch[17](1400/2500): Loss: 0.2961
===> Epoch[17](1500/2500): Loss: 0.2803
===> Epoch[17](1600/2500): Loss: 0.2920
===> Epoch[17](1700/2500): Loss: 0.2878
===> Epoch[17](1800/2500): Loss: 0.2834
===> Epoch[17](1900/2500): Loss: 0.3117
===> Epoch[17](2000/2500): Loss: 0.3081
===> Epoch[17](2100/2500): Loss: 0.3115
===> Epoch[17](2200/2500): Loss: 0.2672
===> Epoch[17](2300/2500): Loss: 0.2801
===> Epoch[17](2400/2500): Loss: 0.2997
===> Epoch[17](2500/2500): Loss: 0.2798
===> Epoch 17 Complete: Avg. Loss: 0.2952
===> Timestamp: [2025-08-03 20:48:52]
===> Loading train datasets
===> Epoch[17](100/2500): Loss: 0.3261
===> Epoch[17](200/2500): Loss: 0.2937
===> Epoch[17](300/2500): Loss: 0.2963
===> Epoch[17](400/2500): Loss: 0.3013
===> Epoch[17](500/2500): Loss: 0.3339
===> Epoch[17](600/2500): Loss: 0.2943
===> Epoch[17](700/2500): Loss: 0.3138
===> Epoch[17](800/2500): Loss: 0.2897
===> Epoch[17](900/2500): Loss: 0.2811
===> Epoch[17](1000/2500): Loss: 0.3163
===> Epoch[17](1100/2500): Loss: 0.3040
===> Epoch[17](1200/2500): Loss: 0.2927
===> Epoch[17](1300/2500): Loss: 0.2977
===> Epoch[17](1400/2500): Loss: 0.2961
===> Epoch[17](1500/2500): Loss: 0.2803
===> Epoch[17](1600/2500): Loss: 0.2920
===> Epoch[17](1700/2500): Loss: 0.2878
===> Epoch[17](1800/2500): Loss: 0.2834
===> Epoch[17](1900/2500): Loss: 0.3117
===> Epoch[17](2000/2500): Loss: 0.3081
===> Epoch[17](2100/2500): Loss: 0.3115
===> Epoch[17](2200/2500): Loss: 0.2672
===> Epoch[17](2300/2500): Loss: 0.2801
===> Epoch[17](2400/2500): Loss: 0.2997
===> Epoch[17](2500/2500): Loss: 0.2798
===> Epoch 17 Complete: Avg. Loss: 0.2952
===> Timestamp: [2025-08-03 20:48:52]
===> Loading train datasets
===> Epoch[17](100/2500): Loss: 0.3261
===> Epoch[17](200/2500): Loss: 0.2937
===> Epoch[17](300/2500): Loss: 0.2963
===> Epoch[17](400/2500): Loss: 0.3013
===> Epoch[17](500/2500): Loss: 0.3339
===> Epoch[17](600/2500): Loss: 0.2943
===> Epoch[17](700/2500): Loss: 0.3138
===> Epoch[17](800/2500): Loss: 0.2897
===> Epoch[17](900/2500): Loss: 0.2811
===> Epoch[17](1000/2500): Loss: 0.3163
===> Epoch[17](1100/2500): Loss: 0.3040
===> Epoch[17](1200/2500): Loss: 0.2927
===> Epoch[17](1300/2500): Loss: 0.2977
===> Epoch[17](1400/2500): Loss: 0.2961
===> Epoch[17](1500/2500): Loss: 0.2803
===> Epoch[17](1600/2500): Loss: 0.2920
===> Epoch[17](1700/2500): Loss: 0.2878
===> Epoch[17](1800/2500): Loss: 0.2834
===> Epoch[17](1900/2500): Loss: 0.3117
===> Epoch[17](2000/2500): Loss: 0.3081
===> Epoch[17](2100/2500): Loss: 0.3115
===> Epoch[17](2200/2500): Loss: 0.2672
===> Epoch[17](2300/2500): Loss: 0.2801
===> Epoch[17](2400/2500): Loss: 0.2997
===> Epoch[17](2500/2500): Loss: 0.2798
===> Epoch 17 Complete: Avg. Loss: 0.2952
===> Timestamp: [2025-08-03 20:48:52]
===> Loading train datasets
===> Epoch[17](100/2500): Loss: 0.3261
===> Epoch[17](200/2500): Loss: 0.2937
===> Epoch[17](300/2500): Loss: 0.2963
===> Epoch[17](400/2500): Loss: 0.3013
===> Epoch[17](500/2500): Loss: 0.3339
===> Epoch[17](600/2500): Loss: 0.2943
===> Epoch[17](700/2500): Loss: 0.3138
===> Epoch[17](800/2500): Loss: 0.2897
===> Epoch[17](900/2500): Loss: 0.2811
===> Epoch[17](1000/2500): Loss: 0.3163
===> Epoch[17](1100/2500): Loss: 0.3040
===> Epoch[17](1200/2500): Loss: 0.2927
===> Epoch[17](1300/2500): Loss: 0.2977
===> Epoch[17](1400/2500): Loss: 0.2961
===> Epoch[17](1500/2500): Loss: 0.2803
===> Epoch[17](1600/2500): Loss: 0.2920
===> Epoch[17](1700/2500): Loss: 0.2878
===> Epoch[17](1800/2500): Loss: 0.2834
===> Epoch[17](1900/2500): Loss: 0.3117
===> Epoch[17](2000/2500): Loss: 0.3081
===> Epoch[17](2100/2500): Loss: 0.3115
===> Epoch[17](2200/2500): Loss: 0.2672
===> Epoch[17](2300/2500): Loss: 0.2801
===> Epoch[17](2400/2500): Loss: 0.2997
===> Epoch[17](2500/2500): Loss: 0.2798
===> Epoch 17 Complete: Avg. Loss: 0.2952
===> Timestamp: [2025-08-03 20:48:52]
===> Loading train datasets
===> Epoch[17](100/2500): Loss: 0.3261
===> Epoch[17](200/2500): Loss: 0.2937
===> Epoch[17](300/2500): Loss: 0.2963
===> Epoch[17](400/2500): Loss: 0.3013
===> Epoch[17](500/2500): Loss: 0.3339
===> Epoch[17](600/2500): Loss: 0.2943
===> Epoch[17](700/2500): Loss: 0.3138
===> Epoch[17](800/2500): Loss: 0.2897
===> Epoch[17](900/2500): Loss: 0.2811
===> Epoch[17](1000/2500): Loss: 0.3163
===> Epoch[17](1100/2500): Loss: 0.3040
===> Epoch[17](1200/2500): Loss: 0.2927
===> Epoch[17](1300/2500): Loss: 0.2977
===> Epoch[17](1400/2500): Loss: 0.2961
===> Epoch[17](1500/2500): Loss: 0.2803
===> Epoch[17](1600/2500): Loss: 0.2920
===> Epoch[17](1700/2500): Loss: 0.2878
===> Epoch[17](1800/2500): Loss: 0.2834
===> Epoch[17](1900/2500): Loss: 0.3117
===> Epoch[17](2000/2500): Loss: 0.3081
===> Epoch[17](2100/2500): Loss: 0.3115
===> Epoch[17](2200/2500): Loss: 0.2672
===> Epoch[17](2300/2500): Loss: 0.2801
===> Epoch[17](2400/2500): Loss: 0.2997
===> Epoch[17](2500/2500): Loss: 0.2798
===> Epoch 17 Complete: Avg. Loss: 0.2952
===> Timestamp: [2025-08-03 20:48:52]
===> Loading train datasets
===> Epoch[17](100/2500): Loss: 0.3261
===> Epoch[17](200/2500): Loss: 0.2937
===> Epoch[17](300/2500): Loss: 0.2963
===> Epoch[17](400/2500): Loss: 0.3013
===> Epoch[17](500/2500): Loss: 0.3339
===> Epoch[17](600/2500): Loss: 0.2943
===> Epoch[17](700/2500): Loss: 0.3138
===> Epoch[17](800/2500): Loss: 0.2897
===> Epoch[17](900/2500): Loss: 0.2811
===> Epoch[17](1000/2500): Loss: 0.3163
===> Epoch[17](1100/2500): Loss: 0.3040
===> Epoch[17](1200/2500): Loss: 0.2927
===> Epoch[17](1300/2500): Loss: 0.2977
===> Epoch[17](1400/2500): Loss: 0.2961
===> Epoch[17](1500/2500): Loss: 0.2803
===> Epoch[17](1600/2500): Loss: 0.2920
===> Epoch[17](1700/2500): Loss: 0.2878
===> Epoch[17](1800/2500): Loss: 0.2834
===> Epoch[17](1900/2500): Loss: 0.3117
===> Epoch[17](2000/2500): Loss: 0.3081
===> Epoch[17](2100/2500): Loss: 0.3115
===> Epoch[17](2200/2500): Loss: 0.2672
===> Epoch[17](2300/2500): Loss: 0.2801
===> Epoch[17](2400/2500): Loss: 0.2997
===> Epoch[17](2500/2500): Loss: 0.2798
===> Epoch 17 Complete: Avg. Loss: 0.2952
===> Timestamp: [2025-08-03 20:48:52]
===> Loading train datasets
===> Epoch[17](100/2500): Loss: 0.3261
===> Epoch[17](200/2500): Loss: 0.2937
===> Epoch[17](300/2500): Loss: 0.2963
===> Epoch[17](400/2500): Loss: 0.3013
===> Epoch[17](500/2500): Loss: 0.3339
===> Epoch[17](600/2500): Loss: 0.2943
===> Epoch[17](700/2500): Loss: 0.3138
===> Epoch[17](800/2500): Loss: 0.2897
===> Epoch[17](900/2500): Loss: 0.2811
===> Epoch[17](1000/2500): Loss: 0.3163
===> Epoch[17](1100/2500): Loss: 0.3040
===> Epoch[17](1200/2500): Loss: 0.2927
===> Epoch[17](1300/2500): Loss: 0.2977
===> Epoch[17](1400/2500): Loss: 0.2961
===> Epoch[17](1500/2500): Loss: 0.2803
===> Epoch[17](1600/2500): Loss: 0.2920
===> Epoch[17](1700/2500): Loss: 0.2878
===> Epoch[17](1800/2500): Loss: 0.2834
===> Epoch[17](1900/2500): Loss: 0.3117
===> Epoch[17](2000/2500): Loss: 0.3081
===> Epoch[17](2100/2500): Loss: 0.3115
===> Epoch[17](2200/2500): Loss: 0.2672
===> Epoch[17](2300/2500): Loss: 0.2801
===> Epoch[17](2400/2500): Loss: 0.2997
===> Epoch[17](2500/2500): Loss: 0.2798
===> Epoch 17 Complete: Avg. Loss: 0.2952
===> Timestamp: [2025-08-03 20:48:52]
===> Loading train datasets
===> Epoch[17](100/2500): Loss: 0.3261
===> Epoch[17](200/2500): Loss: 0.2937
===> Epoch[17](300/2500): Loss: 0.2963
===> Epoch[17](400/2500): Loss: 0.3013
===> Epoch[17](500/2500): Loss: 0.3339
===> Epoch[17](600/2500): Loss: 0.2943
===> Epoch[17](700/2500): Loss: 0.3138
===> Epoch[17](800/2500): Loss: 0.2897
===> Epoch[17](900/2500): Loss: 0.2811
===> Epoch[17](1000/2500): Loss: 0.3163
===> Epoch[17](1100/2500): Loss: 0.3040
===> Epoch[17](1200/2500): Loss: 0.2927
===> Epoch[17](1300/2500): Loss: 0.2977
===> Epoch[17](1400/2500): Loss: 0.2961
===> Epoch[17](1500/2500): Loss: 0.2803
===> Epoch[17](1600/2500): Loss: 0.2920
===> Epoch[17](1700/2500): Loss: 0.2878
===> Epoch[17](1800/2500): Loss: 0.2834
===> Epoch[17](1900/2500): Loss: 0.3117
===> Epoch[17](2000/2500): Loss: 0.3081
===> Epoch[17](2100/2500): Loss: 0.3115
===> Epoch[17](2200/2500): Loss: 0.2672
===> Epoch[17](2300/2500): Loss: 0.2801
===> Epoch[17](2400/2500): Loss: 0.2997
===> Epoch[17](2500/2500): Loss: 0.2798
===> Epoch 17 Complete: Avg. Loss: 0.2952
===> Timestamp: [2025-08-03 20:48:52]
===> Loading train datasets
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2795
===> Epoch[18](200/2500): Loss: 0.2883
===> Epoch[18](300/2500): Loss: 0.3000
===> Epoch[18](400/2500): Loss: 0.2729
===> Epoch[18](500/2500): Loss: 0.2919
===> Epoch[18](600/2500): Loss: 0.3148
===> Epoch[18](700/2500): Loss: 0.3073
===> Epoch[18](800/2500): Loss: 0.2990
===> Epoch[18](900/2500): Loss: 0.2830
===> Epoch[18](1000/2500): Loss: 0.2985
===> Epoch[18](1100/2500): Loss: 0.3121
===> Epoch[18](1200/2500): Loss: 0.2680
===> Epoch[18](1300/2500): Loss: 0.3121
===> Epoch[18](1400/2500): Loss: 0.3125
===> Epoch[18](1500/2500): Loss: 0.3082
===> Epoch[18](1600/2500): Loss: 0.2828
===> Epoch[18](1700/2500): Loss: 0.3050
===> Epoch[18](1800/2500): Loss: 0.2801
===> Epoch[18](1900/2500): Loss: 0.3048
===> Epoch[18](2000/2500): Loss: 0.3198
===> Epoch[18](2100/2500): Loss: 0.3166
===> Epoch[18](2200/2500): Loss: 0.2961
===> Epoch[18](2300/2500): Loss: 0.2796
===> Epoch[18](2400/2500): Loss: 0.2871
===> Epoch[18](2500/2500): Loss: 0.2881
===> Epoch 18 Complete: Avg. Loss: 0.2946
===> Timestamp: [2025-08-03 20:53:26]
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2795
===> Epoch[18](200/2500): Loss: 0.2883
===> Epoch[18](300/2500): Loss: 0.3000
===> Epoch[18](400/2500): Loss: 0.2729
===> Epoch[18](500/2500): Loss: 0.2919
===> Epoch[18](600/2500): Loss: 0.3148
===> Epoch[18](700/2500): Loss: 0.3073
===> Epoch[18](800/2500): Loss: 0.2990
===> Epoch[18](900/2500): Loss: 0.2830
===> Epoch[18](1000/2500): Loss: 0.2985
===> Epoch[18](1100/2500): Loss: 0.3121
===> Epoch[18](1200/2500): Loss: 0.2680
===> Epoch[18](1300/2500): Loss: 0.3121
===> Epoch[18](1400/2500): Loss: 0.3125
===> Epoch[18](1500/2500): Loss: 0.3082
===> Epoch[18](1600/2500): Loss: 0.2828
===> Epoch[18](1700/2500): Loss: 0.3050
===> Epoch[18](1800/2500): Loss: 0.2801
===> Epoch[18](1900/2500): Loss: 0.3048
===> Epoch[18](2000/2500): Loss: 0.3198
===> Epoch[18](2100/2500): Loss: 0.3166
===> Epoch[18](2200/2500): Loss: 0.2961
===> Epoch[18](2300/2500): Loss: 0.2796
===> Epoch[18](2400/2500): Loss: 0.2871
===> Epoch[18](2500/2500): Loss: 0.2881
===> Epoch 18 Complete: Avg. Loss: 0.2946
===> Timestamp: [2025-08-03 20:53:26]
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2795
===> Epoch[18](200/2500): Loss: 0.2883
===> Epoch[18](300/2500): Loss: 0.3000
===> Epoch[18](400/2500): Loss: 0.2729
===> Epoch[18](500/2500): Loss: 0.2919
===> Epoch[18](600/2500): Loss: 0.3148
===> Epoch[18](700/2500): Loss: 0.3073
===> Epoch[18](800/2500): Loss: 0.2990
===> Epoch[18](900/2500): Loss: 0.2830
===> Epoch[18](1000/2500): Loss: 0.2985
===> Epoch[18](1100/2500): Loss: 0.3121
===> Epoch[18](1200/2500): Loss: 0.2680
===> Epoch[18](1300/2500): Loss: 0.3121
===> Epoch[18](1400/2500): Loss: 0.3125
===> Epoch[18](1500/2500): Loss: 0.3082
===> Epoch[18](1600/2500): Loss: 0.2828
===> Epoch[18](1700/2500): Loss: 0.3050
===> Epoch[18](1800/2500): Loss: 0.2801
===> Epoch[18](1900/2500): Loss: 0.3048
===> Epoch[18](2000/2500): Loss: 0.3198
===> Epoch[18](2100/2500): Loss: 0.3166
===> Epoch[18](2200/2500): Loss: 0.2961
===> Epoch[18](2300/2500): Loss: 0.2796
===> Epoch[18](2400/2500): Loss: 0.2871
===> Epoch[18](2500/2500): Loss: 0.2881
===> Epoch 18 Complete: Avg. Loss: 0.2946
===> Timestamp: [2025-08-03 20:53:26]
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2795
===> Epoch[18](200/2500): Loss: 0.2883
===> Epoch[18](300/2500): Loss: 0.3000
===> Epoch[18](400/2500): Loss: 0.2729
===> Epoch[18](500/2500): Loss: 0.2919
===> Epoch[18](600/2500): Loss: 0.3148
===> Epoch[18](700/2500): Loss: 0.3073
===> Epoch[18](800/2500): Loss: 0.2990
===> Epoch[18](900/2500): Loss: 0.2830
===> Epoch[18](1000/2500): Loss: 0.2985
===> Epoch[18](1100/2500): Loss: 0.3121
===> Epoch[18](1200/2500): Loss: 0.2680
===> Epoch[18](1300/2500): Loss: 0.3121
===> Epoch[18](1400/2500): Loss: 0.3125
===> Epoch[18](1500/2500): Loss: 0.3082
===> Epoch[18](1600/2500): Loss: 0.2828
===> Epoch[18](1700/2500): Loss: 0.3050
===> Epoch[18](1800/2500): Loss: 0.2801
===> Epoch[18](1900/2500): Loss: 0.3048
===> Epoch[18](2000/2500): Loss: 0.3198
===> Epoch[18](2100/2500): Loss: 0.3166
===> Epoch[18](2200/2500): Loss: 0.2961
===> Epoch[18](2300/2500): Loss: 0.2796
===> Epoch[18](2400/2500): Loss: 0.2871
===> Epoch[18](2500/2500): Loss: 0.2881
===> Epoch 18 Complete: Avg. Loss: 0.2946
===> Timestamp: [2025-08-03 20:53:26]
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2795
===> Epoch[18](200/2500): Loss: 0.2883
===> Epoch[18](300/2500): Loss: 0.3000
===> Epoch[18](400/2500): Loss: 0.2729
===> Epoch[18](500/2500): Loss: 0.2919
===> Epoch[18](600/2500): Loss: 0.3148
===> Epoch[18](700/2500): Loss: 0.3073
===> Epoch[18](800/2500): Loss: 0.2990
===> Epoch[18](900/2500): Loss: 0.2830
===> Epoch[18](1000/2500): Loss: 0.2985
===> Epoch[18](1100/2500): Loss: 0.3121
===> Epoch[18](1200/2500): Loss: 0.2680
===> Epoch[18](1300/2500): Loss: 0.3121
===> Epoch[18](1400/2500): Loss: 0.3125
===> Epoch[18](1500/2500): Loss: 0.3082
===> Epoch[18](1600/2500): Loss: 0.2828
===> Epoch[18](1700/2500): Loss: 0.3050
===> Epoch[18](1800/2500): Loss: 0.2801
===> Epoch[18](1900/2500): Loss: 0.3048
===> Epoch[18](2000/2500): Loss: 0.3198
===> Epoch[18](2100/2500): Loss: 0.3166
===> Epoch[18](2200/2500): Loss: 0.2961
===> Epoch[18](2300/2500): Loss: 0.2796
===> Epoch[18](2400/2500): Loss: 0.2871
===> Epoch[18](2500/2500): Loss: 0.2881
===> Epoch 18 Complete: Avg. Loss: 0.2946
===> Timestamp: [2025-08-03 20:53:26]
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2795
===> Epoch[18](200/2500): Loss: 0.2883
===> Epoch[18](300/2500): Loss: 0.3000
===> Epoch[18](400/2500): Loss: 0.2729
===> Epoch[18](500/2500): Loss: 0.2919
===> Epoch[18](600/2500): Loss: 0.3148
===> Epoch[18](700/2500): Loss: 0.3073
===> Epoch[18](800/2500): Loss: 0.2990
===> Epoch[18](900/2500): Loss: 0.2830
===> Epoch[18](1000/2500): Loss: 0.2985
===> Epoch[18](1100/2500): Loss: 0.3121
===> Epoch[18](1200/2500): Loss: 0.2680
===> Epoch[18](1300/2500): Loss: 0.3121
===> Epoch[18](1400/2500): Loss: 0.3125
===> Epoch[18](1500/2500): Loss: 0.3082
===> Epoch[18](1600/2500): Loss: 0.2828
===> Epoch[18](1700/2500): Loss: 0.3050
===> Epoch[18](1800/2500): Loss: 0.2801
===> Epoch[18](1900/2500): Loss: 0.3048
===> Epoch[18](2000/2500): Loss: 0.3198
===> Epoch[18](2100/2500): Loss: 0.3166
===> Epoch[18](2200/2500): Loss: 0.2961
===> Epoch[18](2300/2500): Loss: 0.2796
===> Epoch[18](2400/2500): Loss: 0.2871
===> Epoch[18](2500/2500): Loss: 0.2881
===> Epoch 18 Complete: Avg. Loss: 0.2946
===> Timestamp: [2025-08-03 20:53:26]
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2795
===> Epoch[18](200/2500): Loss: 0.2883
===> Epoch[18](300/2500): Loss: 0.3000
===> Epoch[18](400/2500): Loss: 0.2729
===> Epoch[18](500/2500): Loss: 0.2919
===> Epoch[18](600/2500): Loss: 0.3148
===> Epoch[18](700/2500): Loss: 0.3073
===> Epoch[18](800/2500): Loss: 0.2990
===> Epoch[18](900/2500): Loss: 0.2830
===> Epoch[18](1000/2500): Loss: 0.2985
===> Epoch[18](1100/2500): Loss: 0.3121
===> Epoch[18](1200/2500): Loss: 0.2680
===> Epoch[18](1300/2500): Loss: 0.3121
===> Epoch[18](1400/2500): Loss: 0.3125
===> Epoch[18](1500/2500): Loss: 0.3082
===> Epoch[18](1600/2500): Loss: 0.2828
===> Epoch[18](1700/2500): Loss: 0.3050
===> Epoch[18](1800/2500): Loss: 0.2801
===> Epoch[18](1900/2500): Loss: 0.3048
===> Epoch[18](2000/2500): Loss: 0.3198
===> Epoch[18](2100/2500): Loss: 0.3166
===> Epoch[18](2200/2500): Loss: 0.2961
===> Epoch[18](2300/2500): Loss: 0.2796
===> Epoch[18](2400/2500): Loss: 0.2871
===> Epoch[18](2500/2500): Loss: 0.2881
===> Epoch 18 Complete: Avg. Loss: 0.2946
===> Timestamp: [2025-08-03 20:53:26]
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2795
===> Epoch[18](200/2500): Loss: 0.2883
===> Epoch[18](300/2500): Loss: 0.3000
===> Epoch[18](400/2500): Loss: 0.2729
===> Epoch[18](500/2500): Loss: 0.2919
===> Epoch[18](600/2500): Loss: 0.3148
===> Epoch[18](700/2500): Loss: 0.3073
===> Epoch[18](800/2500): Loss: 0.2990
===> Epoch[18](900/2500): Loss: 0.2830
===> Epoch[18](1000/2500): Loss: 0.2985
===> Epoch[18](1100/2500): Loss: 0.3121
===> Epoch[18](1200/2500): Loss: 0.2680
===> Epoch[18](1300/2500): Loss: 0.3121
===> Epoch[18](1400/2500): Loss: 0.3125
===> Epoch[18](1500/2500): Loss: 0.3082
===> Epoch[18](1600/2500): Loss: 0.2828
===> Epoch[18](1700/2500): Loss: 0.3050
===> Epoch[18](1800/2500): Loss: 0.2801
===> Epoch[18](1900/2500): Loss: 0.3048
===> Epoch[18](2000/2500): Loss: 0.3198
===> Epoch[18](2100/2500): Loss: 0.3166
===> Epoch[18](2200/2500): Loss: 0.2961
===> Epoch[18](2300/2500): Loss: 0.2796
===> Epoch[18](2400/2500): Loss: 0.2871
===> Epoch[18](2500/2500): Loss: 0.2881
===> Epoch 18 Complete: Avg. Loss: 0.2946
===> Timestamp: [2025-08-03 20:53:26]
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2795
===> Epoch[18](200/2500): Loss: 0.2883
===> Epoch[18](300/2500): Loss: 0.3000
===> Epoch[18](400/2500): Loss: 0.2729
===> Epoch[18](500/2500): Loss: 0.2919
===> Epoch[18](600/2500): Loss: 0.3148
===> Epoch[18](700/2500): Loss: 0.3073
===> Epoch[18](800/2500): Loss: 0.2990
===> Epoch[18](900/2500): Loss: 0.2830
===> Epoch[18](1000/2500): Loss: 0.2985
===> Epoch[18](1100/2500): Loss: 0.3121
===> Epoch[18](1200/2500): Loss: 0.2680
===> Epoch[18](1300/2500): Loss: 0.3121
===> Epoch[18](1400/2500): Loss: 0.3125
===> Epoch[18](1500/2500): Loss: 0.3082
===> Epoch[18](1600/2500): Loss: 0.2828
===> Epoch[18](1700/2500): Loss: 0.3050
===> Epoch[18](1800/2500): Loss: 0.2801
===> Epoch[18](1900/2500): Loss: 0.3048
===> Epoch[18](2000/2500): Loss: 0.3198
===> Epoch[18](2100/2500): Loss: 0.3166
===> Epoch[18](2200/2500): Loss: 0.2961
===> Epoch[18](2300/2500): Loss: 0.2796
===> Epoch[18](2400/2500): Loss: 0.2871
===> Epoch[18](2500/2500): Loss: 0.2881
===> Epoch 18 Complete: Avg. Loss: 0.2946
===> Timestamp: [2025-08-03 20:53:26]
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2795
===> Epoch[18](200/2500): Loss: 0.2883
===> Epoch[18](300/2500): Loss: 0.3000
===> Epoch[18](400/2500): Loss: 0.2729
===> Epoch[18](500/2500): Loss: 0.2919
===> Epoch[18](600/2500): Loss: 0.3148
===> Epoch[18](700/2500): Loss: 0.3073
===> Epoch[18](800/2500): Loss: 0.2990
===> Epoch[18](900/2500): Loss: 0.2830
===> Epoch[18](1000/2500): Loss: 0.2985
===> Epoch[18](1100/2500): Loss: 0.3121
===> Epoch[18](1200/2500): Loss: 0.2680
===> Epoch[18](1300/2500): Loss: 0.3121
===> Epoch[18](1400/2500): Loss: 0.3125
===> Epoch[18](1500/2500): Loss: 0.3082
===> Epoch[18](1600/2500): Loss: 0.2828
===> Epoch[18](1700/2500): Loss: 0.3050
===> Epoch[18](1800/2500): Loss: 0.2801
===> Epoch[18](1900/2500): Loss: 0.3048
===> Epoch[18](2000/2500): Loss: 0.3198
===> Epoch[18](2100/2500): Loss: 0.3166
===> Epoch[18](2200/2500): Loss: 0.2961
===> Epoch[18](2300/2500): Loss: 0.2796
===> Epoch[18](2400/2500): Loss: 0.2871
===> Epoch[18](2500/2500): Loss: 0.2881
===> Epoch 18 Complete: Avg. Loss: 0.2946
===> Timestamp: [2025-08-03 20:53:26]
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2795
===> Epoch[18](200/2500): Loss: 0.2883
===> Epoch[18](300/2500): Loss: 0.3000
===> Epoch[18](400/2500): Loss: 0.2729
===> Epoch[18](500/2500): Loss: 0.2919
===> Epoch[18](600/2500): Loss: 0.3148
===> Epoch[18](700/2500): Loss: 0.3073
===> Epoch[18](800/2500): Loss: 0.2990
===> Epoch[18](900/2500): Loss: 0.2830
===> Epoch[18](1000/2500): Loss: 0.2985
===> Epoch[18](1100/2500): Loss: 0.3121
===> Epoch[18](1200/2500): Loss: 0.2680
===> Epoch[18](1300/2500): Loss: 0.3121
===> Epoch[18](1400/2500): Loss: 0.3125
===> Epoch[18](1500/2500): Loss: 0.3082
===> Epoch[18](1600/2500): Loss: 0.2828
===> Epoch[18](1700/2500): Loss: 0.3050
===> Epoch[18](1800/2500): Loss: 0.2801
===> Epoch[18](1900/2500): Loss: 0.3048
===> Epoch[18](2000/2500): Loss: 0.3198
===> Epoch[18](2100/2500): Loss: 0.3166
===> Epoch[18](2200/2500): Loss: 0.2961
===> Epoch[18](2300/2500): Loss: 0.2796
===> Epoch[18](2400/2500): Loss: 0.2871
===> Epoch[18](2500/2500): Loss: 0.2881
===> Epoch 18 Complete: Avg. Loss: 0.2946
===> Timestamp: [2025-08-03 20:53:26]
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2795
===> Epoch[18](200/2500): Loss: 0.2883
===> Epoch[18](300/2500): Loss: 0.3000
===> Epoch[18](400/2500): Loss: 0.2729
===> Epoch[18](500/2500): Loss: 0.2919
===> Epoch[18](600/2500): Loss: 0.3148
===> Epoch[18](700/2500): Loss: 0.3073
===> Epoch[18](800/2500): Loss: 0.2990
===> Epoch[18](900/2500): Loss: 0.2830
===> Epoch[18](1000/2500): Loss: 0.2985
===> Epoch[18](1100/2500): Loss: 0.3121
===> Epoch[18](1200/2500): Loss: 0.2680
===> Epoch[18](1300/2500): Loss: 0.3121
===> Epoch[18](1400/2500): Loss: 0.3125
===> Epoch[18](1500/2500): Loss: 0.3082
===> Epoch[18](1600/2500): Loss: 0.2828
===> Epoch[18](1700/2500): Loss: 0.3050
===> Epoch[18](1800/2500): Loss: 0.2801
===> Epoch[18](1900/2500): Loss: 0.3048
===> Epoch[18](2000/2500): Loss: 0.3198
===> Epoch[18](2100/2500): Loss: 0.3166
===> Epoch[18](2200/2500): Loss: 0.2961
===> Epoch[18](2300/2500): Loss: 0.2796
===> Epoch[18](2400/2500): Loss: 0.2871
===> Epoch[18](2500/2500): Loss: 0.2881
===> Epoch 18 Complete: Avg. Loss: 0.2946
===> Timestamp: [2025-08-03 20:53:26]
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2795
===> Epoch[18](200/2500): Loss: 0.2883
===> Epoch[18](300/2500): Loss: 0.3000
===> Epoch[18](400/2500): Loss: 0.2729
===> Epoch[18](500/2500): Loss: 0.2919
===> Epoch[18](600/2500): Loss: 0.3148
===> Epoch[18](700/2500): Loss: 0.3073
===> Epoch[18](800/2500): Loss: 0.2990
===> Epoch[18](900/2500): Loss: 0.2830
===> Epoch[18](1000/2500): Loss: 0.2985
===> Epoch[18](1100/2500): Loss: 0.3121
===> Epoch[18](1200/2500): Loss: 0.2680
===> Epoch[18](1300/2500): Loss: 0.3121
===> Epoch[18](1400/2500): Loss: 0.3125
===> Epoch[18](1500/2500): Loss: 0.3082
===> Epoch[18](1600/2500): Loss: 0.2828
===> Epoch[18](1700/2500): Loss: 0.3050
===> Epoch[18](1800/2500): Loss: 0.2801
===> Epoch[18](1900/2500): Loss: 0.3048
===> Epoch[18](2000/2500): Loss: 0.3198
===> Epoch[18](2100/2500): Loss: 0.3166
===> Epoch[18](2200/2500): Loss: 0.2961
===> Epoch[18](2300/2500): Loss: 0.2796
===> Epoch[18](2400/2500): Loss: 0.2871
===> Epoch[18](2500/2500): Loss: 0.2881
===> Epoch 18 Complete: Avg. Loss: 0.2946
===> Timestamp: [2025-08-03 20:53:26]
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2795
===> Epoch[18](200/2500): Loss: 0.2883
===> Epoch[18](300/2500): Loss: 0.3000
===> Epoch[18](400/2500): Loss: 0.2729
===> Epoch[18](500/2500): Loss: 0.2919
===> Epoch[18](600/2500): Loss: 0.3148
===> Epoch[18](700/2500): Loss: 0.3073
===> Epoch[18](800/2500): Loss: 0.2990
===> Epoch[18](900/2500): Loss: 0.2830
===> Epoch[18](1000/2500): Loss: 0.2985
===> Epoch[18](1100/2500): Loss: 0.3121
===> Epoch[18](1200/2500): Loss: 0.2680
===> Epoch[18](1300/2500): Loss: 0.3121
===> Epoch[18](1400/2500): Loss: 0.3125
===> Epoch[18](1500/2500): Loss: 0.3082
===> Epoch[18](1600/2500): Loss: 0.2828
===> Epoch[18](1700/2500): Loss: 0.3050
===> Epoch[18](1800/2500): Loss: 0.2801
===> Epoch[18](1900/2500): Loss: 0.3048
===> Epoch[18](2000/2500): Loss: 0.3198
===> Epoch[18](2100/2500): Loss: 0.3166
===> Epoch[18](2200/2500): Loss: 0.2961
===> Epoch[18](2300/2500): Loss: 0.2796
===> Epoch[18](2400/2500): Loss: 0.2871
===> Epoch[18](2500/2500): Loss: 0.2881
===> Epoch 18 Complete: Avg. Loss: 0.2946
===> Timestamp: [2025-08-03 20:53:26]
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2795
===> Epoch[18](200/2500): Loss: 0.2883
===> Epoch[18](300/2500): Loss: 0.3000
===> Epoch[18](400/2500): Loss: 0.2729
===> Epoch[18](500/2500): Loss: 0.2919
===> Epoch[18](600/2500): Loss: 0.3148
===> Epoch[18](700/2500): Loss: 0.3073
===> Epoch[18](800/2500): Loss: 0.2990
===> Epoch[18](900/2500): Loss: 0.2830
===> Epoch[18](1000/2500): Loss: 0.2985
===> Epoch[18](1100/2500): Loss: 0.3121
===> Epoch[18](1200/2500): Loss: 0.2680
===> Epoch[18](1300/2500): Loss: 0.3121
===> Epoch[18](1400/2500): Loss: 0.3125
===> Epoch[18](1500/2500): Loss: 0.3082
===> Epoch[18](1600/2500): Loss: 0.2828
===> Epoch[18](1700/2500): Loss: 0.3050
===> Epoch[18](1800/2500): Loss: 0.2801
===> Epoch[18](1900/2500): Loss: 0.3048
===> Epoch[18](2000/2500): Loss: 0.3198
===> Epoch[18](2100/2500): Loss: 0.3166
===> Epoch[18](2200/2500): Loss: 0.2961
===> Epoch[18](2300/2500): Loss: 0.2796
===> Epoch[18](2400/2500): Loss: 0.2871
===> Epoch[18](2500/2500): Loss: 0.2881
===> Epoch 18 Complete: Avg. Loss: 0.2946
===> Timestamp: [2025-08-03 20:53:26]
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2795
===> Epoch[18](200/2500): Loss: 0.2883
===> Epoch[18](300/2500): Loss: 0.3000
===> Epoch[18](400/2500): Loss: 0.2729
===> Epoch[18](500/2500): Loss: 0.2919
===> Epoch[18](600/2500): Loss: 0.3148
===> Epoch[18](700/2500): Loss: 0.3073
===> Epoch[18](800/2500): Loss: 0.2990
===> Epoch[18](900/2500): Loss: 0.2830
===> Epoch[18](1000/2500): Loss: 0.2985
===> Epoch[18](1100/2500): Loss: 0.3121
===> Epoch[18](1200/2500): Loss: 0.2680
===> Epoch[18](1300/2500): Loss: 0.3121
===> Epoch[18](1400/2500): Loss: 0.3125
===> Epoch[18](1500/2500): Loss: 0.3082
===> Epoch[18](1600/2500): Loss: 0.2828
===> Epoch[18](1700/2500): Loss: 0.3050
===> Epoch[18](1800/2500): Loss: 0.2801
===> Epoch[18](1900/2500): Loss: 0.3048
===> Epoch[18](2000/2500): Loss: 0.3198
===> Epoch[18](2100/2500): Loss: 0.3166
===> Epoch[18](2200/2500): Loss: 0.2961
===> Epoch[18](2300/2500): Loss: 0.2796
===> Epoch[18](2400/2500): Loss: 0.2871
===> Epoch[18](2500/2500): Loss: 0.2881
===> Epoch 18 Complete: Avg. Loss: 0.2946
===> Timestamp: [2025-08-03 20:53:26]
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2795
===> Epoch[18](200/2500): Loss: 0.2883
===> Epoch[18](300/2500): Loss: 0.3000
===> Epoch[18](400/2500): Loss: 0.2729
===> Epoch[18](500/2500): Loss: 0.2919
===> Epoch[18](600/2500): Loss: 0.3148
===> Epoch[18](700/2500): Loss: 0.3073
===> Epoch[18](800/2500): Loss: 0.2990
===> Epoch[18](900/2500): Loss: 0.2830
===> Epoch[18](1000/2500): Loss: 0.2985
===> Epoch[18](1100/2500): Loss: 0.3121
===> Epoch[18](1200/2500): Loss: 0.2680
===> Epoch[18](1300/2500): Loss: 0.3121
===> Epoch[18](1400/2500): Loss: 0.3125
===> Epoch[18](1500/2500): Loss: 0.3082
===> Epoch[18](1600/2500): Loss: 0.2828
===> Epoch[18](1700/2500): Loss: 0.3050
===> Epoch[18](1800/2500): Loss: 0.2801
===> Epoch[18](1900/2500): Loss: 0.3048
===> Epoch[18](2000/2500): Loss: 0.3198
===> Epoch[18](2100/2500): Loss: 0.3166
===> Epoch[18](2200/2500): Loss: 0.2961
===> Epoch[18](2300/2500): Loss: 0.2796
===> Epoch[18](2400/2500): Loss: 0.2871
===> Epoch[18](2500/2500): Loss: 0.2881
===> Epoch 18 Complete: Avg. Loss: 0.2946
===> Timestamp: [2025-08-03 20:53:26]
===> Loading train datasets
===> Epoch[18](100/2500): Loss: 0.2795
===> Epoch[18](200/2500): Loss: 0.2883
===> Epoch[18](300/2500): Loss: 0.3000
===> Epoch[18](400/2500): Loss: 0.2729
===> Epoch[18](500/2500): Loss: 0.2919
===> Epoch[18](600/2500): Loss: 0.3148
===> Epoch[18](700/2500): Loss: 0.3073
===> Epoch[18](800/2500): Loss: 0.2990
===> Epoch[18](900/2500): Loss: 0.2830
===> Epoch[18](1000/2500): Loss: 0.2985
===> Epoch[18](1100/2500): Loss: 0.3121
===> Epoch[18](1200/2500): Loss: 0.2680
===> Epoch[18](1300/2500): Loss: 0.3121
===> Epoch[18](1400/2500): Loss: 0.3125
===> Epoch[18](1500/2500): Loss: 0.3082
===> Epoch[18](1600/2500): Loss: 0.2828
===> Epoch[18](1700/2500): Loss: 0.3050
===> Epoch[18](1800/2500): Loss: 0.2801
===> Epoch[18](1900/2500): Loss: 0.3048
===> Epoch[18](2000/2500): Loss: 0.3198
===> Epoch[18](2100/2500): Loss: 0.3166
===> Epoch[18](2200/2500): Loss: 0.2961
===> Epoch[18](2300/2500): Loss: 0.2796
===> Epoch[18](2400/2500): Loss: 0.2871
===> Epoch[18](2500/2500): Loss: 0.2881
===> Epoch 18 Complete: Avg. Loss: 0.2946
===> Timestamp: [2025-08-03 20:53:26]
===> Loading train datasets
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.3010
===> Epoch[19](200/2500): Loss: 0.3323
===> Epoch[19](300/2500): Loss: 0.2710
===> Epoch[19](400/2500): Loss: 0.2965
===> Epoch[19](500/2500): Loss: 0.3121
===> Epoch[19](600/2500): Loss: 0.2913
===> Epoch[19](700/2500): Loss: 0.2806
===> Epoch[19](800/2500): Loss: 0.3116
===> Epoch[19](900/2500): Loss: 0.3044
===> Epoch[19](1000/2500): Loss: 0.3074
===> Epoch[19](1100/2500): Loss: 0.2701
===> Epoch[19](1200/2500): Loss: 0.3104
===> Epoch[19](1300/2500): Loss: 0.2835
===> Epoch[19](1400/2500): Loss: 0.3152
===> Epoch[19](1500/2500): Loss: 0.2962
===> Epoch[19](1600/2500): Loss: 0.2954
===> Epoch[19](1700/2500): Loss: 0.3186
===> Epoch[19](1800/2500): Loss: 0.2787
===> Epoch[19](1900/2500): Loss: 0.2959
===> Epoch[19](2000/2500): Loss: 0.3020
===> Epoch[19](2100/2500): Loss: 0.2947
===> Epoch[19](2200/2500): Loss: 0.3362
===> Epoch[19](2300/2500): Loss: 0.2820
===> Epoch[19](2400/2500): Loss: 0.3069
===> Epoch[19](2500/2500): Loss: 0.2955
===> Epoch 19 Complete: Avg. Loss: 0.2937
===> Timestamp: [2025-08-03 20:58:00]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.3010
===> Epoch[19](200/2500): Loss: 0.3323
===> Epoch[19](300/2500): Loss: 0.2710
===> Epoch[19](400/2500): Loss: 0.2965
===> Epoch[19](500/2500): Loss: 0.3121
===> Epoch[19](600/2500): Loss: 0.2913
===> Epoch[19](700/2500): Loss: 0.2806
===> Epoch[19](800/2500): Loss: 0.3116
===> Epoch[19](900/2500): Loss: 0.3044
===> Epoch[19](1000/2500): Loss: 0.3074
===> Epoch[19](1100/2500): Loss: 0.2701
===> Epoch[19](1200/2500): Loss: 0.3104
===> Epoch[19](1300/2500): Loss: 0.2835
===> Epoch[19](1400/2500): Loss: 0.3152
===> Epoch[19](1500/2500): Loss: 0.2962
===> Epoch[19](1600/2500): Loss: 0.2954
===> Epoch[19](1700/2500): Loss: 0.3186
===> Epoch[19](1800/2500): Loss: 0.2787
===> Epoch[19](1900/2500): Loss: 0.2959
===> Epoch[19](2000/2500): Loss: 0.3020
===> Epoch[19](2100/2500): Loss: 0.2947
===> Epoch[19](2200/2500): Loss: 0.3362
===> Epoch[19](2300/2500): Loss: 0.2820
===> Epoch[19](2400/2500): Loss: 0.3069
===> Epoch[19](2500/2500): Loss: 0.2955
===> Epoch 19 Complete: Avg. Loss: 0.2937
===> Timestamp: [2025-08-03 20:58:00]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.3010
===> Epoch[19](200/2500): Loss: 0.3323
===> Epoch[19](300/2500): Loss: 0.2710
===> Epoch[19](400/2500): Loss: 0.2965
===> Epoch[19](500/2500): Loss: 0.3121
===> Epoch[19](600/2500): Loss: 0.2913
===> Epoch[19](700/2500): Loss: 0.2806
===> Epoch[19](800/2500): Loss: 0.3116
===> Epoch[19](900/2500): Loss: 0.3044
===> Epoch[19](1000/2500): Loss: 0.3074
===> Epoch[19](1100/2500): Loss: 0.2701
===> Epoch[19](1200/2500): Loss: 0.3104
===> Epoch[19](1300/2500): Loss: 0.2835
===> Epoch[19](1400/2500): Loss: 0.3152
===> Epoch[19](1500/2500): Loss: 0.2962
===> Epoch[19](1600/2500): Loss: 0.2954
===> Epoch[19](1700/2500): Loss: 0.3186
===> Epoch[19](1800/2500): Loss: 0.2787
===> Epoch[19](1900/2500): Loss: 0.2959
===> Epoch[19](2000/2500): Loss: 0.3020
===> Epoch[19](2100/2500): Loss: 0.2947
===> Epoch[19](2200/2500): Loss: 0.3362
===> Epoch[19](2300/2500): Loss: 0.2820
===> Epoch[19](2400/2500): Loss: 0.3069
===> Epoch[19](2500/2500): Loss: 0.2955
===> Epoch 19 Complete: Avg. Loss: 0.2937
===> Timestamp: [2025-08-03 20:58:00]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.3010
===> Epoch[19](200/2500): Loss: 0.3323
===> Epoch[19](300/2500): Loss: 0.2710
===> Epoch[19](400/2500): Loss: 0.2965
===> Epoch[19](500/2500): Loss: 0.3121
===> Epoch[19](600/2500): Loss: 0.2913
===> Epoch[19](700/2500): Loss: 0.2806
===> Epoch[19](800/2500): Loss: 0.3116
===> Epoch[19](900/2500): Loss: 0.3044
===> Epoch[19](1000/2500): Loss: 0.3074
===> Epoch[19](1100/2500): Loss: 0.2701
===> Epoch[19](1200/2500): Loss: 0.3104
===> Epoch[19](1300/2500): Loss: 0.2835
===> Epoch[19](1400/2500): Loss: 0.3152
===> Epoch[19](1500/2500): Loss: 0.2962
===> Epoch[19](1600/2500): Loss: 0.2954
===> Epoch[19](1700/2500): Loss: 0.3186
===> Epoch[19](1800/2500): Loss: 0.2787
===> Epoch[19](1900/2500): Loss: 0.2959
===> Epoch[19](2000/2500): Loss: 0.3020
===> Epoch[19](2100/2500): Loss: 0.2947
===> Epoch[19](2200/2500): Loss: 0.3362
===> Epoch[19](2300/2500): Loss: 0.2820
===> Epoch[19](2400/2500): Loss: 0.3069
===> Epoch[19](2500/2500): Loss: 0.2955
===> Epoch 19 Complete: Avg. Loss: 0.2937
===> Timestamp: [2025-08-03 20:58:00]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.3010
===> Epoch[19](200/2500): Loss: 0.3323
===> Epoch[19](300/2500): Loss: 0.2710
===> Epoch[19](400/2500): Loss: 0.2965
===> Epoch[19](500/2500): Loss: 0.3121
===> Epoch[19](600/2500): Loss: 0.2913
===> Epoch[19](700/2500): Loss: 0.2806
===> Epoch[19](800/2500): Loss: 0.3116
===> Epoch[19](900/2500): Loss: 0.3044
===> Epoch[19](1000/2500): Loss: 0.3074
===> Epoch[19](1100/2500): Loss: 0.2701
===> Epoch[19](1200/2500): Loss: 0.3104
===> Epoch[19](1300/2500): Loss: 0.2835
===> Epoch[19](1400/2500): Loss: 0.3152
===> Epoch[19](1500/2500): Loss: 0.2962
===> Epoch[19](1600/2500): Loss: 0.2954
===> Epoch[19](1700/2500): Loss: 0.3186
===> Epoch[19](1800/2500): Loss: 0.2787
===> Epoch[19](1900/2500): Loss: 0.2959
===> Epoch[19](2000/2500): Loss: 0.3020
===> Epoch[19](2100/2500): Loss: 0.2947
===> Epoch[19](2200/2500): Loss: 0.3362
===> Epoch[19](2300/2500): Loss: 0.2820
===> Epoch[19](2400/2500): Loss: 0.3069
===> Epoch[19](2500/2500): Loss: 0.2955
===> Epoch 19 Complete: Avg. Loss: 0.2937
===> Timestamp: [2025-08-03 20:58:00]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.3010
===> Epoch[19](200/2500): Loss: 0.3323
===> Epoch[19](300/2500): Loss: 0.2710
===> Epoch[19](400/2500): Loss: 0.2965
===> Epoch[19](500/2500): Loss: 0.3121
===> Epoch[19](600/2500): Loss: 0.2913
===> Epoch[19](700/2500): Loss: 0.2806
===> Epoch[19](800/2500): Loss: 0.3116
===> Epoch[19](900/2500): Loss: 0.3044
===> Epoch[19](1000/2500): Loss: 0.3074
===> Epoch[19](1100/2500): Loss: 0.2701
===> Epoch[19](1200/2500): Loss: 0.3104
===> Epoch[19](1300/2500): Loss: 0.2835
===> Epoch[19](1400/2500): Loss: 0.3152
===> Epoch[19](1500/2500): Loss: 0.2962
===> Epoch[19](1600/2500): Loss: 0.2954
===> Epoch[19](1700/2500): Loss: 0.3186
===> Epoch[19](1800/2500): Loss: 0.2787
===> Epoch[19](1900/2500): Loss: 0.2959
===> Epoch[19](2000/2500): Loss: 0.3020
===> Epoch[19](2100/2500): Loss: 0.2947
===> Epoch[19](2200/2500): Loss: 0.3362
===> Epoch[19](2300/2500): Loss: 0.2820
===> Epoch[19](2400/2500): Loss: 0.3069
===> Epoch[19](2500/2500): Loss: 0.2955
===> Epoch 19 Complete: Avg. Loss: 0.2937
===> Timestamp: [2025-08-03 20:58:00]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.3010
===> Epoch[19](200/2500): Loss: 0.3323
===> Epoch[19](300/2500): Loss: 0.2710
===> Epoch[19](400/2500): Loss: 0.2965
===> Epoch[19](500/2500): Loss: 0.3121
===> Epoch[19](600/2500): Loss: 0.2913
===> Epoch[19](700/2500): Loss: 0.2806
===> Epoch[19](800/2500): Loss: 0.3116
===> Epoch[19](900/2500): Loss: 0.3044
===> Epoch[19](1000/2500): Loss: 0.3074
===> Epoch[19](1100/2500): Loss: 0.2701
===> Epoch[19](1200/2500): Loss: 0.3104
===> Epoch[19](1300/2500): Loss: 0.2835
===> Epoch[19](1400/2500): Loss: 0.3152
===> Epoch[19](1500/2500): Loss: 0.2962
===> Epoch[19](1600/2500): Loss: 0.2954
===> Epoch[19](1700/2500): Loss: 0.3186
===> Epoch[19](1800/2500): Loss: 0.2787
===> Epoch[19](1900/2500): Loss: 0.2959
===> Epoch[19](2000/2500): Loss: 0.3020
===> Epoch[19](2100/2500): Loss: 0.2947
===> Epoch[19](2200/2500): Loss: 0.3362
===> Epoch[19](2300/2500): Loss: 0.2820
===> Epoch[19](2400/2500): Loss: 0.3069
===> Epoch[19](2500/2500): Loss: 0.2955
===> Epoch 19 Complete: Avg. Loss: 0.2937
===> Timestamp: [2025-08-03 20:58:00]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.3010
===> Epoch[19](200/2500): Loss: 0.3323
===> Epoch[19](300/2500): Loss: 0.2710
===> Epoch[19](400/2500): Loss: 0.2965
===> Epoch[19](500/2500): Loss: 0.3121
===> Epoch[19](600/2500): Loss: 0.2913
===> Epoch[19](700/2500): Loss: 0.2806
===> Epoch[19](800/2500): Loss: 0.3116
===> Epoch[19](900/2500): Loss: 0.3044
===> Epoch[19](1000/2500): Loss: 0.3074
===> Epoch[19](1100/2500): Loss: 0.2701
===> Epoch[19](1200/2500): Loss: 0.3104
===> Epoch[19](1300/2500): Loss: 0.2835
===> Epoch[19](1400/2500): Loss: 0.3152
===> Epoch[19](1500/2500): Loss: 0.2962
===> Epoch[19](1600/2500): Loss: 0.2954
===> Epoch[19](1700/2500): Loss: 0.3186
===> Epoch[19](1800/2500): Loss: 0.2787
===> Epoch[19](1900/2500): Loss: 0.2959
===> Epoch[19](2000/2500): Loss: 0.3020
===> Epoch[19](2100/2500): Loss: 0.2947
===> Epoch[19](2200/2500): Loss: 0.3362
===> Epoch[19](2300/2500): Loss: 0.2820
===> Epoch[19](2400/2500): Loss: 0.3069
===> Epoch[19](2500/2500): Loss: 0.2955
===> Epoch 19 Complete: Avg. Loss: 0.2937
===> Timestamp: [2025-08-03 20:58:00]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.3010
===> Epoch[19](200/2500): Loss: 0.3323
===> Epoch[19](300/2500): Loss: 0.2710
===> Epoch[19](400/2500): Loss: 0.2965
===> Epoch[19](500/2500): Loss: 0.3121
===> Epoch[19](600/2500): Loss: 0.2913
===> Epoch[19](700/2500): Loss: 0.2806
===> Epoch[19](800/2500): Loss: 0.3116
===> Epoch[19](900/2500): Loss: 0.3044
===> Epoch[19](1000/2500): Loss: 0.3074
===> Epoch[19](1100/2500): Loss: 0.2701
===> Epoch[19](1200/2500): Loss: 0.3104
===> Epoch[19](1300/2500): Loss: 0.2835
===> Epoch[19](1400/2500): Loss: 0.3152
===> Epoch[19](1500/2500): Loss: 0.2962
===> Epoch[19](1600/2500): Loss: 0.2954
===> Epoch[19](1700/2500): Loss: 0.3186
===> Epoch[19](1800/2500): Loss: 0.2787
===> Epoch[19](1900/2500): Loss: 0.2959
===> Epoch[19](2000/2500): Loss: 0.3020
===> Epoch[19](2100/2500): Loss: 0.2947
===> Epoch[19](2200/2500): Loss: 0.3362
===> Epoch[19](2300/2500): Loss: 0.2820
===> Epoch[19](2400/2500): Loss: 0.3069
===> Epoch[19](2500/2500): Loss: 0.2955
===> Epoch 19 Complete: Avg. Loss: 0.2937
===> Timestamp: [2025-08-03 20:58:00]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.3010
===> Epoch[19](200/2500): Loss: 0.3323
===> Epoch[19](300/2500): Loss: 0.2710
===> Epoch[19](400/2500): Loss: 0.2965
===> Epoch[19](500/2500): Loss: 0.3121
===> Epoch[19](600/2500): Loss: 0.2913
===> Epoch[19](700/2500): Loss: 0.2806
===> Epoch[19](800/2500): Loss: 0.3116
===> Epoch[19](900/2500): Loss: 0.3044
===> Epoch[19](1000/2500): Loss: 0.3074
===> Epoch[19](1100/2500): Loss: 0.2701
===> Epoch[19](1200/2500): Loss: 0.3104
===> Epoch[19](1300/2500): Loss: 0.2835
===> Epoch[19](1400/2500): Loss: 0.3152
===> Epoch[19](1500/2500): Loss: 0.2962
===> Epoch[19](1600/2500): Loss: 0.2954
===> Epoch[19](1700/2500): Loss: 0.3186
===> Epoch[19](1800/2500): Loss: 0.2787
===> Epoch[19](1900/2500): Loss: 0.2959
===> Epoch[19](2000/2500): Loss: 0.3020
===> Epoch[19](2100/2500): Loss: 0.2947
===> Epoch[19](2200/2500): Loss: 0.3362
===> Epoch[19](2300/2500): Loss: 0.2820
===> Epoch[19](2400/2500): Loss: 0.3069
===> Epoch[19](2500/2500): Loss: 0.2955
===> Epoch 19 Complete: Avg. Loss: 0.2937
===> Timestamp: [2025-08-03 20:58:00]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.3010
===> Epoch[19](200/2500): Loss: 0.3323
===> Epoch[19](300/2500): Loss: 0.2710
===> Epoch[19](400/2500): Loss: 0.2965
===> Epoch[19](500/2500): Loss: 0.3121
===> Epoch[19](600/2500): Loss: 0.2913
===> Epoch[19](700/2500): Loss: 0.2806
===> Epoch[19](800/2500): Loss: 0.3116
===> Epoch[19](900/2500): Loss: 0.3044
===> Epoch[19](1000/2500): Loss: 0.3074
===> Epoch[19](1100/2500): Loss: 0.2701
===> Epoch[19](1200/2500): Loss: 0.3104
===> Epoch[19](1300/2500): Loss: 0.2835
===> Epoch[19](1400/2500): Loss: 0.3152
===> Epoch[19](1500/2500): Loss: 0.2962
===> Epoch[19](1600/2500): Loss: 0.2954
===> Epoch[19](1700/2500): Loss: 0.3186
===> Epoch[19](1800/2500): Loss: 0.2787
===> Epoch[19](1900/2500): Loss: 0.2959
===> Epoch[19](2000/2500): Loss: 0.3020
===> Epoch[19](2100/2500): Loss: 0.2947
===> Epoch[19](2200/2500): Loss: 0.3362
===> Epoch[19](2300/2500): Loss: 0.2820
===> Epoch[19](2400/2500): Loss: 0.3069
===> Epoch[19](2500/2500): Loss: 0.2955
===> Epoch 19 Complete: Avg. Loss: 0.2937
===> Timestamp: [2025-08-03 20:58:00]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.3010
===> Epoch[19](200/2500): Loss: 0.3323
===> Epoch[19](300/2500): Loss: 0.2710
===> Epoch[19](400/2500): Loss: 0.2965
===> Epoch[19](500/2500): Loss: 0.3121
===> Epoch[19](600/2500): Loss: 0.2913
===> Epoch[19](700/2500): Loss: 0.2806
===> Epoch[19](800/2500): Loss: 0.3116
===> Epoch[19](900/2500): Loss: 0.3044
===> Epoch[19](1000/2500): Loss: 0.3074
===> Epoch[19](1100/2500): Loss: 0.2701
===> Epoch[19](1200/2500): Loss: 0.3104
===> Epoch[19](1300/2500): Loss: 0.2835
===> Epoch[19](1400/2500): Loss: 0.3152
===> Epoch[19](1500/2500): Loss: 0.2962
===> Epoch[19](1600/2500): Loss: 0.2954
===> Epoch[19](1700/2500): Loss: 0.3186
===> Epoch[19](1800/2500): Loss: 0.2787
===> Epoch[19](1900/2500): Loss: 0.2959
===> Epoch[19](2000/2500): Loss: 0.3020
===> Epoch[19](2100/2500): Loss: 0.2947
===> Epoch[19](2200/2500): Loss: 0.3362
===> Epoch[19](2300/2500): Loss: 0.2820
===> Epoch[19](2400/2500): Loss: 0.3069
===> Epoch[19](2500/2500): Loss: 0.2955
===> Epoch 19 Complete: Avg. Loss: 0.2937
===> Timestamp: [2025-08-03 20:58:00]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.3010
===> Epoch[19](200/2500): Loss: 0.3323
===> Epoch[19](300/2500): Loss: 0.2710
===> Epoch[19](400/2500): Loss: 0.2965
===> Epoch[19](500/2500): Loss: 0.3121
===> Epoch[19](600/2500): Loss: 0.2913
===> Epoch[19](700/2500): Loss: 0.2806
===> Epoch[19](800/2500): Loss: 0.3116
===> Epoch[19](900/2500): Loss: 0.3044
===> Epoch[19](1000/2500): Loss: 0.3074
===> Epoch[19](1100/2500): Loss: 0.2701
===> Epoch[19](1200/2500): Loss: 0.3104
===> Epoch[19](1300/2500): Loss: 0.2835
===> Epoch[19](1400/2500): Loss: 0.3152
===> Epoch[19](1500/2500): Loss: 0.2962
===> Epoch[19](1600/2500): Loss: 0.2954
===> Epoch[19](1700/2500): Loss: 0.3186
===> Epoch[19](1800/2500): Loss: 0.2787
===> Epoch[19](1900/2500): Loss: 0.2959
===> Epoch[19](2000/2500): Loss: 0.3020
===> Epoch[19](2100/2500): Loss: 0.2947
===> Epoch[19](2200/2500): Loss: 0.3362
===> Epoch[19](2300/2500): Loss: 0.2820
===> Epoch[19](2400/2500): Loss: 0.3069
===> Epoch[19](2500/2500): Loss: 0.2955
===> Epoch 19 Complete: Avg. Loss: 0.2937
===> Timestamp: [2025-08-03 20:58:00]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.3010
===> Epoch[19](200/2500): Loss: 0.3323
===> Epoch[19](300/2500): Loss: 0.2710
===> Epoch[19](400/2500): Loss: 0.2965
===> Epoch[19](500/2500): Loss: 0.3121
===> Epoch[19](600/2500): Loss: 0.2913
===> Epoch[19](700/2500): Loss: 0.2806
===> Epoch[19](800/2500): Loss: 0.3116
===> Epoch[19](900/2500): Loss: 0.3044
===> Epoch[19](1000/2500): Loss: 0.3074
===> Epoch[19](1100/2500): Loss: 0.2701
===> Epoch[19](1200/2500): Loss: 0.3104
===> Epoch[19](1300/2500): Loss: 0.2835
===> Epoch[19](1400/2500): Loss: 0.3152
===> Epoch[19](1500/2500): Loss: 0.2962
===> Epoch[19](1600/2500): Loss: 0.2954
===> Epoch[19](1700/2500): Loss: 0.3186
===> Epoch[19](1800/2500): Loss: 0.2787
===> Epoch[19](1900/2500): Loss: 0.2959
===> Epoch[19](2000/2500): Loss: 0.3020
===> Epoch[19](2100/2500): Loss: 0.2947
===> Epoch[19](2200/2500): Loss: 0.3362
===> Epoch[19](2300/2500): Loss: 0.2820
===> Epoch[19](2400/2500): Loss: 0.3069
===> Epoch[19](2500/2500): Loss: 0.2955
===> Epoch 19 Complete: Avg. Loss: 0.2937
===> Timestamp: [2025-08-03 20:58:00]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.3010
===> Epoch[19](200/2500): Loss: 0.3323
===> Epoch[19](300/2500): Loss: 0.2710
===> Epoch[19](400/2500): Loss: 0.2965
===> Epoch[19](500/2500): Loss: 0.3121
===> Epoch[19](600/2500): Loss: 0.2913
===> Epoch[19](700/2500): Loss: 0.2806
===> Epoch[19](800/2500): Loss: 0.3116
===> Epoch[19](900/2500): Loss: 0.3044
===> Epoch[19](1000/2500): Loss: 0.3074
===> Epoch[19](1100/2500): Loss: 0.2701
===> Epoch[19](1200/2500): Loss: 0.3104
===> Epoch[19](1300/2500): Loss: 0.2835
===> Epoch[19](1400/2500): Loss: 0.3152
===> Epoch[19](1500/2500): Loss: 0.2962
===> Epoch[19](1600/2500): Loss: 0.2954
===> Epoch[19](1700/2500): Loss: 0.3186
===> Epoch[19](1800/2500): Loss: 0.2787
===> Epoch[19](1900/2500): Loss: 0.2959
===> Epoch[19](2000/2500): Loss: 0.3020
===> Epoch[19](2100/2500): Loss: 0.2947
===> Epoch[19](2200/2500): Loss: 0.3362
===> Epoch[19](2300/2500): Loss: 0.2820
===> Epoch[19](2400/2500): Loss: 0.3069
===> Epoch[19](2500/2500): Loss: 0.2955
===> Epoch 19 Complete: Avg. Loss: 0.2937
===> Timestamp: [2025-08-03 20:58:00]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.3010
===> Epoch[19](200/2500): Loss: 0.3323
===> Epoch[19](300/2500): Loss: 0.2710
===> Epoch[19](400/2500): Loss: 0.2965
===> Epoch[19](500/2500): Loss: 0.3121
===> Epoch[19](600/2500): Loss: 0.2913
===> Epoch[19](700/2500): Loss: 0.2806
===> Epoch[19](800/2500): Loss: 0.3116
===> Epoch[19](900/2500): Loss: 0.3044
===> Epoch[19](1000/2500): Loss: 0.3074
===> Epoch[19](1100/2500): Loss: 0.2701
===> Epoch[19](1200/2500): Loss: 0.3104
===> Epoch[19](1300/2500): Loss: 0.2835
===> Epoch[19](1400/2500): Loss: 0.3152
===> Epoch[19](1500/2500): Loss: 0.2962
===> Epoch[19](1600/2500): Loss: 0.2954
===> Epoch[19](1700/2500): Loss: 0.3186
===> Epoch[19](1800/2500): Loss: 0.2787
===> Epoch[19](1900/2500): Loss: 0.2959
===> Epoch[19](2000/2500): Loss: 0.3020
===> Epoch[19](2100/2500): Loss: 0.2947
===> Epoch[19](2200/2500): Loss: 0.3362
===> Epoch[19](2300/2500): Loss: 0.2820
===> Epoch[19](2400/2500): Loss: 0.3069
===> Epoch[19](2500/2500): Loss: 0.2955
===> Epoch 19 Complete: Avg. Loss: 0.2937
===> Timestamp: [2025-08-03 20:58:00]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.3010
===> Epoch[19](200/2500): Loss: 0.3323
===> Epoch[19](300/2500): Loss: 0.2710
===> Epoch[19](400/2500): Loss: 0.2965
===> Epoch[19](500/2500): Loss: 0.3121
===> Epoch[19](600/2500): Loss: 0.2913
===> Epoch[19](700/2500): Loss: 0.2806
===> Epoch[19](800/2500): Loss: 0.3116
===> Epoch[19](900/2500): Loss: 0.3044
===> Epoch[19](1000/2500): Loss: 0.3074
===> Epoch[19](1100/2500): Loss: 0.2701
===> Epoch[19](1200/2500): Loss: 0.3104
===> Epoch[19](1300/2500): Loss: 0.2835
===> Epoch[19](1400/2500): Loss: 0.3152
===> Epoch[19](1500/2500): Loss: 0.2962
===> Epoch[19](1600/2500): Loss: 0.2954
===> Epoch[19](1700/2500): Loss: 0.3186
===> Epoch[19](1800/2500): Loss: 0.2787
===> Epoch[19](1900/2500): Loss: 0.2959
===> Epoch[19](2000/2500): Loss: 0.3020
===> Epoch[19](2100/2500): Loss: 0.2947
===> Epoch[19](2200/2500): Loss: 0.3362
===> Epoch[19](2300/2500): Loss: 0.2820
===> Epoch[19](2400/2500): Loss: 0.3069
===> Epoch[19](2500/2500): Loss: 0.2955
===> Epoch 19 Complete: Avg. Loss: 0.2937
===> Timestamp: [2025-08-03 20:58:00]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.3010
===> Epoch[19](200/2500): Loss: 0.3323
===> Epoch[19](300/2500): Loss: 0.2710
===> Epoch[19](400/2500): Loss: 0.2965
===> Epoch[19](500/2500): Loss: 0.3121
===> Epoch[19](600/2500): Loss: 0.2913
===> Epoch[19](700/2500): Loss: 0.2806
===> Epoch[19](800/2500): Loss: 0.3116
===> Epoch[19](900/2500): Loss: 0.3044
===> Epoch[19](1000/2500): Loss: 0.3074
===> Epoch[19](1100/2500): Loss: 0.2701
===> Epoch[19](1200/2500): Loss: 0.3104
===> Epoch[19](1300/2500): Loss: 0.2835
===> Epoch[19](1400/2500): Loss: 0.3152
===> Epoch[19](1500/2500): Loss: 0.2962
===> Epoch[19](1600/2500): Loss: 0.2954
===> Epoch[19](1700/2500): Loss: 0.3186
===> Epoch[19](1800/2500): Loss: 0.2787
===> Epoch[19](1900/2500): Loss: 0.2959
===> Epoch[19](2000/2500): Loss: 0.3020
===> Epoch[19](2100/2500): Loss: 0.2947
===> Epoch[19](2200/2500): Loss: 0.3362
===> Epoch[19](2300/2500): Loss: 0.2820
===> Epoch[19](2400/2500): Loss: 0.3069
===> Epoch[19](2500/2500): Loss: 0.2955
===> Epoch 19 Complete: Avg. Loss: 0.2937
===> Timestamp: [2025-08-03 20:58:00]
===> Loading train datasets
===> Epoch[19](100/2500): Loss: 0.3010
===> Epoch[19](200/2500): Loss: 0.3323
===> Epoch[19](300/2500): Loss: 0.2710
===> Epoch[19](400/2500): Loss: 0.2965
===> Epoch[19](500/2500): Loss: 0.3121
===> Epoch[19](600/2500): Loss: 0.2913
===> Epoch[19](700/2500): Loss: 0.2806
===> Epoch[19](800/2500): Loss: 0.3116
===> Epoch[19](900/2500): Loss: 0.3044
===> Epoch[19](1000/2500): Loss: 0.3074
===> Epoch[19](1100/2500): Loss: 0.2701
===> Epoch[19](1200/2500): Loss: 0.3104
===> Epoch[19](1300/2500): Loss: 0.2835
===> Epoch[19](1400/2500): Loss: 0.3152
===> Epoch[19](1500/2500): Loss: 0.2962
===> Epoch[19](1600/2500): Loss: 0.2954
===> Epoch[19](1700/2500): Loss: 0.3186
===> Epoch[19](1800/2500): Loss: 0.2787
===> Epoch[19](1900/2500): Loss: 0.2959
===> Epoch[19](2000/2500): Loss: 0.3020
===> Epoch[19](2100/2500): Loss: 0.2947
===> Epoch[19](2200/2500): Loss: 0.3362
===> Epoch[19](2300/2500): Loss: 0.2820
===> Epoch[19](2400/2500): Loss: 0.3069
===> Epoch[19](2500/2500): Loss: 0.2955
===> Epoch 19 Complete: Avg. Loss: 0.2937
===> Timestamp: [2025-08-03 20:58:00]
===> Loading train datasets
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2867
===> Epoch[20](200/2500): Loss: 0.3023
===> Epoch[20](300/2500): Loss: 0.3163
===> Epoch[20](400/2500): Loss: 0.3014
===> Epoch[20](500/2500): Loss: 0.3094
===> Epoch[20](600/2500): Loss: 0.2869
===> Epoch[20](700/2500): Loss: 0.2813
===> Epoch[20](800/2500): Loss: 0.2858
===> Epoch[20](900/2500): Loss: 0.2903
===> Epoch[20](1000/2500): Loss: 0.2823
===> Epoch[20](1100/2500): Loss: 0.2659
===> Epoch[20](1200/2500): Loss: 0.2947
===> Epoch[20](1300/2500): Loss: 0.2814
===> Epoch[20](1400/2500): Loss: 0.2986
===> Epoch[20](1500/2500): Loss: 0.2862
===> Epoch[20](1600/2500): Loss: 0.2861
===> Epoch[20](1700/2500): Loss: 0.2811
===> Epoch[20](1800/2500): Loss: 0.2766
===> Epoch[20](1900/2500): Loss: 0.2943
===> Epoch[20](2000/2500): Loss: 0.2658
===> Epoch[20](2100/2500): Loss: 0.3007
===> Epoch[20](2200/2500): Loss: 0.2728
===> Epoch[20](2300/2500): Loss: 0.2856
===> Epoch[20](2400/2500): Loss: 0.3006
===> Epoch[20](2500/2500): Loss: 0.2845
===> Epoch 20 Complete: Avg. Loss: 0.2927
===> Timestamp: [2025-08-03 21:02:33]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2867
===> Epoch[20](200/2500): Loss: 0.3023
===> Epoch[20](300/2500): Loss: 0.3163
===> Epoch[20](400/2500): Loss: 0.3014
===> Epoch[20](500/2500): Loss: 0.3094
===> Epoch[20](600/2500): Loss: 0.2869
===> Epoch[20](700/2500): Loss: 0.2813
===> Epoch[20](800/2500): Loss: 0.2858
===> Epoch[20](900/2500): Loss: 0.2903
===> Epoch[20](1000/2500): Loss: 0.2823
===> Epoch[20](1100/2500): Loss: 0.2659
===> Epoch[20](1200/2500): Loss: 0.2947
===> Epoch[20](1300/2500): Loss: 0.2814
===> Epoch[20](1400/2500): Loss: 0.2986
===> Epoch[20](1500/2500): Loss: 0.2862
===> Epoch[20](1600/2500): Loss: 0.2861
===> Epoch[20](1700/2500): Loss: 0.2811
===> Epoch[20](1800/2500): Loss: 0.2766
===> Epoch[20](1900/2500): Loss: 0.2943
===> Epoch[20](2000/2500): Loss: 0.2658
===> Epoch[20](2100/2500): Loss: 0.3007
===> Epoch[20](2200/2500): Loss: 0.2728
===> Epoch[20](2300/2500): Loss: 0.2856
===> Epoch[20](2400/2500): Loss: 0.3006
===> Epoch[20](2500/2500): Loss: 0.2845
===> Epoch 20 Complete: Avg. Loss: 0.2927
===> Timestamp: [2025-08-03 21:02:33]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2867
===> Epoch[20](200/2500): Loss: 0.3023
===> Epoch[20](300/2500): Loss: 0.3163
===> Epoch[20](400/2500): Loss: 0.3014
===> Epoch[20](500/2500): Loss: 0.3094
===> Epoch[20](600/2500): Loss: 0.2869
===> Epoch[20](700/2500): Loss: 0.2813
===> Epoch[20](800/2500): Loss: 0.2858
===> Epoch[20](900/2500): Loss: 0.2903
===> Epoch[20](1000/2500): Loss: 0.2823
===> Epoch[20](1100/2500): Loss: 0.2659
===> Epoch[20](1200/2500): Loss: 0.2947
===> Epoch[20](1300/2500): Loss: 0.2814
===> Epoch[20](1400/2500): Loss: 0.2986
===> Epoch[20](1500/2500): Loss: 0.2862
===> Epoch[20](1600/2500): Loss: 0.2861
===> Epoch[20](1700/2500): Loss: 0.2811
===> Epoch[20](1800/2500): Loss: 0.2766
===> Epoch[20](1900/2500): Loss: 0.2943
===> Epoch[20](2000/2500): Loss: 0.2658
===> Epoch[20](2100/2500): Loss: 0.3007
===> Epoch[20](2200/2500): Loss: 0.2728
===> Epoch[20](2300/2500): Loss: 0.2856
===> Epoch[20](2400/2500): Loss: 0.3006
===> Epoch[20](2500/2500): Loss: 0.2845
===> Epoch 20 Complete: Avg. Loss: 0.2927
===> Timestamp: [2025-08-03 21:02:33]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2867
===> Epoch[20](200/2500): Loss: 0.3023
===> Epoch[20](300/2500): Loss: 0.3163
===> Epoch[20](400/2500): Loss: 0.3014
===> Epoch[20](500/2500): Loss: 0.3094
===> Epoch[20](600/2500): Loss: 0.2869
===> Epoch[20](700/2500): Loss: 0.2813
===> Epoch[20](800/2500): Loss: 0.2858
===> Epoch[20](900/2500): Loss: 0.2903
===> Epoch[20](1000/2500): Loss: 0.2823
===> Epoch[20](1100/2500): Loss: 0.2659
===> Epoch[20](1200/2500): Loss: 0.2947
===> Epoch[20](1300/2500): Loss: 0.2814
===> Epoch[20](1400/2500): Loss: 0.2986
===> Epoch[20](1500/2500): Loss: 0.2862
===> Epoch[20](1600/2500): Loss: 0.2861
===> Epoch[20](1700/2500): Loss: 0.2811
===> Epoch[20](1800/2500): Loss: 0.2766
===> Epoch[20](1900/2500): Loss: 0.2943
===> Epoch[20](2000/2500): Loss: 0.2658
===> Epoch[20](2100/2500): Loss: 0.3007
===> Epoch[20](2200/2500): Loss: 0.2728
===> Epoch[20](2300/2500): Loss: 0.2856
===> Epoch[20](2400/2500): Loss: 0.3006
===> Epoch[20](2500/2500): Loss: 0.2845
===> Epoch 20 Complete: Avg. Loss: 0.2927
===> Timestamp: [2025-08-03 21:02:33]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2867
===> Epoch[20](200/2500): Loss: 0.3023
===> Epoch[20](300/2500): Loss: 0.3163
===> Epoch[20](400/2500): Loss: 0.3014
===> Epoch[20](500/2500): Loss: 0.3094
===> Epoch[20](600/2500): Loss: 0.2869
===> Epoch[20](700/2500): Loss: 0.2813
===> Epoch[20](800/2500): Loss: 0.2858
===> Epoch[20](900/2500): Loss: 0.2903
===> Epoch[20](1000/2500): Loss: 0.2823
===> Epoch[20](1100/2500): Loss: 0.2659
===> Epoch[20](1200/2500): Loss: 0.2947
===> Epoch[20](1300/2500): Loss: 0.2814
===> Epoch[20](1400/2500): Loss: 0.2986
===> Epoch[20](1500/2500): Loss: 0.2862
===> Epoch[20](1600/2500): Loss: 0.2861
===> Epoch[20](1700/2500): Loss: 0.2811
===> Epoch[20](1800/2500): Loss: 0.2766
===> Epoch[20](1900/2500): Loss: 0.2943
===> Epoch[20](2000/2500): Loss: 0.2658
===> Epoch[20](2100/2500): Loss: 0.3007
===> Epoch[20](2200/2500): Loss: 0.2728
===> Epoch[20](2300/2500): Loss: 0.2856
===> Epoch[20](2400/2500): Loss: 0.3006
===> Epoch[20](2500/2500): Loss: 0.2845
===> Epoch 20 Complete: Avg. Loss: 0.2927
===> Timestamp: [2025-08-03 21:02:33]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2867
===> Epoch[20](200/2500): Loss: 0.3023
===> Epoch[20](300/2500): Loss: 0.3163
===> Epoch[20](400/2500): Loss: 0.3014
===> Epoch[20](500/2500): Loss: 0.3094
===> Epoch[20](600/2500): Loss: 0.2869
===> Epoch[20](700/2500): Loss: 0.2813
===> Epoch[20](800/2500): Loss: 0.2858
===> Epoch[20](900/2500): Loss: 0.2903
===> Epoch[20](1000/2500): Loss: 0.2823
===> Epoch[20](1100/2500): Loss: 0.2659
===> Epoch[20](1200/2500): Loss: 0.2947
===> Epoch[20](1300/2500): Loss: 0.2814
===> Epoch[20](1400/2500): Loss: 0.2986
===> Epoch[20](1500/2500): Loss: 0.2862
===> Epoch[20](1600/2500): Loss: 0.2861
===> Epoch[20](1700/2500): Loss: 0.2811
===> Epoch[20](1800/2500): Loss: 0.2766
===> Epoch[20](1900/2500): Loss: 0.2943
===> Epoch[20](2000/2500): Loss: 0.2658
===> Epoch[20](2100/2500): Loss: 0.3007
===> Epoch[20](2200/2500): Loss: 0.2728
===> Epoch[20](2300/2500): Loss: 0.2856
===> Epoch[20](2400/2500): Loss: 0.3006
===> Epoch[20](2500/2500): Loss: 0.2845
===> Epoch 20 Complete: Avg. Loss: 0.2927
===> Timestamp: [2025-08-03 21:02:33]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2867
===> Epoch[20](200/2500): Loss: 0.3023
===> Epoch[20](300/2500): Loss: 0.3163
===> Epoch[20](400/2500): Loss: 0.3014
===> Epoch[20](500/2500): Loss: 0.3094
===> Epoch[20](600/2500): Loss: 0.2869
===> Epoch[20](700/2500): Loss: 0.2813
===> Epoch[20](800/2500): Loss: 0.2858
===> Epoch[20](900/2500): Loss: 0.2903
===> Epoch[20](1000/2500): Loss: 0.2823
===> Epoch[20](1100/2500): Loss: 0.2659
===> Epoch[20](1200/2500): Loss: 0.2947
===> Epoch[20](1300/2500): Loss: 0.2814
===> Epoch[20](1400/2500): Loss: 0.2986
===> Epoch[20](1500/2500): Loss: 0.2862
===> Epoch[20](1600/2500): Loss: 0.2861
===> Epoch[20](1700/2500): Loss: 0.2811
===> Epoch[20](1800/2500): Loss: 0.2766
===> Epoch[20](1900/2500): Loss: 0.2943
===> Epoch[20](2000/2500): Loss: 0.2658
===> Epoch[20](2100/2500): Loss: 0.3007
===> Epoch[20](2200/2500): Loss: 0.2728
===> Epoch[20](2300/2500): Loss: 0.2856
===> Epoch[20](2400/2500): Loss: 0.3006
===> Epoch[20](2500/2500): Loss: 0.2845
===> Epoch 20 Complete: Avg. Loss: 0.2927
===> Timestamp: [2025-08-03 21:02:33]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2867
===> Epoch[20](200/2500): Loss: 0.3023
===> Epoch[20](300/2500): Loss: 0.3163
===> Epoch[20](400/2500): Loss: 0.3014
===> Epoch[20](500/2500): Loss: 0.3094
===> Epoch[20](600/2500): Loss: 0.2869
===> Epoch[20](700/2500): Loss: 0.2813
===> Epoch[20](800/2500): Loss: 0.2858
===> Epoch[20](900/2500): Loss: 0.2903
===> Epoch[20](1000/2500): Loss: 0.2823
===> Epoch[20](1100/2500): Loss: 0.2659
===> Epoch[20](1200/2500): Loss: 0.2947
===> Epoch[20](1300/2500): Loss: 0.2814
===> Epoch[20](1400/2500): Loss: 0.2986
===> Epoch[20](1500/2500): Loss: 0.2862
===> Epoch[20](1600/2500): Loss: 0.2861
===> Epoch[20](1700/2500): Loss: 0.2811
===> Epoch[20](1800/2500): Loss: 0.2766
===> Epoch[20](1900/2500): Loss: 0.2943
===> Epoch[20](2000/2500): Loss: 0.2658
===> Epoch[20](2100/2500): Loss: 0.3007
===> Epoch[20](2200/2500): Loss: 0.2728
===> Epoch[20](2300/2500): Loss: 0.2856
===> Epoch[20](2400/2500): Loss: 0.3006
===> Epoch[20](2500/2500): Loss: 0.2845
===> Epoch 20 Complete: Avg. Loss: 0.2927
===> Timestamp: [2025-08-03 21:02:33]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2867
===> Epoch[20](200/2500): Loss: 0.3023
===> Epoch[20](300/2500): Loss: 0.3163
===> Epoch[20](400/2500): Loss: 0.3014
===> Epoch[20](500/2500): Loss: 0.3094
===> Epoch[20](600/2500): Loss: 0.2869
===> Epoch[20](700/2500): Loss: 0.2813
===> Epoch[20](800/2500): Loss: 0.2858
===> Epoch[20](900/2500): Loss: 0.2903
===> Epoch[20](1000/2500): Loss: 0.2823
===> Epoch[20](1100/2500): Loss: 0.2659
===> Epoch[20](1200/2500): Loss: 0.2947
===> Epoch[20](1300/2500): Loss: 0.2814
===> Epoch[20](1400/2500): Loss: 0.2986
===> Epoch[20](1500/2500): Loss: 0.2862
===> Epoch[20](1600/2500): Loss: 0.2861
===> Epoch[20](1700/2500): Loss: 0.2811
===> Epoch[20](1800/2500): Loss: 0.2766
===> Epoch[20](1900/2500): Loss: 0.2943
===> Epoch[20](2000/2500): Loss: 0.2658
===> Epoch[20](2100/2500): Loss: 0.3007
===> Epoch[20](2200/2500): Loss: 0.2728
===> Epoch[20](2300/2500): Loss: 0.2856
===> Epoch[20](2400/2500): Loss: 0.3006
===> Epoch[20](2500/2500): Loss: 0.2845
===> Epoch 20 Complete: Avg. Loss: 0.2927
===> Timestamp: [2025-08-03 21:02:33]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2867
===> Epoch[20](200/2500): Loss: 0.3023
===> Epoch[20](300/2500): Loss: 0.3163
===> Epoch[20](400/2500): Loss: 0.3014
===> Epoch[20](500/2500): Loss: 0.3094
===> Epoch[20](600/2500): Loss: 0.2869
===> Epoch[20](700/2500): Loss: 0.2813
===> Epoch[20](800/2500): Loss: 0.2858
===> Epoch[20](900/2500): Loss: 0.2903
===> Epoch[20](1000/2500): Loss: 0.2823
===> Epoch[20](1100/2500): Loss: 0.2659
===> Epoch[20](1200/2500): Loss: 0.2947
===> Epoch[20](1300/2500): Loss: 0.2814
===> Epoch[20](1400/2500): Loss: 0.2986
===> Epoch[20](1500/2500): Loss: 0.2862
===> Epoch[20](1600/2500): Loss: 0.2861
===> Epoch[20](1700/2500): Loss: 0.2811
===> Epoch[20](1800/2500): Loss: 0.2766
===> Epoch[20](1900/2500): Loss: 0.2943
===> Epoch[20](2000/2500): Loss: 0.2658
===> Epoch[20](2100/2500): Loss: 0.3007
===> Epoch[20](2200/2500): Loss: 0.2728
===> Epoch[20](2300/2500): Loss: 0.2856
===> Epoch[20](2400/2500): Loss: 0.3006
===> Epoch[20](2500/2500): Loss: 0.2845
===> Epoch 20 Complete: Avg. Loss: 0.2927
===> Timestamp: [2025-08-03 21:02:33]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2867
===> Epoch[20](200/2500): Loss: 0.3023
===> Epoch[20](300/2500): Loss: 0.3163
===> Epoch[20](400/2500): Loss: 0.3014
===> Epoch[20](500/2500): Loss: 0.3094
===> Epoch[20](600/2500): Loss: 0.2869
===> Epoch[20](700/2500): Loss: 0.2813
===> Epoch[20](800/2500): Loss: 0.2858
===> Epoch[20](900/2500): Loss: 0.2903
===> Epoch[20](1000/2500): Loss: 0.2823
===> Epoch[20](1100/2500): Loss: 0.2659
===> Epoch[20](1200/2500): Loss: 0.2947
===> Epoch[20](1300/2500): Loss: 0.2814
===> Epoch[20](1400/2500): Loss: 0.2986
===> Epoch[20](1500/2500): Loss: 0.2862
===> Epoch[20](1600/2500): Loss: 0.2861
===> Epoch[20](1700/2500): Loss: 0.2811
===> Epoch[20](1800/2500): Loss: 0.2766
===> Epoch[20](1900/2500): Loss: 0.2943
===> Epoch[20](2000/2500): Loss: 0.2658
===> Epoch[20](2100/2500): Loss: 0.3007
===> Epoch[20](2200/2500): Loss: 0.2728
===> Epoch[20](2300/2500): Loss: 0.2856
===> Epoch[20](2400/2500): Loss: 0.3006
===> Epoch[20](2500/2500): Loss: 0.2845
===> Epoch 20 Complete: Avg. Loss: 0.2927
===> Timestamp: [2025-08-03 21:02:33]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2867
===> Epoch[20](200/2500): Loss: 0.3023
===> Epoch[20](300/2500): Loss: 0.3163
===> Epoch[20](400/2500): Loss: 0.3014
===> Epoch[20](500/2500): Loss: 0.3094
===> Epoch[20](600/2500): Loss: 0.2869
===> Epoch[20](700/2500): Loss: 0.2813
===> Epoch[20](800/2500): Loss: 0.2858
===> Epoch[20](900/2500): Loss: 0.2903
===> Epoch[20](1000/2500): Loss: 0.2823
===> Epoch[20](1100/2500): Loss: 0.2659
===> Epoch[20](1200/2500): Loss: 0.2947
===> Epoch[20](1300/2500): Loss: 0.2814
===> Epoch[20](1400/2500): Loss: 0.2986
===> Epoch[20](1500/2500): Loss: 0.2862
===> Epoch[20](1600/2500): Loss: 0.2861
===> Epoch[20](1700/2500): Loss: 0.2811
===> Epoch[20](1800/2500): Loss: 0.2766
===> Epoch[20](1900/2500): Loss: 0.2943
===> Epoch[20](2000/2500): Loss: 0.2658
===> Epoch[20](2100/2500): Loss: 0.3007
===> Epoch[20](2200/2500): Loss: 0.2728
===> Epoch[20](2300/2500): Loss: 0.2856
===> Epoch[20](2400/2500): Loss: 0.3006
===> Epoch[20](2500/2500): Loss: 0.2845
===> Epoch 20 Complete: Avg. Loss: 0.2927
===> Timestamp: [2025-08-03 21:02:33]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2867
===> Epoch[20](200/2500): Loss: 0.3023
===> Epoch[20](300/2500): Loss: 0.3163
===> Epoch[20](400/2500): Loss: 0.3014
===> Epoch[20](500/2500): Loss: 0.3094
===> Epoch[20](600/2500): Loss: 0.2869
===> Epoch[20](700/2500): Loss: 0.2813
===> Epoch[20](800/2500): Loss: 0.2858
===> Epoch[20](900/2500): Loss: 0.2903
===> Epoch[20](1000/2500): Loss: 0.2823
===> Epoch[20](1100/2500): Loss: 0.2659
===> Epoch[20](1200/2500): Loss: 0.2947
===> Epoch[20](1300/2500): Loss: 0.2814
===> Epoch[20](1400/2500): Loss: 0.2986
===> Epoch[20](1500/2500): Loss: 0.2862
===> Epoch[20](1600/2500): Loss: 0.2861
===> Epoch[20](1700/2500): Loss: 0.2811
===> Epoch[20](1800/2500): Loss: 0.2766
===> Epoch[20](1900/2500): Loss: 0.2943
===> Epoch[20](2000/2500): Loss: 0.2658
===> Epoch[20](2100/2500): Loss: 0.3007
===> Epoch[20](2200/2500): Loss: 0.2728
===> Epoch[20](2300/2500): Loss: 0.2856
===> Epoch[20](2400/2500): Loss: 0.3006
===> Epoch[20](2500/2500): Loss: 0.2845
===> Epoch 20 Complete: Avg. Loss: 0.2927
===> Timestamp: [2025-08-03 21:02:33]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2867
===> Epoch[20](200/2500): Loss: 0.3023
===> Epoch[20](300/2500): Loss: 0.3163
===> Epoch[20](400/2500): Loss: 0.3014
===> Epoch[20](500/2500): Loss: 0.3094
===> Epoch[20](600/2500): Loss: 0.2869
===> Epoch[20](700/2500): Loss: 0.2813
===> Epoch[20](800/2500): Loss: 0.2858
===> Epoch[20](900/2500): Loss: 0.2903
===> Epoch[20](1000/2500): Loss: 0.2823
===> Epoch[20](1100/2500): Loss: 0.2659
===> Epoch[20](1200/2500): Loss: 0.2947
===> Epoch[20](1300/2500): Loss: 0.2814
===> Epoch[20](1400/2500): Loss: 0.2986
===> Epoch[20](1500/2500): Loss: 0.2862
===> Epoch[20](1600/2500): Loss: 0.2861
===> Epoch[20](1700/2500): Loss: 0.2811
===> Epoch[20](1800/2500): Loss: 0.2766
===> Epoch[20](1900/2500): Loss: 0.2943
===> Epoch[20](2000/2500): Loss: 0.2658
===> Epoch[20](2100/2500): Loss: 0.3007
===> Epoch[20](2200/2500): Loss: 0.2728
===> Epoch[20](2300/2500): Loss: 0.2856
===> Epoch[20](2400/2500): Loss: 0.3006
===> Epoch[20](2500/2500): Loss: 0.2845
===> Epoch 20 Complete: Avg. Loss: 0.2927
===> Timestamp: [2025-08-03 21:02:33]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2867
===> Epoch[20](200/2500): Loss: 0.3023
===> Epoch[20](300/2500): Loss: 0.3163
===> Epoch[20](400/2500): Loss: 0.3014
===> Epoch[20](500/2500): Loss: 0.3094
===> Epoch[20](600/2500): Loss: 0.2869
===> Epoch[20](700/2500): Loss: 0.2813
===> Epoch[20](800/2500): Loss: 0.2858
===> Epoch[20](900/2500): Loss: 0.2903
===> Epoch[20](1000/2500): Loss: 0.2823
===> Epoch[20](1100/2500): Loss: 0.2659
===> Epoch[20](1200/2500): Loss: 0.2947
===> Epoch[20](1300/2500): Loss: 0.2814
===> Epoch[20](1400/2500): Loss: 0.2986
===> Epoch[20](1500/2500): Loss: 0.2862
===> Epoch[20](1600/2500): Loss: 0.2861
===> Epoch[20](1700/2500): Loss: 0.2811
===> Epoch[20](1800/2500): Loss: 0.2766
===> Epoch[20](1900/2500): Loss: 0.2943
===> Epoch[20](2000/2500): Loss: 0.2658
===> Epoch[20](2100/2500): Loss: 0.3007
===> Epoch[20](2200/2500): Loss: 0.2728
===> Epoch[20](2300/2500): Loss: 0.2856
===> Epoch[20](2400/2500): Loss: 0.3006
===> Epoch[20](2500/2500): Loss: 0.2845
===> Epoch 20 Complete: Avg. Loss: 0.2927
===> Timestamp: [2025-08-03 21:02:33]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2867
===> Epoch[20](200/2500): Loss: 0.3023
===> Epoch[20](300/2500): Loss: 0.3163
===> Epoch[20](400/2500): Loss: 0.3014
===> Epoch[20](500/2500): Loss: 0.3094
===> Epoch[20](600/2500): Loss: 0.2869
===> Epoch[20](700/2500): Loss: 0.2813
===> Epoch[20](800/2500): Loss: 0.2858
===> Epoch[20](900/2500): Loss: 0.2903
===> Epoch[20](1000/2500): Loss: 0.2823
===> Epoch[20](1100/2500): Loss: 0.2659
===> Epoch[20](1200/2500): Loss: 0.2947
===> Epoch[20](1300/2500): Loss: 0.2814
===> Epoch[20](1400/2500): Loss: 0.2986
===> Epoch[20](1500/2500): Loss: 0.2862
===> Epoch[20](1600/2500): Loss: 0.2861
===> Epoch[20](1700/2500): Loss: 0.2811
===> Epoch[20](1800/2500): Loss: 0.2766
===> Epoch[20](1900/2500): Loss: 0.2943
===> Epoch[20](2000/2500): Loss: 0.2658
===> Epoch[20](2100/2500): Loss: 0.3007
===> Epoch[20](2200/2500): Loss: 0.2728
===> Epoch[20](2300/2500): Loss: 0.2856
===> Epoch[20](2400/2500): Loss: 0.3006
===> Epoch[20](2500/2500): Loss: 0.2845
===> Epoch 20 Complete: Avg. Loss: 0.2927
===> Timestamp: [2025-08-03 21:02:33]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2867
===> Epoch[20](200/2500): Loss: 0.3023
===> Epoch[20](300/2500): Loss: 0.3163
===> Epoch[20](400/2500): Loss: 0.3014
===> Epoch[20](500/2500): Loss: 0.3094
===> Epoch[20](600/2500): Loss: 0.2869
===> Epoch[20](700/2500): Loss: 0.2813
===> Epoch[20](800/2500): Loss: 0.2858
===> Epoch[20](900/2500): Loss: 0.2903
===> Epoch[20](1000/2500): Loss: 0.2823
===> Epoch[20](1100/2500): Loss: 0.2659
===> Epoch[20](1200/2500): Loss: 0.2947
===> Epoch[20](1300/2500): Loss: 0.2814
===> Epoch[20](1400/2500): Loss: 0.2986
===> Epoch[20](1500/2500): Loss: 0.2862
===> Epoch[20](1600/2500): Loss: 0.2861
===> Epoch[20](1700/2500): Loss: 0.2811
===> Epoch[20](1800/2500): Loss: 0.2766
===> Epoch[20](1900/2500): Loss: 0.2943
===> Epoch[20](2000/2500): Loss: 0.2658
===> Epoch[20](2100/2500): Loss: 0.3007
===> Epoch[20](2200/2500): Loss: 0.2728
===> Epoch[20](2300/2500): Loss: 0.2856
===> Epoch[20](2400/2500): Loss: 0.3006
===> Epoch[20](2500/2500): Loss: 0.2845
===> Epoch 20 Complete: Avg. Loss: 0.2927
===> Timestamp: [2025-08-03 21:02:33]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2867
===> Epoch[20](200/2500): Loss: 0.3023
===> Epoch[20](300/2500): Loss: 0.3163
===> Epoch[20](400/2500): Loss: 0.3014
===> Epoch[20](500/2500): Loss: 0.3094
===> Epoch[20](600/2500): Loss: 0.2869
===> Epoch[20](700/2500): Loss: 0.2813
===> Epoch[20](800/2500): Loss: 0.2858
===> Epoch[20](900/2500): Loss: 0.2903
===> Epoch[20](1000/2500): Loss: 0.2823
===> Epoch[20](1100/2500): Loss: 0.2659
===> Epoch[20](1200/2500): Loss: 0.2947
===> Epoch[20](1300/2500): Loss: 0.2814
===> Epoch[20](1400/2500): Loss: 0.2986
===> Epoch[20](1500/2500): Loss: 0.2862
===> Epoch[20](1600/2500): Loss: 0.2861
===> Epoch[20](1700/2500): Loss: 0.2811
===> Epoch[20](1800/2500): Loss: 0.2766
===> Epoch[20](1900/2500): Loss: 0.2943
===> Epoch[20](2000/2500): Loss: 0.2658
===> Epoch[20](2100/2500): Loss: 0.3007
===> Epoch[20](2200/2500): Loss: 0.2728
===> Epoch[20](2300/2500): Loss: 0.2856
===> Epoch[20](2400/2500): Loss: 0.3006
===> Epoch[20](2500/2500): Loss: 0.2845
===> Epoch 20 Complete: Avg. Loss: 0.2927
===> Timestamp: [2025-08-03 21:02:33]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2867
===> Epoch[20](200/2500): Loss: 0.3023
===> Epoch[20](300/2500): Loss: 0.3163
===> Epoch[20](400/2500): Loss: 0.3014
===> Epoch[20](500/2500): Loss: 0.3094
===> Epoch[20](600/2500): Loss: 0.2869
===> Epoch[20](700/2500): Loss: 0.2813
===> Epoch[20](800/2500): Loss: 0.2858
===> Epoch[20](900/2500): Loss: 0.2903
===> Epoch[20](1000/2500): Loss: 0.2823
===> Epoch[20](1100/2500): Loss: 0.2659
===> Epoch[20](1200/2500): Loss: 0.2947
===> Epoch[20](1300/2500): Loss: 0.2814
===> Epoch[20](1400/2500): Loss: 0.2986
===> Epoch[20](1500/2500): Loss: 0.2862
===> Epoch[20](1600/2500): Loss: 0.2861
===> Epoch[20](1700/2500): Loss: 0.2811
===> Epoch[20](1800/2500): Loss: 0.2766
===> Epoch[20](1900/2500): Loss: 0.2943
===> Epoch[20](2000/2500): Loss: 0.2658
===> Epoch[20](2100/2500): Loss: 0.3007
===> Epoch[20](2200/2500): Loss: 0.2728
===> Epoch[20](2300/2500): Loss: 0.2856
===> Epoch[20](2400/2500): Loss: 0.3006
===> Epoch[20](2500/2500): Loss: 0.2845
===> Epoch 20 Complete: Avg. Loss: 0.2927
===> Timestamp: [2025-08-03 21:02:33]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Epoch[20](100/2500): Loss: 0.2867
===> Epoch[20](200/2500): Loss: 0.3023
===> Epoch[20](300/2500): Loss: 0.3163
===> Epoch[20](400/2500): Loss: 0.3014
===> Epoch[20](500/2500): Loss: 0.3094
===> Epoch[20](600/2500): Loss: 0.2869
===> Epoch[20](700/2500): Loss: 0.2813
===> Epoch[20](800/2500): Loss: 0.2858
===> Epoch[20](900/2500): Loss: 0.2903
===> Epoch[20](1000/2500): Loss: 0.2823
===> Epoch[20](1100/2500): Loss: 0.2659
===> Epoch[20](1200/2500): Loss: 0.2947
===> Epoch[20](1300/2500): Loss: 0.2814
===> Epoch[20](1400/2500): Loss: 0.2986
===> Epoch[20](1500/2500): Loss: 0.2862
===> Epoch[20](1600/2500): Loss: 0.2861
===> Epoch[20](1700/2500): Loss: 0.2811
===> Epoch[20](1800/2500): Loss: 0.2766
===> Epoch[20](1900/2500): Loss: 0.2943
===> Epoch[20](2000/2500): Loss: 0.2658
===> Epoch[20](2100/2500): Loss: 0.3007
===> Epoch[20](2200/2500): Loss: 0.2728
===> Epoch[20](2300/2500): Loss: 0.2856
===> Epoch[20](2400/2500): Loss: 0.3006
===> Epoch[20](2500/2500): Loss: 0.2845
===> Epoch 20 Complete: Avg. Loss: 0.2927
===> Timestamp: [2025-08-03 21:02:33]
Checkpoint saved to TrainedNet/_epoch_20.pth
===> Loading train datasets
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2778
===> Epoch[21](200/2500): Loss: 0.3054
===> Epoch[21](300/2500): Loss: 0.3164
===> Epoch[21](400/2500): Loss: 0.2605
===> Epoch[21](500/2500): Loss: 0.2899
===> Epoch[21](600/2500): Loss: 0.2777
===> Epoch[21](700/2500): Loss: 0.3215
===> Epoch[21](800/2500): Loss: 0.2978
===> Epoch[21](900/2500): Loss: 0.3204
===> Epoch[21](1000/2500): Loss: 0.2808
===> Epoch[21](1100/2500): Loss: 0.2853
===> Epoch[21](1200/2500): Loss: 0.3019
===> Epoch[21](1300/2500): Loss: 0.3022
===> Epoch[21](1400/2500): Loss: 0.3062
===> Epoch[21](1500/2500): Loss: 0.2803
===> Epoch[21](1600/2500): Loss: 0.3022
===> Epoch[21](1700/2500): Loss: 0.3095
===> Epoch[21](1800/2500): Loss: 0.3031
===> Epoch[21](1900/2500): Loss: 0.2893
===> Epoch[21](2000/2500): Loss: 0.2924
===> Epoch[21](2100/2500): Loss: 0.2892
===> Epoch[21](2200/2500): Loss: 0.2880
===> Epoch[21](2300/2500): Loss: 0.2762
===> Epoch[21](2400/2500): Loss: 0.2734
===> Epoch[21](2500/2500): Loss: 0.2813
===> Epoch 21 Complete: Avg. Loss: 0.2920
===> Timestamp: [2025-08-03 21:07:07]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2778
===> Epoch[21](200/2500): Loss: 0.3054
===> Epoch[21](300/2500): Loss: 0.3164
===> Epoch[21](400/2500): Loss: 0.2605
===> Epoch[21](500/2500): Loss: 0.2899
===> Epoch[21](600/2500): Loss: 0.2777
===> Epoch[21](700/2500): Loss: 0.3215
===> Epoch[21](800/2500): Loss: 0.2978
===> Epoch[21](900/2500): Loss: 0.3204
===> Epoch[21](1000/2500): Loss: 0.2808
===> Epoch[21](1100/2500): Loss: 0.2853
===> Epoch[21](1200/2500): Loss: 0.3019
===> Epoch[21](1300/2500): Loss: 0.3022
===> Epoch[21](1400/2500): Loss: 0.3062
===> Epoch[21](1500/2500): Loss: 0.2803
===> Epoch[21](1600/2500): Loss: 0.3022
===> Epoch[21](1700/2500): Loss: 0.3095
===> Epoch[21](1800/2500): Loss: 0.3031
===> Epoch[21](1900/2500): Loss: 0.2893
===> Epoch[21](2000/2500): Loss: 0.2924
===> Epoch[21](2100/2500): Loss: 0.2892
===> Epoch[21](2200/2500): Loss: 0.2880
===> Epoch[21](2300/2500): Loss: 0.2762
===> Epoch[21](2400/2500): Loss: 0.2734
===> Epoch[21](2500/2500): Loss: 0.2813
===> Epoch 21 Complete: Avg. Loss: 0.2920
===> Timestamp: [2025-08-03 21:07:07]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2778
===> Epoch[21](200/2500): Loss: 0.3054
===> Epoch[21](300/2500): Loss: 0.3164
===> Epoch[21](400/2500): Loss: 0.2605
===> Epoch[21](500/2500): Loss: 0.2899
===> Epoch[21](600/2500): Loss: 0.2777
===> Epoch[21](700/2500): Loss: 0.3215
===> Epoch[21](800/2500): Loss: 0.2978
===> Epoch[21](900/2500): Loss: 0.3204
===> Epoch[21](1000/2500): Loss: 0.2808
===> Epoch[21](1100/2500): Loss: 0.2853
===> Epoch[21](1200/2500): Loss: 0.3019
===> Epoch[21](1300/2500): Loss: 0.3022
===> Epoch[21](1400/2500): Loss: 0.3062
===> Epoch[21](1500/2500): Loss: 0.2803
===> Epoch[21](1600/2500): Loss: 0.3022
===> Epoch[21](1700/2500): Loss: 0.3095
===> Epoch[21](1800/2500): Loss: 0.3031
===> Epoch[21](1900/2500): Loss: 0.2893
===> Epoch[21](2000/2500): Loss: 0.2924
===> Epoch[21](2100/2500): Loss: 0.2892
===> Epoch[21](2200/2500): Loss: 0.2880
===> Epoch[21](2300/2500): Loss: 0.2762
===> Epoch[21](2400/2500): Loss: 0.2734
===> Epoch[21](2500/2500): Loss: 0.2813
===> Epoch 21 Complete: Avg. Loss: 0.2920
===> Timestamp: [2025-08-03 21:07:07]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2778
===> Epoch[21](200/2500): Loss: 0.3054
===> Epoch[21](300/2500): Loss: 0.3164
===> Epoch[21](400/2500): Loss: 0.2605
===> Epoch[21](500/2500): Loss: 0.2899
===> Epoch[21](600/2500): Loss: 0.2777
===> Epoch[21](700/2500): Loss: 0.3215
===> Epoch[21](800/2500): Loss: 0.2978
===> Epoch[21](900/2500): Loss: 0.3204
===> Epoch[21](1000/2500): Loss: 0.2808
===> Epoch[21](1100/2500): Loss: 0.2853
===> Epoch[21](1200/2500): Loss: 0.3019
===> Epoch[21](1300/2500): Loss: 0.3022
===> Epoch[21](1400/2500): Loss: 0.3062
===> Epoch[21](1500/2500): Loss: 0.2803
===> Epoch[21](1600/2500): Loss: 0.3022
===> Epoch[21](1700/2500): Loss: 0.3095
===> Epoch[21](1800/2500): Loss: 0.3031
===> Epoch[21](1900/2500): Loss: 0.2893
===> Epoch[21](2000/2500): Loss: 0.2924
===> Epoch[21](2100/2500): Loss: 0.2892
===> Epoch[21](2200/2500): Loss: 0.2880
===> Epoch[21](2300/2500): Loss: 0.2762
===> Epoch[21](2400/2500): Loss: 0.2734
===> Epoch[21](2500/2500): Loss: 0.2813
===> Epoch 21 Complete: Avg. Loss: 0.2920
===> Timestamp: [2025-08-03 21:07:07]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2778
===> Epoch[21](200/2500): Loss: 0.3054
===> Epoch[21](300/2500): Loss: 0.3164
===> Epoch[21](400/2500): Loss: 0.2605
===> Epoch[21](500/2500): Loss: 0.2899
===> Epoch[21](600/2500): Loss: 0.2777
===> Epoch[21](700/2500): Loss: 0.3215
===> Epoch[21](800/2500): Loss: 0.2978
===> Epoch[21](900/2500): Loss: 0.3204
===> Epoch[21](1000/2500): Loss: 0.2808
===> Epoch[21](1100/2500): Loss: 0.2853
===> Epoch[21](1200/2500): Loss: 0.3019
===> Epoch[21](1300/2500): Loss: 0.3022
===> Epoch[21](1400/2500): Loss: 0.3062
===> Epoch[21](1500/2500): Loss: 0.2803
===> Epoch[21](1600/2500): Loss: 0.3022
===> Epoch[21](1700/2500): Loss: 0.3095
===> Epoch[21](1800/2500): Loss: 0.3031
===> Epoch[21](1900/2500): Loss: 0.2893
===> Epoch[21](2000/2500): Loss: 0.2924
===> Epoch[21](2100/2500): Loss: 0.2892
===> Epoch[21](2200/2500): Loss: 0.2880
===> Epoch[21](2300/2500): Loss: 0.2762
===> Epoch[21](2400/2500): Loss: 0.2734
===> Epoch[21](2500/2500): Loss: 0.2813
===> Epoch 21 Complete: Avg. Loss: 0.2920
===> Timestamp: [2025-08-03 21:07:07]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2778
===> Epoch[21](200/2500): Loss: 0.3054
===> Epoch[21](300/2500): Loss: 0.3164
===> Epoch[21](400/2500): Loss: 0.2605
===> Epoch[21](500/2500): Loss: 0.2899
===> Epoch[21](600/2500): Loss: 0.2777
===> Epoch[21](700/2500): Loss: 0.3215
===> Epoch[21](800/2500): Loss: 0.2978
===> Epoch[21](900/2500): Loss: 0.3204
===> Epoch[21](1000/2500): Loss: 0.2808
===> Epoch[21](1100/2500): Loss: 0.2853
===> Epoch[21](1200/2500): Loss: 0.3019
===> Epoch[21](1300/2500): Loss: 0.3022
===> Epoch[21](1400/2500): Loss: 0.3062
===> Epoch[21](1500/2500): Loss: 0.2803
===> Epoch[21](1600/2500): Loss: 0.3022
===> Epoch[21](1700/2500): Loss: 0.3095
===> Epoch[21](1800/2500): Loss: 0.3031
===> Epoch[21](1900/2500): Loss: 0.2893
===> Epoch[21](2000/2500): Loss: 0.2924
===> Epoch[21](2100/2500): Loss: 0.2892
===> Epoch[21](2200/2500): Loss: 0.2880
===> Epoch[21](2300/2500): Loss: 0.2762
===> Epoch[21](2400/2500): Loss: 0.2734
===> Epoch[21](2500/2500): Loss: 0.2813
===> Epoch 21 Complete: Avg. Loss: 0.2920
===> Timestamp: [2025-08-03 21:07:07]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2778
===> Epoch[21](200/2500): Loss: 0.3054
===> Epoch[21](300/2500): Loss: 0.3164
===> Epoch[21](400/2500): Loss: 0.2605
===> Epoch[21](500/2500): Loss: 0.2899
===> Epoch[21](600/2500): Loss: 0.2777
===> Epoch[21](700/2500): Loss: 0.3215
===> Epoch[21](800/2500): Loss: 0.2978
===> Epoch[21](900/2500): Loss: 0.3204
===> Epoch[21](1000/2500): Loss: 0.2808
===> Epoch[21](1100/2500): Loss: 0.2853
===> Epoch[21](1200/2500): Loss: 0.3019
===> Epoch[21](1300/2500): Loss: 0.3022
===> Epoch[21](1400/2500): Loss: 0.3062
===> Epoch[21](1500/2500): Loss: 0.2803
===> Epoch[21](1600/2500): Loss: 0.3022
===> Epoch[21](1700/2500): Loss: 0.3095
===> Epoch[21](1800/2500): Loss: 0.3031
===> Epoch[21](1900/2500): Loss: 0.2893
===> Epoch[21](2000/2500): Loss: 0.2924
===> Epoch[21](2100/2500): Loss: 0.2892
===> Epoch[21](2200/2500): Loss: 0.2880
===> Epoch[21](2300/2500): Loss: 0.2762
===> Epoch[21](2400/2500): Loss: 0.2734
===> Epoch[21](2500/2500): Loss: 0.2813
===> Epoch 21 Complete: Avg. Loss: 0.2920
===> Timestamp: [2025-08-03 21:07:07]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2778
===> Epoch[21](200/2500): Loss: 0.3054
===> Epoch[21](300/2500): Loss: 0.3164
===> Epoch[21](400/2500): Loss: 0.2605
===> Epoch[21](500/2500): Loss: 0.2899
===> Epoch[21](600/2500): Loss: 0.2777
===> Epoch[21](700/2500): Loss: 0.3215
===> Epoch[21](800/2500): Loss: 0.2978
===> Epoch[21](900/2500): Loss: 0.3204
===> Epoch[21](1000/2500): Loss: 0.2808
===> Epoch[21](1100/2500): Loss: 0.2853
===> Epoch[21](1200/2500): Loss: 0.3019
===> Epoch[21](1300/2500): Loss: 0.3022
===> Epoch[21](1400/2500): Loss: 0.3062
===> Epoch[21](1500/2500): Loss: 0.2803
===> Epoch[21](1600/2500): Loss: 0.3022
===> Epoch[21](1700/2500): Loss: 0.3095
===> Epoch[21](1800/2500): Loss: 0.3031
===> Epoch[21](1900/2500): Loss: 0.2893
===> Epoch[21](2000/2500): Loss: 0.2924
===> Epoch[21](2100/2500): Loss: 0.2892
===> Epoch[21](2200/2500): Loss: 0.2880
===> Epoch[21](2300/2500): Loss: 0.2762
===> Epoch[21](2400/2500): Loss: 0.2734
===> Epoch[21](2500/2500): Loss: 0.2813
===> Epoch 21 Complete: Avg. Loss: 0.2920
===> Timestamp: [2025-08-03 21:07:07]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2778
===> Epoch[21](200/2500): Loss: 0.3054
===> Epoch[21](300/2500): Loss: 0.3164
===> Epoch[21](400/2500): Loss: 0.2605
===> Epoch[21](500/2500): Loss: 0.2899
===> Epoch[21](600/2500): Loss: 0.2777
===> Epoch[21](700/2500): Loss: 0.3215
===> Epoch[21](800/2500): Loss: 0.2978
===> Epoch[21](900/2500): Loss: 0.3204
===> Epoch[21](1000/2500): Loss: 0.2808
===> Epoch[21](1100/2500): Loss: 0.2853
===> Epoch[21](1200/2500): Loss: 0.3019
===> Epoch[21](1300/2500): Loss: 0.3022
===> Epoch[21](1400/2500): Loss: 0.3062
===> Epoch[21](1500/2500): Loss: 0.2803
===> Epoch[21](1600/2500): Loss: 0.3022
===> Epoch[21](1700/2500): Loss: 0.3095
===> Epoch[21](1800/2500): Loss: 0.3031
===> Epoch[21](1900/2500): Loss: 0.2893
===> Epoch[21](2000/2500): Loss: 0.2924
===> Epoch[21](2100/2500): Loss: 0.2892
===> Epoch[21](2200/2500): Loss: 0.2880
===> Epoch[21](2300/2500): Loss: 0.2762
===> Epoch[21](2400/2500): Loss: 0.2734
===> Epoch[21](2500/2500): Loss: 0.2813
===> Epoch 21 Complete: Avg. Loss: 0.2920
===> Timestamp: [2025-08-03 21:07:07]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2778
===> Epoch[21](200/2500): Loss: 0.3054
===> Epoch[21](300/2500): Loss: 0.3164
===> Epoch[21](400/2500): Loss: 0.2605
===> Epoch[21](500/2500): Loss: 0.2899
===> Epoch[21](600/2500): Loss: 0.2777
===> Epoch[21](700/2500): Loss: 0.3215
===> Epoch[21](800/2500): Loss: 0.2978
===> Epoch[21](900/2500): Loss: 0.3204
===> Epoch[21](1000/2500): Loss: 0.2808
===> Epoch[21](1100/2500): Loss: 0.2853
===> Epoch[21](1200/2500): Loss: 0.3019
===> Epoch[21](1300/2500): Loss: 0.3022
===> Epoch[21](1400/2500): Loss: 0.3062
===> Epoch[21](1500/2500): Loss: 0.2803
===> Epoch[21](1600/2500): Loss: 0.3022
===> Epoch[21](1700/2500): Loss: 0.3095
===> Epoch[21](1800/2500): Loss: 0.3031
===> Epoch[21](1900/2500): Loss: 0.2893
===> Epoch[21](2000/2500): Loss: 0.2924
===> Epoch[21](2100/2500): Loss: 0.2892
===> Epoch[21](2200/2500): Loss: 0.2880
===> Epoch[21](2300/2500): Loss: 0.2762
===> Epoch[21](2400/2500): Loss: 0.2734
===> Epoch[21](2500/2500): Loss: 0.2813
===> Epoch 21 Complete: Avg. Loss: 0.2920
===> Timestamp: [2025-08-03 21:07:07]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2778
===> Epoch[21](200/2500): Loss: 0.3054
===> Epoch[21](300/2500): Loss: 0.3164
===> Epoch[21](400/2500): Loss: 0.2605
===> Epoch[21](500/2500): Loss: 0.2899
===> Epoch[21](600/2500): Loss: 0.2777
===> Epoch[21](700/2500): Loss: 0.3215
===> Epoch[21](800/2500): Loss: 0.2978
===> Epoch[21](900/2500): Loss: 0.3204
===> Epoch[21](1000/2500): Loss: 0.2808
===> Epoch[21](1100/2500): Loss: 0.2853
===> Epoch[21](1200/2500): Loss: 0.3019
===> Epoch[21](1300/2500): Loss: 0.3022
===> Epoch[21](1400/2500): Loss: 0.3062
===> Epoch[21](1500/2500): Loss: 0.2803
===> Epoch[21](1600/2500): Loss: 0.3022
===> Epoch[21](1700/2500): Loss: 0.3095
===> Epoch[21](1800/2500): Loss: 0.3031
===> Epoch[21](1900/2500): Loss: 0.2893
===> Epoch[21](2000/2500): Loss: 0.2924
===> Epoch[21](2100/2500): Loss: 0.2892
===> Epoch[21](2200/2500): Loss: 0.2880
===> Epoch[21](2300/2500): Loss: 0.2762
===> Epoch[21](2400/2500): Loss: 0.2734
===> Epoch[21](2500/2500): Loss: 0.2813
===> Epoch 21 Complete: Avg. Loss: 0.2920
===> Timestamp: [2025-08-03 21:07:07]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2778
===> Epoch[21](200/2500): Loss: 0.3054
===> Epoch[21](300/2500): Loss: 0.3164
===> Epoch[21](400/2500): Loss: 0.2605
===> Epoch[21](500/2500): Loss: 0.2899
===> Epoch[21](600/2500): Loss: 0.2777
===> Epoch[21](700/2500): Loss: 0.3215
===> Epoch[21](800/2500): Loss: 0.2978
===> Epoch[21](900/2500): Loss: 0.3204
===> Epoch[21](1000/2500): Loss: 0.2808
===> Epoch[21](1100/2500): Loss: 0.2853
===> Epoch[21](1200/2500): Loss: 0.3019
===> Epoch[21](1300/2500): Loss: 0.3022
===> Epoch[21](1400/2500): Loss: 0.3062
===> Epoch[21](1500/2500): Loss: 0.2803
===> Epoch[21](1600/2500): Loss: 0.3022
===> Epoch[21](1700/2500): Loss: 0.3095
===> Epoch[21](1800/2500): Loss: 0.3031
===> Epoch[21](1900/2500): Loss: 0.2893
===> Epoch[21](2000/2500): Loss: 0.2924
===> Epoch[21](2100/2500): Loss: 0.2892
===> Epoch[21](2200/2500): Loss: 0.2880
===> Epoch[21](2300/2500): Loss: 0.2762
===> Epoch[21](2400/2500): Loss: 0.2734
===> Epoch[21](2500/2500): Loss: 0.2813
===> Epoch 21 Complete: Avg. Loss: 0.2920
===> Timestamp: [2025-08-03 21:07:07]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2778
===> Epoch[21](200/2500): Loss: 0.3054
===> Epoch[21](300/2500): Loss: 0.3164
===> Epoch[21](400/2500): Loss: 0.2605
===> Epoch[21](500/2500): Loss: 0.2899
===> Epoch[21](600/2500): Loss: 0.2777
===> Epoch[21](700/2500): Loss: 0.3215
===> Epoch[21](800/2500): Loss: 0.2978
===> Epoch[21](900/2500): Loss: 0.3204
===> Epoch[21](1000/2500): Loss: 0.2808
===> Epoch[21](1100/2500): Loss: 0.2853
===> Epoch[21](1200/2500): Loss: 0.3019
===> Epoch[21](1300/2500): Loss: 0.3022
===> Epoch[21](1400/2500): Loss: 0.3062
===> Epoch[21](1500/2500): Loss: 0.2803
===> Epoch[21](1600/2500): Loss: 0.3022
===> Epoch[21](1700/2500): Loss: 0.3095
===> Epoch[21](1800/2500): Loss: 0.3031
===> Epoch[21](1900/2500): Loss: 0.2893
===> Epoch[21](2000/2500): Loss: 0.2924
===> Epoch[21](2100/2500): Loss: 0.2892
===> Epoch[21](2200/2500): Loss: 0.2880
===> Epoch[21](2300/2500): Loss: 0.2762
===> Epoch[21](2400/2500): Loss: 0.2734
===> Epoch[21](2500/2500): Loss: 0.2813
===> Epoch 21 Complete: Avg. Loss: 0.2920
===> Timestamp: [2025-08-03 21:07:07]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2778
===> Epoch[21](200/2500): Loss: 0.3054
===> Epoch[21](300/2500): Loss: 0.3164
===> Epoch[21](400/2500): Loss: 0.2605
===> Epoch[21](500/2500): Loss: 0.2899
===> Epoch[21](600/2500): Loss: 0.2777
===> Epoch[21](700/2500): Loss: 0.3215
===> Epoch[21](800/2500): Loss: 0.2978
===> Epoch[21](900/2500): Loss: 0.3204
===> Epoch[21](1000/2500): Loss: 0.2808
===> Epoch[21](1100/2500): Loss: 0.2853
===> Epoch[21](1200/2500): Loss: 0.3019
===> Epoch[21](1300/2500): Loss: 0.3022
===> Epoch[21](1400/2500): Loss: 0.3062
===> Epoch[21](1500/2500): Loss: 0.2803
===> Epoch[21](1600/2500): Loss: 0.3022
===> Epoch[21](1700/2500): Loss: 0.3095
===> Epoch[21](1800/2500): Loss: 0.3031
===> Epoch[21](1900/2500): Loss: 0.2893
===> Epoch[21](2000/2500): Loss: 0.2924
===> Epoch[21](2100/2500): Loss: 0.2892
===> Epoch[21](2200/2500): Loss: 0.2880
===> Epoch[21](2300/2500): Loss: 0.2762
===> Epoch[21](2400/2500): Loss: 0.2734
===> Epoch[21](2500/2500): Loss: 0.2813
===> Epoch 21 Complete: Avg. Loss: 0.2920
===> Timestamp: [2025-08-03 21:07:07]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2778
===> Epoch[21](200/2500): Loss: 0.3054
===> Epoch[21](300/2500): Loss: 0.3164
===> Epoch[21](400/2500): Loss: 0.2605
===> Epoch[21](500/2500): Loss: 0.2899
===> Epoch[21](600/2500): Loss: 0.2777
===> Epoch[21](700/2500): Loss: 0.3215
===> Epoch[21](800/2500): Loss: 0.2978
===> Epoch[21](900/2500): Loss: 0.3204
===> Epoch[21](1000/2500): Loss: 0.2808
===> Epoch[21](1100/2500): Loss: 0.2853
===> Epoch[21](1200/2500): Loss: 0.3019
===> Epoch[21](1300/2500): Loss: 0.3022
===> Epoch[21](1400/2500): Loss: 0.3062
===> Epoch[21](1500/2500): Loss: 0.2803
===> Epoch[21](1600/2500): Loss: 0.3022
===> Epoch[21](1700/2500): Loss: 0.3095
===> Epoch[21](1800/2500): Loss: 0.3031
===> Epoch[21](1900/2500): Loss: 0.2893
===> Epoch[21](2000/2500): Loss: 0.2924
===> Epoch[21](2100/2500): Loss: 0.2892
===> Epoch[21](2200/2500): Loss: 0.2880
===> Epoch[21](2300/2500): Loss: 0.2762
===> Epoch[21](2400/2500): Loss: 0.2734
===> Epoch[21](2500/2500): Loss: 0.2813
===> Epoch 21 Complete: Avg. Loss: 0.2920
===> Timestamp: [2025-08-03 21:07:07]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2778
===> Epoch[21](200/2500): Loss: 0.3054
===> Epoch[21](300/2500): Loss: 0.3164
===> Epoch[21](400/2500): Loss: 0.2605
===> Epoch[21](500/2500): Loss: 0.2899
===> Epoch[21](600/2500): Loss: 0.2777
===> Epoch[21](700/2500): Loss: 0.3215
===> Epoch[21](800/2500): Loss: 0.2978
===> Epoch[21](900/2500): Loss: 0.3204
===> Epoch[21](1000/2500): Loss: 0.2808
===> Epoch[21](1100/2500): Loss: 0.2853
===> Epoch[21](1200/2500): Loss: 0.3019
===> Epoch[21](1300/2500): Loss: 0.3022
===> Epoch[21](1400/2500): Loss: 0.3062
===> Epoch[21](1500/2500): Loss: 0.2803
===> Epoch[21](1600/2500): Loss: 0.3022
===> Epoch[21](1700/2500): Loss: 0.3095
===> Epoch[21](1800/2500): Loss: 0.3031
===> Epoch[21](1900/2500): Loss: 0.2893
===> Epoch[21](2000/2500): Loss: 0.2924
===> Epoch[21](2100/2500): Loss: 0.2892
===> Epoch[21](2200/2500): Loss: 0.2880
===> Epoch[21](2300/2500): Loss: 0.2762
===> Epoch[21](2400/2500): Loss: 0.2734
===> Epoch[21](2500/2500): Loss: 0.2813
===> Epoch 21 Complete: Avg. Loss: 0.2920
===> Timestamp: [2025-08-03 21:07:07]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2778
===> Epoch[21](200/2500): Loss: 0.3054
===> Epoch[21](300/2500): Loss: 0.3164
===> Epoch[21](400/2500): Loss: 0.2605
===> Epoch[21](500/2500): Loss: 0.2899
===> Epoch[21](600/2500): Loss: 0.2777
===> Epoch[21](700/2500): Loss: 0.3215
===> Epoch[21](800/2500): Loss: 0.2978
===> Epoch[21](900/2500): Loss: 0.3204
===> Epoch[21](1000/2500): Loss: 0.2808
===> Epoch[21](1100/2500): Loss: 0.2853
===> Epoch[21](1200/2500): Loss: 0.3019
===> Epoch[21](1300/2500): Loss: 0.3022
===> Epoch[21](1400/2500): Loss: 0.3062
===> Epoch[21](1500/2500): Loss: 0.2803
===> Epoch[21](1600/2500): Loss: 0.3022
===> Epoch[21](1700/2500): Loss: 0.3095
===> Epoch[21](1800/2500): Loss: 0.3031
===> Epoch[21](1900/2500): Loss: 0.2893
===> Epoch[21](2000/2500): Loss: 0.2924
===> Epoch[21](2100/2500): Loss: 0.2892
===> Epoch[21](2200/2500): Loss: 0.2880
===> Epoch[21](2300/2500): Loss: 0.2762
===> Epoch[21](2400/2500): Loss: 0.2734
===> Epoch[21](2500/2500): Loss: 0.2813
===> Epoch 21 Complete: Avg. Loss: 0.2920
===> Timestamp: [2025-08-03 21:07:07]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2778
===> Epoch[21](200/2500): Loss: 0.3054
===> Epoch[21](300/2500): Loss: 0.3164
===> Epoch[21](400/2500): Loss: 0.2605
===> Epoch[21](500/2500): Loss: 0.2899
===> Epoch[21](600/2500): Loss: 0.2777
===> Epoch[21](700/2500): Loss: 0.3215
===> Epoch[21](800/2500): Loss: 0.2978
===> Epoch[21](900/2500): Loss: 0.3204
===> Epoch[21](1000/2500): Loss: 0.2808
===> Epoch[21](1100/2500): Loss: 0.2853
===> Epoch[21](1200/2500): Loss: 0.3019
===> Epoch[21](1300/2500): Loss: 0.3022
===> Epoch[21](1400/2500): Loss: 0.3062
===> Epoch[21](1500/2500): Loss: 0.2803
===> Epoch[21](1600/2500): Loss: 0.3022
===> Epoch[21](1700/2500): Loss: 0.3095
===> Epoch[21](1800/2500): Loss: 0.3031
===> Epoch[21](1900/2500): Loss: 0.2893
===> Epoch[21](2000/2500): Loss: 0.2924
===> Epoch[21](2100/2500): Loss: 0.2892
===> Epoch[21](2200/2500): Loss: 0.2880
===> Epoch[21](2300/2500): Loss: 0.2762
===> Epoch[21](2400/2500): Loss: 0.2734
===> Epoch[21](2500/2500): Loss: 0.2813
===> Epoch 21 Complete: Avg. Loss: 0.2920
===> Timestamp: [2025-08-03 21:07:07]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2778
===> Epoch[21](200/2500): Loss: 0.3054
===> Epoch[21](300/2500): Loss: 0.3164
===> Epoch[21](400/2500): Loss: 0.2605
===> Epoch[21](500/2500): Loss: 0.2899
===> Epoch[21](600/2500): Loss: 0.2777
===> Epoch[21](700/2500): Loss: 0.3215
===> Epoch[21](800/2500): Loss: 0.2978
===> Epoch[21](900/2500): Loss: 0.3204
===> Epoch[21](1000/2500): Loss: 0.2808
===> Epoch[21](1100/2500): Loss: 0.2853
===> Epoch[21](1200/2500): Loss: 0.3019
===> Epoch[21](1300/2500): Loss: 0.3022
===> Epoch[21](1400/2500): Loss: 0.3062
===> Epoch[21](1500/2500): Loss: 0.2803
===> Epoch[21](1600/2500): Loss: 0.3022
===> Epoch[21](1700/2500): Loss: 0.3095
===> Epoch[21](1800/2500): Loss: 0.3031
===> Epoch[21](1900/2500): Loss: 0.2893
===> Epoch[21](2000/2500): Loss: 0.2924
===> Epoch[21](2100/2500): Loss: 0.2892
===> Epoch[21](2200/2500): Loss: 0.2880
===> Epoch[21](2300/2500): Loss: 0.2762
===> Epoch[21](2400/2500): Loss: 0.2734
===> Epoch[21](2500/2500): Loss: 0.2813
===> Epoch 21 Complete: Avg. Loss: 0.2920
===> Timestamp: [2025-08-03 21:07:07]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2778
===> Epoch[21](200/2500): Loss: 0.3054
===> Epoch[21](300/2500): Loss: 0.3164
===> Epoch[21](400/2500): Loss: 0.2605
===> Epoch[21](500/2500): Loss: 0.2899
===> Epoch[21](600/2500): Loss: 0.2777
===> Epoch[21](700/2500): Loss: 0.3215
===> Epoch[21](800/2500): Loss: 0.2978
===> Epoch[21](900/2500): Loss: 0.3204
===> Epoch[21](1000/2500): Loss: 0.2808
===> Epoch[21](1100/2500): Loss: 0.2853
===> Epoch[21](1200/2500): Loss: 0.3019
===> Epoch[21](1300/2500): Loss: 0.3022
===> Epoch[21](1400/2500): Loss: 0.3062
===> Epoch[21](1500/2500): Loss: 0.2803
===> Epoch[21](1600/2500): Loss: 0.3022
===> Epoch[21](1700/2500): Loss: 0.3095
===> Epoch[21](1800/2500): Loss: 0.3031
===> Epoch[21](1900/2500): Loss: 0.2893
===> Epoch[21](2000/2500): Loss: 0.2924
===> Epoch[21](2100/2500): Loss: 0.2892
===> Epoch[21](2200/2500): Loss: 0.2880
===> Epoch[21](2300/2500): Loss: 0.2762
===> Epoch[21](2400/2500): Loss: 0.2734
===> Epoch[21](2500/2500): Loss: 0.2813
===> Epoch 21 Complete: Avg. Loss: 0.2920
===> Timestamp: [2025-08-03 21:07:07]
===> Loading train datasets
===> Epoch[21](100/2500): Loss: 0.2778
===> Epoch[21](200/2500): Loss: 0.3054
===> Epoch[21](300/2500): Loss: 0.3164
===> Epoch[21](400/2500): Loss: 0.2605
===> Epoch[21](500/2500): Loss: 0.2899
===> Epoch[21](600/2500): Loss: 0.2777
===> Epoch[21](700/2500): Loss: 0.3215
===> Epoch[21](800/2500): Loss: 0.2978
===> Epoch[21](900/2500): Loss: 0.3204
===> Epoch[21](1000/2500): Loss: 0.2808
===> Epoch[21](1100/2500): Loss: 0.2853
===> Epoch[21](1200/2500): Loss: 0.3019
===> Epoch[21](1300/2500): Loss: 0.3022
===> Epoch[21](1400/2500): Loss: 0.3062
===> Epoch[21](1500/2500): Loss: 0.2803
===> Epoch[21](1600/2500): Loss: 0.3022
===> Epoch[21](1700/2500): Loss: 0.3095
===> Epoch[21](1800/2500): Loss: 0.3031
===> Epoch[21](1900/2500): Loss: 0.2893
===> Epoch[21](2000/2500): Loss: 0.2924
===> Epoch[21](2100/2500): Loss: 0.2892
===> Epoch[21](2200/2500): Loss: 0.2880
===> Epoch[21](2300/2500): Loss: 0.2762
===> Epoch[21](2400/2500): Loss: 0.2734
===> Epoch[21](2500/2500): Loss: 0.2813
===> Epoch 21 Complete: Avg. Loss: 0.2920
===> Timestamp: [2025-08-03 21:07:07]
===> Loading train datasets
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.3127
===> Epoch[22](200/2500): Loss: 0.2795
===> Epoch[22](300/2500): Loss: 0.2886
===> Epoch[22](400/2500): Loss: 0.3006
===> Epoch[22](500/2500): Loss: 0.2929
===> Epoch[22](600/2500): Loss: 0.2724
===> Epoch[22](700/2500): Loss: 0.3010
===> Epoch[22](800/2500): Loss: 0.2916
===> Epoch[22](900/2500): Loss: 0.3055
===> Epoch[22](1000/2500): Loss: 0.2919
===> Epoch[22](1100/2500): Loss: 0.2749
===> Epoch[22](1200/2500): Loss: 0.3128
===> Epoch[22](1300/2500): Loss: 0.2960
===> Epoch[22](1400/2500): Loss: 0.3078
===> Epoch[22](1500/2500): Loss: 0.2844
===> Epoch[22](1600/2500): Loss: 0.3032
===> Epoch[22](1700/2500): Loss: 0.2964
===> Epoch[22](1800/2500): Loss: 0.3008
===> Epoch[22](1900/2500): Loss: 0.2886
===> Epoch[22](2000/2500): Loss: 0.2713
===> Epoch[22](2100/2500): Loss: 0.2963
===> Epoch[22](2200/2500): Loss: 0.2791
===> Epoch[22](2300/2500): Loss: 0.2840
===> Epoch[22](2400/2500): Loss: 0.2847
===> Epoch[22](2500/2500): Loss: 0.3298
===> Epoch 22 Complete: Avg. Loss: 0.2911
===> Timestamp: [2025-08-03 21:11:41]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.3127
===> Epoch[22](200/2500): Loss: 0.2795
===> Epoch[22](300/2500): Loss: 0.2886
===> Epoch[22](400/2500): Loss: 0.3006
===> Epoch[22](500/2500): Loss: 0.2929
===> Epoch[22](600/2500): Loss: 0.2724
===> Epoch[22](700/2500): Loss: 0.3010
===> Epoch[22](800/2500): Loss: 0.2916
===> Epoch[22](900/2500): Loss: 0.3055
===> Epoch[22](1000/2500): Loss: 0.2919
===> Epoch[22](1100/2500): Loss: 0.2749
===> Epoch[22](1200/2500): Loss: 0.3128
===> Epoch[22](1300/2500): Loss: 0.2960
===> Epoch[22](1400/2500): Loss: 0.3078
===> Epoch[22](1500/2500): Loss: 0.2844
===> Epoch[22](1600/2500): Loss: 0.3032
===> Epoch[22](1700/2500): Loss: 0.2964
===> Epoch[22](1800/2500): Loss: 0.3008
===> Epoch[22](1900/2500): Loss: 0.2886
===> Epoch[22](2000/2500): Loss: 0.2713
===> Epoch[22](2100/2500): Loss: 0.2963
===> Epoch[22](2200/2500): Loss: 0.2791
===> Epoch[22](2300/2500): Loss: 0.2840
===> Epoch[22](2400/2500): Loss: 0.2847
===> Epoch[22](2500/2500): Loss: 0.3298
===> Epoch 22 Complete: Avg. Loss: 0.2911
===> Timestamp: [2025-08-03 21:11:41]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.3127
===> Epoch[22](200/2500): Loss: 0.2795
===> Epoch[22](300/2500): Loss: 0.2886
===> Epoch[22](400/2500): Loss: 0.3006
===> Epoch[22](500/2500): Loss: 0.2929
===> Epoch[22](600/2500): Loss: 0.2724
===> Epoch[22](700/2500): Loss: 0.3010
===> Epoch[22](800/2500): Loss: 0.2916
===> Epoch[22](900/2500): Loss: 0.3055
===> Epoch[22](1000/2500): Loss: 0.2919
===> Epoch[22](1100/2500): Loss: 0.2749
===> Epoch[22](1200/2500): Loss: 0.3128
===> Epoch[22](1300/2500): Loss: 0.2960
===> Epoch[22](1400/2500): Loss: 0.3078
===> Epoch[22](1500/2500): Loss: 0.2844
===> Epoch[22](1600/2500): Loss: 0.3032
===> Epoch[22](1700/2500): Loss: 0.2964
===> Epoch[22](1800/2500): Loss: 0.3008
===> Epoch[22](1900/2500): Loss: 0.2886
===> Epoch[22](2000/2500): Loss: 0.2713
===> Epoch[22](2100/2500): Loss: 0.2963
===> Epoch[22](2200/2500): Loss: 0.2791
===> Epoch[22](2300/2500): Loss: 0.2840
===> Epoch[22](2400/2500): Loss: 0.2847
===> Epoch[22](2500/2500): Loss: 0.3298
===> Epoch 22 Complete: Avg. Loss: 0.2911
===> Timestamp: [2025-08-03 21:11:41]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.3127
===> Epoch[22](200/2500): Loss: 0.2795
===> Epoch[22](300/2500): Loss: 0.2886
===> Epoch[22](400/2500): Loss: 0.3006
===> Epoch[22](500/2500): Loss: 0.2929
===> Epoch[22](600/2500): Loss: 0.2724
===> Epoch[22](700/2500): Loss: 0.3010
===> Epoch[22](800/2500): Loss: 0.2916
===> Epoch[22](900/2500): Loss: 0.3055
===> Epoch[22](1000/2500): Loss: 0.2919
===> Epoch[22](1100/2500): Loss: 0.2749
===> Epoch[22](1200/2500): Loss: 0.3128
===> Epoch[22](1300/2500): Loss: 0.2960
===> Epoch[22](1400/2500): Loss: 0.3078
===> Epoch[22](1500/2500): Loss: 0.2844
===> Epoch[22](1600/2500): Loss: 0.3032
===> Epoch[22](1700/2500): Loss: 0.2964
===> Epoch[22](1800/2500): Loss: 0.3008
===> Epoch[22](1900/2500): Loss: 0.2886
===> Epoch[22](2000/2500): Loss: 0.2713
===> Epoch[22](2100/2500): Loss: 0.2963
===> Epoch[22](2200/2500): Loss: 0.2791
===> Epoch[22](2300/2500): Loss: 0.2840
===> Epoch[22](2400/2500): Loss: 0.2847
===> Epoch[22](2500/2500): Loss: 0.3298
===> Epoch 22 Complete: Avg. Loss: 0.2911
===> Timestamp: [2025-08-03 21:11:41]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.3127
===> Epoch[22](200/2500): Loss: 0.2795
===> Epoch[22](300/2500): Loss: 0.2886
===> Epoch[22](400/2500): Loss: 0.3006
===> Epoch[22](500/2500): Loss: 0.2929
===> Epoch[22](600/2500): Loss: 0.2724
===> Epoch[22](700/2500): Loss: 0.3010
===> Epoch[22](800/2500): Loss: 0.2916
===> Epoch[22](900/2500): Loss: 0.3055
===> Epoch[22](1000/2500): Loss: 0.2919
===> Epoch[22](1100/2500): Loss: 0.2749
===> Epoch[22](1200/2500): Loss: 0.3128
===> Epoch[22](1300/2500): Loss: 0.2960
===> Epoch[22](1400/2500): Loss: 0.3078
===> Epoch[22](1500/2500): Loss: 0.2844
===> Epoch[22](1600/2500): Loss: 0.3032
===> Epoch[22](1700/2500): Loss: 0.2964
===> Epoch[22](1800/2500): Loss: 0.3008
===> Epoch[22](1900/2500): Loss: 0.2886
===> Epoch[22](2000/2500): Loss: 0.2713
===> Epoch[22](2100/2500): Loss: 0.2963
===> Epoch[22](2200/2500): Loss: 0.2791
===> Epoch[22](2300/2500): Loss: 0.2840
===> Epoch[22](2400/2500): Loss: 0.2847
===> Epoch[22](2500/2500): Loss: 0.3298
===> Epoch 22 Complete: Avg. Loss: 0.2911
===> Timestamp: [2025-08-03 21:11:41]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.3127
===> Epoch[22](200/2500): Loss: 0.2795
===> Epoch[22](300/2500): Loss: 0.2886
===> Epoch[22](400/2500): Loss: 0.3006
===> Epoch[22](500/2500): Loss: 0.2929
===> Epoch[22](600/2500): Loss: 0.2724
===> Epoch[22](700/2500): Loss: 0.3010
===> Epoch[22](800/2500): Loss: 0.2916
===> Epoch[22](900/2500): Loss: 0.3055
===> Epoch[22](1000/2500): Loss: 0.2919
===> Epoch[22](1100/2500): Loss: 0.2749
===> Epoch[22](1200/2500): Loss: 0.3128
===> Epoch[22](1300/2500): Loss: 0.2960
===> Epoch[22](1400/2500): Loss: 0.3078
===> Epoch[22](1500/2500): Loss: 0.2844
===> Epoch[22](1600/2500): Loss: 0.3032
===> Epoch[22](1700/2500): Loss: 0.2964
===> Epoch[22](1800/2500): Loss: 0.3008
===> Epoch[22](1900/2500): Loss: 0.2886
===> Epoch[22](2000/2500): Loss: 0.2713
===> Epoch[22](2100/2500): Loss: 0.2963
===> Epoch[22](2200/2500): Loss: 0.2791
===> Epoch[22](2300/2500): Loss: 0.2840
===> Epoch[22](2400/2500): Loss: 0.2847
===> Epoch[22](2500/2500): Loss: 0.3298
===> Epoch 22 Complete: Avg. Loss: 0.2911
===> Timestamp: [2025-08-03 21:11:41]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.3127
===> Epoch[22](200/2500): Loss: 0.2795
===> Epoch[22](300/2500): Loss: 0.2886
===> Epoch[22](400/2500): Loss: 0.3006
===> Epoch[22](500/2500): Loss: 0.2929
===> Epoch[22](600/2500): Loss: 0.2724
===> Epoch[22](700/2500): Loss: 0.3010
===> Epoch[22](800/2500): Loss: 0.2916
===> Epoch[22](900/2500): Loss: 0.3055
===> Epoch[22](1000/2500): Loss: 0.2919
===> Epoch[22](1100/2500): Loss: 0.2749
===> Epoch[22](1200/2500): Loss: 0.3128
===> Epoch[22](1300/2500): Loss: 0.2960
===> Epoch[22](1400/2500): Loss: 0.3078
===> Epoch[22](1500/2500): Loss: 0.2844
===> Epoch[22](1600/2500): Loss: 0.3032
===> Epoch[22](1700/2500): Loss: 0.2964
===> Epoch[22](1800/2500): Loss: 0.3008
===> Epoch[22](1900/2500): Loss: 0.2886
===> Epoch[22](2000/2500): Loss: 0.2713
===> Epoch[22](2100/2500): Loss: 0.2963
===> Epoch[22](2200/2500): Loss: 0.2791
===> Epoch[22](2300/2500): Loss: 0.2840
===> Epoch[22](2400/2500): Loss: 0.2847
===> Epoch[22](2500/2500): Loss: 0.3298
===> Epoch 22 Complete: Avg. Loss: 0.2911
===> Timestamp: [2025-08-03 21:11:41]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.3127
===> Epoch[22](200/2500): Loss: 0.2795
===> Epoch[22](300/2500): Loss: 0.2886
===> Epoch[22](400/2500): Loss: 0.3006
===> Epoch[22](500/2500): Loss: 0.2929
===> Epoch[22](600/2500): Loss: 0.2724
===> Epoch[22](700/2500): Loss: 0.3010
===> Epoch[22](800/2500): Loss: 0.2916
===> Epoch[22](900/2500): Loss: 0.3055
===> Epoch[22](1000/2500): Loss: 0.2919
===> Epoch[22](1100/2500): Loss: 0.2749
===> Epoch[22](1200/2500): Loss: 0.3128
===> Epoch[22](1300/2500): Loss: 0.2960
===> Epoch[22](1400/2500): Loss: 0.3078
===> Epoch[22](1500/2500): Loss: 0.2844
===> Epoch[22](1600/2500): Loss: 0.3032
===> Epoch[22](1700/2500): Loss: 0.2964
===> Epoch[22](1800/2500): Loss: 0.3008
===> Epoch[22](1900/2500): Loss: 0.2886
===> Epoch[22](2000/2500): Loss: 0.2713
===> Epoch[22](2100/2500): Loss: 0.2963
===> Epoch[22](2200/2500): Loss: 0.2791
===> Epoch[22](2300/2500): Loss: 0.2840
===> Epoch[22](2400/2500): Loss: 0.2847
===> Epoch[22](2500/2500): Loss: 0.3298
===> Epoch 22 Complete: Avg. Loss: 0.2911
===> Timestamp: [2025-08-03 21:11:41]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.3127
===> Epoch[22](200/2500): Loss: 0.2795
===> Epoch[22](300/2500): Loss: 0.2886
===> Epoch[22](400/2500): Loss: 0.3006
===> Epoch[22](500/2500): Loss: 0.2929
===> Epoch[22](600/2500): Loss: 0.2724
===> Epoch[22](700/2500): Loss: 0.3010
===> Epoch[22](800/2500): Loss: 0.2916
===> Epoch[22](900/2500): Loss: 0.3055
===> Epoch[22](1000/2500): Loss: 0.2919
===> Epoch[22](1100/2500): Loss: 0.2749
===> Epoch[22](1200/2500): Loss: 0.3128
===> Epoch[22](1300/2500): Loss: 0.2960
===> Epoch[22](1400/2500): Loss: 0.3078
===> Epoch[22](1500/2500): Loss: 0.2844
===> Epoch[22](1600/2500): Loss: 0.3032
===> Epoch[22](1700/2500): Loss: 0.2964
===> Epoch[22](1800/2500): Loss: 0.3008
===> Epoch[22](1900/2500): Loss: 0.2886
===> Epoch[22](2000/2500): Loss: 0.2713
===> Epoch[22](2100/2500): Loss: 0.2963
===> Epoch[22](2200/2500): Loss: 0.2791
===> Epoch[22](2300/2500): Loss: 0.2840
===> Epoch[22](2400/2500): Loss: 0.2847
===> Epoch[22](2500/2500): Loss: 0.3298
===> Epoch 22 Complete: Avg. Loss: 0.2911
===> Timestamp: [2025-08-03 21:11:41]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.3127
===> Epoch[22](200/2500): Loss: 0.2795
===> Epoch[22](300/2500): Loss: 0.2886
===> Epoch[22](400/2500): Loss: 0.3006
===> Epoch[22](500/2500): Loss: 0.2929
===> Epoch[22](600/2500): Loss: 0.2724
===> Epoch[22](700/2500): Loss: 0.3010
===> Epoch[22](800/2500): Loss: 0.2916
===> Epoch[22](900/2500): Loss: 0.3055
===> Epoch[22](1000/2500): Loss: 0.2919
===> Epoch[22](1100/2500): Loss: 0.2749
===> Epoch[22](1200/2500): Loss: 0.3128
===> Epoch[22](1300/2500): Loss: 0.2960
===> Epoch[22](1400/2500): Loss: 0.3078
===> Epoch[22](1500/2500): Loss: 0.2844
===> Epoch[22](1600/2500): Loss: 0.3032
===> Epoch[22](1700/2500): Loss: 0.2964
===> Epoch[22](1800/2500): Loss: 0.3008
===> Epoch[22](1900/2500): Loss: 0.2886
===> Epoch[22](2000/2500): Loss: 0.2713
===> Epoch[22](2100/2500): Loss: 0.2963
===> Epoch[22](2200/2500): Loss: 0.2791
===> Epoch[22](2300/2500): Loss: 0.2840
===> Epoch[22](2400/2500): Loss: 0.2847
===> Epoch[22](2500/2500): Loss: 0.3298
===> Epoch 22 Complete: Avg. Loss: 0.2911
===> Timestamp: [2025-08-03 21:11:41]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.3127
===> Epoch[22](200/2500): Loss: 0.2795
===> Epoch[22](300/2500): Loss: 0.2886
===> Epoch[22](400/2500): Loss: 0.3006
===> Epoch[22](500/2500): Loss: 0.2929
===> Epoch[22](600/2500): Loss: 0.2724
===> Epoch[22](700/2500): Loss: 0.3010
===> Epoch[22](800/2500): Loss: 0.2916
===> Epoch[22](900/2500): Loss: 0.3055
===> Epoch[22](1000/2500): Loss: 0.2919
===> Epoch[22](1100/2500): Loss: 0.2749
===> Epoch[22](1200/2500): Loss: 0.3128
===> Epoch[22](1300/2500): Loss: 0.2960
===> Epoch[22](1400/2500): Loss: 0.3078
===> Epoch[22](1500/2500): Loss: 0.2844
===> Epoch[22](1600/2500): Loss: 0.3032
===> Epoch[22](1700/2500): Loss: 0.2964
===> Epoch[22](1800/2500): Loss: 0.3008
===> Epoch[22](1900/2500): Loss: 0.2886
===> Epoch[22](2000/2500): Loss: 0.2713
===> Epoch[22](2100/2500): Loss: 0.2963
===> Epoch[22](2200/2500): Loss: 0.2791
===> Epoch[22](2300/2500): Loss: 0.2840
===> Epoch[22](2400/2500): Loss: 0.2847
===> Epoch[22](2500/2500): Loss: 0.3298
===> Epoch 22 Complete: Avg. Loss: 0.2911
===> Timestamp: [2025-08-03 21:11:41]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.3127
===> Epoch[22](200/2500): Loss: 0.2795
===> Epoch[22](300/2500): Loss: 0.2886
===> Epoch[22](400/2500): Loss: 0.3006
===> Epoch[22](500/2500): Loss: 0.2929
===> Epoch[22](600/2500): Loss: 0.2724
===> Epoch[22](700/2500): Loss: 0.3010
===> Epoch[22](800/2500): Loss: 0.2916
===> Epoch[22](900/2500): Loss: 0.3055
===> Epoch[22](1000/2500): Loss: 0.2919
===> Epoch[22](1100/2500): Loss: 0.2749
===> Epoch[22](1200/2500): Loss: 0.3128
===> Epoch[22](1300/2500): Loss: 0.2960
===> Epoch[22](1400/2500): Loss: 0.3078
===> Epoch[22](1500/2500): Loss: 0.2844
===> Epoch[22](1600/2500): Loss: 0.3032
===> Epoch[22](1700/2500): Loss: 0.2964
===> Epoch[22](1800/2500): Loss: 0.3008
===> Epoch[22](1900/2500): Loss: 0.2886
===> Epoch[22](2000/2500): Loss: 0.2713
===> Epoch[22](2100/2500): Loss: 0.2963
===> Epoch[22](2200/2500): Loss: 0.2791
===> Epoch[22](2300/2500): Loss: 0.2840
===> Epoch[22](2400/2500): Loss: 0.2847
===> Epoch[22](2500/2500): Loss: 0.3298
===> Epoch 22 Complete: Avg. Loss: 0.2911
===> Timestamp: [2025-08-03 21:11:41]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.3127
===> Epoch[22](200/2500): Loss: 0.2795
===> Epoch[22](300/2500): Loss: 0.2886
===> Epoch[22](400/2500): Loss: 0.3006
===> Epoch[22](500/2500): Loss: 0.2929
===> Epoch[22](600/2500): Loss: 0.2724
===> Epoch[22](700/2500): Loss: 0.3010
===> Epoch[22](800/2500): Loss: 0.2916
===> Epoch[22](900/2500): Loss: 0.3055
===> Epoch[22](1000/2500): Loss: 0.2919
===> Epoch[22](1100/2500): Loss: 0.2749
===> Epoch[22](1200/2500): Loss: 0.3128
===> Epoch[22](1300/2500): Loss: 0.2960
===> Epoch[22](1400/2500): Loss: 0.3078
===> Epoch[22](1500/2500): Loss: 0.2844
===> Epoch[22](1600/2500): Loss: 0.3032
===> Epoch[22](1700/2500): Loss: 0.2964
===> Epoch[22](1800/2500): Loss: 0.3008
===> Epoch[22](1900/2500): Loss: 0.2886
===> Epoch[22](2000/2500): Loss: 0.2713
===> Epoch[22](2100/2500): Loss: 0.2963
===> Epoch[22](2200/2500): Loss: 0.2791
===> Epoch[22](2300/2500): Loss: 0.2840
===> Epoch[22](2400/2500): Loss: 0.2847
===> Epoch[22](2500/2500): Loss: 0.3298
===> Epoch 22 Complete: Avg. Loss: 0.2911
===> Timestamp: [2025-08-03 21:11:41]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.3127
===> Epoch[22](200/2500): Loss: 0.2795
===> Epoch[22](300/2500): Loss: 0.2886
===> Epoch[22](400/2500): Loss: 0.3006
===> Epoch[22](500/2500): Loss: 0.2929
===> Epoch[22](600/2500): Loss: 0.2724
===> Epoch[22](700/2500): Loss: 0.3010
===> Epoch[22](800/2500): Loss: 0.2916
===> Epoch[22](900/2500): Loss: 0.3055
===> Epoch[22](1000/2500): Loss: 0.2919
===> Epoch[22](1100/2500): Loss: 0.2749
===> Epoch[22](1200/2500): Loss: 0.3128
===> Epoch[22](1300/2500): Loss: 0.2960
===> Epoch[22](1400/2500): Loss: 0.3078
===> Epoch[22](1500/2500): Loss: 0.2844
===> Epoch[22](1600/2500): Loss: 0.3032
===> Epoch[22](1700/2500): Loss: 0.2964
===> Epoch[22](1800/2500): Loss: 0.3008
===> Epoch[22](1900/2500): Loss: 0.2886
===> Epoch[22](2000/2500): Loss: 0.2713
===> Epoch[22](2100/2500): Loss: 0.2963
===> Epoch[22](2200/2500): Loss: 0.2791
===> Epoch[22](2300/2500): Loss: 0.2840
===> Epoch[22](2400/2500): Loss: 0.2847
===> Epoch[22](2500/2500): Loss: 0.3298
===> Epoch 22 Complete: Avg. Loss: 0.2911
===> Timestamp: [2025-08-03 21:11:41]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.3127
===> Epoch[22](200/2500): Loss: 0.2795
===> Epoch[22](300/2500): Loss: 0.2886
===> Epoch[22](400/2500): Loss: 0.3006
===> Epoch[22](500/2500): Loss: 0.2929
===> Epoch[22](600/2500): Loss: 0.2724
===> Epoch[22](700/2500): Loss: 0.3010
===> Epoch[22](800/2500): Loss: 0.2916
===> Epoch[22](900/2500): Loss: 0.3055
===> Epoch[22](1000/2500): Loss: 0.2919
===> Epoch[22](1100/2500): Loss: 0.2749
===> Epoch[22](1200/2500): Loss: 0.3128
===> Epoch[22](1300/2500): Loss: 0.2960
===> Epoch[22](1400/2500): Loss: 0.3078
===> Epoch[22](1500/2500): Loss: 0.2844
===> Epoch[22](1600/2500): Loss: 0.3032
===> Epoch[22](1700/2500): Loss: 0.2964
===> Epoch[22](1800/2500): Loss: 0.3008
===> Epoch[22](1900/2500): Loss: 0.2886
===> Epoch[22](2000/2500): Loss: 0.2713
===> Epoch[22](2100/2500): Loss: 0.2963
===> Epoch[22](2200/2500): Loss: 0.2791
===> Epoch[22](2300/2500): Loss: 0.2840
===> Epoch[22](2400/2500): Loss: 0.2847
===> Epoch[22](2500/2500): Loss: 0.3298
===> Epoch 22 Complete: Avg. Loss: 0.2911
===> Timestamp: [2025-08-03 21:11:41]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.3127
===> Epoch[22](200/2500): Loss: 0.2795
===> Epoch[22](300/2500): Loss: 0.2886
===> Epoch[22](400/2500): Loss: 0.3006
===> Epoch[22](500/2500): Loss: 0.2929
===> Epoch[22](600/2500): Loss: 0.2724
===> Epoch[22](700/2500): Loss: 0.3010
===> Epoch[22](800/2500): Loss: 0.2916
===> Epoch[22](900/2500): Loss: 0.3055
===> Epoch[22](1000/2500): Loss: 0.2919
===> Epoch[22](1100/2500): Loss: 0.2749
===> Epoch[22](1200/2500): Loss: 0.3128
===> Epoch[22](1300/2500): Loss: 0.2960
===> Epoch[22](1400/2500): Loss: 0.3078
===> Epoch[22](1500/2500): Loss: 0.2844
===> Epoch[22](1600/2500): Loss: 0.3032
===> Epoch[22](1700/2500): Loss: 0.2964
===> Epoch[22](1800/2500): Loss: 0.3008
===> Epoch[22](1900/2500): Loss: 0.2886
===> Epoch[22](2000/2500): Loss: 0.2713
===> Epoch[22](2100/2500): Loss: 0.2963
===> Epoch[22](2200/2500): Loss: 0.2791
===> Epoch[22](2300/2500): Loss: 0.2840
===> Epoch[22](2400/2500): Loss: 0.2847
===> Epoch[22](2500/2500): Loss: 0.3298
===> Epoch 22 Complete: Avg. Loss: 0.2911
===> Timestamp: [2025-08-03 21:11:41]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.3127
===> Epoch[22](200/2500): Loss: 0.2795
===> Epoch[22](300/2500): Loss: 0.2886
===> Epoch[22](400/2500): Loss: 0.3006
===> Epoch[22](500/2500): Loss: 0.2929
===> Epoch[22](600/2500): Loss: 0.2724
===> Epoch[22](700/2500): Loss: 0.3010
===> Epoch[22](800/2500): Loss: 0.2916
===> Epoch[22](900/2500): Loss: 0.3055
===> Epoch[22](1000/2500): Loss: 0.2919
===> Epoch[22](1100/2500): Loss: 0.2749
===> Epoch[22](1200/2500): Loss: 0.3128
===> Epoch[22](1300/2500): Loss: 0.2960
===> Epoch[22](1400/2500): Loss: 0.3078
===> Epoch[22](1500/2500): Loss: 0.2844
===> Epoch[22](1600/2500): Loss: 0.3032
===> Epoch[22](1700/2500): Loss: 0.2964
===> Epoch[22](1800/2500): Loss: 0.3008
===> Epoch[22](1900/2500): Loss: 0.2886
===> Epoch[22](2000/2500): Loss: 0.2713
===> Epoch[22](2100/2500): Loss: 0.2963
===> Epoch[22](2200/2500): Loss: 0.2791
===> Epoch[22](2300/2500): Loss: 0.2840
===> Epoch[22](2400/2500): Loss: 0.2847
===> Epoch[22](2500/2500): Loss: 0.3298
===> Epoch 22 Complete: Avg. Loss: 0.2911
===> Timestamp: [2025-08-03 21:11:41]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.3127
===> Epoch[22](200/2500): Loss: 0.2795
===> Epoch[22](300/2500): Loss: 0.2886
===> Epoch[22](400/2500): Loss: 0.3006
===> Epoch[22](500/2500): Loss: 0.2929
===> Epoch[22](600/2500): Loss: 0.2724
===> Epoch[22](700/2500): Loss: 0.3010
===> Epoch[22](800/2500): Loss: 0.2916
===> Epoch[22](900/2500): Loss: 0.3055
===> Epoch[22](1000/2500): Loss: 0.2919
===> Epoch[22](1100/2500): Loss: 0.2749
===> Epoch[22](1200/2500): Loss: 0.3128
===> Epoch[22](1300/2500): Loss: 0.2960
===> Epoch[22](1400/2500): Loss: 0.3078
===> Epoch[22](1500/2500): Loss: 0.2844
===> Epoch[22](1600/2500): Loss: 0.3032
===> Epoch[22](1700/2500): Loss: 0.2964
===> Epoch[22](1800/2500): Loss: 0.3008
===> Epoch[22](1900/2500): Loss: 0.2886
===> Epoch[22](2000/2500): Loss: 0.2713
===> Epoch[22](2100/2500): Loss: 0.2963
===> Epoch[22](2200/2500): Loss: 0.2791
===> Epoch[22](2300/2500): Loss: 0.2840
===> Epoch[22](2400/2500): Loss: 0.2847
===> Epoch[22](2500/2500): Loss: 0.3298
===> Epoch 22 Complete: Avg. Loss: 0.2911
===> Timestamp: [2025-08-03 21:11:41]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.3127
===> Epoch[22](200/2500): Loss: 0.2795
===> Epoch[22](300/2500): Loss: 0.2886
===> Epoch[22](400/2500): Loss: 0.3006
===> Epoch[22](500/2500): Loss: 0.2929
===> Epoch[22](600/2500): Loss: 0.2724
===> Epoch[22](700/2500): Loss: 0.3010
===> Epoch[22](800/2500): Loss: 0.2916
===> Epoch[22](900/2500): Loss: 0.3055
===> Epoch[22](1000/2500): Loss: 0.2919
===> Epoch[22](1100/2500): Loss: 0.2749
===> Epoch[22](1200/2500): Loss: 0.3128
===> Epoch[22](1300/2500): Loss: 0.2960
===> Epoch[22](1400/2500): Loss: 0.3078
===> Epoch[22](1500/2500): Loss: 0.2844
===> Epoch[22](1600/2500): Loss: 0.3032
===> Epoch[22](1700/2500): Loss: 0.2964
===> Epoch[22](1800/2500): Loss: 0.3008
===> Epoch[22](1900/2500): Loss: 0.2886
===> Epoch[22](2000/2500): Loss: 0.2713
===> Epoch[22](2100/2500): Loss: 0.2963
===> Epoch[22](2200/2500): Loss: 0.2791
===> Epoch[22](2300/2500): Loss: 0.2840
===> Epoch[22](2400/2500): Loss: 0.2847
===> Epoch[22](2500/2500): Loss: 0.3298
===> Epoch 22 Complete: Avg. Loss: 0.2911
===> Timestamp: [2025-08-03 21:11:41]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.3127
===> Epoch[22](200/2500): Loss: 0.2795
===> Epoch[22](300/2500): Loss: 0.2886
===> Epoch[22](400/2500): Loss: 0.3006
===> Epoch[22](500/2500): Loss: 0.2929
===> Epoch[22](600/2500): Loss: 0.2724
===> Epoch[22](700/2500): Loss: 0.3010
===> Epoch[22](800/2500): Loss: 0.2916
===> Epoch[22](900/2500): Loss: 0.3055
===> Epoch[22](1000/2500): Loss: 0.2919
===> Epoch[22](1100/2500): Loss: 0.2749
===> Epoch[22](1200/2500): Loss: 0.3128
===> Epoch[22](1300/2500): Loss: 0.2960
===> Epoch[22](1400/2500): Loss: 0.3078
===> Epoch[22](1500/2500): Loss: 0.2844
===> Epoch[22](1600/2500): Loss: 0.3032
===> Epoch[22](1700/2500): Loss: 0.2964
===> Epoch[22](1800/2500): Loss: 0.3008
===> Epoch[22](1900/2500): Loss: 0.2886
===> Epoch[22](2000/2500): Loss: 0.2713
===> Epoch[22](2100/2500): Loss: 0.2963
===> Epoch[22](2200/2500): Loss: 0.2791
===> Epoch[22](2300/2500): Loss: 0.2840
===> Epoch[22](2400/2500): Loss: 0.2847
===> Epoch[22](2500/2500): Loss: 0.3298
===> Epoch 22 Complete: Avg. Loss: 0.2911
===> Timestamp: [2025-08-03 21:11:41]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.3127
===> Epoch[22](200/2500): Loss: 0.2795
===> Epoch[22](300/2500): Loss: 0.2886
===> Epoch[22](400/2500): Loss: 0.3006
===> Epoch[22](500/2500): Loss: 0.2929
===> Epoch[22](600/2500): Loss: 0.2724
===> Epoch[22](700/2500): Loss: 0.3010
===> Epoch[22](800/2500): Loss: 0.2916
===> Epoch[22](900/2500): Loss: 0.3055
===> Epoch[22](1000/2500): Loss: 0.2919
===> Epoch[22](1100/2500): Loss: 0.2749
===> Epoch[22](1200/2500): Loss: 0.3128
===> Epoch[22](1300/2500): Loss: 0.2960
===> Epoch[22](1400/2500): Loss: 0.3078
===> Epoch[22](1500/2500): Loss: 0.2844
===> Epoch[22](1600/2500): Loss: 0.3032
===> Epoch[22](1700/2500): Loss: 0.2964
===> Epoch[22](1800/2500): Loss: 0.3008
===> Epoch[22](1900/2500): Loss: 0.2886
===> Epoch[22](2000/2500): Loss: 0.2713
===> Epoch[22](2100/2500): Loss: 0.2963
===> Epoch[22](2200/2500): Loss: 0.2791
===> Epoch[22](2300/2500): Loss: 0.2840
===> Epoch[22](2400/2500): Loss: 0.2847
===> Epoch[22](2500/2500): Loss: 0.3298
===> Epoch 22 Complete: Avg. Loss: 0.2911
===> Timestamp: [2025-08-03 21:11:41]
===> Loading train datasets
===> Epoch[22](100/2500): Loss: 0.3127
===> Epoch[22](200/2500): Loss: 0.2795
===> Epoch[22](300/2500): Loss: 0.2886
===> Epoch[22](400/2500): Loss: 0.3006
===> Epoch[22](500/2500): Loss: 0.2929
===> Epoch[22](600/2500): Loss: 0.2724
===> Epoch[22](700/2500): Loss: 0.3010
===> Epoch[22](800/2500): Loss: 0.2916
===> Epoch[22](900/2500): Loss: 0.3055
===> Epoch[22](1000/2500): Loss: 0.2919
===> Epoch[22](1100/2500): Loss: 0.2749
===> Epoch[22](1200/2500): Loss: 0.3128
===> Epoch[22](1300/2500): Loss: 0.2960
===> Epoch[22](1400/2500): Loss: 0.3078
===> Epoch[22](1500/2500): Loss: 0.2844
===> Epoch[22](1600/2500): Loss: 0.3032
===> Epoch[22](1700/2500): Loss: 0.2964
===> Epoch[22](1800/2500): Loss: 0.3008
===> Epoch[22](1900/2500): Loss: 0.2886
===> Epoch[22](2000/2500): Loss: 0.2713
===> Epoch[22](2100/2500): Loss: 0.2963
===> Epoch[22](2200/2500): Loss: 0.2791
===> Epoch[22](2300/2500): Loss: 0.2840
===> Epoch[22](2400/2500): Loss: 0.2847
===> Epoch[22](2500/2500): Loss: 0.3298
===> Epoch 22 Complete: Avg. Loss: 0.2911
===> Timestamp: [2025-08-03 21:11:41]
===> Loading train datasets
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2877
===> Epoch[23](200/2500): Loss: 0.2957
===> Epoch[23](300/2500): Loss: 0.2855
===> Epoch[23](400/2500): Loss: 0.2751
===> Epoch[23](500/2500): Loss: 0.3166
===> Epoch[23](600/2500): Loss: 0.3158
===> Epoch[23](700/2500): Loss: 0.2887
===> Epoch[23](800/2500): Loss: 0.2963
===> Epoch[23](900/2500): Loss: 0.2843
===> Epoch[23](1000/2500): Loss: 0.2983
===> Epoch[23](1100/2500): Loss: 0.2636
===> Epoch[23](1200/2500): Loss: 0.2951
===> Epoch[23](1300/2500): Loss: 0.3079
===> Epoch[23](1400/2500): Loss: 0.2866
===> Epoch[23](1500/2500): Loss: 0.2919
===> Epoch[23](1600/2500): Loss: 0.2970
===> Epoch[23](1700/2500): Loss: 0.3076
===> Epoch[23](1800/2500): Loss: 0.2546
===> Epoch[23](1900/2500): Loss: 0.2708
===> Epoch[23](2000/2500): Loss: 0.2798
===> Epoch[23](2100/2500): Loss: 0.3153
===> Epoch[23](2200/2500): Loss: 0.3161
===> Epoch[23](2300/2500): Loss: 0.2718
===> Epoch[23](2400/2500): Loss: 0.2764
===> Epoch[23](2500/2500): Loss: 0.2932
===> Epoch 23 Complete: Avg. Loss: 0.2903
===> Timestamp: [2025-08-03 21:16:15]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2877
===> Epoch[23](200/2500): Loss: 0.2957
===> Epoch[23](300/2500): Loss: 0.2855
===> Epoch[23](400/2500): Loss: 0.2751
===> Epoch[23](500/2500): Loss: 0.3166
===> Epoch[23](600/2500): Loss: 0.3158
===> Epoch[23](700/2500): Loss: 0.2887
===> Epoch[23](800/2500): Loss: 0.2963
===> Epoch[23](900/2500): Loss: 0.2843
===> Epoch[23](1000/2500): Loss: 0.2983
===> Epoch[23](1100/2500): Loss: 0.2636
===> Epoch[23](1200/2500): Loss: 0.2951
===> Epoch[23](1300/2500): Loss: 0.3079
===> Epoch[23](1400/2500): Loss: 0.2866
===> Epoch[23](1500/2500): Loss: 0.2919
===> Epoch[23](1600/2500): Loss: 0.2970
===> Epoch[23](1700/2500): Loss: 0.3076
===> Epoch[23](1800/2500): Loss: 0.2546
===> Epoch[23](1900/2500): Loss: 0.2708
===> Epoch[23](2000/2500): Loss: 0.2798
===> Epoch[23](2100/2500): Loss: 0.3153
===> Epoch[23](2200/2500): Loss: 0.3161
===> Epoch[23](2300/2500): Loss: 0.2718
===> Epoch[23](2400/2500): Loss: 0.2764
===> Epoch[23](2500/2500): Loss: 0.2932
===> Epoch 23 Complete: Avg. Loss: 0.2903
===> Timestamp: [2025-08-03 21:16:15]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2877
===> Epoch[23](200/2500): Loss: 0.2957
===> Epoch[23](300/2500): Loss: 0.2855
===> Epoch[23](400/2500): Loss: 0.2751
===> Epoch[23](500/2500): Loss: 0.3166
===> Epoch[23](600/2500): Loss: 0.3158
===> Epoch[23](700/2500): Loss: 0.2887
===> Epoch[23](800/2500): Loss: 0.2963
===> Epoch[23](900/2500): Loss: 0.2843
===> Epoch[23](1000/2500): Loss: 0.2983
===> Epoch[23](1100/2500): Loss: 0.2636
===> Epoch[23](1200/2500): Loss: 0.2951
===> Epoch[23](1300/2500): Loss: 0.3079
===> Epoch[23](1400/2500): Loss: 0.2866
===> Epoch[23](1500/2500): Loss: 0.2919
===> Epoch[23](1600/2500): Loss: 0.2970
===> Epoch[23](1700/2500): Loss: 0.3076
===> Epoch[23](1800/2500): Loss: 0.2546
===> Epoch[23](1900/2500): Loss: 0.2708
===> Epoch[23](2000/2500): Loss: 0.2798
===> Epoch[23](2100/2500): Loss: 0.3153
===> Epoch[23](2200/2500): Loss: 0.3161
===> Epoch[23](2300/2500): Loss: 0.2718
===> Epoch[23](2400/2500): Loss: 0.2764
===> Epoch[23](2500/2500): Loss: 0.2932
===> Epoch 23 Complete: Avg. Loss: 0.2903
===> Timestamp: [2025-08-03 21:16:15]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2877
===> Epoch[23](200/2500): Loss: 0.2957
===> Epoch[23](300/2500): Loss: 0.2855
===> Epoch[23](400/2500): Loss: 0.2751
===> Epoch[23](500/2500): Loss: 0.3166
===> Epoch[23](600/2500): Loss: 0.3158
===> Epoch[23](700/2500): Loss: 0.2887
===> Epoch[23](800/2500): Loss: 0.2963
===> Epoch[23](900/2500): Loss: 0.2843
===> Epoch[23](1000/2500): Loss: 0.2983
===> Epoch[23](1100/2500): Loss: 0.2636
===> Epoch[23](1200/2500): Loss: 0.2951
===> Epoch[23](1300/2500): Loss: 0.3079
===> Epoch[23](1400/2500): Loss: 0.2866
===> Epoch[23](1500/2500): Loss: 0.2919
===> Epoch[23](1600/2500): Loss: 0.2970
===> Epoch[23](1700/2500): Loss: 0.3076
===> Epoch[23](1800/2500): Loss: 0.2546
===> Epoch[23](1900/2500): Loss: 0.2708
===> Epoch[23](2000/2500): Loss: 0.2798
===> Epoch[23](2100/2500): Loss: 0.3153
===> Epoch[23](2200/2500): Loss: 0.3161
===> Epoch[23](2300/2500): Loss: 0.2718
===> Epoch[23](2400/2500): Loss: 0.2764
===> Epoch[23](2500/2500): Loss: 0.2932
===> Epoch 23 Complete: Avg. Loss: 0.2903
===> Timestamp: [2025-08-03 21:16:15]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2877
===> Epoch[23](200/2500): Loss: 0.2957
===> Epoch[23](300/2500): Loss: 0.2855
===> Epoch[23](400/2500): Loss: 0.2751
===> Epoch[23](500/2500): Loss: 0.3166
===> Epoch[23](600/2500): Loss: 0.3158
===> Epoch[23](700/2500): Loss: 0.2887
===> Epoch[23](800/2500): Loss: 0.2963
===> Epoch[23](900/2500): Loss: 0.2843
===> Epoch[23](1000/2500): Loss: 0.2983
===> Epoch[23](1100/2500): Loss: 0.2636
===> Epoch[23](1200/2500): Loss: 0.2951
===> Epoch[23](1300/2500): Loss: 0.3079
===> Epoch[23](1400/2500): Loss: 0.2866
===> Epoch[23](1500/2500): Loss: 0.2919
===> Epoch[23](1600/2500): Loss: 0.2970
===> Epoch[23](1700/2500): Loss: 0.3076
===> Epoch[23](1800/2500): Loss: 0.2546
===> Epoch[23](1900/2500): Loss: 0.2708
===> Epoch[23](2000/2500): Loss: 0.2798
===> Epoch[23](2100/2500): Loss: 0.3153
===> Epoch[23](2200/2500): Loss: 0.3161
===> Epoch[23](2300/2500): Loss: 0.2718
===> Epoch[23](2400/2500): Loss: 0.2764
===> Epoch[23](2500/2500): Loss: 0.2932
===> Epoch 23 Complete: Avg. Loss: 0.2903
===> Timestamp: [2025-08-03 21:16:15]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2877
===> Epoch[23](200/2500): Loss: 0.2957
===> Epoch[23](300/2500): Loss: 0.2855
===> Epoch[23](400/2500): Loss: 0.2751
===> Epoch[23](500/2500): Loss: 0.3166
===> Epoch[23](600/2500): Loss: 0.3158
===> Epoch[23](700/2500): Loss: 0.2887
===> Epoch[23](800/2500): Loss: 0.2963
===> Epoch[23](900/2500): Loss: 0.2843
===> Epoch[23](1000/2500): Loss: 0.2983
===> Epoch[23](1100/2500): Loss: 0.2636
===> Epoch[23](1200/2500): Loss: 0.2951
===> Epoch[23](1300/2500): Loss: 0.3079
===> Epoch[23](1400/2500): Loss: 0.2866
===> Epoch[23](1500/2500): Loss: 0.2919
===> Epoch[23](1600/2500): Loss: 0.2970
===> Epoch[23](1700/2500): Loss: 0.3076
===> Epoch[23](1800/2500): Loss: 0.2546
===> Epoch[23](1900/2500): Loss: 0.2708
===> Epoch[23](2000/2500): Loss: 0.2798
===> Epoch[23](2100/2500): Loss: 0.3153
===> Epoch[23](2200/2500): Loss: 0.3161
===> Epoch[23](2300/2500): Loss: 0.2718
===> Epoch[23](2400/2500): Loss: 0.2764
===> Epoch[23](2500/2500): Loss: 0.2932
===> Epoch 23 Complete: Avg. Loss: 0.2903
===> Timestamp: [2025-08-03 21:16:15]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2877
===> Epoch[23](200/2500): Loss: 0.2957
===> Epoch[23](300/2500): Loss: 0.2855
===> Epoch[23](400/2500): Loss: 0.2751
===> Epoch[23](500/2500): Loss: 0.3166
===> Epoch[23](600/2500): Loss: 0.3158
===> Epoch[23](700/2500): Loss: 0.2887
===> Epoch[23](800/2500): Loss: 0.2963
===> Epoch[23](900/2500): Loss: 0.2843
===> Epoch[23](1000/2500): Loss: 0.2983
===> Epoch[23](1100/2500): Loss: 0.2636
===> Epoch[23](1200/2500): Loss: 0.2951
===> Epoch[23](1300/2500): Loss: 0.3079
===> Epoch[23](1400/2500): Loss: 0.2866
===> Epoch[23](1500/2500): Loss: 0.2919
===> Epoch[23](1600/2500): Loss: 0.2970
===> Epoch[23](1700/2500): Loss: 0.3076
===> Epoch[23](1800/2500): Loss: 0.2546
===> Epoch[23](1900/2500): Loss: 0.2708
===> Epoch[23](2000/2500): Loss: 0.2798
===> Epoch[23](2100/2500): Loss: 0.3153
===> Epoch[23](2200/2500): Loss: 0.3161
===> Epoch[23](2300/2500): Loss: 0.2718
===> Epoch[23](2400/2500): Loss: 0.2764
===> Epoch[23](2500/2500): Loss: 0.2932
===> Epoch 23 Complete: Avg. Loss: 0.2903
===> Timestamp: [2025-08-03 21:16:15]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2877
===> Epoch[23](200/2500): Loss: 0.2957
===> Epoch[23](300/2500): Loss: 0.2855
===> Epoch[23](400/2500): Loss: 0.2751
===> Epoch[23](500/2500): Loss: 0.3166
===> Epoch[23](600/2500): Loss: 0.3158
===> Epoch[23](700/2500): Loss: 0.2887
===> Epoch[23](800/2500): Loss: 0.2963
===> Epoch[23](900/2500): Loss: 0.2843
===> Epoch[23](1000/2500): Loss: 0.2983
===> Epoch[23](1100/2500): Loss: 0.2636
===> Epoch[23](1200/2500): Loss: 0.2951
===> Epoch[23](1300/2500): Loss: 0.3079
===> Epoch[23](1400/2500): Loss: 0.2866
===> Epoch[23](1500/2500): Loss: 0.2919
===> Epoch[23](1600/2500): Loss: 0.2970
===> Epoch[23](1700/2500): Loss: 0.3076
===> Epoch[23](1800/2500): Loss: 0.2546
===> Epoch[23](1900/2500): Loss: 0.2708
===> Epoch[23](2000/2500): Loss: 0.2798
===> Epoch[23](2100/2500): Loss: 0.3153
===> Epoch[23](2200/2500): Loss: 0.3161
===> Epoch[23](2300/2500): Loss: 0.2718
===> Epoch[23](2400/2500): Loss: 0.2764
===> Epoch[23](2500/2500): Loss: 0.2932
===> Epoch 23 Complete: Avg. Loss: 0.2903
===> Timestamp: [2025-08-03 21:16:15]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2877
===> Epoch[23](200/2500): Loss: 0.2957
===> Epoch[23](300/2500): Loss: 0.2855
===> Epoch[23](400/2500): Loss: 0.2751
===> Epoch[23](500/2500): Loss: 0.3166
===> Epoch[23](600/2500): Loss: 0.3158
===> Epoch[23](700/2500): Loss: 0.2887
===> Epoch[23](800/2500): Loss: 0.2963
===> Epoch[23](900/2500): Loss: 0.2843
===> Epoch[23](1000/2500): Loss: 0.2983
===> Epoch[23](1100/2500): Loss: 0.2636
===> Epoch[23](1200/2500): Loss: 0.2951
===> Epoch[23](1300/2500): Loss: 0.3079
===> Epoch[23](1400/2500): Loss: 0.2866
===> Epoch[23](1500/2500): Loss: 0.2919
===> Epoch[23](1600/2500): Loss: 0.2970
===> Epoch[23](1700/2500): Loss: 0.3076
===> Epoch[23](1800/2500): Loss: 0.2546
===> Epoch[23](1900/2500): Loss: 0.2708
===> Epoch[23](2000/2500): Loss: 0.2798
===> Epoch[23](2100/2500): Loss: 0.3153
===> Epoch[23](2200/2500): Loss: 0.3161
===> Epoch[23](2300/2500): Loss: 0.2718
===> Epoch[23](2400/2500): Loss: 0.2764
===> Epoch[23](2500/2500): Loss: 0.2932
===> Epoch 23 Complete: Avg. Loss: 0.2903
===> Timestamp: [2025-08-03 21:16:15]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2877
===> Epoch[23](200/2500): Loss: 0.2957
===> Epoch[23](300/2500): Loss: 0.2855
===> Epoch[23](400/2500): Loss: 0.2751
===> Epoch[23](500/2500): Loss: 0.3166
===> Epoch[23](600/2500): Loss: 0.3158
===> Epoch[23](700/2500): Loss: 0.2887
===> Epoch[23](800/2500): Loss: 0.2963
===> Epoch[23](900/2500): Loss: 0.2843
===> Epoch[23](1000/2500): Loss: 0.2983
===> Epoch[23](1100/2500): Loss: 0.2636
===> Epoch[23](1200/2500): Loss: 0.2951
===> Epoch[23](1300/2500): Loss: 0.3079
===> Epoch[23](1400/2500): Loss: 0.2866
===> Epoch[23](1500/2500): Loss: 0.2919
===> Epoch[23](1600/2500): Loss: 0.2970
===> Epoch[23](1700/2500): Loss: 0.3076
===> Epoch[23](1800/2500): Loss: 0.2546
===> Epoch[23](1900/2500): Loss: 0.2708
===> Epoch[23](2000/2500): Loss: 0.2798
===> Epoch[23](2100/2500): Loss: 0.3153
===> Epoch[23](2200/2500): Loss: 0.3161
===> Epoch[23](2300/2500): Loss: 0.2718
===> Epoch[23](2400/2500): Loss: 0.2764
===> Epoch[23](2500/2500): Loss: 0.2932
===> Epoch 23 Complete: Avg. Loss: 0.2903
===> Timestamp: [2025-08-03 21:16:15]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2877
===> Epoch[23](200/2500): Loss: 0.2957
===> Epoch[23](300/2500): Loss: 0.2855
===> Epoch[23](400/2500): Loss: 0.2751
===> Epoch[23](500/2500): Loss: 0.3166
===> Epoch[23](600/2500): Loss: 0.3158
===> Epoch[23](700/2500): Loss: 0.2887
===> Epoch[23](800/2500): Loss: 0.2963
===> Epoch[23](900/2500): Loss: 0.2843
===> Epoch[23](1000/2500): Loss: 0.2983
===> Epoch[23](1100/2500): Loss: 0.2636
===> Epoch[23](1200/2500): Loss: 0.2951
===> Epoch[23](1300/2500): Loss: 0.3079
===> Epoch[23](1400/2500): Loss: 0.2866
===> Epoch[23](1500/2500): Loss: 0.2919
===> Epoch[23](1600/2500): Loss: 0.2970
===> Epoch[23](1700/2500): Loss: 0.3076
===> Epoch[23](1800/2500): Loss: 0.2546
===> Epoch[23](1900/2500): Loss: 0.2708
===> Epoch[23](2000/2500): Loss: 0.2798
===> Epoch[23](2100/2500): Loss: 0.3153
===> Epoch[23](2200/2500): Loss: 0.3161
===> Epoch[23](2300/2500): Loss: 0.2718
===> Epoch[23](2400/2500): Loss: 0.2764
===> Epoch[23](2500/2500): Loss: 0.2932
===> Epoch 23 Complete: Avg. Loss: 0.2903
===> Timestamp: [2025-08-03 21:16:15]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2877
===> Epoch[23](200/2500): Loss: 0.2957
===> Epoch[23](300/2500): Loss: 0.2855
===> Epoch[23](400/2500): Loss: 0.2751
===> Epoch[23](500/2500): Loss: 0.3166
===> Epoch[23](600/2500): Loss: 0.3158
===> Epoch[23](700/2500): Loss: 0.2887
===> Epoch[23](800/2500): Loss: 0.2963
===> Epoch[23](900/2500): Loss: 0.2843
===> Epoch[23](1000/2500): Loss: 0.2983
===> Epoch[23](1100/2500): Loss: 0.2636
===> Epoch[23](1200/2500): Loss: 0.2951
===> Epoch[23](1300/2500): Loss: 0.3079
===> Epoch[23](1400/2500): Loss: 0.2866
===> Epoch[23](1500/2500): Loss: 0.2919
===> Epoch[23](1600/2500): Loss: 0.2970
===> Epoch[23](1700/2500): Loss: 0.3076
===> Epoch[23](1800/2500): Loss: 0.2546
===> Epoch[23](1900/2500): Loss: 0.2708
===> Epoch[23](2000/2500): Loss: 0.2798
===> Epoch[23](2100/2500): Loss: 0.3153
===> Epoch[23](2200/2500): Loss: 0.3161
===> Epoch[23](2300/2500): Loss: 0.2718
===> Epoch[23](2400/2500): Loss: 0.2764
===> Epoch[23](2500/2500): Loss: 0.2932
===> Epoch 23 Complete: Avg. Loss: 0.2903
===> Timestamp: [2025-08-03 21:16:15]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2877
===> Epoch[23](200/2500): Loss: 0.2957
===> Epoch[23](300/2500): Loss: 0.2855
===> Epoch[23](400/2500): Loss: 0.2751
===> Epoch[23](500/2500): Loss: 0.3166
===> Epoch[23](600/2500): Loss: 0.3158
===> Epoch[23](700/2500): Loss: 0.2887
===> Epoch[23](800/2500): Loss: 0.2963
===> Epoch[23](900/2500): Loss: 0.2843
===> Epoch[23](1000/2500): Loss: 0.2983
===> Epoch[23](1100/2500): Loss: 0.2636
===> Epoch[23](1200/2500): Loss: 0.2951
===> Epoch[23](1300/2500): Loss: 0.3079
===> Epoch[23](1400/2500): Loss: 0.2866
===> Epoch[23](1500/2500): Loss: 0.2919
===> Epoch[23](1600/2500): Loss: 0.2970
===> Epoch[23](1700/2500): Loss: 0.3076
===> Epoch[23](1800/2500): Loss: 0.2546
===> Epoch[23](1900/2500): Loss: 0.2708
===> Epoch[23](2000/2500): Loss: 0.2798
===> Epoch[23](2100/2500): Loss: 0.3153
===> Epoch[23](2200/2500): Loss: 0.3161
===> Epoch[23](2300/2500): Loss: 0.2718
===> Epoch[23](2400/2500): Loss: 0.2764
===> Epoch[23](2500/2500): Loss: 0.2932
===> Epoch 23 Complete: Avg. Loss: 0.2903
===> Timestamp: [2025-08-03 21:16:15]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2877
===> Epoch[23](200/2500): Loss: 0.2957
===> Epoch[23](300/2500): Loss: 0.2855
===> Epoch[23](400/2500): Loss: 0.2751
===> Epoch[23](500/2500): Loss: 0.3166
===> Epoch[23](600/2500): Loss: 0.3158
===> Epoch[23](700/2500): Loss: 0.2887
===> Epoch[23](800/2500): Loss: 0.2963
===> Epoch[23](900/2500): Loss: 0.2843
===> Epoch[23](1000/2500): Loss: 0.2983
===> Epoch[23](1100/2500): Loss: 0.2636
===> Epoch[23](1200/2500): Loss: 0.2951
===> Epoch[23](1300/2500): Loss: 0.3079
===> Epoch[23](1400/2500): Loss: 0.2866
===> Epoch[23](1500/2500): Loss: 0.2919
===> Epoch[23](1600/2500): Loss: 0.2970
===> Epoch[23](1700/2500): Loss: 0.3076
===> Epoch[23](1800/2500): Loss: 0.2546
===> Epoch[23](1900/2500): Loss: 0.2708
===> Epoch[23](2000/2500): Loss: 0.2798
===> Epoch[23](2100/2500): Loss: 0.3153
===> Epoch[23](2200/2500): Loss: 0.3161
===> Epoch[23](2300/2500): Loss: 0.2718
===> Epoch[23](2400/2500): Loss: 0.2764
===> Epoch[23](2500/2500): Loss: 0.2932
===> Epoch 23 Complete: Avg. Loss: 0.2903
===> Timestamp: [2025-08-03 21:16:15]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2877
===> Epoch[23](200/2500): Loss: 0.2957
===> Epoch[23](300/2500): Loss: 0.2855
===> Epoch[23](400/2500): Loss: 0.2751
===> Epoch[23](500/2500): Loss: 0.3166
===> Epoch[23](600/2500): Loss: 0.3158
===> Epoch[23](700/2500): Loss: 0.2887
===> Epoch[23](800/2500): Loss: 0.2963
===> Epoch[23](900/2500): Loss: 0.2843
===> Epoch[23](1000/2500): Loss: 0.2983
===> Epoch[23](1100/2500): Loss: 0.2636
===> Epoch[23](1200/2500): Loss: 0.2951
===> Epoch[23](1300/2500): Loss: 0.3079
===> Epoch[23](1400/2500): Loss: 0.2866
===> Epoch[23](1500/2500): Loss: 0.2919
===> Epoch[23](1600/2500): Loss: 0.2970
===> Epoch[23](1700/2500): Loss: 0.3076
===> Epoch[23](1800/2500): Loss: 0.2546
===> Epoch[23](1900/2500): Loss: 0.2708
===> Epoch[23](2000/2500): Loss: 0.2798
===> Epoch[23](2100/2500): Loss: 0.3153
===> Epoch[23](2200/2500): Loss: 0.3161
===> Epoch[23](2300/2500): Loss: 0.2718
===> Epoch[23](2400/2500): Loss: 0.2764
===> Epoch[23](2500/2500): Loss: 0.2932
===> Epoch 23 Complete: Avg. Loss: 0.2903
===> Timestamp: [2025-08-03 21:16:15]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2877
===> Epoch[23](200/2500): Loss: 0.2957
===> Epoch[23](300/2500): Loss: 0.2855
===> Epoch[23](400/2500): Loss: 0.2751
===> Epoch[23](500/2500): Loss: 0.3166
===> Epoch[23](600/2500): Loss: 0.3158
===> Epoch[23](700/2500): Loss: 0.2887
===> Epoch[23](800/2500): Loss: 0.2963
===> Epoch[23](900/2500): Loss: 0.2843
===> Epoch[23](1000/2500): Loss: 0.2983
===> Epoch[23](1100/2500): Loss: 0.2636
===> Epoch[23](1200/2500): Loss: 0.2951
===> Epoch[23](1300/2500): Loss: 0.3079
===> Epoch[23](1400/2500): Loss: 0.2866
===> Epoch[23](1500/2500): Loss: 0.2919
===> Epoch[23](1600/2500): Loss: 0.2970
===> Epoch[23](1700/2500): Loss: 0.3076
===> Epoch[23](1800/2500): Loss: 0.2546
===> Epoch[23](1900/2500): Loss: 0.2708
===> Epoch[23](2000/2500): Loss: 0.2798
===> Epoch[23](2100/2500): Loss: 0.3153
===> Epoch[23](2200/2500): Loss: 0.3161
===> Epoch[23](2300/2500): Loss: 0.2718
===> Epoch[23](2400/2500): Loss: 0.2764
===> Epoch[23](2500/2500): Loss: 0.2932
===> Epoch 23 Complete: Avg. Loss: 0.2903
===> Timestamp: [2025-08-03 21:16:15]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2877
===> Epoch[23](200/2500): Loss: 0.2957
===> Epoch[23](300/2500): Loss: 0.2855
===> Epoch[23](400/2500): Loss: 0.2751
===> Epoch[23](500/2500): Loss: 0.3166
===> Epoch[23](600/2500): Loss: 0.3158
===> Epoch[23](700/2500): Loss: 0.2887
===> Epoch[23](800/2500): Loss: 0.2963
===> Epoch[23](900/2500): Loss: 0.2843
===> Epoch[23](1000/2500): Loss: 0.2983
===> Epoch[23](1100/2500): Loss: 0.2636
===> Epoch[23](1200/2500): Loss: 0.2951
===> Epoch[23](1300/2500): Loss: 0.3079
===> Epoch[23](1400/2500): Loss: 0.2866
===> Epoch[23](1500/2500): Loss: 0.2919
===> Epoch[23](1600/2500): Loss: 0.2970
===> Epoch[23](1700/2500): Loss: 0.3076
===> Epoch[23](1800/2500): Loss: 0.2546
===> Epoch[23](1900/2500): Loss: 0.2708
===> Epoch[23](2000/2500): Loss: 0.2798
===> Epoch[23](2100/2500): Loss: 0.3153
===> Epoch[23](2200/2500): Loss: 0.3161
===> Epoch[23](2300/2500): Loss: 0.2718
===> Epoch[23](2400/2500): Loss: 0.2764
===> Epoch[23](2500/2500): Loss: 0.2932
===> Epoch 23 Complete: Avg. Loss: 0.2903
===> Timestamp: [2025-08-03 21:16:15]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2877
===> Epoch[23](200/2500): Loss: 0.2957
===> Epoch[23](300/2500): Loss: 0.2855
===> Epoch[23](400/2500): Loss: 0.2751
===> Epoch[23](500/2500): Loss: 0.3166
===> Epoch[23](600/2500): Loss: 0.3158
===> Epoch[23](700/2500): Loss: 0.2887
===> Epoch[23](800/2500): Loss: 0.2963
===> Epoch[23](900/2500): Loss: 0.2843
===> Epoch[23](1000/2500): Loss: 0.2983
===> Epoch[23](1100/2500): Loss: 0.2636
===> Epoch[23](1200/2500): Loss: 0.2951
===> Epoch[23](1300/2500): Loss: 0.3079
===> Epoch[23](1400/2500): Loss: 0.2866
===> Epoch[23](1500/2500): Loss: 0.2919
===> Epoch[23](1600/2500): Loss: 0.2970
===> Epoch[23](1700/2500): Loss: 0.3076
===> Epoch[23](1800/2500): Loss: 0.2546
===> Epoch[23](1900/2500): Loss: 0.2708
===> Epoch[23](2000/2500): Loss: 0.2798
===> Epoch[23](2100/2500): Loss: 0.3153
===> Epoch[23](2200/2500): Loss: 0.3161
===> Epoch[23](2300/2500): Loss: 0.2718
===> Epoch[23](2400/2500): Loss: 0.2764
===> Epoch[23](2500/2500): Loss: 0.2932
===> Epoch 23 Complete: Avg. Loss: 0.2903
===> Timestamp: [2025-08-03 21:16:15]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2877
===> Epoch[23](200/2500): Loss: 0.2957
===> Epoch[23](300/2500): Loss: 0.2855
===> Epoch[23](400/2500): Loss: 0.2751
===> Epoch[23](500/2500): Loss: 0.3166
===> Epoch[23](600/2500): Loss: 0.3158
===> Epoch[23](700/2500): Loss: 0.2887
===> Epoch[23](800/2500): Loss: 0.2963
===> Epoch[23](900/2500): Loss: 0.2843
===> Epoch[23](1000/2500): Loss: 0.2983
===> Epoch[23](1100/2500): Loss: 0.2636
===> Epoch[23](1200/2500): Loss: 0.2951
===> Epoch[23](1300/2500): Loss: 0.3079
===> Epoch[23](1400/2500): Loss: 0.2866
===> Epoch[23](1500/2500): Loss: 0.2919
===> Epoch[23](1600/2500): Loss: 0.2970
===> Epoch[23](1700/2500): Loss: 0.3076
===> Epoch[23](1800/2500): Loss: 0.2546
===> Epoch[23](1900/2500): Loss: 0.2708
===> Epoch[23](2000/2500): Loss: 0.2798
===> Epoch[23](2100/2500): Loss: 0.3153
===> Epoch[23](2200/2500): Loss: 0.3161
===> Epoch[23](2300/2500): Loss: 0.2718
===> Epoch[23](2400/2500): Loss: 0.2764
===> Epoch[23](2500/2500): Loss: 0.2932
===> Epoch 23 Complete: Avg. Loss: 0.2903
===> Timestamp: [2025-08-03 21:16:15]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2877
===> Epoch[23](200/2500): Loss: 0.2957
===> Epoch[23](300/2500): Loss: 0.2855
===> Epoch[23](400/2500): Loss: 0.2751
===> Epoch[23](500/2500): Loss: 0.3166
===> Epoch[23](600/2500): Loss: 0.3158
===> Epoch[23](700/2500): Loss: 0.2887
===> Epoch[23](800/2500): Loss: 0.2963
===> Epoch[23](900/2500): Loss: 0.2843
===> Epoch[23](1000/2500): Loss: 0.2983
===> Epoch[23](1100/2500): Loss: 0.2636
===> Epoch[23](1200/2500): Loss: 0.2951
===> Epoch[23](1300/2500): Loss: 0.3079
===> Epoch[23](1400/2500): Loss: 0.2866
===> Epoch[23](1500/2500): Loss: 0.2919
===> Epoch[23](1600/2500): Loss: 0.2970
===> Epoch[23](1700/2500): Loss: 0.3076
===> Epoch[23](1800/2500): Loss: 0.2546
===> Epoch[23](1900/2500): Loss: 0.2708
===> Epoch[23](2000/2500): Loss: 0.2798
===> Epoch[23](2100/2500): Loss: 0.3153
===> Epoch[23](2200/2500): Loss: 0.3161
===> Epoch[23](2300/2500): Loss: 0.2718
===> Epoch[23](2400/2500): Loss: 0.2764
===> Epoch[23](2500/2500): Loss: 0.2932
===> Epoch 23 Complete: Avg. Loss: 0.2903
===> Timestamp: [2025-08-03 21:16:15]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2877
===> Epoch[23](200/2500): Loss: 0.2957
===> Epoch[23](300/2500): Loss: 0.2855
===> Epoch[23](400/2500): Loss: 0.2751
===> Epoch[23](500/2500): Loss: 0.3166
===> Epoch[23](600/2500): Loss: 0.3158
===> Epoch[23](700/2500): Loss: 0.2887
===> Epoch[23](800/2500): Loss: 0.2963
===> Epoch[23](900/2500): Loss: 0.2843
===> Epoch[23](1000/2500): Loss: 0.2983
===> Epoch[23](1100/2500): Loss: 0.2636
===> Epoch[23](1200/2500): Loss: 0.2951
===> Epoch[23](1300/2500): Loss: 0.3079
===> Epoch[23](1400/2500): Loss: 0.2866
===> Epoch[23](1500/2500): Loss: 0.2919
===> Epoch[23](1600/2500): Loss: 0.2970
===> Epoch[23](1700/2500): Loss: 0.3076
===> Epoch[23](1800/2500): Loss: 0.2546
===> Epoch[23](1900/2500): Loss: 0.2708
===> Epoch[23](2000/2500): Loss: 0.2798
===> Epoch[23](2100/2500): Loss: 0.3153
===> Epoch[23](2200/2500): Loss: 0.3161
===> Epoch[23](2300/2500): Loss: 0.2718
===> Epoch[23](2400/2500): Loss: 0.2764
===> Epoch[23](2500/2500): Loss: 0.2932
===> Epoch 23 Complete: Avg. Loss: 0.2903
===> Timestamp: [2025-08-03 21:16:15]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2877
===> Epoch[23](200/2500): Loss: 0.2957
===> Epoch[23](300/2500): Loss: 0.2855
===> Epoch[23](400/2500): Loss: 0.2751
===> Epoch[23](500/2500): Loss: 0.3166
===> Epoch[23](600/2500): Loss: 0.3158
===> Epoch[23](700/2500): Loss: 0.2887
===> Epoch[23](800/2500): Loss: 0.2963
===> Epoch[23](900/2500): Loss: 0.2843
===> Epoch[23](1000/2500): Loss: 0.2983
===> Epoch[23](1100/2500): Loss: 0.2636
===> Epoch[23](1200/2500): Loss: 0.2951
===> Epoch[23](1300/2500): Loss: 0.3079
===> Epoch[23](1400/2500): Loss: 0.2866
===> Epoch[23](1500/2500): Loss: 0.2919
===> Epoch[23](1600/2500): Loss: 0.2970
===> Epoch[23](1700/2500): Loss: 0.3076
===> Epoch[23](1800/2500): Loss: 0.2546
===> Epoch[23](1900/2500): Loss: 0.2708
===> Epoch[23](2000/2500): Loss: 0.2798
===> Epoch[23](2100/2500): Loss: 0.3153
===> Epoch[23](2200/2500): Loss: 0.3161
===> Epoch[23](2300/2500): Loss: 0.2718
===> Epoch[23](2400/2500): Loss: 0.2764
===> Epoch[23](2500/2500): Loss: 0.2932
===> Epoch 23 Complete: Avg. Loss: 0.2903
===> Timestamp: [2025-08-03 21:16:15]
===> Loading train datasets
===> Epoch[23](100/2500): Loss: 0.2877
===> Epoch[23](200/2500): Loss: 0.2957
===> Epoch[23](300/2500): Loss: 0.2855
===> Epoch[23](400/2500): Loss: 0.2751
===> Epoch[23](500/2500): Loss: 0.3166
===> Epoch[23](600/2500): Loss: 0.3158
===> Epoch[23](700/2500): Loss: 0.2887
===> Epoch[23](800/2500): Loss: 0.2963
===> Epoch[23](900/2500): Loss: 0.2843
===> Epoch[23](1000/2500): Loss: 0.2983
===> Epoch[23](1100/2500): Loss: 0.2636
===> Epoch[23](1200/2500): Loss: 0.2951
===> Epoch[23](1300/2500): Loss: 0.3079
===> Epoch[23](1400/2500): Loss: 0.2866
===> Epoch[23](1500/2500): Loss: 0.2919
===> Epoch[23](1600/2500): Loss: 0.2970
===> Epoch[23](1700/2500): Loss: 0.3076
===> Epoch[23](1800/2500): Loss: 0.2546
===> Epoch[23](1900/2500): Loss: 0.2708
===> Epoch[23](2000/2500): Loss: 0.2798
===> Epoch[23](2100/2500): Loss: 0.3153
===> Epoch[23](2200/2500): Loss: 0.3161
===> Epoch[23](2300/2500): Loss: 0.2718
===> Epoch[23](2400/2500): Loss: 0.2764
===> Epoch[23](2500/2500): Loss: 0.2932
===> Epoch 23 Complete: Avg. Loss: 0.2903
===> Timestamp: [2025-08-03 21:16:15]
===> Loading train datasets
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2788
===> Epoch[24](200/2500): Loss: 0.2912
===> Epoch[24](300/2500): Loss: 0.3024
===> Epoch[24](400/2500): Loss: 0.3079
===> Epoch[24](500/2500): Loss: 0.3277
===> Epoch[24](600/2500): Loss: 0.2795
===> Epoch[24](700/2500): Loss: 0.2865
===> Epoch[24](800/2500): Loss: 0.2983
===> Epoch[24](900/2500): Loss: 0.2881
===> Epoch[24](1000/2500): Loss: 0.3033
===> Epoch[24](1100/2500): Loss: 0.2997
===> Epoch[24](1200/2500): Loss: 0.3436
===> Epoch[24](1300/2500): Loss: 0.2759
===> Epoch[24](1400/2500): Loss: 0.2979
===> Epoch[24](1500/2500): Loss: 0.2861
===> Epoch[24](1600/2500): Loss: 0.3220
===> Epoch[24](1700/2500): Loss: 0.2859
===> Epoch[24](1800/2500): Loss: 0.2911
===> Epoch[24](1900/2500): Loss: 0.2920
===> Epoch[24](2000/2500): Loss: 0.2714
===> Epoch[24](2100/2500): Loss: 0.2980
===> Epoch[24](2200/2500): Loss: 0.2858
===> Epoch[24](2300/2500): Loss: 0.2866
===> Epoch[24](2400/2500): Loss: 0.2907
===> Epoch[24](2500/2500): Loss: 0.2581
===> Epoch 24 Complete: Avg. Loss: 0.2900
===> Timestamp: [2025-08-03 21:20:49]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2788
===> Epoch[24](200/2500): Loss: 0.2912
===> Epoch[24](300/2500): Loss: 0.3024
===> Epoch[24](400/2500): Loss: 0.3079
===> Epoch[24](500/2500): Loss: 0.3277
===> Epoch[24](600/2500): Loss: 0.2795
===> Epoch[24](700/2500): Loss: 0.2865
===> Epoch[24](800/2500): Loss: 0.2983
===> Epoch[24](900/2500): Loss: 0.2881
===> Epoch[24](1000/2500): Loss: 0.3033
===> Epoch[24](1100/2500): Loss: 0.2997
===> Epoch[24](1200/2500): Loss: 0.3436
===> Epoch[24](1300/2500): Loss: 0.2759
===> Epoch[24](1400/2500): Loss: 0.2979
===> Epoch[24](1500/2500): Loss: 0.2861
===> Epoch[24](1600/2500): Loss: 0.3220
===> Epoch[24](1700/2500): Loss: 0.2859
===> Epoch[24](1800/2500): Loss: 0.2911
===> Epoch[24](1900/2500): Loss: 0.2920
===> Epoch[24](2000/2500): Loss: 0.2714
===> Epoch[24](2100/2500): Loss: 0.2980
===> Epoch[24](2200/2500): Loss: 0.2858
===> Epoch[24](2300/2500): Loss: 0.2866
===> Epoch[24](2400/2500): Loss: 0.2907
===> Epoch[24](2500/2500): Loss: 0.2581
===> Epoch 24 Complete: Avg. Loss: 0.2900
===> Timestamp: [2025-08-03 21:20:49]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2788
===> Epoch[24](200/2500): Loss: 0.2912
===> Epoch[24](300/2500): Loss: 0.3024
===> Epoch[24](400/2500): Loss: 0.3079
===> Epoch[24](500/2500): Loss: 0.3277
===> Epoch[24](600/2500): Loss: 0.2795
===> Epoch[24](700/2500): Loss: 0.2865
===> Epoch[24](800/2500): Loss: 0.2983
===> Epoch[24](900/2500): Loss: 0.2881
===> Epoch[24](1000/2500): Loss: 0.3033
===> Epoch[24](1100/2500): Loss: 0.2997
===> Epoch[24](1200/2500): Loss: 0.3436
===> Epoch[24](1300/2500): Loss: 0.2759
===> Epoch[24](1400/2500): Loss: 0.2979
===> Epoch[24](1500/2500): Loss: 0.2861
===> Epoch[24](1600/2500): Loss: 0.3220
===> Epoch[24](1700/2500): Loss: 0.2859
===> Epoch[24](1800/2500): Loss: 0.2911
===> Epoch[24](1900/2500): Loss: 0.2920
===> Epoch[24](2000/2500): Loss: 0.2714
===> Epoch[24](2100/2500): Loss: 0.2980
===> Epoch[24](2200/2500): Loss: 0.2858
===> Epoch[24](2300/2500): Loss: 0.2866
===> Epoch[24](2400/2500): Loss: 0.2907
===> Epoch[24](2500/2500): Loss: 0.2581
===> Epoch 24 Complete: Avg. Loss: 0.2900
===> Timestamp: [2025-08-03 21:20:49]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2788
===> Epoch[24](200/2500): Loss: 0.2912
===> Epoch[24](300/2500): Loss: 0.3024
===> Epoch[24](400/2500): Loss: 0.3079
===> Epoch[24](500/2500): Loss: 0.3277
===> Epoch[24](600/2500): Loss: 0.2795
===> Epoch[24](700/2500): Loss: 0.2865
===> Epoch[24](800/2500): Loss: 0.2983
===> Epoch[24](900/2500): Loss: 0.2881
===> Epoch[24](1000/2500): Loss: 0.3033
===> Epoch[24](1100/2500): Loss: 0.2997
===> Epoch[24](1200/2500): Loss: 0.3436
===> Epoch[24](1300/2500): Loss: 0.2759
===> Epoch[24](1400/2500): Loss: 0.2979
===> Epoch[24](1500/2500): Loss: 0.2861
===> Epoch[24](1600/2500): Loss: 0.3220
===> Epoch[24](1700/2500): Loss: 0.2859
===> Epoch[24](1800/2500): Loss: 0.2911
===> Epoch[24](1900/2500): Loss: 0.2920
===> Epoch[24](2000/2500): Loss: 0.2714
===> Epoch[24](2100/2500): Loss: 0.2980
===> Epoch[24](2200/2500): Loss: 0.2858
===> Epoch[24](2300/2500): Loss: 0.2866
===> Epoch[24](2400/2500): Loss: 0.2907
===> Epoch[24](2500/2500): Loss: 0.2581
===> Epoch 24 Complete: Avg. Loss: 0.2900
===> Timestamp: [2025-08-03 21:20:49]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2788
===> Epoch[24](200/2500): Loss: 0.2912
===> Epoch[24](300/2500): Loss: 0.3024
===> Epoch[24](400/2500): Loss: 0.3079
===> Epoch[24](500/2500): Loss: 0.3277
===> Epoch[24](600/2500): Loss: 0.2795
===> Epoch[24](700/2500): Loss: 0.2865
===> Epoch[24](800/2500): Loss: 0.2983
===> Epoch[24](900/2500): Loss: 0.2881
===> Epoch[24](1000/2500): Loss: 0.3033
===> Epoch[24](1100/2500): Loss: 0.2997
===> Epoch[24](1200/2500): Loss: 0.3436
===> Epoch[24](1300/2500): Loss: 0.2759
===> Epoch[24](1400/2500): Loss: 0.2979
===> Epoch[24](1500/2500): Loss: 0.2861
===> Epoch[24](1600/2500): Loss: 0.3220
===> Epoch[24](1700/2500): Loss: 0.2859
===> Epoch[24](1800/2500): Loss: 0.2911
===> Epoch[24](1900/2500): Loss: 0.2920
===> Epoch[24](2000/2500): Loss: 0.2714
===> Epoch[24](2100/2500): Loss: 0.2980
===> Epoch[24](2200/2500): Loss: 0.2858
===> Epoch[24](2300/2500): Loss: 0.2866
===> Epoch[24](2400/2500): Loss: 0.2907
===> Epoch[24](2500/2500): Loss: 0.2581
===> Epoch 24 Complete: Avg. Loss: 0.2900
===> Timestamp: [2025-08-03 21:20:49]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2788
===> Epoch[24](200/2500): Loss: 0.2912
===> Epoch[24](300/2500): Loss: 0.3024
===> Epoch[24](400/2500): Loss: 0.3079
===> Epoch[24](500/2500): Loss: 0.3277
===> Epoch[24](600/2500): Loss: 0.2795
===> Epoch[24](700/2500): Loss: 0.2865
===> Epoch[24](800/2500): Loss: 0.2983
===> Epoch[24](900/2500): Loss: 0.2881
===> Epoch[24](1000/2500): Loss: 0.3033
===> Epoch[24](1100/2500): Loss: 0.2997
===> Epoch[24](1200/2500): Loss: 0.3436
===> Epoch[24](1300/2500): Loss: 0.2759
===> Epoch[24](1400/2500): Loss: 0.2979
===> Epoch[24](1500/2500): Loss: 0.2861
===> Epoch[24](1600/2500): Loss: 0.3220
===> Epoch[24](1700/2500): Loss: 0.2859
===> Epoch[24](1800/2500): Loss: 0.2911
===> Epoch[24](1900/2500): Loss: 0.2920
===> Epoch[24](2000/2500): Loss: 0.2714
===> Epoch[24](2100/2500): Loss: 0.2980
===> Epoch[24](2200/2500): Loss: 0.2858
===> Epoch[24](2300/2500): Loss: 0.2866
===> Epoch[24](2400/2500): Loss: 0.2907
===> Epoch[24](2500/2500): Loss: 0.2581
===> Epoch 24 Complete: Avg. Loss: 0.2900
===> Timestamp: [2025-08-03 21:20:49]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2788
===> Epoch[24](200/2500): Loss: 0.2912
===> Epoch[24](300/2500): Loss: 0.3024
===> Epoch[24](400/2500): Loss: 0.3079
===> Epoch[24](500/2500): Loss: 0.3277
===> Epoch[24](600/2500): Loss: 0.2795
===> Epoch[24](700/2500): Loss: 0.2865
===> Epoch[24](800/2500): Loss: 0.2983
===> Epoch[24](900/2500): Loss: 0.2881
===> Epoch[24](1000/2500): Loss: 0.3033
===> Epoch[24](1100/2500): Loss: 0.2997
===> Epoch[24](1200/2500): Loss: 0.3436
===> Epoch[24](1300/2500): Loss: 0.2759
===> Epoch[24](1400/2500): Loss: 0.2979
===> Epoch[24](1500/2500): Loss: 0.2861
===> Epoch[24](1600/2500): Loss: 0.3220
===> Epoch[24](1700/2500): Loss: 0.2859
===> Epoch[24](1800/2500): Loss: 0.2911
===> Epoch[24](1900/2500): Loss: 0.2920
===> Epoch[24](2000/2500): Loss: 0.2714
===> Epoch[24](2100/2500): Loss: 0.2980
===> Epoch[24](2200/2500): Loss: 0.2858
===> Epoch[24](2300/2500): Loss: 0.2866
===> Epoch[24](2400/2500): Loss: 0.2907
===> Epoch[24](2500/2500): Loss: 0.2581
===> Epoch 24 Complete: Avg. Loss: 0.2900
===> Timestamp: [2025-08-03 21:20:49]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2788
===> Epoch[24](200/2500): Loss: 0.2912
===> Epoch[24](300/2500): Loss: 0.3024
===> Epoch[24](400/2500): Loss: 0.3079
===> Epoch[24](500/2500): Loss: 0.3277
===> Epoch[24](600/2500): Loss: 0.2795
===> Epoch[24](700/2500): Loss: 0.2865
===> Epoch[24](800/2500): Loss: 0.2983
===> Epoch[24](900/2500): Loss: 0.2881
===> Epoch[24](1000/2500): Loss: 0.3033
===> Epoch[24](1100/2500): Loss: 0.2997
===> Epoch[24](1200/2500): Loss: 0.3436
===> Epoch[24](1300/2500): Loss: 0.2759
===> Epoch[24](1400/2500): Loss: 0.2979
===> Epoch[24](1500/2500): Loss: 0.2861
===> Epoch[24](1600/2500): Loss: 0.3220
===> Epoch[24](1700/2500): Loss: 0.2859
===> Epoch[24](1800/2500): Loss: 0.2911
===> Epoch[24](1900/2500): Loss: 0.2920
===> Epoch[24](2000/2500): Loss: 0.2714
===> Epoch[24](2100/2500): Loss: 0.2980
===> Epoch[24](2200/2500): Loss: 0.2858
===> Epoch[24](2300/2500): Loss: 0.2866
===> Epoch[24](2400/2500): Loss: 0.2907
===> Epoch[24](2500/2500): Loss: 0.2581
===> Epoch 24 Complete: Avg. Loss: 0.2900
===> Timestamp: [2025-08-03 21:20:49]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2788
===> Epoch[24](200/2500): Loss: 0.2912
===> Epoch[24](300/2500): Loss: 0.3024
===> Epoch[24](400/2500): Loss: 0.3079
===> Epoch[24](500/2500): Loss: 0.3277
===> Epoch[24](600/2500): Loss: 0.2795
===> Epoch[24](700/2500): Loss: 0.2865
===> Epoch[24](800/2500): Loss: 0.2983
===> Epoch[24](900/2500): Loss: 0.2881
===> Epoch[24](1000/2500): Loss: 0.3033
===> Epoch[24](1100/2500): Loss: 0.2997
===> Epoch[24](1200/2500): Loss: 0.3436
===> Epoch[24](1300/2500): Loss: 0.2759
===> Epoch[24](1400/2500): Loss: 0.2979
===> Epoch[24](1500/2500): Loss: 0.2861
===> Epoch[24](1600/2500): Loss: 0.3220
===> Epoch[24](1700/2500): Loss: 0.2859
===> Epoch[24](1800/2500): Loss: 0.2911
===> Epoch[24](1900/2500): Loss: 0.2920
===> Epoch[24](2000/2500): Loss: 0.2714
===> Epoch[24](2100/2500): Loss: 0.2980
===> Epoch[24](2200/2500): Loss: 0.2858
===> Epoch[24](2300/2500): Loss: 0.2866
===> Epoch[24](2400/2500): Loss: 0.2907
===> Epoch[24](2500/2500): Loss: 0.2581
===> Epoch 24 Complete: Avg. Loss: 0.2900
===> Timestamp: [2025-08-03 21:20:49]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2788
===> Epoch[24](200/2500): Loss: 0.2912
===> Epoch[24](300/2500): Loss: 0.3024
===> Epoch[24](400/2500): Loss: 0.3079
===> Epoch[24](500/2500): Loss: 0.3277
===> Epoch[24](600/2500): Loss: 0.2795
===> Epoch[24](700/2500): Loss: 0.2865
===> Epoch[24](800/2500): Loss: 0.2983
===> Epoch[24](900/2500): Loss: 0.2881
===> Epoch[24](1000/2500): Loss: 0.3033
===> Epoch[24](1100/2500): Loss: 0.2997
===> Epoch[24](1200/2500): Loss: 0.3436
===> Epoch[24](1300/2500): Loss: 0.2759
===> Epoch[24](1400/2500): Loss: 0.2979
===> Epoch[24](1500/2500): Loss: 0.2861
===> Epoch[24](1600/2500): Loss: 0.3220
===> Epoch[24](1700/2500): Loss: 0.2859
===> Epoch[24](1800/2500): Loss: 0.2911
===> Epoch[24](1900/2500): Loss: 0.2920
===> Epoch[24](2000/2500): Loss: 0.2714
===> Epoch[24](2100/2500): Loss: 0.2980
===> Epoch[24](2200/2500): Loss: 0.2858
===> Epoch[24](2300/2500): Loss: 0.2866
===> Epoch[24](2400/2500): Loss: 0.2907
===> Epoch[24](2500/2500): Loss: 0.2581
===> Epoch 24 Complete: Avg. Loss: 0.2900
===> Timestamp: [2025-08-03 21:20:49]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2788
===> Epoch[24](200/2500): Loss: 0.2912
===> Epoch[24](300/2500): Loss: 0.3024
===> Epoch[24](400/2500): Loss: 0.3079
===> Epoch[24](500/2500): Loss: 0.3277
===> Epoch[24](600/2500): Loss: 0.2795
===> Epoch[24](700/2500): Loss: 0.2865
===> Epoch[24](800/2500): Loss: 0.2983
===> Epoch[24](900/2500): Loss: 0.2881
===> Epoch[24](1000/2500): Loss: 0.3033
===> Epoch[24](1100/2500): Loss: 0.2997
===> Epoch[24](1200/2500): Loss: 0.3436
===> Epoch[24](1300/2500): Loss: 0.2759
===> Epoch[24](1400/2500): Loss: 0.2979
===> Epoch[24](1500/2500): Loss: 0.2861
===> Epoch[24](1600/2500): Loss: 0.3220
===> Epoch[24](1700/2500): Loss: 0.2859
===> Epoch[24](1800/2500): Loss: 0.2911
===> Epoch[24](1900/2500): Loss: 0.2920
===> Epoch[24](2000/2500): Loss: 0.2714
===> Epoch[24](2100/2500): Loss: 0.2980
===> Epoch[24](2200/2500): Loss: 0.2858
===> Epoch[24](2300/2500): Loss: 0.2866
===> Epoch[24](2400/2500): Loss: 0.2907
===> Epoch[24](2500/2500): Loss: 0.2581
===> Epoch 24 Complete: Avg. Loss: 0.2900
===> Timestamp: [2025-08-03 21:20:49]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2788
===> Epoch[24](200/2500): Loss: 0.2912
===> Epoch[24](300/2500): Loss: 0.3024
===> Epoch[24](400/2500): Loss: 0.3079
===> Epoch[24](500/2500): Loss: 0.3277
===> Epoch[24](600/2500): Loss: 0.2795
===> Epoch[24](700/2500): Loss: 0.2865
===> Epoch[24](800/2500): Loss: 0.2983
===> Epoch[24](900/2500): Loss: 0.2881
===> Epoch[24](1000/2500): Loss: 0.3033
===> Epoch[24](1100/2500): Loss: 0.2997
===> Epoch[24](1200/2500): Loss: 0.3436
===> Epoch[24](1300/2500): Loss: 0.2759
===> Epoch[24](1400/2500): Loss: 0.2979
===> Epoch[24](1500/2500): Loss: 0.2861
===> Epoch[24](1600/2500): Loss: 0.3220
===> Epoch[24](1700/2500): Loss: 0.2859
===> Epoch[24](1800/2500): Loss: 0.2911
===> Epoch[24](1900/2500): Loss: 0.2920
===> Epoch[24](2000/2500): Loss: 0.2714
===> Epoch[24](2100/2500): Loss: 0.2980
===> Epoch[24](2200/2500): Loss: 0.2858
===> Epoch[24](2300/2500): Loss: 0.2866
===> Epoch[24](2400/2500): Loss: 0.2907
===> Epoch[24](2500/2500): Loss: 0.2581
===> Epoch 24 Complete: Avg. Loss: 0.2900
===> Timestamp: [2025-08-03 21:20:49]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2788
===> Epoch[24](200/2500): Loss: 0.2912
===> Epoch[24](300/2500): Loss: 0.3024
===> Epoch[24](400/2500): Loss: 0.3079
===> Epoch[24](500/2500): Loss: 0.3277
===> Epoch[24](600/2500): Loss: 0.2795
===> Epoch[24](700/2500): Loss: 0.2865
===> Epoch[24](800/2500): Loss: 0.2983
===> Epoch[24](900/2500): Loss: 0.2881
===> Epoch[24](1000/2500): Loss: 0.3033
===> Epoch[24](1100/2500): Loss: 0.2997
===> Epoch[24](1200/2500): Loss: 0.3436
===> Epoch[24](1300/2500): Loss: 0.2759
===> Epoch[24](1400/2500): Loss: 0.2979
===> Epoch[24](1500/2500): Loss: 0.2861
===> Epoch[24](1600/2500): Loss: 0.3220
===> Epoch[24](1700/2500): Loss: 0.2859
===> Epoch[24](1800/2500): Loss: 0.2911
===> Epoch[24](1900/2500): Loss: 0.2920
===> Epoch[24](2000/2500): Loss: 0.2714
===> Epoch[24](2100/2500): Loss: 0.2980
===> Epoch[24](2200/2500): Loss: 0.2858
===> Epoch[24](2300/2500): Loss: 0.2866
===> Epoch[24](2400/2500): Loss: 0.2907
===> Epoch[24](2500/2500): Loss: 0.2581
===> Epoch 24 Complete: Avg. Loss: 0.2900
===> Timestamp: [2025-08-03 21:20:49]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2788
===> Epoch[24](200/2500): Loss: 0.2912
===> Epoch[24](300/2500): Loss: 0.3024
===> Epoch[24](400/2500): Loss: 0.3079
===> Epoch[24](500/2500): Loss: 0.3277
===> Epoch[24](600/2500): Loss: 0.2795
===> Epoch[24](700/2500): Loss: 0.2865
===> Epoch[24](800/2500): Loss: 0.2983
===> Epoch[24](900/2500): Loss: 0.2881
===> Epoch[24](1000/2500): Loss: 0.3033
===> Epoch[24](1100/2500): Loss: 0.2997
===> Epoch[24](1200/2500): Loss: 0.3436
===> Epoch[24](1300/2500): Loss: 0.2759
===> Epoch[24](1400/2500): Loss: 0.2979
===> Epoch[24](1500/2500): Loss: 0.2861
===> Epoch[24](1600/2500): Loss: 0.3220
===> Epoch[24](1700/2500): Loss: 0.2859
===> Epoch[24](1800/2500): Loss: 0.2911
===> Epoch[24](1900/2500): Loss: 0.2920
===> Epoch[24](2000/2500): Loss: 0.2714
===> Epoch[24](2100/2500): Loss: 0.2980
===> Epoch[24](2200/2500): Loss: 0.2858
===> Epoch[24](2300/2500): Loss: 0.2866
===> Epoch[24](2400/2500): Loss: 0.2907
===> Epoch[24](2500/2500): Loss: 0.2581
===> Epoch 24 Complete: Avg. Loss: 0.2900
===> Timestamp: [2025-08-03 21:20:49]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2788
===> Epoch[24](200/2500): Loss: 0.2912
===> Epoch[24](300/2500): Loss: 0.3024
===> Epoch[24](400/2500): Loss: 0.3079
===> Epoch[24](500/2500): Loss: 0.3277
===> Epoch[24](600/2500): Loss: 0.2795
===> Epoch[24](700/2500): Loss: 0.2865
===> Epoch[24](800/2500): Loss: 0.2983
===> Epoch[24](900/2500): Loss: 0.2881
===> Epoch[24](1000/2500): Loss: 0.3033
===> Epoch[24](1100/2500): Loss: 0.2997
===> Epoch[24](1200/2500): Loss: 0.3436
===> Epoch[24](1300/2500): Loss: 0.2759
===> Epoch[24](1400/2500): Loss: 0.2979
===> Epoch[24](1500/2500): Loss: 0.2861
===> Epoch[24](1600/2500): Loss: 0.3220
===> Epoch[24](1700/2500): Loss: 0.2859
===> Epoch[24](1800/2500): Loss: 0.2911
===> Epoch[24](1900/2500): Loss: 0.2920
===> Epoch[24](2000/2500): Loss: 0.2714
===> Epoch[24](2100/2500): Loss: 0.2980
===> Epoch[24](2200/2500): Loss: 0.2858
===> Epoch[24](2300/2500): Loss: 0.2866
===> Epoch[24](2400/2500): Loss: 0.2907
===> Epoch[24](2500/2500): Loss: 0.2581
===> Epoch 24 Complete: Avg. Loss: 0.2900
===> Timestamp: [2025-08-03 21:20:49]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2788
===> Epoch[24](200/2500): Loss: 0.2912
===> Epoch[24](300/2500): Loss: 0.3024
===> Epoch[24](400/2500): Loss: 0.3079
===> Epoch[24](500/2500): Loss: 0.3277
===> Epoch[24](600/2500): Loss: 0.2795
===> Epoch[24](700/2500): Loss: 0.2865
===> Epoch[24](800/2500): Loss: 0.2983
===> Epoch[24](900/2500): Loss: 0.2881
===> Epoch[24](1000/2500): Loss: 0.3033
===> Epoch[24](1100/2500): Loss: 0.2997
===> Epoch[24](1200/2500): Loss: 0.3436
===> Epoch[24](1300/2500): Loss: 0.2759
===> Epoch[24](1400/2500): Loss: 0.2979
===> Epoch[24](1500/2500): Loss: 0.2861
===> Epoch[24](1600/2500): Loss: 0.3220
===> Epoch[24](1700/2500): Loss: 0.2859
===> Epoch[24](1800/2500): Loss: 0.2911
===> Epoch[24](1900/2500): Loss: 0.2920
===> Epoch[24](2000/2500): Loss: 0.2714
===> Epoch[24](2100/2500): Loss: 0.2980
===> Epoch[24](2200/2500): Loss: 0.2858
===> Epoch[24](2300/2500): Loss: 0.2866
===> Epoch[24](2400/2500): Loss: 0.2907
===> Epoch[24](2500/2500): Loss: 0.2581
===> Epoch 24 Complete: Avg. Loss: 0.2900
===> Timestamp: [2025-08-03 21:20:49]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2788
===> Epoch[24](200/2500): Loss: 0.2912
===> Epoch[24](300/2500): Loss: 0.3024
===> Epoch[24](400/2500): Loss: 0.3079
===> Epoch[24](500/2500): Loss: 0.3277
===> Epoch[24](600/2500): Loss: 0.2795
===> Epoch[24](700/2500): Loss: 0.2865
===> Epoch[24](800/2500): Loss: 0.2983
===> Epoch[24](900/2500): Loss: 0.2881
===> Epoch[24](1000/2500): Loss: 0.3033
===> Epoch[24](1100/2500): Loss: 0.2997
===> Epoch[24](1200/2500): Loss: 0.3436
===> Epoch[24](1300/2500): Loss: 0.2759
===> Epoch[24](1400/2500): Loss: 0.2979
===> Epoch[24](1500/2500): Loss: 0.2861
===> Epoch[24](1600/2500): Loss: 0.3220
===> Epoch[24](1700/2500): Loss: 0.2859
===> Epoch[24](1800/2500): Loss: 0.2911
===> Epoch[24](1900/2500): Loss: 0.2920
===> Epoch[24](2000/2500): Loss: 0.2714
===> Epoch[24](2100/2500): Loss: 0.2980
===> Epoch[24](2200/2500): Loss: 0.2858
===> Epoch[24](2300/2500): Loss: 0.2866
===> Epoch[24](2400/2500): Loss: 0.2907
===> Epoch[24](2500/2500): Loss: 0.2581
===> Epoch 24 Complete: Avg. Loss: 0.2900
===> Timestamp: [2025-08-03 21:20:49]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2788
===> Epoch[24](200/2500): Loss: 0.2912
===> Epoch[24](300/2500): Loss: 0.3024
===> Epoch[24](400/2500): Loss: 0.3079
===> Epoch[24](500/2500): Loss: 0.3277
===> Epoch[24](600/2500): Loss: 0.2795
===> Epoch[24](700/2500): Loss: 0.2865
===> Epoch[24](800/2500): Loss: 0.2983
===> Epoch[24](900/2500): Loss: 0.2881
===> Epoch[24](1000/2500): Loss: 0.3033
===> Epoch[24](1100/2500): Loss: 0.2997
===> Epoch[24](1200/2500): Loss: 0.3436
===> Epoch[24](1300/2500): Loss: 0.2759
===> Epoch[24](1400/2500): Loss: 0.2979
===> Epoch[24](1500/2500): Loss: 0.2861
===> Epoch[24](1600/2500): Loss: 0.3220
===> Epoch[24](1700/2500): Loss: 0.2859
===> Epoch[24](1800/2500): Loss: 0.2911
===> Epoch[24](1900/2500): Loss: 0.2920
===> Epoch[24](2000/2500): Loss: 0.2714
===> Epoch[24](2100/2500): Loss: 0.2980
===> Epoch[24](2200/2500): Loss: 0.2858
===> Epoch[24](2300/2500): Loss: 0.2866
===> Epoch[24](2400/2500): Loss: 0.2907
===> Epoch[24](2500/2500): Loss: 0.2581
===> Epoch 24 Complete: Avg. Loss: 0.2900
===> Timestamp: [2025-08-03 21:20:49]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2788
===> Epoch[24](200/2500): Loss: 0.2912
===> Epoch[24](300/2500): Loss: 0.3024
===> Epoch[24](400/2500): Loss: 0.3079
===> Epoch[24](500/2500): Loss: 0.3277
===> Epoch[24](600/2500): Loss: 0.2795
===> Epoch[24](700/2500): Loss: 0.2865
===> Epoch[24](800/2500): Loss: 0.2983
===> Epoch[24](900/2500): Loss: 0.2881
===> Epoch[24](1000/2500): Loss: 0.3033
===> Epoch[24](1100/2500): Loss: 0.2997
===> Epoch[24](1200/2500): Loss: 0.3436
===> Epoch[24](1300/2500): Loss: 0.2759
===> Epoch[24](1400/2500): Loss: 0.2979
===> Epoch[24](1500/2500): Loss: 0.2861
===> Epoch[24](1600/2500): Loss: 0.3220
===> Epoch[24](1700/2500): Loss: 0.2859
===> Epoch[24](1800/2500): Loss: 0.2911
===> Epoch[24](1900/2500): Loss: 0.2920
===> Epoch[24](2000/2500): Loss: 0.2714
===> Epoch[24](2100/2500): Loss: 0.2980
===> Epoch[24](2200/2500): Loss: 0.2858
===> Epoch[24](2300/2500): Loss: 0.2866
===> Epoch[24](2400/2500): Loss: 0.2907
===> Epoch[24](2500/2500): Loss: 0.2581
===> Epoch 24 Complete: Avg. Loss: 0.2900
===> Timestamp: [2025-08-03 21:20:49]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2788
===> Epoch[24](200/2500): Loss: 0.2912
===> Epoch[24](300/2500): Loss: 0.3024
===> Epoch[24](400/2500): Loss: 0.3079
===> Epoch[24](500/2500): Loss: 0.3277
===> Epoch[24](600/2500): Loss: 0.2795
===> Epoch[24](700/2500): Loss: 0.2865
===> Epoch[24](800/2500): Loss: 0.2983
===> Epoch[24](900/2500): Loss: 0.2881
===> Epoch[24](1000/2500): Loss: 0.3033
===> Epoch[24](1100/2500): Loss: 0.2997
===> Epoch[24](1200/2500): Loss: 0.3436
===> Epoch[24](1300/2500): Loss: 0.2759
===> Epoch[24](1400/2500): Loss: 0.2979
===> Epoch[24](1500/2500): Loss: 0.2861
===> Epoch[24](1600/2500): Loss: 0.3220
===> Epoch[24](1700/2500): Loss: 0.2859
===> Epoch[24](1800/2500): Loss: 0.2911
===> Epoch[24](1900/2500): Loss: 0.2920
===> Epoch[24](2000/2500): Loss: 0.2714
===> Epoch[24](2100/2500): Loss: 0.2980
===> Epoch[24](2200/2500): Loss: 0.2858
===> Epoch[24](2300/2500): Loss: 0.2866
===> Epoch[24](2400/2500): Loss: 0.2907
===> Epoch[24](2500/2500): Loss: 0.2581
===> Epoch 24 Complete: Avg. Loss: 0.2900
===> Timestamp: [2025-08-03 21:20:49]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2788
===> Epoch[24](200/2500): Loss: 0.2912
===> Epoch[24](300/2500): Loss: 0.3024
===> Epoch[24](400/2500): Loss: 0.3079
===> Epoch[24](500/2500): Loss: 0.3277
===> Epoch[24](600/2500): Loss: 0.2795
===> Epoch[24](700/2500): Loss: 0.2865
===> Epoch[24](800/2500): Loss: 0.2983
===> Epoch[24](900/2500): Loss: 0.2881
===> Epoch[24](1000/2500): Loss: 0.3033
===> Epoch[24](1100/2500): Loss: 0.2997
===> Epoch[24](1200/2500): Loss: 0.3436
===> Epoch[24](1300/2500): Loss: 0.2759
===> Epoch[24](1400/2500): Loss: 0.2979
===> Epoch[24](1500/2500): Loss: 0.2861
===> Epoch[24](1600/2500): Loss: 0.3220
===> Epoch[24](1700/2500): Loss: 0.2859
===> Epoch[24](1800/2500): Loss: 0.2911
===> Epoch[24](1900/2500): Loss: 0.2920
===> Epoch[24](2000/2500): Loss: 0.2714
===> Epoch[24](2100/2500): Loss: 0.2980
===> Epoch[24](2200/2500): Loss: 0.2858
===> Epoch[24](2300/2500): Loss: 0.2866
===> Epoch[24](2400/2500): Loss: 0.2907
===> Epoch[24](2500/2500): Loss: 0.2581
===> Epoch 24 Complete: Avg. Loss: 0.2900
===> Timestamp: [2025-08-03 21:20:49]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2788
===> Epoch[24](200/2500): Loss: 0.2912
===> Epoch[24](300/2500): Loss: 0.3024
===> Epoch[24](400/2500): Loss: 0.3079
===> Epoch[24](500/2500): Loss: 0.3277
===> Epoch[24](600/2500): Loss: 0.2795
===> Epoch[24](700/2500): Loss: 0.2865
===> Epoch[24](800/2500): Loss: 0.2983
===> Epoch[24](900/2500): Loss: 0.2881
===> Epoch[24](1000/2500): Loss: 0.3033
===> Epoch[24](1100/2500): Loss: 0.2997
===> Epoch[24](1200/2500): Loss: 0.3436
===> Epoch[24](1300/2500): Loss: 0.2759
===> Epoch[24](1400/2500): Loss: 0.2979
===> Epoch[24](1500/2500): Loss: 0.2861
===> Epoch[24](1600/2500): Loss: 0.3220
===> Epoch[24](1700/2500): Loss: 0.2859
===> Epoch[24](1800/2500): Loss: 0.2911
===> Epoch[24](1900/2500): Loss: 0.2920
===> Epoch[24](2000/2500): Loss: 0.2714
===> Epoch[24](2100/2500): Loss: 0.2980
===> Epoch[24](2200/2500): Loss: 0.2858
===> Epoch[24](2300/2500): Loss: 0.2866
===> Epoch[24](2400/2500): Loss: 0.2907
===> Epoch[24](2500/2500): Loss: 0.2581
===> Epoch 24 Complete: Avg. Loss: 0.2900
===> Timestamp: [2025-08-03 21:20:49]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2788
===> Epoch[24](200/2500): Loss: 0.2912
===> Epoch[24](300/2500): Loss: 0.3024
===> Epoch[24](400/2500): Loss: 0.3079
===> Epoch[24](500/2500): Loss: 0.3277
===> Epoch[24](600/2500): Loss: 0.2795
===> Epoch[24](700/2500): Loss: 0.2865
===> Epoch[24](800/2500): Loss: 0.2983
===> Epoch[24](900/2500): Loss: 0.2881
===> Epoch[24](1000/2500): Loss: 0.3033
===> Epoch[24](1100/2500): Loss: 0.2997
===> Epoch[24](1200/2500): Loss: 0.3436
===> Epoch[24](1300/2500): Loss: 0.2759
===> Epoch[24](1400/2500): Loss: 0.2979
===> Epoch[24](1500/2500): Loss: 0.2861
===> Epoch[24](1600/2500): Loss: 0.3220
===> Epoch[24](1700/2500): Loss: 0.2859
===> Epoch[24](1800/2500): Loss: 0.2911
===> Epoch[24](1900/2500): Loss: 0.2920
===> Epoch[24](2000/2500): Loss: 0.2714
===> Epoch[24](2100/2500): Loss: 0.2980
===> Epoch[24](2200/2500): Loss: 0.2858
===> Epoch[24](2300/2500): Loss: 0.2866
===> Epoch[24](2400/2500): Loss: 0.2907
===> Epoch[24](2500/2500): Loss: 0.2581
===> Epoch 24 Complete: Avg. Loss: 0.2900
===> Timestamp: [2025-08-03 21:20:49]
===> Loading train datasets
===> Epoch[24](100/2500): Loss: 0.2788
===> Epoch[24](200/2500): Loss: 0.2912
===> Epoch[24](300/2500): Loss: 0.3024
===> Epoch[24](400/2500): Loss: 0.3079
===> Epoch[24](500/2500): Loss: 0.3277
===> Epoch[24](600/2500): Loss: 0.2795
===> Epoch[24](700/2500): Loss: 0.2865
===> Epoch[24](800/2500): Loss: 0.2983
===> Epoch[24](900/2500): Loss: 0.2881
===> Epoch[24](1000/2500): Loss: 0.3033
===> Epoch[24](1100/2500): Loss: 0.2997
===> Epoch[24](1200/2500): Loss: 0.3436
===> Epoch[24](1300/2500): Loss: 0.2759
===> Epoch[24](1400/2500): Loss: 0.2979
===> Epoch[24](1500/2500): Loss: 0.2861
===> Epoch[24](1600/2500): Loss: 0.3220
===> Epoch[24](1700/2500): Loss: 0.2859
===> Epoch[24](1800/2500): Loss: 0.2911
===> Epoch[24](1900/2500): Loss: 0.2920
===> Epoch[24](2000/2500): Loss: 0.2714
===> Epoch[24](2100/2500): Loss: 0.2980
===> Epoch[24](2200/2500): Loss: 0.2858
===> Epoch[24](2300/2500): Loss: 0.2866
===> Epoch[24](2400/2500): Loss: 0.2907
===> Epoch[24](2500/2500): Loss: 0.2581
===> Epoch 24 Complete: Avg. Loss: 0.2900
===> Timestamp: [2025-08-03 21:20:49]
===> Loading train datasets
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2778
===> Epoch[25](200/2500): Loss: 0.2796
===> Epoch[25](300/2500): Loss: 0.3073
===> Epoch[25](400/2500): Loss: 0.2709
===> Epoch[25](500/2500): Loss: 0.2708
===> Epoch[25](600/2500): Loss: 0.3023
===> Epoch[25](700/2500): Loss: 0.2673
===> Epoch[25](800/2500): Loss: 0.2836
===> Epoch[25](900/2500): Loss: 0.3190
===> Epoch[25](1000/2500): Loss: 0.2852
===> Epoch[25](1100/2500): Loss: 0.2906
===> Epoch[25](1200/2500): Loss: 0.3025
===> Epoch[25](1300/2500): Loss: 0.2873
===> Epoch[25](1400/2500): Loss: 0.2839
===> Epoch[25](1500/2500): Loss: 0.2747
===> Epoch[25](1600/2500): Loss: 0.2870
===> Epoch[25](1700/2500): Loss: 0.2972
===> Epoch[25](1800/2500): Loss: 0.2947
===> Epoch[25](1900/2500): Loss: 0.2898
===> Epoch[25](2000/2500): Loss: 0.2777
===> Epoch[25](2100/2500): Loss: 0.2944
===> Epoch[25](2200/2500): Loss: 0.3146
===> Epoch[25](2300/2500): Loss: 0.2740
===> Epoch[25](2400/2500): Loss: 0.2896
===> Epoch[25](2500/2500): Loss: 0.2822
===> Epoch 25 Complete: Avg. Loss: 0.2892
===> Timestamp: [2025-08-03 21:25:23]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2778
===> Epoch[25](200/2500): Loss: 0.2796
===> Epoch[25](300/2500): Loss: 0.3073
===> Epoch[25](400/2500): Loss: 0.2709
===> Epoch[25](500/2500): Loss: 0.2708
===> Epoch[25](600/2500): Loss: 0.3023
===> Epoch[25](700/2500): Loss: 0.2673
===> Epoch[25](800/2500): Loss: 0.2836
===> Epoch[25](900/2500): Loss: 0.3190
===> Epoch[25](1000/2500): Loss: 0.2852
===> Epoch[25](1100/2500): Loss: 0.2906
===> Epoch[25](1200/2500): Loss: 0.3025
===> Epoch[25](1300/2500): Loss: 0.2873
===> Epoch[25](1400/2500): Loss: 0.2839
===> Epoch[25](1500/2500): Loss: 0.2747
===> Epoch[25](1600/2500): Loss: 0.2870
===> Epoch[25](1700/2500): Loss: 0.2972
===> Epoch[25](1800/2500): Loss: 0.2947
===> Epoch[25](1900/2500): Loss: 0.2898
===> Epoch[25](2000/2500): Loss: 0.2777
===> Epoch[25](2100/2500): Loss: 0.2944
===> Epoch[25](2200/2500): Loss: 0.3146
===> Epoch[25](2300/2500): Loss: 0.2740
===> Epoch[25](2400/2500): Loss: 0.2896
===> Epoch[25](2500/2500): Loss: 0.2822
===> Epoch 25 Complete: Avg. Loss: 0.2892
===> Timestamp: [2025-08-03 21:25:23]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2778
===> Epoch[25](200/2500): Loss: 0.2796
===> Epoch[25](300/2500): Loss: 0.3073
===> Epoch[25](400/2500): Loss: 0.2709
===> Epoch[25](500/2500): Loss: 0.2708
===> Epoch[25](600/2500): Loss: 0.3023
===> Epoch[25](700/2500): Loss: 0.2673
===> Epoch[25](800/2500): Loss: 0.2836
===> Epoch[25](900/2500): Loss: 0.3190
===> Epoch[25](1000/2500): Loss: 0.2852
===> Epoch[25](1100/2500): Loss: 0.2906
===> Epoch[25](1200/2500): Loss: 0.3025
===> Epoch[25](1300/2500): Loss: 0.2873
===> Epoch[25](1400/2500): Loss: 0.2839
===> Epoch[25](1500/2500): Loss: 0.2747
===> Epoch[25](1600/2500): Loss: 0.2870
===> Epoch[25](1700/2500): Loss: 0.2972
===> Epoch[25](1800/2500): Loss: 0.2947
===> Epoch[25](1900/2500): Loss: 0.2898
===> Epoch[25](2000/2500): Loss: 0.2777
===> Epoch[25](2100/2500): Loss: 0.2944
===> Epoch[25](2200/2500): Loss: 0.3146
===> Epoch[25](2300/2500): Loss: 0.2740
===> Epoch[25](2400/2500): Loss: 0.2896
===> Epoch[25](2500/2500): Loss: 0.2822
===> Epoch 25 Complete: Avg. Loss: 0.2892
===> Timestamp: [2025-08-03 21:25:23]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2778
===> Epoch[25](200/2500): Loss: 0.2796
===> Epoch[25](300/2500): Loss: 0.3073
===> Epoch[25](400/2500): Loss: 0.2709
===> Epoch[25](500/2500): Loss: 0.2708
===> Epoch[25](600/2500): Loss: 0.3023
===> Epoch[25](700/2500): Loss: 0.2673
===> Epoch[25](800/2500): Loss: 0.2836
===> Epoch[25](900/2500): Loss: 0.3190
===> Epoch[25](1000/2500): Loss: 0.2852
===> Epoch[25](1100/2500): Loss: 0.2906
===> Epoch[25](1200/2500): Loss: 0.3025
===> Epoch[25](1300/2500): Loss: 0.2873
===> Epoch[25](1400/2500): Loss: 0.2839
===> Epoch[25](1500/2500): Loss: 0.2747
===> Epoch[25](1600/2500): Loss: 0.2870
===> Epoch[25](1700/2500): Loss: 0.2972
===> Epoch[25](1800/2500): Loss: 0.2947
===> Epoch[25](1900/2500): Loss: 0.2898
===> Epoch[25](2000/2500): Loss: 0.2777
===> Epoch[25](2100/2500): Loss: 0.2944
===> Epoch[25](2200/2500): Loss: 0.3146
===> Epoch[25](2300/2500): Loss: 0.2740
===> Epoch[25](2400/2500): Loss: 0.2896
===> Epoch[25](2500/2500): Loss: 0.2822
===> Epoch 25 Complete: Avg. Loss: 0.2892
===> Timestamp: [2025-08-03 21:25:23]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2778
===> Epoch[25](200/2500): Loss: 0.2796
===> Epoch[25](300/2500): Loss: 0.3073
===> Epoch[25](400/2500): Loss: 0.2709
===> Epoch[25](500/2500): Loss: 0.2708
===> Epoch[25](600/2500): Loss: 0.3023
===> Epoch[25](700/2500): Loss: 0.2673
===> Epoch[25](800/2500): Loss: 0.2836
===> Epoch[25](900/2500): Loss: 0.3190
===> Epoch[25](1000/2500): Loss: 0.2852
===> Epoch[25](1100/2500): Loss: 0.2906
===> Epoch[25](1200/2500): Loss: 0.3025
===> Epoch[25](1300/2500): Loss: 0.2873
===> Epoch[25](1400/2500): Loss: 0.2839
===> Epoch[25](1500/2500): Loss: 0.2747
===> Epoch[25](1600/2500): Loss: 0.2870
===> Epoch[25](1700/2500): Loss: 0.2972
===> Epoch[25](1800/2500): Loss: 0.2947
===> Epoch[25](1900/2500): Loss: 0.2898
===> Epoch[25](2000/2500): Loss: 0.2777
===> Epoch[25](2100/2500): Loss: 0.2944
===> Epoch[25](2200/2500): Loss: 0.3146
===> Epoch[25](2300/2500): Loss: 0.2740
===> Epoch[25](2400/2500): Loss: 0.2896
===> Epoch[25](2500/2500): Loss: 0.2822
===> Epoch 25 Complete: Avg. Loss: 0.2892
===> Timestamp: [2025-08-03 21:25:23]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2778
===> Epoch[25](200/2500): Loss: 0.2796
===> Epoch[25](300/2500): Loss: 0.3073
===> Epoch[25](400/2500): Loss: 0.2709
===> Epoch[25](500/2500): Loss: 0.2708
===> Epoch[25](600/2500): Loss: 0.3023
===> Epoch[25](700/2500): Loss: 0.2673
===> Epoch[25](800/2500): Loss: 0.2836
===> Epoch[25](900/2500): Loss: 0.3190
===> Epoch[25](1000/2500): Loss: 0.2852
===> Epoch[25](1100/2500): Loss: 0.2906
===> Epoch[25](1200/2500): Loss: 0.3025
===> Epoch[25](1300/2500): Loss: 0.2873
===> Epoch[25](1400/2500): Loss: 0.2839
===> Epoch[25](1500/2500): Loss: 0.2747
===> Epoch[25](1600/2500): Loss: 0.2870
===> Epoch[25](1700/2500): Loss: 0.2972
===> Epoch[25](1800/2500): Loss: 0.2947
===> Epoch[25](1900/2500): Loss: 0.2898
===> Epoch[25](2000/2500): Loss: 0.2777
===> Epoch[25](2100/2500): Loss: 0.2944
===> Epoch[25](2200/2500): Loss: 0.3146
===> Epoch[25](2300/2500): Loss: 0.2740
===> Epoch[25](2400/2500): Loss: 0.2896
===> Epoch[25](2500/2500): Loss: 0.2822
===> Epoch 25 Complete: Avg. Loss: 0.2892
===> Timestamp: [2025-08-03 21:25:23]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2778
===> Epoch[25](200/2500): Loss: 0.2796
===> Epoch[25](300/2500): Loss: 0.3073
===> Epoch[25](400/2500): Loss: 0.2709
===> Epoch[25](500/2500): Loss: 0.2708
===> Epoch[25](600/2500): Loss: 0.3023
===> Epoch[25](700/2500): Loss: 0.2673
===> Epoch[25](800/2500): Loss: 0.2836
===> Epoch[25](900/2500): Loss: 0.3190
===> Epoch[25](1000/2500): Loss: 0.2852
===> Epoch[25](1100/2500): Loss: 0.2906
===> Epoch[25](1200/2500): Loss: 0.3025
===> Epoch[25](1300/2500): Loss: 0.2873
===> Epoch[25](1400/2500): Loss: 0.2839
===> Epoch[25](1500/2500): Loss: 0.2747
===> Epoch[25](1600/2500): Loss: 0.2870
===> Epoch[25](1700/2500): Loss: 0.2972
===> Epoch[25](1800/2500): Loss: 0.2947
===> Epoch[25](1900/2500): Loss: 0.2898
===> Epoch[25](2000/2500): Loss: 0.2777
===> Epoch[25](2100/2500): Loss: 0.2944
===> Epoch[25](2200/2500): Loss: 0.3146
===> Epoch[25](2300/2500): Loss: 0.2740
===> Epoch[25](2400/2500): Loss: 0.2896
===> Epoch[25](2500/2500): Loss: 0.2822
===> Epoch 25 Complete: Avg. Loss: 0.2892
===> Timestamp: [2025-08-03 21:25:23]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2778
===> Epoch[25](200/2500): Loss: 0.2796
===> Epoch[25](300/2500): Loss: 0.3073
===> Epoch[25](400/2500): Loss: 0.2709
===> Epoch[25](500/2500): Loss: 0.2708
===> Epoch[25](600/2500): Loss: 0.3023
===> Epoch[25](700/2500): Loss: 0.2673
===> Epoch[25](800/2500): Loss: 0.2836
===> Epoch[25](900/2500): Loss: 0.3190
===> Epoch[25](1000/2500): Loss: 0.2852
===> Epoch[25](1100/2500): Loss: 0.2906
===> Epoch[25](1200/2500): Loss: 0.3025
===> Epoch[25](1300/2500): Loss: 0.2873
===> Epoch[25](1400/2500): Loss: 0.2839
===> Epoch[25](1500/2500): Loss: 0.2747
===> Epoch[25](1600/2500): Loss: 0.2870
===> Epoch[25](1700/2500): Loss: 0.2972
===> Epoch[25](1800/2500): Loss: 0.2947
===> Epoch[25](1900/2500): Loss: 0.2898
===> Epoch[25](2000/2500): Loss: 0.2777
===> Epoch[25](2100/2500): Loss: 0.2944
===> Epoch[25](2200/2500): Loss: 0.3146
===> Epoch[25](2300/2500): Loss: 0.2740
===> Epoch[25](2400/2500): Loss: 0.2896
===> Epoch[25](2500/2500): Loss: 0.2822
===> Epoch 25 Complete: Avg. Loss: 0.2892
===> Timestamp: [2025-08-03 21:25:23]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2778
===> Epoch[25](200/2500): Loss: 0.2796
===> Epoch[25](300/2500): Loss: 0.3073
===> Epoch[25](400/2500): Loss: 0.2709
===> Epoch[25](500/2500): Loss: 0.2708
===> Epoch[25](600/2500): Loss: 0.3023
===> Epoch[25](700/2500): Loss: 0.2673
===> Epoch[25](800/2500): Loss: 0.2836
===> Epoch[25](900/2500): Loss: 0.3190
===> Epoch[25](1000/2500): Loss: 0.2852
===> Epoch[25](1100/2500): Loss: 0.2906
===> Epoch[25](1200/2500): Loss: 0.3025
===> Epoch[25](1300/2500): Loss: 0.2873
===> Epoch[25](1400/2500): Loss: 0.2839
===> Epoch[25](1500/2500): Loss: 0.2747
===> Epoch[25](1600/2500): Loss: 0.2870
===> Epoch[25](1700/2500): Loss: 0.2972
===> Epoch[25](1800/2500): Loss: 0.2947
===> Epoch[25](1900/2500): Loss: 0.2898
===> Epoch[25](2000/2500): Loss: 0.2777
===> Epoch[25](2100/2500): Loss: 0.2944
===> Epoch[25](2200/2500): Loss: 0.3146
===> Epoch[25](2300/2500): Loss: 0.2740
===> Epoch[25](2400/2500): Loss: 0.2896
===> Epoch[25](2500/2500): Loss: 0.2822
===> Epoch 25 Complete: Avg. Loss: 0.2892
===> Timestamp: [2025-08-03 21:25:23]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2778
===> Epoch[25](200/2500): Loss: 0.2796
===> Epoch[25](300/2500): Loss: 0.3073
===> Epoch[25](400/2500): Loss: 0.2709
===> Epoch[25](500/2500): Loss: 0.2708
===> Epoch[25](600/2500): Loss: 0.3023
===> Epoch[25](700/2500): Loss: 0.2673
===> Epoch[25](800/2500): Loss: 0.2836
===> Epoch[25](900/2500): Loss: 0.3190
===> Epoch[25](1000/2500): Loss: 0.2852
===> Epoch[25](1100/2500): Loss: 0.2906
===> Epoch[25](1200/2500): Loss: 0.3025
===> Epoch[25](1300/2500): Loss: 0.2873
===> Epoch[25](1400/2500): Loss: 0.2839
===> Epoch[25](1500/2500): Loss: 0.2747
===> Epoch[25](1600/2500): Loss: 0.2870
===> Epoch[25](1700/2500): Loss: 0.2972
===> Epoch[25](1800/2500): Loss: 0.2947
===> Epoch[25](1900/2500): Loss: 0.2898
===> Epoch[25](2000/2500): Loss: 0.2777
===> Epoch[25](2100/2500): Loss: 0.2944
===> Epoch[25](2200/2500): Loss: 0.3146
===> Epoch[25](2300/2500): Loss: 0.2740
===> Epoch[25](2400/2500): Loss: 0.2896
===> Epoch[25](2500/2500): Loss: 0.2822
===> Epoch 25 Complete: Avg. Loss: 0.2892
===> Timestamp: [2025-08-03 21:25:23]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2778
===> Epoch[25](200/2500): Loss: 0.2796
===> Epoch[25](300/2500): Loss: 0.3073
===> Epoch[25](400/2500): Loss: 0.2709
===> Epoch[25](500/2500): Loss: 0.2708
===> Epoch[25](600/2500): Loss: 0.3023
===> Epoch[25](700/2500): Loss: 0.2673
===> Epoch[25](800/2500): Loss: 0.2836
===> Epoch[25](900/2500): Loss: 0.3190
===> Epoch[25](1000/2500): Loss: 0.2852
===> Epoch[25](1100/2500): Loss: 0.2906
===> Epoch[25](1200/2500): Loss: 0.3025
===> Epoch[25](1300/2500): Loss: 0.2873
===> Epoch[25](1400/2500): Loss: 0.2839
===> Epoch[25](1500/2500): Loss: 0.2747
===> Epoch[25](1600/2500): Loss: 0.2870
===> Epoch[25](1700/2500): Loss: 0.2972
===> Epoch[25](1800/2500): Loss: 0.2947
===> Epoch[25](1900/2500): Loss: 0.2898
===> Epoch[25](2000/2500): Loss: 0.2777
===> Epoch[25](2100/2500): Loss: 0.2944
===> Epoch[25](2200/2500): Loss: 0.3146
===> Epoch[25](2300/2500): Loss: 0.2740
===> Epoch[25](2400/2500): Loss: 0.2896
===> Epoch[25](2500/2500): Loss: 0.2822
===> Epoch 25 Complete: Avg. Loss: 0.2892
===> Timestamp: [2025-08-03 21:25:23]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2778
===> Epoch[25](200/2500): Loss: 0.2796
===> Epoch[25](300/2500): Loss: 0.3073
===> Epoch[25](400/2500): Loss: 0.2709
===> Epoch[25](500/2500): Loss: 0.2708
===> Epoch[25](600/2500): Loss: 0.3023
===> Epoch[25](700/2500): Loss: 0.2673
===> Epoch[25](800/2500): Loss: 0.2836
===> Epoch[25](900/2500): Loss: 0.3190
===> Epoch[25](1000/2500): Loss: 0.2852
===> Epoch[25](1100/2500): Loss: 0.2906
===> Epoch[25](1200/2500): Loss: 0.3025
===> Epoch[25](1300/2500): Loss: 0.2873
===> Epoch[25](1400/2500): Loss: 0.2839
===> Epoch[25](1500/2500): Loss: 0.2747
===> Epoch[25](1600/2500): Loss: 0.2870
===> Epoch[25](1700/2500): Loss: 0.2972
===> Epoch[25](1800/2500): Loss: 0.2947
===> Epoch[25](1900/2500): Loss: 0.2898
===> Epoch[25](2000/2500): Loss: 0.2777
===> Epoch[25](2100/2500): Loss: 0.2944
===> Epoch[25](2200/2500): Loss: 0.3146
===> Epoch[25](2300/2500): Loss: 0.2740
===> Epoch[25](2400/2500): Loss: 0.2896
===> Epoch[25](2500/2500): Loss: 0.2822
===> Epoch 25 Complete: Avg. Loss: 0.2892
===> Timestamp: [2025-08-03 21:25:23]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2778
===> Epoch[25](200/2500): Loss: 0.2796
===> Epoch[25](300/2500): Loss: 0.3073
===> Epoch[25](400/2500): Loss: 0.2709
===> Epoch[25](500/2500): Loss: 0.2708
===> Epoch[25](600/2500): Loss: 0.3023
===> Epoch[25](700/2500): Loss: 0.2673
===> Epoch[25](800/2500): Loss: 0.2836
===> Epoch[25](900/2500): Loss: 0.3190
===> Epoch[25](1000/2500): Loss: 0.2852
===> Epoch[25](1100/2500): Loss: 0.2906
===> Epoch[25](1200/2500): Loss: 0.3025
===> Epoch[25](1300/2500): Loss: 0.2873
===> Epoch[25](1400/2500): Loss: 0.2839
===> Epoch[25](1500/2500): Loss: 0.2747
===> Epoch[25](1600/2500): Loss: 0.2870
===> Epoch[25](1700/2500): Loss: 0.2972
===> Epoch[25](1800/2500): Loss: 0.2947
===> Epoch[25](1900/2500): Loss: 0.2898
===> Epoch[25](2000/2500): Loss: 0.2777
===> Epoch[25](2100/2500): Loss: 0.2944
===> Epoch[25](2200/2500): Loss: 0.3146
===> Epoch[25](2300/2500): Loss: 0.2740
===> Epoch[25](2400/2500): Loss: 0.2896
===> Epoch[25](2500/2500): Loss: 0.2822
===> Epoch 25 Complete: Avg. Loss: 0.2892
===> Timestamp: [2025-08-03 21:25:23]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2778
===> Epoch[25](200/2500): Loss: 0.2796
===> Epoch[25](300/2500): Loss: 0.3073
===> Epoch[25](400/2500): Loss: 0.2709
===> Epoch[25](500/2500): Loss: 0.2708
===> Epoch[25](600/2500): Loss: 0.3023
===> Epoch[25](700/2500): Loss: 0.2673
===> Epoch[25](800/2500): Loss: 0.2836
===> Epoch[25](900/2500): Loss: 0.3190
===> Epoch[25](1000/2500): Loss: 0.2852
===> Epoch[25](1100/2500): Loss: 0.2906
===> Epoch[25](1200/2500): Loss: 0.3025
===> Epoch[25](1300/2500): Loss: 0.2873
===> Epoch[25](1400/2500): Loss: 0.2839
===> Epoch[25](1500/2500): Loss: 0.2747
===> Epoch[25](1600/2500): Loss: 0.2870
===> Epoch[25](1700/2500): Loss: 0.2972
===> Epoch[25](1800/2500): Loss: 0.2947
===> Epoch[25](1900/2500): Loss: 0.2898
===> Epoch[25](2000/2500): Loss: 0.2777
===> Epoch[25](2100/2500): Loss: 0.2944
===> Epoch[25](2200/2500): Loss: 0.3146
===> Epoch[25](2300/2500): Loss: 0.2740
===> Epoch[25](2400/2500): Loss: 0.2896
===> Epoch[25](2500/2500): Loss: 0.2822
===> Epoch 25 Complete: Avg. Loss: 0.2892
===> Timestamp: [2025-08-03 21:25:23]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2778
===> Epoch[25](200/2500): Loss: 0.2796
===> Epoch[25](300/2500): Loss: 0.3073
===> Epoch[25](400/2500): Loss: 0.2709
===> Epoch[25](500/2500): Loss: 0.2708
===> Epoch[25](600/2500): Loss: 0.3023
===> Epoch[25](700/2500): Loss: 0.2673
===> Epoch[25](800/2500): Loss: 0.2836
===> Epoch[25](900/2500): Loss: 0.3190
===> Epoch[25](1000/2500): Loss: 0.2852
===> Epoch[25](1100/2500): Loss: 0.2906
===> Epoch[25](1200/2500): Loss: 0.3025
===> Epoch[25](1300/2500): Loss: 0.2873
===> Epoch[25](1400/2500): Loss: 0.2839
===> Epoch[25](1500/2500): Loss: 0.2747
===> Epoch[25](1600/2500): Loss: 0.2870
===> Epoch[25](1700/2500): Loss: 0.2972
===> Epoch[25](1800/2500): Loss: 0.2947
===> Epoch[25](1900/2500): Loss: 0.2898
===> Epoch[25](2000/2500): Loss: 0.2777
===> Epoch[25](2100/2500): Loss: 0.2944
===> Epoch[25](2200/2500): Loss: 0.3146
===> Epoch[25](2300/2500): Loss: 0.2740
===> Epoch[25](2400/2500): Loss: 0.2896
===> Epoch[25](2500/2500): Loss: 0.2822
===> Epoch 25 Complete: Avg. Loss: 0.2892
===> Timestamp: [2025-08-03 21:25:23]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2778
===> Epoch[25](200/2500): Loss: 0.2796
===> Epoch[25](300/2500): Loss: 0.3073
===> Epoch[25](400/2500): Loss: 0.2709
===> Epoch[25](500/2500): Loss: 0.2708
===> Epoch[25](600/2500): Loss: 0.3023
===> Epoch[25](700/2500): Loss: 0.2673
===> Epoch[25](800/2500): Loss: 0.2836
===> Epoch[25](900/2500): Loss: 0.3190
===> Epoch[25](1000/2500): Loss: 0.2852
===> Epoch[25](1100/2500): Loss: 0.2906
===> Epoch[25](1200/2500): Loss: 0.3025
===> Epoch[25](1300/2500): Loss: 0.2873
===> Epoch[25](1400/2500): Loss: 0.2839
===> Epoch[25](1500/2500): Loss: 0.2747
===> Epoch[25](1600/2500): Loss: 0.2870
===> Epoch[25](1700/2500): Loss: 0.2972
===> Epoch[25](1800/2500): Loss: 0.2947
===> Epoch[25](1900/2500): Loss: 0.2898
===> Epoch[25](2000/2500): Loss: 0.2777
===> Epoch[25](2100/2500): Loss: 0.2944
===> Epoch[25](2200/2500): Loss: 0.3146
===> Epoch[25](2300/2500): Loss: 0.2740
===> Epoch[25](2400/2500): Loss: 0.2896
===> Epoch[25](2500/2500): Loss: 0.2822
===> Epoch 25 Complete: Avg. Loss: 0.2892
===> Timestamp: [2025-08-03 21:25:23]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2778
===> Epoch[25](200/2500): Loss: 0.2796
===> Epoch[25](300/2500): Loss: 0.3073
===> Epoch[25](400/2500): Loss: 0.2709
===> Epoch[25](500/2500): Loss: 0.2708
===> Epoch[25](600/2500): Loss: 0.3023
===> Epoch[25](700/2500): Loss: 0.2673
===> Epoch[25](800/2500): Loss: 0.2836
===> Epoch[25](900/2500): Loss: 0.3190
===> Epoch[25](1000/2500): Loss: 0.2852
===> Epoch[25](1100/2500): Loss: 0.2906
===> Epoch[25](1200/2500): Loss: 0.3025
===> Epoch[25](1300/2500): Loss: 0.2873
===> Epoch[25](1400/2500): Loss: 0.2839
===> Epoch[25](1500/2500): Loss: 0.2747
===> Epoch[25](1600/2500): Loss: 0.2870
===> Epoch[25](1700/2500): Loss: 0.2972
===> Epoch[25](1800/2500): Loss: 0.2947
===> Epoch[25](1900/2500): Loss: 0.2898
===> Epoch[25](2000/2500): Loss: 0.2777
===> Epoch[25](2100/2500): Loss: 0.2944
===> Epoch[25](2200/2500): Loss: 0.3146
===> Epoch[25](2300/2500): Loss: 0.2740
===> Epoch[25](2400/2500): Loss: 0.2896
===> Epoch[25](2500/2500): Loss: 0.2822
===> Epoch 25 Complete: Avg. Loss: 0.2892
===> Timestamp: [2025-08-03 21:25:23]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2778
===> Epoch[25](200/2500): Loss: 0.2796
===> Epoch[25](300/2500): Loss: 0.3073
===> Epoch[25](400/2500): Loss: 0.2709
===> Epoch[25](500/2500): Loss: 0.2708
===> Epoch[25](600/2500): Loss: 0.3023
===> Epoch[25](700/2500): Loss: 0.2673
===> Epoch[25](800/2500): Loss: 0.2836
===> Epoch[25](900/2500): Loss: 0.3190
===> Epoch[25](1000/2500): Loss: 0.2852
===> Epoch[25](1100/2500): Loss: 0.2906
===> Epoch[25](1200/2500): Loss: 0.3025
===> Epoch[25](1300/2500): Loss: 0.2873
===> Epoch[25](1400/2500): Loss: 0.2839
===> Epoch[25](1500/2500): Loss: 0.2747
===> Epoch[25](1600/2500): Loss: 0.2870
===> Epoch[25](1700/2500): Loss: 0.2972
===> Epoch[25](1800/2500): Loss: 0.2947
===> Epoch[25](1900/2500): Loss: 0.2898
===> Epoch[25](2000/2500): Loss: 0.2777
===> Epoch[25](2100/2500): Loss: 0.2944
===> Epoch[25](2200/2500): Loss: 0.3146
===> Epoch[25](2300/2500): Loss: 0.2740
===> Epoch[25](2400/2500): Loss: 0.2896
===> Epoch[25](2500/2500): Loss: 0.2822
===> Epoch 25 Complete: Avg. Loss: 0.2892
===> Timestamp: [2025-08-03 21:25:23]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2778
===> Epoch[25](200/2500): Loss: 0.2796
===> Epoch[25](300/2500): Loss: 0.3073
===> Epoch[25](400/2500): Loss: 0.2709
===> Epoch[25](500/2500): Loss: 0.2708
===> Epoch[25](600/2500): Loss: 0.3023
===> Epoch[25](700/2500): Loss: 0.2673
===> Epoch[25](800/2500): Loss: 0.2836
===> Epoch[25](900/2500): Loss: 0.3190
===> Epoch[25](1000/2500): Loss: 0.2852
===> Epoch[25](1100/2500): Loss: 0.2906
===> Epoch[25](1200/2500): Loss: 0.3025
===> Epoch[25](1300/2500): Loss: 0.2873
===> Epoch[25](1400/2500): Loss: 0.2839
===> Epoch[25](1500/2500): Loss: 0.2747
===> Epoch[25](1600/2500): Loss: 0.2870
===> Epoch[25](1700/2500): Loss: 0.2972
===> Epoch[25](1800/2500): Loss: 0.2947
===> Epoch[25](1900/2500): Loss: 0.2898
===> Epoch[25](2000/2500): Loss: 0.2777
===> Epoch[25](2100/2500): Loss: 0.2944
===> Epoch[25](2200/2500): Loss: 0.3146
===> Epoch[25](2300/2500): Loss: 0.2740
===> Epoch[25](2400/2500): Loss: 0.2896
===> Epoch[25](2500/2500): Loss: 0.2822
===> Epoch 25 Complete: Avg. Loss: 0.2892
===> Timestamp: [2025-08-03 21:25:23]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2778
===> Epoch[25](200/2500): Loss: 0.2796
===> Epoch[25](300/2500): Loss: 0.3073
===> Epoch[25](400/2500): Loss: 0.2709
===> Epoch[25](500/2500): Loss: 0.2708
===> Epoch[25](600/2500): Loss: 0.3023
===> Epoch[25](700/2500): Loss: 0.2673
===> Epoch[25](800/2500): Loss: 0.2836
===> Epoch[25](900/2500): Loss: 0.3190
===> Epoch[25](1000/2500): Loss: 0.2852
===> Epoch[25](1100/2500): Loss: 0.2906
===> Epoch[25](1200/2500): Loss: 0.3025
===> Epoch[25](1300/2500): Loss: 0.2873
===> Epoch[25](1400/2500): Loss: 0.2839
===> Epoch[25](1500/2500): Loss: 0.2747
===> Epoch[25](1600/2500): Loss: 0.2870
===> Epoch[25](1700/2500): Loss: 0.2972
===> Epoch[25](1800/2500): Loss: 0.2947
===> Epoch[25](1900/2500): Loss: 0.2898
===> Epoch[25](2000/2500): Loss: 0.2777
===> Epoch[25](2100/2500): Loss: 0.2944
===> Epoch[25](2200/2500): Loss: 0.3146
===> Epoch[25](2300/2500): Loss: 0.2740
===> Epoch[25](2400/2500): Loss: 0.2896
===> Epoch[25](2500/2500): Loss: 0.2822
===> Epoch 25 Complete: Avg. Loss: 0.2892
===> Timestamp: [2025-08-03 21:25:23]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2778
===> Epoch[25](200/2500): Loss: 0.2796
===> Epoch[25](300/2500): Loss: 0.3073
===> Epoch[25](400/2500): Loss: 0.2709
===> Epoch[25](500/2500): Loss: 0.2708
===> Epoch[25](600/2500): Loss: 0.3023
===> Epoch[25](700/2500): Loss: 0.2673
===> Epoch[25](800/2500): Loss: 0.2836
===> Epoch[25](900/2500): Loss: 0.3190
===> Epoch[25](1000/2500): Loss: 0.2852
===> Epoch[25](1100/2500): Loss: 0.2906
===> Epoch[25](1200/2500): Loss: 0.3025
===> Epoch[25](1300/2500): Loss: 0.2873
===> Epoch[25](1400/2500): Loss: 0.2839
===> Epoch[25](1500/2500): Loss: 0.2747
===> Epoch[25](1600/2500): Loss: 0.2870
===> Epoch[25](1700/2500): Loss: 0.2972
===> Epoch[25](1800/2500): Loss: 0.2947
===> Epoch[25](1900/2500): Loss: 0.2898
===> Epoch[25](2000/2500): Loss: 0.2777
===> Epoch[25](2100/2500): Loss: 0.2944
===> Epoch[25](2200/2500): Loss: 0.3146
===> Epoch[25](2300/2500): Loss: 0.2740
===> Epoch[25](2400/2500): Loss: 0.2896
===> Epoch[25](2500/2500): Loss: 0.2822
===> Epoch 25 Complete: Avg. Loss: 0.2892
===> Timestamp: [2025-08-03 21:25:23]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2778
===> Epoch[25](200/2500): Loss: 0.2796
===> Epoch[25](300/2500): Loss: 0.3073
===> Epoch[25](400/2500): Loss: 0.2709
===> Epoch[25](500/2500): Loss: 0.2708
===> Epoch[25](600/2500): Loss: 0.3023
===> Epoch[25](700/2500): Loss: 0.2673
===> Epoch[25](800/2500): Loss: 0.2836
===> Epoch[25](900/2500): Loss: 0.3190
===> Epoch[25](1000/2500): Loss: 0.2852
===> Epoch[25](1100/2500): Loss: 0.2906
===> Epoch[25](1200/2500): Loss: 0.3025
===> Epoch[25](1300/2500): Loss: 0.2873
===> Epoch[25](1400/2500): Loss: 0.2839
===> Epoch[25](1500/2500): Loss: 0.2747
===> Epoch[25](1600/2500): Loss: 0.2870
===> Epoch[25](1700/2500): Loss: 0.2972
===> Epoch[25](1800/2500): Loss: 0.2947
===> Epoch[25](1900/2500): Loss: 0.2898
===> Epoch[25](2000/2500): Loss: 0.2777
===> Epoch[25](2100/2500): Loss: 0.2944
===> Epoch[25](2200/2500): Loss: 0.3146
===> Epoch[25](2300/2500): Loss: 0.2740
===> Epoch[25](2400/2500): Loss: 0.2896
===> Epoch[25](2500/2500): Loss: 0.2822
===> Epoch 25 Complete: Avg. Loss: 0.2892
===> Timestamp: [2025-08-03 21:25:23]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2778
===> Epoch[25](200/2500): Loss: 0.2796
===> Epoch[25](300/2500): Loss: 0.3073
===> Epoch[25](400/2500): Loss: 0.2709
===> Epoch[25](500/2500): Loss: 0.2708
===> Epoch[25](600/2500): Loss: 0.3023
===> Epoch[25](700/2500): Loss: 0.2673
===> Epoch[25](800/2500): Loss: 0.2836
===> Epoch[25](900/2500): Loss: 0.3190
===> Epoch[25](1000/2500): Loss: 0.2852
===> Epoch[25](1100/2500): Loss: 0.2906
===> Epoch[25](1200/2500): Loss: 0.3025
===> Epoch[25](1300/2500): Loss: 0.2873
===> Epoch[25](1400/2500): Loss: 0.2839
===> Epoch[25](1500/2500): Loss: 0.2747
===> Epoch[25](1600/2500): Loss: 0.2870
===> Epoch[25](1700/2500): Loss: 0.2972
===> Epoch[25](1800/2500): Loss: 0.2947
===> Epoch[25](1900/2500): Loss: 0.2898
===> Epoch[25](2000/2500): Loss: 0.2777
===> Epoch[25](2100/2500): Loss: 0.2944
===> Epoch[25](2200/2500): Loss: 0.3146
===> Epoch[25](2300/2500): Loss: 0.2740
===> Epoch[25](2400/2500): Loss: 0.2896
===> Epoch[25](2500/2500): Loss: 0.2822
===> Epoch 25 Complete: Avg. Loss: 0.2892
===> Timestamp: [2025-08-03 21:25:23]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2778
===> Epoch[25](200/2500): Loss: 0.2796
===> Epoch[25](300/2500): Loss: 0.3073
===> Epoch[25](400/2500): Loss: 0.2709
===> Epoch[25](500/2500): Loss: 0.2708
===> Epoch[25](600/2500): Loss: 0.3023
===> Epoch[25](700/2500): Loss: 0.2673
===> Epoch[25](800/2500): Loss: 0.2836
===> Epoch[25](900/2500): Loss: 0.3190
===> Epoch[25](1000/2500): Loss: 0.2852
===> Epoch[25](1100/2500): Loss: 0.2906
===> Epoch[25](1200/2500): Loss: 0.3025
===> Epoch[25](1300/2500): Loss: 0.2873
===> Epoch[25](1400/2500): Loss: 0.2839
===> Epoch[25](1500/2500): Loss: 0.2747
===> Epoch[25](1600/2500): Loss: 0.2870
===> Epoch[25](1700/2500): Loss: 0.2972
===> Epoch[25](1800/2500): Loss: 0.2947
===> Epoch[25](1900/2500): Loss: 0.2898
===> Epoch[25](2000/2500): Loss: 0.2777
===> Epoch[25](2100/2500): Loss: 0.2944
===> Epoch[25](2200/2500): Loss: 0.3146
===> Epoch[25](2300/2500): Loss: 0.2740
===> Epoch[25](2400/2500): Loss: 0.2896
===> Epoch[25](2500/2500): Loss: 0.2822
===> Epoch 25 Complete: Avg. Loss: 0.2892
===> Timestamp: [2025-08-03 21:25:23]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Epoch[25](100/2500): Loss: 0.2778
===> Epoch[25](200/2500): Loss: 0.2796
===> Epoch[25](300/2500): Loss: 0.3073
===> Epoch[25](400/2500): Loss: 0.2709
===> Epoch[25](500/2500): Loss: 0.2708
===> Epoch[25](600/2500): Loss: 0.3023
===> Epoch[25](700/2500): Loss: 0.2673
===> Epoch[25](800/2500): Loss: 0.2836
===> Epoch[25](900/2500): Loss: 0.3190
===> Epoch[25](1000/2500): Loss: 0.2852
===> Epoch[25](1100/2500): Loss: 0.2906
===> Epoch[25](1200/2500): Loss: 0.3025
===> Epoch[25](1300/2500): Loss: 0.2873
===> Epoch[25](1400/2500): Loss: 0.2839
===> Epoch[25](1500/2500): Loss: 0.2747
===> Epoch[25](1600/2500): Loss: 0.2870
===> Epoch[25](1700/2500): Loss: 0.2972
===> Epoch[25](1800/2500): Loss: 0.2947
===> Epoch[25](1900/2500): Loss: 0.2898
===> Epoch[25](2000/2500): Loss: 0.2777
===> Epoch[25](2100/2500): Loss: 0.2944
===> Epoch[25](2200/2500): Loss: 0.3146
===> Epoch[25](2300/2500): Loss: 0.2740
===> Epoch[25](2400/2500): Loss: 0.2896
===> Epoch[25](2500/2500): Loss: 0.2822
===> Epoch 25 Complete: Avg. Loss: 0.2892
===> Timestamp: [2025-08-03 21:25:23]
Checkpoint saved to TrainedNet/_epoch_25.pth
===> Loading train datasets
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2908
===> Epoch[26](200/2500): Loss: 0.2777
===> Epoch[26](300/2500): Loss: 0.2709
===> Epoch[26](400/2500): Loss: 0.2831
===> Epoch[26](500/2500): Loss: 0.3068
===> Epoch[26](600/2500): Loss: 0.2929
===> Epoch[26](700/2500): Loss: 0.3029
===> Epoch[26](800/2500): Loss: 0.3024
===> Epoch[26](900/2500): Loss: 0.2934
===> Epoch[26](1000/2500): Loss: 0.2995
===> Epoch[26](1100/2500): Loss: 0.3057
===> Epoch[26](1200/2500): Loss: 0.2902
===> Epoch[26](1300/2500): Loss: 0.2569
===> Epoch[26](1400/2500): Loss: 0.2704
===> Epoch[26](1500/2500): Loss: 0.2955
===> Epoch[26](1600/2500): Loss: 0.2792
===> Epoch[26](1700/2500): Loss: 0.2863
===> Epoch[26](1800/2500): Loss: 0.2744
===> Epoch[26](1900/2500): Loss: 0.2703
===> Epoch[26](2000/2500): Loss: 0.3062
===> Epoch[26](2100/2500): Loss: 0.3144
===> Epoch[26](2200/2500): Loss: 0.3044
===> Epoch[26](2300/2500): Loss: 0.3068
===> Epoch[26](2400/2500): Loss: 0.2872
===> Epoch[26](2500/2500): Loss: 0.2895
===> Epoch 26 Complete: Avg. Loss: 0.2888
===> Timestamp: [2025-08-03 21:29:57]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2908
===> Epoch[26](200/2500): Loss: 0.2777
===> Epoch[26](300/2500): Loss: 0.2709
===> Epoch[26](400/2500): Loss: 0.2831
===> Epoch[26](500/2500): Loss: 0.3068
===> Epoch[26](600/2500): Loss: 0.2929
===> Epoch[26](700/2500): Loss: 0.3029
===> Epoch[26](800/2500): Loss: 0.3024
===> Epoch[26](900/2500): Loss: 0.2934
===> Epoch[26](1000/2500): Loss: 0.2995
===> Epoch[26](1100/2500): Loss: 0.3057
===> Epoch[26](1200/2500): Loss: 0.2902
===> Epoch[26](1300/2500): Loss: 0.2569
===> Epoch[26](1400/2500): Loss: 0.2704
===> Epoch[26](1500/2500): Loss: 0.2955
===> Epoch[26](1600/2500): Loss: 0.2792
===> Epoch[26](1700/2500): Loss: 0.2863
===> Epoch[26](1800/2500): Loss: 0.2744
===> Epoch[26](1900/2500): Loss: 0.2703
===> Epoch[26](2000/2500): Loss: 0.3062
===> Epoch[26](2100/2500): Loss: 0.3144
===> Epoch[26](2200/2500): Loss: 0.3044
===> Epoch[26](2300/2500): Loss: 0.3068
===> Epoch[26](2400/2500): Loss: 0.2872
===> Epoch[26](2500/2500): Loss: 0.2895
===> Epoch 26 Complete: Avg. Loss: 0.2888
===> Timestamp: [2025-08-03 21:29:57]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2908
===> Epoch[26](200/2500): Loss: 0.2777
===> Epoch[26](300/2500): Loss: 0.2709
===> Epoch[26](400/2500): Loss: 0.2831
===> Epoch[26](500/2500): Loss: 0.3068
===> Epoch[26](600/2500): Loss: 0.2929
===> Epoch[26](700/2500): Loss: 0.3029
===> Epoch[26](800/2500): Loss: 0.3024
===> Epoch[26](900/2500): Loss: 0.2934
===> Epoch[26](1000/2500): Loss: 0.2995
===> Epoch[26](1100/2500): Loss: 0.3057
===> Epoch[26](1200/2500): Loss: 0.2902
===> Epoch[26](1300/2500): Loss: 0.2569
===> Epoch[26](1400/2500): Loss: 0.2704
===> Epoch[26](1500/2500): Loss: 0.2955
===> Epoch[26](1600/2500): Loss: 0.2792
===> Epoch[26](1700/2500): Loss: 0.2863
===> Epoch[26](1800/2500): Loss: 0.2744
===> Epoch[26](1900/2500): Loss: 0.2703
===> Epoch[26](2000/2500): Loss: 0.3062
===> Epoch[26](2100/2500): Loss: 0.3144
===> Epoch[26](2200/2500): Loss: 0.3044
===> Epoch[26](2300/2500): Loss: 0.3068
===> Epoch[26](2400/2500): Loss: 0.2872
===> Epoch[26](2500/2500): Loss: 0.2895
===> Epoch 26 Complete: Avg. Loss: 0.2888
===> Timestamp: [2025-08-03 21:29:57]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2908
===> Epoch[26](200/2500): Loss: 0.2777
===> Epoch[26](300/2500): Loss: 0.2709
===> Epoch[26](400/2500): Loss: 0.2831
===> Epoch[26](500/2500): Loss: 0.3068
===> Epoch[26](600/2500): Loss: 0.2929
===> Epoch[26](700/2500): Loss: 0.3029
===> Epoch[26](800/2500): Loss: 0.3024
===> Epoch[26](900/2500): Loss: 0.2934
===> Epoch[26](1000/2500): Loss: 0.2995
===> Epoch[26](1100/2500): Loss: 0.3057
===> Epoch[26](1200/2500): Loss: 0.2902
===> Epoch[26](1300/2500): Loss: 0.2569
===> Epoch[26](1400/2500): Loss: 0.2704
===> Epoch[26](1500/2500): Loss: 0.2955
===> Epoch[26](1600/2500): Loss: 0.2792
===> Epoch[26](1700/2500): Loss: 0.2863
===> Epoch[26](1800/2500): Loss: 0.2744
===> Epoch[26](1900/2500): Loss: 0.2703
===> Epoch[26](2000/2500): Loss: 0.3062
===> Epoch[26](2100/2500): Loss: 0.3144
===> Epoch[26](2200/2500): Loss: 0.3044
===> Epoch[26](2300/2500): Loss: 0.3068
===> Epoch[26](2400/2500): Loss: 0.2872
===> Epoch[26](2500/2500): Loss: 0.2895
===> Epoch 26 Complete: Avg. Loss: 0.2888
===> Timestamp: [2025-08-03 21:29:57]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2908
===> Epoch[26](200/2500): Loss: 0.2777
===> Epoch[26](300/2500): Loss: 0.2709
===> Epoch[26](400/2500): Loss: 0.2831
===> Epoch[26](500/2500): Loss: 0.3068
===> Epoch[26](600/2500): Loss: 0.2929
===> Epoch[26](700/2500): Loss: 0.3029
===> Epoch[26](800/2500): Loss: 0.3024
===> Epoch[26](900/2500): Loss: 0.2934
===> Epoch[26](1000/2500): Loss: 0.2995
===> Epoch[26](1100/2500): Loss: 0.3057
===> Epoch[26](1200/2500): Loss: 0.2902
===> Epoch[26](1300/2500): Loss: 0.2569
===> Epoch[26](1400/2500): Loss: 0.2704
===> Epoch[26](1500/2500): Loss: 0.2955
===> Epoch[26](1600/2500): Loss: 0.2792
===> Epoch[26](1700/2500): Loss: 0.2863
===> Epoch[26](1800/2500): Loss: 0.2744
===> Epoch[26](1900/2500): Loss: 0.2703
===> Epoch[26](2000/2500): Loss: 0.3062
===> Epoch[26](2100/2500): Loss: 0.3144
===> Epoch[26](2200/2500): Loss: 0.3044
===> Epoch[26](2300/2500): Loss: 0.3068
===> Epoch[26](2400/2500): Loss: 0.2872
===> Epoch[26](2500/2500): Loss: 0.2895
===> Epoch 26 Complete: Avg. Loss: 0.2888
===> Timestamp: [2025-08-03 21:29:57]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2908
===> Epoch[26](200/2500): Loss: 0.2777
===> Epoch[26](300/2500): Loss: 0.2709
===> Epoch[26](400/2500): Loss: 0.2831
===> Epoch[26](500/2500): Loss: 0.3068
===> Epoch[26](600/2500): Loss: 0.2929
===> Epoch[26](700/2500): Loss: 0.3029
===> Epoch[26](800/2500): Loss: 0.3024
===> Epoch[26](900/2500): Loss: 0.2934
===> Epoch[26](1000/2500): Loss: 0.2995
===> Epoch[26](1100/2500): Loss: 0.3057
===> Epoch[26](1200/2500): Loss: 0.2902
===> Epoch[26](1300/2500): Loss: 0.2569
===> Epoch[26](1400/2500): Loss: 0.2704
===> Epoch[26](1500/2500): Loss: 0.2955
===> Epoch[26](1600/2500): Loss: 0.2792
===> Epoch[26](1700/2500): Loss: 0.2863
===> Epoch[26](1800/2500): Loss: 0.2744
===> Epoch[26](1900/2500): Loss: 0.2703
===> Epoch[26](2000/2500): Loss: 0.3062
===> Epoch[26](2100/2500): Loss: 0.3144
===> Epoch[26](2200/2500): Loss: 0.3044
===> Epoch[26](2300/2500): Loss: 0.3068
===> Epoch[26](2400/2500): Loss: 0.2872
===> Epoch[26](2500/2500): Loss: 0.2895
===> Epoch 26 Complete: Avg. Loss: 0.2888
===> Timestamp: [2025-08-03 21:29:57]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2908
===> Epoch[26](200/2500): Loss: 0.2777
===> Epoch[26](300/2500): Loss: 0.2709
===> Epoch[26](400/2500): Loss: 0.2831
===> Epoch[26](500/2500): Loss: 0.3068
===> Epoch[26](600/2500): Loss: 0.2929
===> Epoch[26](700/2500): Loss: 0.3029
===> Epoch[26](800/2500): Loss: 0.3024
===> Epoch[26](900/2500): Loss: 0.2934
===> Epoch[26](1000/2500): Loss: 0.2995
===> Epoch[26](1100/2500): Loss: 0.3057
===> Epoch[26](1200/2500): Loss: 0.2902
===> Epoch[26](1300/2500): Loss: 0.2569
===> Epoch[26](1400/2500): Loss: 0.2704
===> Epoch[26](1500/2500): Loss: 0.2955
===> Epoch[26](1600/2500): Loss: 0.2792
===> Epoch[26](1700/2500): Loss: 0.2863
===> Epoch[26](1800/2500): Loss: 0.2744
===> Epoch[26](1900/2500): Loss: 0.2703
===> Epoch[26](2000/2500): Loss: 0.3062
===> Epoch[26](2100/2500): Loss: 0.3144
===> Epoch[26](2200/2500): Loss: 0.3044
===> Epoch[26](2300/2500): Loss: 0.3068
===> Epoch[26](2400/2500): Loss: 0.2872
===> Epoch[26](2500/2500): Loss: 0.2895
===> Epoch 26 Complete: Avg. Loss: 0.2888
===> Timestamp: [2025-08-03 21:29:57]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2908
===> Epoch[26](200/2500): Loss: 0.2777
===> Epoch[26](300/2500): Loss: 0.2709
===> Epoch[26](400/2500): Loss: 0.2831
===> Epoch[26](500/2500): Loss: 0.3068
===> Epoch[26](600/2500): Loss: 0.2929
===> Epoch[26](700/2500): Loss: 0.3029
===> Epoch[26](800/2500): Loss: 0.3024
===> Epoch[26](900/2500): Loss: 0.2934
===> Epoch[26](1000/2500): Loss: 0.2995
===> Epoch[26](1100/2500): Loss: 0.3057
===> Epoch[26](1200/2500): Loss: 0.2902
===> Epoch[26](1300/2500): Loss: 0.2569
===> Epoch[26](1400/2500): Loss: 0.2704
===> Epoch[26](1500/2500): Loss: 0.2955
===> Epoch[26](1600/2500): Loss: 0.2792
===> Epoch[26](1700/2500): Loss: 0.2863
===> Epoch[26](1800/2500): Loss: 0.2744
===> Epoch[26](1900/2500): Loss: 0.2703
===> Epoch[26](2000/2500): Loss: 0.3062
===> Epoch[26](2100/2500): Loss: 0.3144
===> Epoch[26](2200/2500): Loss: 0.3044
===> Epoch[26](2300/2500): Loss: 0.3068
===> Epoch[26](2400/2500): Loss: 0.2872
===> Epoch[26](2500/2500): Loss: 0.2895
===> Epoch 26 Complete: Avg. Loss: 0.2888
===> Timestamp: [2025-08-03 21:29:57]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2908
===> Epoch[26](200/2500): Loss: 0.2777
===> Epoch[26](300/2500): Loss: 0.2709
===> Epoch[26](400/2500): Loss: 0.2831
===> Epoch[26](500/2500): Loss: 0.3068
===> Epoch[26](600/2500): Loss: 0.2929
===> Epoch[26](700/2500): Loss: 0.3029
===> Epoch[26](800/2500): Loss: 0.3024
===> Epoch[26](900/2500): Loss: 0.2934
===> Epoch[26](1000/2500): Loss: 0.2995
===> Epoch[26](1100/2500): Loss: 0.3057
===> Epoch[26](1200/2500): Loss: 0.2902
===> Epoch[26](1300/2500): Loss: 0.2569
===> Epoch[26](1400/2500): Loss: 0.2704
===> Epoch[26](1500/2500): Loss: 0.2955
===> Epoch[26](1600/2500): Loss: 0.2792
===> Epoch[26](1700/2500): Loss: 0.2863
===> Epoch[26](1800/2500): Loss: 0.2744
===> Epoch[26](1900/2500): Loss: 0.2703
===> Epoch[26](2000/2500): Loss: 0.3062
===> Epoch[26](2100/2500): Loss: 0.3144
===> Epoch[26](2200/2500): Loss: 0.3044
===> Epoch[26](2300/2500): Loss: 0.3068
===> Epoch[26](2400/2500): Loss: 0.2872
===> Epoch[26](2500/2500): Loss: 0.2895
===> Epoch 26 Complete: Avg. Loss: 0.2888
===> Timestamp: [2025-08-03 21:29:57]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2908
===> Epoch[26](200/2500): Loss: 0.2777
===> Epoch[26](300/2500): Loss: 0.2709
===> Epoch[26](400/2500): Loss: 0.2831
===> Epoch[26](500/2500): Loss: 0.3068
===> Epoch[26](600/2500): Loss: 0.2929
===> Epoch[26](700/2500): Loss: 0.3029
===> Epoch[26](800/2500): Loss: 0.3024
===> Epoch[26](900/2500): Loss: 0.2934
===> Epoch[26](1000/2500): Loss: 0.2995
===> Epoch[26](1100/2500): Loss: 0.3057
===> Epoch[26](1200/2500): Loss: 0.2902
===> Epoch[26](1300/2500): Loss: 0.2569
===> Epoch[26](1400/2500): Loss: 0.2704
===> Epoch[26](1500/2500): Loss: 0.2955
===> Epoch[26](1600/2500): Loss: 0.2792
===> Epoch[26](1700/2500): Loss: 0.2863
===> Epoch[26](1800/2500): Loss: 0.2744
===> Epoch[26](1900/2500): Loss: 0.2703
===> Epoch[26](2000/2500): Loss: 0.3062
===> Epoch[26](2100/2500): Loss: 0.3144
===> Epoch[26](2200/2500): Loss: 0.3044
===> Epoch[26](2300/2500): Loss: 0.3068
===> Epoch[26](2400/2500): Loss: 0.2872
===> Epoch[26](2500/2500): Loss: 0.2895
===> Epoch 26 Complete: Avg. Loss: 0.2888
===> Timestamp: [2025-08-03 21:29:57]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2908
===> Epoch[26](200/2500): Loss: 0.2777
===> Epoch[26](300/2500): Loss: 0.2709
===> Epoch[26](400/2500): Loss: 0.2831
===> Epoch[26](500/2500): Loss: 0.3068
===> Epoch[26](600/2500): Loss: 0.2929
===> Epoch[26](700/2500): Loss: 0.3029
===> Epoch[26](800/2500): Loss: 0.3024
===> Epoch[26](900/2500): Loss: 0.2934
===> Epoch[26](1000/2500): Loss: 0.2995
===> Epoch[26](1100/2500): Loss: 0.3057
===> Epoch[26](1200/2500): Loss: 0.2902
===> Epoch[26](1300/2500): Loss: 0.2569
===> Epoch[26](1400/2500): Loss: 0.2704
===> Epoch[26](1500/2500): Loss: 0.2955
===> Epoch[26](1600/2500): Loss: 0.2792
===> Epoch[26](1700/2500): Loss: 0.2863
===> Epoch[26](1800/2500): Loss: 0.2744
===> Epoch[26](1900/2500): Loss: 0.2703
===> Epoch[26](2000/2500): Loss: 0.3062
===> Epoch[26](2100/2500): Loss: 0.3144
===> Epoch[26](2200/2500): Loss: 0.3044
===> Epoch[26](2300/2500): Loss: 0.3068
===> Epoch[26](2400/2500): Loss: 0.2872
===> Epoch[26](2500/2500): Loss: 0.2895
===> Epoch 26 Complete: Avg. Loss: 0.2888
===> Timestamp: [2025-08-03 21:29:57]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2908
===> Epoch[26](200/2500): Loss: 0.2777
===> Epoch[26](300/2500): Loss: 0.2709
===> Epoch[26](400/2500): Loss: 0.2831
===> Epoch[26](500/2500): Loss: 0.3068
===> Epoch[26](600/2500): Loss: 0.2929
===> Epoch[26](700/2500): Loss: 0.3029
===> Epoch[26](800/2500): Loss: 0.3024
===> Epoch[26](900/2500): Loss: 0.2934
===> Epoch[26](1000/2500): Loss: 0.2995
===> Epoch[26](1100/2500): Loss: 0.3057
===> Epoch[26](1200/2500): Loss: 0.2902
===> Epoch[26](1300/2500): Loss: 0.2569
===> Epoch[26](1400/2500): Loss: 0.2704
===> Epoch[26](1500/2500): Loss: 0.2955
===> Epoch[26](1600/2500): Loss: 0.2792
===> Epoch[26](1700/2500): Loss: 0.2863
===> Epoch[26](1800/2500): Loss: 0.2744
===> Epoch[26](1900/2500): Loss: 0.2703
===> Epoch[26](2000/2500): Loss: 0.3062
===> Epoch[26](2100/2500): Loss: 0.3144
===> Epoch[26](2200/2500): Loss: 0.3044
===> Epoch[26](2300/2500): Loss: 0.3068
===> Epoch[26](2400/2500): Loss: 0.2872
===> Epoch[26](2500/2500): Loss: 0.2895
===> Epoch 26 Complete: Avg. Loss: 0.2888
===> Timestamp: [2025-08-03 21:29:57]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2908
===> Epoch[26](200/2500): Loss: 0.2777
===> Epoch[26](300/2500): Loss: 0.2709
===> Epoch[26](400/2500): Loss: 0.2831
===> Epoch[26](500/2500): Loss: 0.3068
===> Epoch[26](600/2500): Loss: 0.2929
===> Epoch[26](700/2500): Loss: 0.3029
===> Epoch[26](800/2500): Loss: 0.3024
===> Epoch[26](900/2500): Loss: 0.2934
===> Epoch[26](1000/2500): Loss: 0.2995
===> Epoch[26](1100/2500): Loss: 0.3057
===> Epoch[26](1200/2500): Loss: 0.2902
===> Epoch[26](1300/2500): Loss: 0.2569
===> Epoch[26](1400/2500): Loss: 0.2704
===> Epoch[26](1500/2500): Loss: 0.2955
===> Epoch[26](1600/2500): Loss: 0.2792
===> Epoch[26](1700/2500): Loss: 0.2863
===> Epoch[26](1800/2500): Loss: 0.2744
===> Epoch[26](1900/2500): Loss: 0.2703
===> Epoch[26](2000/2500): Loss: 0.3062
===> Epoch[26](2100/2500): Loss: 0.3144
===> Epoch[26](2200/2500): Loss: 0.3044
===> Epoch[26](2300/2500): Loss: 0.3068
===> Epoch[26](2400/2500): Loss: 0.2872
===> Epoch[26](2500/2500): Loss: 0.2895
===> Epoch 26 Complete: Avg. Loss: 0.2888
===> Timestamp: [2025-08-03 21:29:57]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2908
===> Epoch[26](200/2500): Loss: 0.2777
===> Epoch[26](300/2500): Loss: 0.2709
===> Epoch[26](400/2500): Loss: 0.2831
===> Epoch[26](500/2500): Loss: 0.3068
===> Epoch[26](600/2500): Loss: 0.2929
===> Epoch[26](700/2500): Loss: 0.3029
===> Epoch[26](800/2500): Loss: 0.3024
===> Epoch[26](900/2500): Loss: 0.2934
===> Epoch[26](1000/2500): Loss: 0.2995
===> Epoch[26](1100/2500): Loss: 0.3057
===> Epoch[26](1200/2500): Loss: 0.2902
===> Epoch[26](1300/2500): Loss: 0.2569
===> Epoch[26](1400/2500): Loss: 0.2704
===> Epoch[26](1500/2500): Loss: 0.2955
===> Epoch[26](1600/2500): Loss: 0.2792
===> Epoch[26](1700/2500): Loss: 0.2863
===> Epoch[26](1800/2500): Loss: 0.2744
===> Epoch[26](1900/2500): Loss: 0.2703
===> Epoch[26](2000/2500): Loss: 0.3062
===> Epoch[26](2100/2500): Loss: 0.3144
===> Epoch[26](2200/2500): Loss: 0.3044
===> Epoch[26](2300/2500): Loss: 0.3068
===> Epoch[26](2400/2500): Loss: 0.2872
===> Epoch[26](2500/2500): Loss: 0.2895
===> Epoch 26 Complete: Avg. Loss: 0.2888
===> Timestamp: [2025-08-03 21:29:57]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2908
===> Epoch[26](200/2500): Loss: 0.2777
===> Epoch[26](300/2500): Loss: 0.2709
===> Epoch[26](400/2500): Loss: 0.2831
===> Epoch[26](500/2500): Loss: 0.3068
===> Epoch[26](600/2500): Loss: 0.2929
===> Epoch[26](700/2500): Loss: 0.3029
===> Epoch[26](800/2500): Loss: 0.3024
===> Epoch[26](900/2500): Loss: 0.2934
===> Epoch[26](1000/2500): Loss: 0.2995
===> Epoch[26](1100/2500): Loss: 0.3057
===> Epoch[26](1200/2500): Loss: 0.2902
===> Epoch[26](1300/2500): Loss: 0.2569
===> Epoch[26](1400/2500): Loss: 0.2704
===> Epoch[26](1500/2500): Loss: 0.2955
===> Epoch[26](1600/2500): Loss: 0.2792
===> Epoch[26](1700/2500): Loss: 0.2863
===> Epoch[26](1800/2500): Loss: 0.2744
===> Epoch[26](1900/2500): Loss: 0.2703
===> Epoch[26](2000/2500): Loss: 0.3062
===> Epoch[26](2100/2500): Loss: 0.3144
===> Epoch[26](2200/2500): Loss: 0.3044
===> Epoch[26](2300/2500): Loss: 0.3068
===> Epoch[26](2400/2500): Loss: 0.2872
===> Epoch[26](2500/2500): Loss: 0.2895
===> Epoch 26 Complete: Avg. Loss: 0.2888
===> Timestamp: [2025-08-03 21:29:57]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2908
===> Epoch[26](200/2500): Loss: 0.2777
===> Epoch[26](300/2500): Loss: 0.2709
===> Epoch[26](400/2500): Loss: 0.2831
===> Epoch[26](500/2500): Loss: 0.3068
===> Epoch[26](600/2500): Loss: 0.2929
===> Epoch[26](700/2500): Loss: 0.3029
===> Epoch[26](800/2500): Loss: 0.3024
===> Epoch[26](900/2500): Loss: 0.2934
===> Epoch[26](1000/2500): Loss: 0.2995
===> Epoch[26](1100/2500): Loss: 0.3057
===> Epoch[26](1200/2500): Loss: 0.2902
===> Epoch[26](1300/2500): Loss: 0.2569
===> Epoch[26](1400/2500): Loss: 0.2704
===> Epoch[26](1500/2500): Loss: 0.2955
===> Epoch[26](1600/2500): Loss: 0.2792
===> Epoch[26](1700/2500): Loss: 0.2863
===> Epoch[26](1800/2500): Loss: 0.2744
===> Epoch[26](1900/2500): Loss: 0.2703
===> Epoch[26](2000/2500): Loss: 0.3062
===> Epoch[26](2100/2500): Loss: 0.3144
===> Epoch[26](2200/2500): Loss: 0.3044
===> Epoch[26](2300/2500): Loss: 0.3068
===> Epoch[26](2400/2500): Loss: 0.2872
===> Epoch[26](2500/2500): Loss: 0.2895
===> Epoch 26 Complete: Avg. Loss: 0.2888
===> Timestamp: [2025-08-03 21:29:57]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2908
===> Epoch[26](200/2500): Loss: 0.2777
===> Epoch[26](300/2500): Loss: 0.2709
===> Epoch[26](400/2500): Loss: 0.2831
===> Epoch[26](500/2500): Loss: 0.3068
===> Epoch[26](600/2500): Loss: 0.2929
===> Epoch[26](700/2500): Loss: 0.3029
===> Epoch[26](800/2500): Loss: 0.3024
===> Epoch[26](900/2500): Loss: 0.2934
===> Epoch[26](1000/2500): Loss: 0.2995
===> Epoch[26](1100/2500): Loss: 0.3057
===> Epoch[26](1200/2500): Loss: 0.2902
===> Epoch[26](1300/2500): Loss: 0.2569
===> Epoch[26](1400/2500): Loss: 0.2704
===> Epoch[26](1500/2500): Loss: 0.2955
===> Epoch[26](1600/2500): Loss: 0.2792
===> Epoch[26](1700/2500): Loss: 0.2863
===> Epoch[26](1800/2500): Loss: 0.2744
===> Epoch[26](1900/2500): Loss: 0.2703
===> Epoch[26](2000/2500): Loss: 0.3062
===> Epoch[26](2100/2500): Loss: 0.3144
===> Epoch[26](2200/2500): Loss: 0.3044
===> Epoch[26](2300/2500): Loss: 0.3068
===> Epoch[26](2400/2500): Loss: 0.2872
===> Epoch[26](2500/2500): Loss: 0.2895
===> Epoch 26 Complete: Avg. Loss: 0.2888
===> Timestamp: [2025-08-03 21:29:57]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2908
===> Epoch[26](200/2500): Loss: 0.2777
===> Epoch[26](300/2500): Loss: 0.2709
===> Epoch[26](400/2500): Loss: 0.2831
===> Epoch[26](500/2500): Loss: 0.3068
===> Epoch[26](600/2500): Loss: 0.2929
===> Epoch[26](700/2500): Loss: 0.3029
===> Epoch[26](800/2500): Loss: 0.3024
===> Epoch[26](900/2500): Loss: 0.2934
===> Epoch[26](1000/2500): Loss: 0.2995
===> Epoch[26](1100/2500): Loss: 0.3057
===> Epoch[26](1200/2500): Loss: 0.2902
===> Epoch[26](1300/2500): Loss: 0.2569
===> Epoch[26](1400/2500): Loss: 0.2704
===> Epoch[26](1500/2500): Loss: 0.2955
===> Epoch[26](1600/2500): Loss: 0.2792
===> Epoch[26](1700/2500): Loss: 0.2863
===> Epoch[26](1800/2500): Loss: 0.2744
===> Epoch[26](1900/2500): Loss: 0.2703
===> Epoch[26](2000/2500): Loss: 0.3062
===> Epoch[26](2100/2500): Loss: 0.3144
===> Epoch[26](2200/2500): Loss: 0.3044
===> Epoch[26](2300/2500): Loss: 0.3068
===> Epoch[26](2400/2500): Loss: 0.2872
===> Epoch[26](2500/2500): Loss: 0.2895
===> Epoch 26 Complete: Avg. Loss: 0.2888
===> Timestamp: [2025-08-03 21:29:57]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2908
===> Epoch[26](200/2500): Loss: 0.2777
===> Epoch[26](300/2500): Loss: 0.2709
===> Epoch[26](400/2500): Loss: 0.2831
===> Epoch[26](500/2500): Loss: 0.3068
===> Epoch[26](600/2500): Loss: 0.2929
===> Epoch[26](700/2500): Loss: 0.3029
===> Epoch[26](800/2500): Loss: 0.3024
===> Epoch[26](900/2500): Loss: 0.2934
===> Epoch[26](1000/2500): Loss: 0.2995
===> Epoch[26](1100/2500): Loss: 0.3057
===> Epoch[26](1200/2500): Loss: 0.2902
===> Epoch[26](1300/2500): Loss: 0.2569
===> Epoch[26](1400/2500): Loss: 0.2704
===> Epoch[26](1500/2500): Loss: 0.2955
===> Epoch[26](1600/2500): Loss: 0.2792
===> Epoch[26](1700/2500): Loss: 0.2863
===> Epoch[26](1800/2500): Loss: 0.2744
===> Epoch[26](1900/2500): Loss: 0.2703
===> Epoch[26](2000/2500): Loss: 0.3062
===> Epoch[26](2100/2500): Loss: 0.3144
===> Epoch[26](2200/2500): Loss: 0.3044
===> Epoch[26](2300/2500): Loss: 0.3068
===> Epoch[26](2400/2500): Loss: 0.2872
===> Epoch[26](2500/2500): Loss: 0.2895
===> Epoch 26 Complete: Avg. Loss: 0.2888
===> Timestamp: [2025-08-03 21:29:57]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2908
===> Epoch[26](200/2500): Loss: 0.2777
===> Epoch[26](300/2500): Loss: 0.2709
===> Epoch[26](400/2500): Loss: 0.2831
===> Epoch[26](500/2500): Loss: 0.3068
===> Epoch[26](600/2500): Loss: 0.2929
===> Epoch[26](700/2500): Loss: 0.3029
===> Epoch[26](800/2500): Loss: 0.3024
===> Epoch[26](900/2500): Loss: 0.2934
===> Epoch[26](1000/2500): Loss: 0.2995
===> Epoch[26](1100/2500): Loss: 0.3057
===> Epoch[26](1200/2500): Loss: 0.2902
===> Epoch[26](1300/2500): Loss: 0.2569
===> Epoch[26](1400/2500): Loss: 0.2704
===> Epoch[26](1500/2500): Loss: 0.2955
===> Epoch[26](1600/2500): Loss: 0.2792
===> Epoch[26](1700/2500): Loss: 0.2863
===> Epoch[26](1800/2500): Loss: 0.2744
===> Epoch[26](1900/2500): Loss: 0.2703
===> Epoch[26](2000/2500): Loss: 0.3062
===> Epoch[26](2100/2500): Loss: 0.3144
===> Epoch[26](2200/2500): Loss: 0.3044
===> Epoch[26](2300/2500): Loss: 0.3068
===> Epoch[26](2400/2500): Loss: 0.2872
===> Epoch[26](2500/2500): Loss: 0.2895
===> Epoch 26 Complete: Avg. Loss: 0.2888
===> Timestamp: [2025-08-03 21:29:57]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2908
===> Epoch[26](200/2500): Loss: 0.2777
===> Epoch[26](300/2500): Loss: 0.2709
===> Epoch[26](400/2500): Loss: 0.2831
===> Epoch[26](500/2500): Loss: 0.3068
===> Epoch[26](600/2500): Loss: 0.2929
===> Epoch[26](700/2500): Loss: 0.3029
===> Epoch[26](800/2500): Loss: 0.3024
===> Epoch[26](900/2500): Loss: 0.2934
===> Epoch[26](1000/2500): Loss: 0.2995
===> Epoch[26](1100/2500): Loss: 0.3057
===> Epoch[26](1200/2500): Loss: 0.2902
===> Epoch[26](1300/2500): Loss: 0.2569
===> Epoch[26](1400/2500): Loss: 0.2704
===> Epoch[26](1500/2500): Loss: 0.2955
===> Epoch[26](1600/2500): Loss: 0.2792
===> Epoch[26](1700/2500): Loss: 0.2863
===> Epoch[26](1800/2500): Loss: 0.2744
===> Epoch[26](1900/2500): Loss: 0.2703
===> Epoch[26](2000/2500): Loss: 0.3062
===> Epoch[26](2100/2500): Loss: 0.3144
===> Epoch[26](2200/2500): Loss: 0.3044
===> Epoch[26](2300/2500): Loss: 0.3068
===> Epoch[26](2400/2500): Loss: 0.2872
===> Epoch[26](2500/2500): Loss: 0.2895
===> Epoch 26 Complete: Avg. Loss: 0.2888
===> Timestamp: [2025-08-03 21:29:57]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2908
===> Epoch[26](200/2500): Loss: 0.2777
===> Epoch[26](300/2500): Loss: 0.2709
===> Epoch[26](400/2500): Loss: 0.2831
===> Epoch[26](500/2500): Loss: 0.3068
===> Epoch[26](600/2500): Loss: 0.2929
===> Epoch[26](700/2500): Loss: 0.3029
===> Epoch[26](800/2500): Loss: 0.3024
===> Epoch[26](900/2500): Loss: 0.2934
===> Epoch[26](1000/2500): Loss: 0.2995
===> Epoch[26](1100/2500): Loss: 0.3057
===> Epoch[26](1200/2500): Loss: 0.2902
===> Epoch[26](1300/2500): Loss: 0.2569
===> Epoch[26](1400/2500): Loss: 0.2704
===> Epoch[26](1500/2500): Loss: 0.2955
===> Epoch[26](1600/2500): Loss: 0.2792
===> Epoch[26](1700/2500): Loss: 0.2863
===> Epoch[26](1800/2500): Loss: 0.2744
===> Epoch[26](1900/2500): Loss: 0.2703
===> Epoch[26](2000/2500): Loss: 0.3062
===> Epoch[26](2100/2500): Loss: 0.3144
===> Epoch[26](2200/2500): Loss: 0.3044
===> Epoch[26](2300/2500): Loss: 0.3068
===> Epoch[26](2400/2500): Loss: 0.2872
===> Epoch[26](2500/2500): Loss: 0.2895
===> Epoch 26 Complete: Avg. Loss: 0.2888
===> Timestamp: [2025-08-03 21:29:57]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2908
===> Epoch[26](200/2500): Loss: 0.2777
===> Epoch[26](300/2500): Loss: 0.2709
===> Epoch[26](400/2500): Loss: 0.2831
===> Epoch[26](500/2500): Loss: 0.3068
===> Epoch[26](600/2500): Loss: 0.2929
===> Epoch[26](700/2500): Loss: 0.3029
===> Epoch[26](800/2500): Loss: 0.3024
===> Epoch[26](900/2500): Loss: 0.2934
===> Epoch[26](1000/2500): Loss: 0.2995
===> Epoch[26](1100/2500): Loss: 0.3057
===> Epoch[26](1200/2500): Loss: 0.2902
===> Epoch[26](1300/2500): Loss: 0.2569
===> Epoch[26](1400/2500): Loss: 0.2704
===> Epoch[26](1500/2500): Loss: 0.2955
===> Epoch[26](1600/2500): Loss: 0.2792
===> Epoch[26](1700/2500): Loss: 0.2863
===> Epoch[26](1800/2500): Loss: 0.2744
===> Epoch[26](1900/2500): Loss: 0.2703
===> Epoch[26](2000/2500): Loss: 0.3062
===> Epoch[26](2100/2500): Loss: 0.3144
===> Epoch[26](2200/2500): Loss: 0.3044
===> Epoch[26](2300/2500): Loss: 0.3068
===> Epoch[26](2400/2500): Loss: 0.2872
===> Epoch[26](2500/2500): Loss: 0.2895
===> Epoch 26 Complete: Avg. Loss: 0.2888
===> Timestamp: [2025-08-03 21:29:57]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2908
===> Epoch[26](200/2500): Loss: 0.2777
===> Epoch[26](300/2500): Loss: 0.2709
===> Epoch[26](400/2500): Loss: 0.2831
===> Epoch[26](500/2500): Loss: 0.3068
===> Epoch[26](600/2500): Loss: 0.2929
===> Epoch[26](700/2500): Loss: 0.3029
===> Epoch[26](800/2500): Loss: 0.3024
===> Epoch[26](900/2500): Loss: 0.2934
===> Epoch[26](1000/2500): Loss: 0.2995
===> Epoch[26](1100/2500): Loss: 0.3057
===> Epoch[26](1200/2500): Loss: 0.2902
===> Epoch[26](1300/2500): Loss: 0.2569
===> Epoch[26](1400/2500): Loss: 0.2704
===> Epoch[26](1500/2500): Loss: 0.2955
===> Epoch[26](1600/2500): Loss: 0.2792
===> Epoch[26](1700/2500): Loss: 0.2863
===> Epoch[26](1800/2500): Loss: 0.2744
===> Epoch[26](1900/2500): Loss: 0.2703
===> Epoch[26](2000/2500): Loss: 0.3062
===> Epoch[26](2100/2500): Loss: 0.3144
===> Epoch[26](2200/2500): Loss: 0.3044
===> Epoch[26](2300/2500): Loss: 0.3068
===> Epoch[26](2400/2500): Loss: 0.2872
===> Epoch[26](2500/2500): Loss: 0.2895
===> Epoch 26 Complete: Avg. Loss: 0.2888
===> Timestamp: [2025-08-03 21:29:57]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2908
===> Epoch[26](200/2500): Loss: 0.2777
===> Epoch[26](300/2500): Loss: 0.2709
===> Epoch[26](400/2500): Loss: 0.2831
===> Epoch[26](500/2500): Loss: 0.3068
===> Epoch[26](600/2500): Loss: 0.2929
===> Epoch[26](700/2500): Loss: 0.3029
===> Epoch[26](800/2500): Loss: 0.3024
===> Epoch[26](900/2500): Loss: 0.2934
===> Epoch[26](1000/2500): Loss: 0.2995
===> Epoch[26](1100/2500): Loss: 0.3057
===> Epoch[26](1200/2500): Loss: 0.2902
===> Epoch[26](1300/2500): Loss: 0.2569
===> Epoch[26](1400/2500): Loss: 0.2704
===> Epoch[26](1500/2500): Loss: 0.2955
===> Epoch[26](1600/2500): Loss: 0.2792
===> Epoch[26](1700/2500): Loss: 0.2863
===> Epoch[26](1800/2500): Loss: 0.2744
===> Epoch[26](1900/2500): Loss: 0.2703
===> Epoch[26](2000/2500): Loss: 0.3062
===> Epoch[26](2100/2500): Loss: 0.3144
===> Epoch[26](2200/2500): Loss: 0.3044
===> Epoch[26](2300/2500): Loss: 0.3068
===> Epoch[26](2400/2500): Loss: 0.2872
===> Epoch[26](2500/2500): Loss: 0.2895
===> Epoch 26 Complete: Avg. Loss: 0.2888
===> Timestamp: [2025-08-03 21:29:57]
===> Loading train datasets
===> Epoch[26](100/2500): Loss: 0.2908
===> Epoch[26](200/2500): Loss: 0.2777
===> Epoch[26](300/2500): Loss: 0.2709
===> Epoch[26](400/2500): Loss: 0.2831
===> Epoch[26](500/2500): Loss: 0.3068
===> Epoch[26](600/2500): Loss: 0.2929
===> Epoch[26](700/2500): Loss: 0.3029
===> Epoch[26](800/2500): Loss: 0.3024
===> Epoch[26](900/2500): Loss: 0.2934
===> Epoch[26](1000/2500): Loss: 0.2995
===> Epoch[26](1100/2500): Loss: 0.3057
===> Epoch[26](1200/2500): Loss: 0.2902
===> Epoch[26](1300/2500): Loss: 0.2569
===> Epoch[26](1400/2500): Loss: 0.2704
===> Epoch[26](1500/2500): Loss: 0.2955
===> Epoch[26](1600/2500): Loss: 0.2792
===> Epoch[26](1700/2500): Loss: 0.2863
===> Epoch[26](1800/2500): Loss: 0.2744
===> Epoch[26](1900/2500): Loss: 0.2703
===> Epoch[26](2000/2500): Loss: 0.3062
===> Epoch[26](2100/2500): Loss: 0.3144
===> Epoch[26](2200/2500): Loss: 0.3044
===> Epoch[26](2300/2500): Loss: 0.3068
===> Epoch[26](2400/2500): Loss: 0.2872
===> Epoch[26](2500/2500): Loss: 0.2895
===> Epoch 26 Complete: Avg. Loss: 0.2888
===> Timestamp: [2025-08-03 21:29:57]
===> Loading train datasets
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2941
===> Epoch[27](200/2500): Loss: 0.2860
===> Epoch[27](300/2500): Loss: 0.2823
===> Epoch[27](400/2500): Loss: 0.3023
===> Epoch[27](500/2500): Loss: 0.2866
===> Epoch[27](600/2500): Loss: 0.2834
===> Epoch[27](700/2500): Loss: 0.2825
===> Epoch[27](800/2500): Loss: 0.2902
===> Epoch[27](900/2500): Loss: 0.2850
===> Epoch[27](1000/2500): Loss: 0.3017
===> Epoch[27](1100/2500): Loss: 0.2701
===> Epoch[27](1200/2500): Loss: 0.2738
===> Epoch[27](1300/2500): Loss: 0.2756
===> Epoch[27](1400/2500): Loss: 0.2778
===> Epoch[27](1500/2500): Loss: 0.3026
===> Epoch[27](1600/2500): Loss: 0.2768
===> Epoch[27](1700/2500): Loss: 0.2830
===> Epoch[27](1800/2500): Loss: 0.2921
===> Epoch[27](1900/2500): Loss: 0.2767
===> Epoch[27](2000/2500): Loss: 0.2690
===> Epoch[27](2100/2500): Loss: 0.2966
===> Epoch[27](2200/2500): Loss: 0.2848
===> Epoch[27](2300/2500): Loss: 0.2817
===> Epoch[27](2400/2500): Loss: 0.3092
===> Epoch[27](2500/2500): Loss: 0.2851
===> Epoch 27 Complete: Avg. Loss: 0.2885
===> Timestamp: [2025-08-03 21:34:31]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2941
===> Epoch[27](200/2500): Loss: 0.2860
===> Epoch[27](300/2500): Loss: 0.2823
===> Epoch[27](400/2500): Loss: 0.3023
===> Epoch[27](500/2500): Loss: 0.2866
===> Epoch[27](600/2500): Loss: 0.2834
===> Epoch[27](700/2500): Loss: 0.2825
===> Epoch[27](800/2500): Loss: 0.2902
===> Epoch[27](900/2500): Loss: 0.2850
===> Epoch[27](1000/2500): Loss: 0.3017
===> Epoch[27](1100/2500): Loss: 0.2701
===> Epoch[27](1200/2500): Loss: 0.2738
===> Epoch[27](1300/2500): Loss: 0.2756
===> Epoch[27](1400/2500): Loss: 0.2778
===> Epoch[27](1500/2500): Loss: 0.3026
===> Epoch[27](1600/2500): Loss: 0.2768
===> Epoch[27](1700/2500): Loss: 0.2830
===> Epoch[27](1800/2500): Loss: 0.2921
===> Epoch[27](1900/2500): Loss: 0.2767
===> Epoch[27](2000/2500): Loss: 0.2690
===> Epoch[27](2100/2500): Loss: 0.2966
===> Epoch[27](2200/2500): Loss: 0.2848
===> Epoch[27](2300/2500): Loss: 0.2817
===> Epoch[27](2400/2500): Loss: 0.3092
===> Epoch[27](2500/2500): Loss: 0.2851
===> Epoch 27 Complete: Avg. Loss: 0.2885
===> Timestamp: [2025-08-03 21:34:31]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2941
===> Epoch[27](200/2500): Loss: 0.2860
===> Epoch[27](300/2500): Loss: 0.2823
===> Epoch[27](400/2500): Loss: 0.3023
===> Epoch[27](500/2500): Loss: 0.2866
===> Epoch[27](600/2500): Loss: 0.2834
===> Epoch[27](700/2500): Loss: 0.2825
===> Epoch[27](800/2500): Loss: 0.2902
===> Epoch[27](900/2500): Loss: 0.2850
===> Epoch[27](1000/2500): Loss: 0.3017
===> Epoch[27](1100/2500): Loss: 0.2701
===> Epoch[27](1200/2500): Loss: 0.2738
===> Epoch[27](1300/2500): Loss: 0.2756
===> Epoch[27](1400/2500): Loss: 0.2778
===> Epoch[27](1500/2500): Loss: 0.3026
===> Epoch[27](1600/2500): Loss: 0.2768
===> Epoch[27](1700/2500): Loss: 0.2830
===> Epoch[27](1800/2500): Loss: 0.2921
===> Epoch[27](1900/2500): Loss: 0.2767
===> Epoch[27](2000/2500): Loss: 0.2690
===> Epoch[27](2100/2500): Loss: 0.2966
===> Epoch[27](2200/2500): Loss: 0.2848
===> Epoch[27](2300/2500): Loss: 0.2817
===> Epoch[27](2400/2500): Loss: 0.3092
===> Epoch[27](2500/2500): Loss: 0.2851
===> Epoch 27 Complete: Avg. Loss: 0.2885
===> Timestamp: [2025-08-03 21:34:31]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2941
===> Epoch[27](200/2500): Loss: 0.2860
===> Epoch[27](300/2500): Loss: 0.2823
===> Epoch[27](400/2500): Loss: 0.3023
===> Epoch[27](500/2500): Loss: 0.2866
===> Epoch[27](600/2500): Loss: 0.2834
===> Epoch[27](700/2500): Loss: 0.2825
===> Epoch[27](800/2500): Loss: 0.2902
===> Epoch[27](900/2500): Loss: 0.2850
===> Epoch[27](1000/2500): Loss: 0.3017
===> Epoch[27](1100/2500): Loss: 0.2701
===> Epoch[27](1200/2500): Loss: 0.2738
===> Epoch[27](1300/2500): Loss: 0.2756
===> Epoch[27](1400/2500): Loss: 0.2778
===> Epoch[27](1500/2500): Loss: 0.3026
===> Epoch[27](1600/2500): Loss: 0.2768
===> Epoch[27](1700/2500): Loss: 0.2830
===> Epoch[27](1800/2500): Loss: 0.2921
===> Epoch[27](1900/2500): Loss: 0.2767
===> Epoch[27](2000/2500): Loss: 0.2690
===> Epoch[27](2100/2500): Loss: 0.2966
===> Epoch[27](2200/2500): Loss: 0.2848
===> Epoch[27](2300/2500): Loss: 0.2817
===> Epoch[27](2400/2500): Loss: 0.3092
===> Epoch[27](2500/2500): Loss: 0.2851
===> Epoch 27 Complete: Avg. Loss: 0.2885
===> Timestamp: [2025-08-03 21:34:31]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2941
===> Epoch[27](200/2500): Loss: 0.2860
===> Epoch[27](300/2500): Loss: 0.2823
===> Epoch[27](400/2500): Loss: 0.3023
===> Epoch[27](500/2500): Loss: 0.2866
===> Epoch[27](600/2500): Loss: 0.2834
===> Epoch[27](700/2500): Loss: 0.2825
===> Epoch[27](800/2500): Loss: 0.2902
===> Epoch[27](900/2500): Loss: 0.2850
===> Epoch[27](1000/2500): Loss: 0.3017
===> Epoch[27](1100/2500): Loss: 0.2701
===> Epoch[27](1200/2500): Loss: 0.2738
===> Epoch[27](1300/2500): Loss: 0.2756
===> Epoch[27](1400/2500): Loss: 0.2778
===> Epoch[27](1500/2500): Loss: 0.3026
===> Epoch[27](1600/2500): Loss: 0.2768
===> Epoch[27](1700/2500): Loss: 0.2830
===> Epoch[27](1800/2500): Loss: 0.2921
===> Epoch[27](1900/2500): Loss: 0.2767
===> Epoch[27](2000/2500): Loss: 0.2690
===> Epoch[27](2100/2500): Loss: 0.2966
===> Epoch[27](2200/2500): Loss: 0.2848
===> Epoch[27](2300/2500): Loss: 0.2817
===> Epoch[27](2400/2500): Loss: 0.3092
===> Epoch[27](2500/2500): Loss: 0.2851
===> Epoch 27 Complete: Avg. Loss: 0.2885
===> Timestamp: [2025-08-03 21:34:31]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2941
===> Epoch[27](200/2500): Loss: 0.2860
===> Epoch[27](300/2500): Loss: 0.2823
===> Epoch[27](400/2500): Loss: 0.3023
===> Epoch[27](500/2500): Loss: 0.2866
===> Epoch[27](600/2500): Loss: 0.2834
===> Epoch[27](700/2500): Loss: 0.2825
===> Epoch[27](800/2500): Loss: 0.2902
===> Epoch[27](900/2500): Loss: 0.2850
===> Epoch[27](1000/2500): Loss: 0.3017
===> Epoch[27](1100/2500): Loss: 0.2701
===> Epoch[27](1200/2500): Loss: 0.2738
===> Epoch[27](1300/2500): Loss: 0.2756
===> Epoch[27](1400/2500): Loss: 0.2778
===> Epoch[27](1500/2500): Loss: 0.3026
===> Epoch[27](1600/2500): Loss: 0.2768
===> Epoch[27](1700/2500): Loss: 0.2830
===> Epoch[27](1800/2500): Loss: 0.2921
===> Epoch[27](1900/2500): Loss: 0.2767
===> Epoch[27](2000/2500): Loss: 0.2690
===> Epoch[27](2100/2500): Loss: 0.2966
===> Epoch[27](2200/2500): Loss: 0.2848
===> Epoch[27](2300/2500): Loss: 0.2817
===> Epoch[27](2400/2500): Loss: 0.3092
===> Epoch[27](2500/2500): Loss: 0.2851
===> Epoch 27 Complete: Avg. Loss: 0.2885
===> Timestamp: [2025-08-03 21:34:31]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2941
===> Epoch[27](200/2500): Loss: 0.2860
===> Epoch[27](300/2500): Loss: 0.2823
===> Epoch[27](400/2500): Loss: 0.3023
===> Epoch[27](500/2500): Loss: 0.2866
===> Epoch[27](600/2500): Loss: 0.2834
===> Epoch[27](700/2500): Loss: 0.2825
===> Epoch[27](800/2500): Loss: 0.2902
===> Epoch[27](900/2500): Loss: 0.2850
===> Epoch[27](1000/2500): Loss: 0.3017
===> Epoch[27](1100/2500): Loss: 0.2701
===> Epoch[27](1200/2500): Loss: 0.2738
===> Epoch[27](1300/2500): Loss: 0.2756
===> Epoch[27](1400/2500): Loss: 0.2778
===> Epoch[27](1500/2500): Loss: 0.3026
===> Epoch[27](1600/2500): Loss: 0.2768
===> Epoch[27](1700/2500): Loss: 0.2830
===> Epoch[27](1800/2500): Loss: 0.2921
===> Epoch[27](1900/2500): Loss: 0.2767
===> Epoch[27](2000/2500): Loss: 0.2690
===> Epoch[27](2100/2500): Loss: 0.2966
===> Epoch[27](2200/2500): Loss: 0.2848
===> Epoch[27](2300/2500): Loss: 0.2817
===> Epoch[27](2400/2500): Loss: 0.3092
===> Epoch[27](2500/2500): Loss: 0.2851
===> Epoch 27 Complete: Avg. Loss: 0.2885
===> Timestamp: [2025-08-03 21:34:31]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2941
===> Epoch[27](200/2500): Loss: 0.2860
===> Epoch[27](300/2500): Loss: 0.2823
===> Epoch[27](400/2500): Loss: 0.3023
===> Epoch[27](500/2500): Loss: 0.2866
===> Epoch[27](600/2500): Loss: 0.2834
===> Epoch[27](700/2500): Loss: 0.2825
===> Epoch[27](800/2500): Loss: 0.2902
===> Epoch[27](900/2500): Loss: 0.2850
===> Epoch[27](1000/2500): Loss: 0.3017
===> Epoch[27](1100/2500): Loss: 0.2701
===> Epoch[27](1200/2500): Loss: 0.2738
===> Epoch[27](1300/2500): Loss: 0.2756
===> Epoch[27](1400/2500): Loss: 0.2778
===> Epoch[27](1500/2500): Loss: 0.3026
===> Epoch[27](1600/2500): Loss: 0.2768
===> Epoch[27](1700/2500): Loss: 0.2830
===> Epoch[27](1800/2500): Loss: 0.2921
===> Epoch[27](1900/2500): Loss: 0.2767
===> Epoch[27](2000/2500): Loss: 0.2690
===> Epoch[27](2100/2500): Loss: 0.2966
===> Epoch[27](2200/2500): Loss: 0.2848
===> Epoch[27](2300/2500): Loss: 0.2817
===> Epoch[27](2400/2500): Loss: 0.3092
===> Epoch[27](2500/2500): Loss: 0.2851
===> Epoch 27 Complete: Avg. Loss: 0.2885
===> Timestamp: [2025-08-03 21:34:31]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2941
===> Epoch[27](200/2500): Loss: 0.2860
===> Epoch[27](300/2500): Loss: 0.2823
===> Epoch[27](400/2500): Loss: 0.3023
===> Epoch[27](500/2500): Loss: 0.2866
===> Epoch[27](600/2500): Loss: 0.2834
===> Epoch[27](700/2500): Loss: 0.2825
===> Epoch[27](800/2500): Loss: 0.2902
===> Epoch[27](900/2500): Loss: 0.2850
===> Epoch[27](1000/2500): Loss: 0.3017
===> Epoch[27](1100/2500): Loss: 0.2701
===> Epoch[27](1200/2500): Loss: 0.2738
===> Epoch[27](1300/2500): Loss: 0.2756
===> Epoch[27](1400/2500): Loss: 0.2778
===> Epoch[27](1500/2500): Loss: 0.3026
===> Epoch[27](1600/2500): Loss: 0.2768
===> Epoch[27](1700/2500): Loss: 0.2830
===> Epoch[27](1800/2500): Loss: 0.2921
===> Epoch[27](1900/2500): Loss: 0.2767
===> Epoch[27](2000/2500): Loss: 0.2690
===> Epoch[27](2100/2500): Loss: 0.2966
===> Epoch[27](2200/2500): Loss: 0.2848
===> Epoch[27](2300/2500): Loss: 0.2817
===> Epoch[27](2400/2500): Loss: 0.3092
===> Epoch[27](2500/2500): Loss: 0.2851
===> Epoch 27 Complete: Avg. Loss: 0.2885
===> Timestamp: [2025-08-03 21:34:31]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2941
===> Epoch[27](200/2500): Loss: 0.2860
===> Epoch[27](300/2500): Loss: 0.2823
===> Epoch[27](400/2500): Loss: 0.3023
===> Epoch[27](500/2500): Loss: 0.2866
===> Epoch[27](600/2500): Loss: 0.2834
===> Epoch[27](700/2500): Loss: 0.2825
===> Epoch[27](800/2500): Loss: 0.2902
===> Epoch[27](900/2500): Loss: 0.2850
===> Epoch[27](1000/2500): Loss: 0.3017
===> Epoch[27](1100/2500): Loss: 0.2701
===> Epoch[27](1200/2500): Loss: 0.2738
===> Epoch[27](1300/2500): Loss: 0.2756
===> Epoch[27](1400/2500): Loss: 0.2778
===> Epoch[27](1500/2500): Loss: 0.3026
===> Epoch[27](1600/2500): Loss: 0.2768
===> Epoch[27](1700/2500): Loss: 0.2830
===> Epoch[27](1800/2500): Loss: 0.2921
===> Epoch[27](1900/2500): Loss: 0.2767
===> Epoch[27](2000/2500): Loss: 0.2690
===> Epoch[27](2100/2500): Loss: 0.2966
===> Epoch[27](2200/2500): Loss: 0.2848
===> Epoch[27](2300/2500): Loss: 0.2817
===> Epoch[27](2400/2500): Loss: 0.3092
===> Epoch[27](2500/2500): Loss: 0.2851
===> Epoch 27 Complete: Avg. Loss: 0.2885
===> Timestamp: [2025-08-03 21:34:31]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2941
===> Epoch[27](200/2500): Loss: 0.2860
===> Epoch[27](300/2500): Loss: 0.2823
===> Epoch[27](400/2500): Loss: 0.3023
===> Epoch[27](500/2500): Loss: 0.2866
===> Epoch[27](600/2500): Loss: 0.2834
===> Epoch[27](700/2500): Loss: 0.2825
===> Epoch[27](800/2500): Loss: 0.2902
===> Epoch[27](900/2500): Loss: 0.2850
===> Epoch[27](1000/2500): Loss: 0.3017
===> Epoch[27](1100/2500): Loss: 0.2701
===> Epoch[27](1200/2500): Loss: 0.2738
===> Epoch[27](1300/2500): Loss: 0.2756
===> Epoch[27](1400/2500): Loss: 0.2778
===> Epoch[27](1500/2500): Loss: 0.3026
===> Epoch[27](1600/2500): Loss: 0.2768
===> Epoch[27](1700/2500): Loss: 0.2830
===> Epoch[27](1800/2500): Loss: 0.2921
===> Epoch[27](1900/2500): Loss: 0.2767
===> Epoch[27](2000/2500): Loss: 0.2690
===> Epoch[27](2100/2500): Loss: 0.2966
===> Epoch[27](2200/2500): Loss: 0.2848
===> Epoch[27](2300/2500): Loss: 0.2817
===> Epoch[27](2400/2500): Loss: 0.3092
===> Epoch[27](2500/2500): Loss: 0.2851
===> Epoch 27 Complete: Avg. Loss: 0.2885
===> Timestamp: [2025-08-03 21:34:31]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2941
===> Epoch[27](200/2500): Loss: 0.2860
===> Epoch[27](300/2500): Loss: 0.2823
===> Epoch[27](400/2500): Loss: 0.3023
===> Epoch[27](500/2500): Loss: 0.2866
===> Epoch[27](600/2500): Loss: 0.2834
===> Epoch[27](700/2500): Loss: 0.2825
===> Epoch[27](800/2500): Loss: 0.2902
===> Epoch[27](900/2500): Loss: 0.2850
===> Epoch[27](1000/2500): Loss: 0.3017
===> Epoch[27](1100/2500): Loss: 0.2701
===> Epoch[27](1200/2500): Loss: 0.2738
===> Epoch[27](1300/2500): Loss: 0.2756
===> Epoch[27](1400/2500): Loss: 0.2778
===> Epoch[27](1500/2500): Loss: 0.3026
===> Epoch[27](1600/2500): Loss: 0.2768
===> Epoch[27](1700/2500): Loss: 0.2830
===> Epoch[27](1800/2500): Loss: 0.2921
===> Epoch[27](1900/2500): Loss: 0.2767
===> Epoch[27](2000/2500): Loss: 0.2690
===> Epoch[27](2100/2500): Loss: 0.2966
===> Epoch[27](2200/2500): Loss: 0.2848
===> Epoch[27](2300/2500): Loss: 0.2817
===> Epoch[27](2400/2500): Loss: 0.3092
===> Epoch[27](2500/2500): Loss: 0.2851
===> Epoch 27 Complete: Avg. Loss: 0.2885
===> Timestamp: [2025-08-03 21:34:31]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2941
===> Epoch[27](200/2500): Loss: 0.2860
===> Epoch[27](300/2500): Loss: 0.2823
===> Epoch[27](400/2500): Loss: 0.3023
===> Epoch[27](500/2500): Loss: 0.2866
===> Epoch[27](600/2500): Loss: 0.2834
===> Epoch[27](700/2500): Loss: 0.2825
===> Epoch[27](800/2500): Loss: 0.2902
===> Epoch[27](900/2500): Loss: 0.2850
===> Epoch[27](1000/2500): Loss: 0.3017
===> Epoch[27](1100/2500): Loss: 0.2701
===> Epoch[27](1200/2500): Loss: 0.2738
===> Epoch[27](1300/2500): Loss: 0.2756
===> Epoch[27](1400/2500): Loss: 0.2778
===> Epoch[27](1500/2500): Loss: 0.3026
===> Epoch[27](1600/2500): Loss: 0.2768
===> Epoch[27](1700/2500): Loss: 0.2830
===> Epoch[27](1800/2500): Loss: 0.2921
===> Epoch[27](1900/2500): Loss: 0.2767
===> Epoch[27](2000/2500): Loss: 0.2690
===> Epoch[27](2100/2500): Loss: 0.2966
===> Epoch[27](2200/2500): Loss: 0.2848
===> Epoch[27](2300/2500): Loss: 0.2817
===> Epoch[27](2400/2500): Loss: 0.3092
===> Epoch[27](2500/2500): Loss: 0.2851
===> Epoch 27 Complete: Avg. Loss: 0.2885
===> Timestamp: [2025-08-03 21:34:31]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2941
===> Epoch[27](200/2500): Loss: 0.2860
===> Epoch[27](300/2500): Loss: 0.2823
===> Epoch[27](400/2500): Loss: 0.3023
===> Epoch[27](500/2500): Loss: 0.2866
===> Epoch[27](600/2500): Loss: 0.2834
===> Epoch[27](700/2500): Loss: 0.2825
===> Epoch[27](800/2500): Loss: 0.2902
===> Epoch[27](900/2500): Loss: 0.2850
===> Epoch[27](1000/2500): Loss: 0.3017
===> Epoch[27](1100/2500): Loss: 0.2701
===> Epoch[27](1200/2500): Loss: 0.2738
===> Epoch[27](1300/2500): Loss: 0.2756
===> Epoch[27](1400/2500): Loss: 0.2778
===> Epoch[27](1500/2500): Loss: 0.3026
===> Epoch[27](1600/2500): Loss: 0.2768
===> Epoch[27](1700/2500): Loss: 0.2830
===> Epoch[27](1800/2500): Loss: 0.2921
===> Epoch[27](1900/2500): Loss: 0.2767
===> Epoch[27](2000/2500): Loss: 0.2690
===> Epoch[27](2100/2500): Loss: 0.2966
===> Epoch[27](2200/2500): Loss: 0.2848
===> Epoch[27](2300/2500): Loss: 0.2817
===> Epoch[27](2400/2500): Loss: 0.3092
===> Epoch[27](2500/2500): Loss: 0.2851
===> Epoch 27 Complete: Avg. Loss: 0.2885
===> Timestamp: [2025-08-03 21:34:31]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2941
===> Epoch[27](200/2500): Loss: 0.2860
===> Epoch[27](300/2500): Loss: 0.2823
===> Epoch[27](400/2500): Loss: 0.3023
===> Epoch[27](500/2500): Loss: 0.2866
===> Epoch[27](600/2500): Loss: 0.2834
===> Epoch[27](700/2500): Loss: 0.2825
===> Epoch[27](800/2500): Loss: 0.2902
===> Epoch[27](900/2500): Loss: 0.2850
===> Epoch[27](1000/2500): Loss: 0.3017
===> Epoch[27](1100/2500): Loss: 0.2701
===> Epoch[27](1200/2500): Loss: 0.2738
===> Epoch[27](1300/2500): Loss: 0.2756
===> Epoch[27](1400/2500): Loss: 0.2778
===> Epoch[27](1500/2500): Loss: 0.3026
===> Epoch[27](1600/2500): Loss: 0.2768
===> Epoch[27](1700/2500): Loss: 0.2830
===> Epoch[27](1800/2500): Loss: 0.2921
===> Epoch[27](1900/2500): Loss: 0.2767
===> Epoch[27](2000/2500): Loss: 0.2690
===> Epoch[27](2100/2500): Loss: 0.2966
===> Epoch[27](2200/2500): Loss: 0.2848
===> Epoch[27](2300/2500): Loss: 0.2817
===> Epoch[27](2400/2500): Loss: 0.3092
===> Epoch[27](2500/2500): Loss: 0.2851
===> Epoch 27 Complete: Avg. Loss: 0.2885
===> Timestamp: [2025-08-03 21:34:31]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2941
===> Epoch[27](200/2500): Loss: 0.2860
===> Epoch[27](300/2500): Loss: 0.2823
===> Epoch[27](400/2500): Loss: 0.3023
===> Epoch[27](500/2500): Loss: 0.2866
===> Epoch[27](600/2500): Loss: 0.2834
===> Epoch[27](700/2500): Loss: 0.2825
===> Epoch[27](800/2500): Loss: 0.2902
===> Epoch[27](900/2500): Loss: 0.2850
===> Epoch[27](1000/2500): Loss: 0.3017
===> Epoch[27](1100/2500): Loss: 0.2701
===> Epoch[27](1200/2500): Loss: 0.2738
===> Epoch[27](1300/2500): Loss: 0.2756
===> Epoch[27](1400/2500): Loss: 0.2778
===> Epoch[27](1500/2500): Loss: 0.3026
===> Epoch[27](1600/2500): Loss: 0.2768
===> Epoch[27](1700/2500): Loss: 0.2830
===> Epoch[27](1800/2500): Loss: 0.2921
===> Epoch[27](1900/2500): Loss: 0.2767
===> Epoch[27](2000/2500): Loss: 0.2690
===> Epoch[27](2100/2500): Loss: 0.2966
===> Epoch[27](2200/2500): Loss: 0.2848
===> Epoch[27](2300/2500): Loss: 0.2817
===> Epoch[27](2400/2500): Loss: 0.3092
===> Epoch[27](2500/2500): Loss: 0.2851
===> Epoch 27 Complete: Avg. Loss: 0.2885
===> Timestamp: [2025-08-03 21:34:31]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2941
===> Epoch[27](200/2500): Loss: 0.2860
===> Epoch[27](300/2500): Loss: 0.2823
===> Epoch[27](400/2500): Loss: 0.3023
===> Epoch[27](500/2500): Loss: 0.2866
===> Epoch[27](600/2500): Loss: 0.2834
===> Epoch[27](700/2500): Loss: 0.2825
===> Epoch[27](800/2500): Loss: 0.2902
===> Epoch[27](900/2500): Loss: 0.2850
===> Epoch[27](1000/2500): Loss: 0.3017
===> Epoch[27](1100/2500): Loss: 0.2701
===> Epoch[27](1200/2500): Loss: 0.2738
===> Epoch[27](1300/2500): Loss: 0.2756
===> Epoch[27](1400/2500): Loss: 0.2778
===> Epoch[27](1500/2500): Loss: 0.3026
===> Epoch[27](1600/2500): Loss: 0.2768
===> Epoch[27](1700/2500): Loss: 0.2830
===> Epoch[27](1800/2500): Loss: 0.2921
===> Epoch[27](1900/2500): Loss: 0.2767
===> Epoch[27](2000/2500): Loss: 0.2690
===> Epoch[27](2100/2500): Loss: 0.2966
===> Epoch[27](2200/2500): Loss: 0.2848
===> Epoch[27](2300/2500): Loss: 0.2817
===> Epoch[27](2400/2500): Loss: 0.3092
===> Epoch[27](2500/2500): Loss: 0.2851
===> Epoch 27 Complete: Avg. Loss: 0.2885
===> Timestamp: [2025-08-03 21:34:31]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2941
===> Epoch[27](200/2500): Loss: 0.2860
===> Epoch[27](300/2500): Loss: 0.2823
===> Epoch[27](400/2500): Loss: 0.3023
===> Epoch[27](500/2500): Loss: 0.2866
===> Epoch[27](600/2500): Loss: 0.2834
===> Epoch[27](700/2500): Loss: 0.2825
===> Epoch[27](800/2500): Loss: 0.2902
===> Epoch[27](900/2500): Loss: 0.2850
===> Epoch[27](1000/2500): Loss: 0.3017
===> Epoch[27](1100/2500): Loss: 0.2701
===> Epoch[27](1200/2500): Loss: 0.2738
===> Epoch[27](1300/2500): Loss: 0.2756
===> Epoch[27](1400/2500): Loss: 0.2778
===> Epoch[27](1500/2500): Loss: 0.3026
===> Epoch[27](1600/2500): Loss: 0.2768
===> Epoch[27](1700/2500): Loss: 0.2830
===> Epoch[27](1800/2500): Loss: 0.2921
===> Epoch[27](1900/2500): Loss: 0.2767
===> Epoch[27](2000/2500): Loss: 0.2690
===> Epoch[27](2100/2500): Loss: 0.2966
===> Epoch[27](2200/2500): Loss: 0.2848
===> Epoch[27](2300/2500): Loss: 0.2817
===> Epoch[27](2400/2500): Loss: 0.3092
===> Epoch[27](2500/2500): Loss: 0.2851
===> Epoch 27 Complete: Avg. Loss: 0.2885
===> Timestamp: [2025-08-03 21:34:31]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2941
===> Epoch[27](200/2500): Loss: 0.2860
===> Epoch[27](300/2500): Loss: 0.2823
===> Epoch[27](400/2500): Loss: 0.3023
===> Epoch[27](500/2500): Loss: 0.2866
===> Epoch[27](600/2500): Loss: 0.2834
===> Epoch[27](700/2500): Loss: 0.2825
===> Epoch[27](800/2500): Loss: 0.2902
===> Epoch[27](900/2500): Loss: 0.2850
===> Epoch[27](1000/2500): Loss: 0.3017
===> Epoch[27](1100/2500): Loss: 0.2701
===> Epoch[27](1200/2500): Loss: 0.2738
===> Epoch[27](1300/2500): Loss: 0.2756
===> Epoch[27](1400/2500): Loss: 0.2778
===> Epoch[27](1500/2500): Loss: 0.3026
===> Epoch[27](1600/2500): Loss: 0.2768
===> Epoch[27](1700/2500): Loss: 0.2830
===> Epoch[27](1800/2500): Loss: 0.2921
===> Epoch[27](1900/2500): Loss: 0.2767
===> Epoch[27](2000/2500): Loss: 0.2690
===> Epoch[27](2100/2500): Loss: 0.2966
===> Epoch[27](2200/2500): Loss: 0.2848
===> Epoch[27](2300/2500): Loss: 0.2817
===> Epoch[27](2400/2500): Loss: 0.3092
===> Epoch[27](2500/2500): Loss: 0.2851
===> Epoch 27 Complete: Avg. Loss: 0.2885
===> Timestamp: [2025-08-03 21:34:31]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2941
===> Epoch[27](200/2500): Loss: 0.2860
===> Epoch[27](300/2500): Loss: 0.2823
===> Epoch[27](400/2500): Loss: 0.3023
===> Epoch[27](500/2500): Loss: 0.2866
===> Epoch[27](600/2500): Loss: 0.2834
===> Epoch[27](700/2500): Loss: 0.2825
===> Epoch[27](800/2500): Loss: 0.2902
===> Epoch[27](900/2500): Loss: 0.2850
===> Epoch[27](1000/2500): Loss: 0.3017
===> Epoch[27](1100/2500): Loss: 0.2701
===> Epoch[27](1200/2500): Loss: 0.2738
===> Epoch[27](1300/2500): Loss: 0.2756
===> Epoch[27](1400/2500): Loss: 0.2778
===> Epoch[27](1500/2500): Loss: 0.3026
===> Epoch[27](1600/2500): Loss: 0.2768
===> Epoch[27](1700/2500): Loss: 0.2830
===> Epoch[27](1800/2500): Loss: 0.2921
===> Epoch[27](1900/2500): Loss: 0.2767
===> Epoch[27](2000/2500): Loss: 0.2690
===> Epoch[27](2100/2500): Loss: 0.2966
===> Epoch[27](2200/2500): Loss: 0.2848
===> Epoch[27](2300/2500): Loss: 0.2817
===> Epoch[27](2400/2500): Loss: 0.3092
===> Epoch[27](2500/2500): Loss: 0.2851
===> Epoch 27 Complete: Avg. Loss: 0.2885
===> Timestamp: [2025-08-03 21:34:31]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2941
===> Epoch[27](200/2500): Loss: 0.2860
===> Epoch[27](300/2500): Loss: 0.2823
===> Epoch[27](400/2500): Loss: 0.3023
===> Epoch[27](500/2500): Loss: 0.2866
===> Epoch[27](600/2500): Loss: 0.2834
===> Epoch[27](700/2500): Loss: 0.2825
===> Epoch[27](800/2500): Loss: 0.2902
===> Epoch[27](900/2500): Loss: 0.2850
===> Epoch[27](1000/2500): Loss: 0.3017
===> Epoch[27](1100/2500): Loss: 0.2701
===> Epoch[27](1200/2500): Loss: 0.2738
===> Epoch[27](1300/2500): Loss: 0.2756
===> Epoch[27](1400/2500): Loss: 0.2778
===> Epoch[27](1500/2500): Loss: 0.3026
===> Epoch[27](1600/2500): Loss: 0.2768
===> Epoch[27](1700/2500): Loss: 0.2830
===> Epoch[27](1800/2500): Loss: 0.2921
===> Epoch[27](1900/2500): Loss: 0.2767
===> Epoch[27](2000/2500): Loss: 0.2690
===> Epoch[27](2100/2500): Loss: 0.2966
===> Epoch[27](2200/2500): Loss: 0.2848
===> Epoch[27](2300/2500): Loss: 0.2817
===> Epoch[27](2400/2500): Loss: 0.3092
===> Epoch[27](2500/2500): Loss: 0.2851
===> Epoch 27 Complete: Avg. Loss: 0.2885
===> Timestamp: [2025-08-03 21:34:31]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2941
===> Epoch[27](200/2500): Loss: 0.2860
===> Epoch[27](300/2500): Loss: 0.2823
===> Epoch[27](400/2500): Loss: 0.3023
===> Epoch[27](500/2500): Loss: 0.2866
===> Epoch[27](600/2500): Loss: 0.2834
===> Epoch[27](700/2500): Loss: 0.2825
===> Epoch[27](800/2500): Loss: 0.2902
===> Epoch[27](900/2500): Loss: 0.2850
===> Epoch[27](1000/2500): Loss: 0.3017
===> Epoch[27](1100/2500): Loss: 0.2701
===> Epoch[27](1200/2500): Loss: 0.2738
===> Epoch[27](1300/2500): Loss: 0.2756
===> Epoch[27](1400/2500): Loss: 0.2778
===> Epoch[27](1500/2500): Loss: 0.3026
===> Epoch[27](1600/2500): Loss: 0.2768
===> Epoch[27](1700/2500): Loss: 0.2830
===> Epoch[27](1800/2500): Loss: 0.2921
===> Epoch[27](1900/2500): Loss: 0.2767
===> Epoch[27](2000/2500): Loss: 0.2690
===> Epoch[27](2100/2500): Loss: 0.2966
===> Epoch[27](2200/2500): Loss: 0.2848
===> Epoch[27](2300/2500): Loss: 0.2817
===> Epoch[27](2400/2500): Loss: 0.3092
===> Epoch[27](2500/2500): Loss: 0.2851
===> Epoch 27 Complete: Avg. Loss: 0.2885
===> Timestamp: [2025-08-03 21:34:31]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2941
===> Epoch[27](200/2500): Loss: 0.2860
===> Epoch[27](300/2500): Loss: 0.2823
===> Epoch[27](400/2500): Loss: 0.3023
===> Epoch[27](500/2500): Loss: 0.2866
===> Epoch[27](600/2500): Loss: 0.2834
===> Epoch[27](700/2500): Loss: 0.2825
===> Epoch[27](800/2500): Loss: 0.2902
===> Epoch[27](900/2500): Loss: 0.2850
===> Epoch[27](1000/2500): Loss: 0.3017
===> Epoch[27](1100/2500): Loss: 0.2701
===> Epoch[27](1200/2500): Loss: 0.2738
===> Epoch[27](1300/2500): Loss: 0.2756
===> Epoch[27](1400/2500): Loss: 0.2778
===> Epoch[27](1500/2500): Loss: 0.3026
===> Epoch[27](1600/2500): Loss: 0.2768
===> Epoch[27](1700/2500): Loss: 0.2830
===> Epoch[27](1800/2500): Loss: 0.2921
===> Epoch[27](1900/2500): Loss: 0.2767
===> Epoch[27](2000/2500): Loss: 0.2690
===> Epoch[27](2100/2500): Loss: 0.2966
===> Epoch[27](2200/2500): Loss: 0.2848
===> Epoch[27](2300/2500): Loss: 0.2817
===> Epoch[27](2400/2500): Loss: 0.3092
===> Epoch[27](2500/2500): Loss: 0.2851
===> Epoch 27 Complete: Avg. Loss: 0.2885
===> Timestamp: [2025-08-03 21:34:31]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2941
===> Epoch[27](200/2500): Loss: 0.2860
===> Epoch[27](300/2500): Loss: 0.2823
===> Epoch[27](400/2500): Loss: 0.3023
===> Epoch[27](500/2500): Loss: 0.2866
===> Epoch[27](600/2500): Loss: 0.2834
===> Epoch[27](700/2500): Loss: 0.2825
===> Epoch[27](800/2500): Loss: 0.2902
===> Epoch[27](900/2500): Loss: 0.2850
===> Epoch[27](1000/2500): Loss: 0.3017
===> Epoch[27](1100/2500): Loss: 0.2701
===> Epoch[27](1200/2500): Loss: 0.2738
===> Epoch[27](1300/2500): Loss: 0.2756
===> Epoch[27](1400/2500): Loss: 0.2778
===> Epoch[27](1500/2500): Loss: 0.3026
===> Epoch[27](1600/2500): Loss: 0.2768
===> Epoch[27](1700/2500): Loss: 0.2830
===> Epoch[27](1800/2500): Loss: 0.2921
===> Epoch[27](1900/2500): Loss: 0.2767
===> Epoch[27](2000/2500): Loss: 0.2690
===> Epoch[27](2100/2500): Loss: 0.2966
===> Epoch[27](2200/2500): Loss: 0.2848
===> Epoch[27](2300/2500): Loss: 0.2817
===> Epoch[27](2400/2500): Loss: 0.3092
===> Epoch[27](2500/2500): Loss: 0.2851
===> Epoch 27 Complete: Avg. Loss: 0.2885
===> Timestamp: [2025-08-03 21:34:31]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2941
===> Epoch[27](200/2500): Loss: 0.2860
===> Epoch[27](300/2500): Loss: 0.2823
===> Epoch[27](400/2500): Loss: 0.3023
===> Epoch[27](500/2500): Loss: 0.2866
===> Epoch[27](600/2500): Loss: 0.2834
===> Epoch[27](700/2500): Loss: 0.2825
===> Epoch[27](800/2500): Loss: 0.2902
===> Epoch[27](900/2500): Loss: 0.2850
===> Epoch[27](1000/2500): Loss: 0.3017
===> Epoch[27](1100/2500): Loss: 0.2701
===> Epoch[27](1200/2500): Loss: 0.2738
===> Epoch[27](1300/2500): Loss: 0.2756
===> Epoch[27](1400/2500): Loss: 0.2778
===> Epoch[27](1500/2500): Loss: 0.3026
===> Epoch[27](1600/2500): Loss: 0.2768
===> Epoch[27](1700/2500): Loss: 0.2830
===> Epoch[27](1800/2500): Loss: 0.2921
===> Epoch[27](1900/2500): Loss: 0.2767
===> Epoch[27](2000/2500): Loss: 0.2690
===> Epoch[27](2100/2500): Loss: 0.2966
===> Epoch[27](2200/2500): Loss: 0.2848
===> Epoch[27](2300/2500): Loss: 0.2817
===> Epoch[27](2400/2500): Loss: 0.3092
===> Epoch[27](2500/2500): Loss: 0.2851
===> Epoch 27 Complete: Avg. Loss: 0.2885
===> Timestamp: [2025-08-03 21:34:31]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2941
===> Epoch[27](200/2500): Loss: 0.2860
===> Epoch[27](300/2500): Loss: 0.2823
===> Epoch[27](400/2500): Loss: 0.3023
===> Epoch[27](500/2500): Loss: 0.2866
===> Epoch[27](600/2500): Loss: 0.2834
===> Epoch[27](700/2500): Loss: 0.2825
===> Epoch[27](800/2500): Loss: 0.2902
===> Epoch[27](900/2500): Loss: 0.2850
===> Epoch[27](1000/2500): Loss: 0.3017
===> Epoch[27](1100/2500): Loss: 0.2701
===> Epoch[27](1200/2500): Loss: 0.2738
===> Epoch[27](1300/2500): Loss: 0.2756
===> Epoch[27](1400/2500): Loss: 0.2778
===> Epoch[27](1500/2500): Loss: 0.3026
===> Epoch[27](1600/2500): Loss: 0.2768
===> Epoch[27](1700/2500): Loss: 0.2830
===> Epoch[27](1800/2500): Loss: 0.2921
===> Epoch[27](1900/2500): Loss: 0.2767
===> Epoch[27](2000/2500): Loss: 0.2690
===> Epoch[27](2100/2500): Loss: 0.2966
===> Epoch[27](2200/2500): Loss: 0.2848
===> Epoch[27](2300/2500): Loss: 0.2817
===> Epoch[27](2400/2500): Loss: 0.3092
===> Epoch[27](2500/2500): Loss: 0.2851
===> Epoch 27 Complete: Avg. Loss: 0.2885
===> Timestamp: [2025-08-03 21:34:31]
===> Loading train datasets
===> Epoch[27](100/2500): Loss: 0.2941
===> Epoch[27](200/2500): Loss: 0.2860
===> Epoch[27](300/2500): Loss: 0.2823
===> Epoch[27](400/2500): Loss: 0.3023
===> Epoch[27](500/2500): Loss: 0.2866
===> Epoch[27](600/2500): Loss: 0.2834
===> Epoch[27](700/2500): Loss: 0.2825
===> Epoch[27](800/2500): Loss: 0.2902
===> Epoch[27](900/2500): Loss: 0.2850
===> Epoch[27](1000/2500): Loss: 0.3017
===> Epoch[27](1100/2500): Loss: 0.2701
===> Epoch[27](1200/2500): Loss: 0.2738
===> Epoch[27](1300/2500): Loss: 0.2756
===> Epoch[27](1400/2500): Loss: 0.2778
===> Epoch[27](1500/2500): Loss: 0.3026
===> Epoch[27](1600/2500): Loss: 0.2768
===> Epoch[27](1700/2500): Loss: 0.2830
===> Epoch[27](1800/2500): Loss: 0.2921
===> Epoch[27](1900/2500): Loss: 0.2767
===> Epoch[27](2000/2500): Loss: 0.2690
===> Epoch[27](2100/2500): Loss: 0.2966
===> Epoch[27](2200/2500): Loss: 0.2848
===> Epoch[27](2300/2500): Loss: 0.2817
===> Epoch[27](2400/2500): Loss: 0.3092
===> Epoch[27](2500/2500): Loss: 0.2851
===> Epoch 27 Complete: Avg. Loss: 0.2885
===> Timestamp: [2025-08-03 21:34:31]
===> Loading train datasets
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.3124
===> Epoch[28](200/2500): Loss: 0.2792
===> Epoch[28](300/2500): Loss: 0.3023
===> Epoch[28](400/2500): Loss: 0.2901
===> Epoch[28](500/2500): Loss: 0.2766
===> Epoch[28](600/2500): Loss: 0.2938
===> Epoch[28](700/2500): Loss: 0.3015
===> Epoch[28](800/2500): Loss: 0.2867
===> Epoch[28](900/2500): Loss: 0.2902
===> Epoch[28](1000/2500): Loss: 0.2701
===> Epoch[28](1100/2500): Loss: 0.2973
===> Epoch[28](1200/2500): Loss: 0.2575
===> Epoch[28](1300/2500): Loss: 0.3000
===> Epoch[28](1400/2500): Loss: 0.2869
===> Epoch[28](1500/2500): Loss: 0.2729
===> Epoch[28](1600/2500): Loss: 0.2737
===> Epoch[28](1700/2500): Loss: 0.2886
===> Epoch[28](1800/2500): Loss: 0.3086
===> Epoch[28](1900/2500): Loss: 0.2941
===> Epoch[28](2000/2500): Loss: 0.2765
===> Epoch[28](2100/2500): Loss: 0.2702
===> Epoch[28](2200/2500): Loss: 0.2813
===> Epoch[28](2300/2500): Loss: 0.2728
===> Epoch[28](2400/2500): Loss: 0.2681
===> Epoch[28](2500/2500): Loss: 0.2800
===> Epoch 28 Complete: Avg. Loss: 0.2880
===> Timestamp: [2025-08-03 21:39:05]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.3124
===> Epoch[28](200/2500): Loss: 0.2792
===> Epoch[28](300/2500): Loss: 0.3023
===> Epoch[28](400/2500): Loss: 0.2901
===> Epoch[28](500/2500): Loss: 0.2766
===> Epoch[28](600/2500): Loss: 0.2938
===> Epoch[28](700/2500): Loss: 0.3015
===> Epoch[28](800/2500): Loss: 0.2867
===> Epoch[28](900/2500): Loss: 0.2902
===> Epoch[28](1000/2500): Loss: 0.2701
===> Epoch[28](1100/2500): Loss: 0.2973
===> Epoch[28](1200/2500): Loss: 0.2575
===> Epoch[28](1300/2500): Loss: 0.3000
===> Epoch[28](1400/2500): Loss: 0.2869
===> Epoch[28](1500/2500): Loss: 0.2729
===> Epoch[28](1600/2500): Loss: 0.2737
===> Epoch[28](1700/2500): Loss: 0.2886
===> Epoch[28](1800/2500): Loss: 0.3086
===> Epoch[28](1900/2500): Loss: 0.2941
===> Epoch[28](2000/2500): Loss: 0.2765
===> Epoch[28](2100/2500): Loss: 0.2702
===> Epoch[28](2200/2500): Loss: 0.2813
===> Epoch[28](2300/2500): Loss: 0.2728
===> Epoch[28](2400/2500): Loss: 0.2681
===> Epoch[28](2500/2500): Loss: 0.2800
===> Epoch 28 Complete: Avg. Loss: 0.2880
===> Timestamp: [2025-08-03 21:39:05]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.3124
===> Epoch[28](200/2500): Loss: 0.2792
===> Epoch[28](300/2500): Loss: 0.3023
===> Epoch[28](400/2500): Loss: 0.2901
===> Epoch[28](500/2500): Loss: 0.2766
===> Epoch[28](600/2500): Loss: 0.2938
===> Epoch[28](700/2500): Loss: 0.3015
===> Epoch[28](800/2500): Loss: 0.2867
===> Epoch[28](900/2500): Loss: 0.2902
===> Epoch[28](1000/2500): Loss: 0.2701
===> Epoch[28](1100/2500): Loss: 0.2973
===> Epoch[28](1200/2500): Loss: 0.2575
===> Epoch[28](1300/2500): Loss: 0.3000
===> Epoch[28](1400/2500): Loss: 0.2869
===> Epoch[28](1500/2500): Loss: 0.2729
===> Epoch[28](1600/2500): Loss: 0.2737
===> Epoch[28](1700/2500): Loss: 0.2886
===> Epoch[28](1800/2500): Loss: 0.3086
===> Epoch[28](1900/2500): Loss: 0.2941
===> Epoch[28](2000/2500): Loss: 0.2765
===> Epoch[28](2100/2500): Loss: 0.2702
===> Epoch[28](2200/2500): Loss: 0.2813
===> Epoch[28](2300/2500): Loss: 0.2728
===> Epoch[28](2400/2500): Loss: 0.2681
===> Epoch[28](2500/2500): Loss: 0.2800
===> Epoch 28 Complete: Avg. Loss: 0.2880
===> Timestamp: [2025-08-03 21:39:05]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.3124
===> Epoch[28](200/2500): Loss: 0.2792
===> Epoch[28](300/2500): Loss: 0.3023
===> Epoch[28](400/2500): Loss: 0.2901
===> Epoch[28](500/2500): Loss: 0.2766
===> Epoch[28](600/2500): Loss: 0.2938
===> Epoch[28](700/2500): Loss: 0.3015
===> Epoch[28](800/2500): Loss: 0.2867
===> Epoch[28](900/2500): Loss: 0.2902
===> Epoch[28](1000/2500): Loss: 0.2701
===> Epoch[28](1100/2500): Loss: 0.2973
===> Epoch[28](1200/2500): Loss: 0.2575
===> Epoch[28](1300/2500): Loss: 0.3000
===> Epoch[28](1400/2500): Loss: 0.2869
===> Epoch[28](1500/2500): Loss: 0.2729
===> Epoch[28](1600/2500): Loss: 0.2737
===> Epoch[28](1700/2500): Loss: 0.2886
===> Epoch[28](1800/2500): Loss: 0.3086
===> Epoch[28](1900/2500): Loss: 0.2941
===> Epoch[28](2000/2500): Loss: 0.2765
===> Epoch[28](2100/2500): Loss: 0.2702
===> Epoch[28](2200/2500): Loss: 0.2813
===> Epoch[28](2300/2500): Loss: 0.2728
===> Epoch[28](2400/2500): Loss: 0.2681
===> Epoch[28](2500/2500): Loss: 0.2800
===> Epoch 28 Complete: Avg. Loss: 0.2880
===> Timestamp: [2025-08-03 21:39:05]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.3124
===> Epoch[28](200/2500): Loss: 0.2792
===> Epoch[28](300/2500): Loss: 0.3023
===> Epoch[28](400/2500): Loss: 0.2901
===> Epoch[28](500/2500): Loss: 0.2766
===> Epoch[28](600/2500): Loss: 0.2938
===> Epoch[28](700/2500): Loss: 0.3015
===> Epoch[28](800/2500): Loss: 0.2867
===> Epoch[28](900/2500): Loss: 0.2902
===> Epoch[28](1000/2500): Loss: 0.2701
===> Epoch[28](1100/2500): Loss: 0.2973
===> Epoch[28](1200/2500): Loss: 0.2575
===> Epoch[28](1300/2500): Loss: 0.3000
===> Epoch[28](1400/2500): Loss: 0.2869
===> Epoch[28](1500/2500): Loss: 0.2729
===> Epoch[28](1600/2500): Loss: 0.2737
===> Epoch[28](1700/2500): Loss: 0.2886
===> Epoch[28](1800/2500): Loss: 0.3086
===> Epoch[28](1900/2500): Loss: 0.2941
===> Epoch[28](2000/2500): Loss: 0.2765
===> Epoch[28](2100/2500): Loss: 0.2702
===> Epoch[28](2200/2500): Loss: 0.2813
===> Epoch[28](2300/2500): Loss: 0.2728
===> Epoch[28](2400/2500): Loss: 0.2681
===> Epoch[28](2500/2500): Loss: 0.2800
===> Epoch 28 Complete: Avg. Loss: 0.2880
===> Timestamp: [2025-08-03 21:39:05]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.3124
===> Epoch[28](200/2500): Loss: 0.2792
===> Epoch[28](300/2500): Loss: 0.3023
===> Epoch[28](400/2500): Loss: 0.2901
===> Epoch[28](500/2500): Loss: 0.2766
===> Epoch[28](600/2500): Loss: 0.2938
===> Epoch[28](700/2500): Loss: 0.3015
===> Epoch[28](800/2500): Loss: 0.2867
===> Epoch[28](900/2500): Loss: 0.2902
===> Epoch[28](1000/2500): Loss: 0.2701
===> Epoch[28](1100/2500): Loss: 0.2973
===> Epoch[28](1200/2500): Loss: 0.2575
===> Epoch[28](1300/2500): Loss: 0.3000
===> Epoch[28](1400/2500): Loss: 0.2869
===> Epoch[28](1500/2500): Loss: 0.2729
===> Epoch[28](1600/2500): Loss: 0.2737
===> Epoch[28](1700/2500): Loss: 0.2886
===> Epoch[28](1800/2500): Loss: 0.3086
===> Epoch[28](1900/2500): Loss: 0.2941
===> Epoch[28](2000/2500): Loss: 0.2765
===> Epoch[28](2100/2500): Loss: 0.2702
===> Epoch[28](2200/2500): Loss: 0.2813
===> Epoch[28](2300/2500): Loss: 0.2728
===> Epoch[28](2400/2500): Loss: 0.2681
===> Epoch[28](2500/2500): Loss: 0.2800
===> Epoch 28 Complete: Avg. Loss: 0.2880
===> Timestamp: [2025-08-03 21:39:05]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.3124
===> Epoch[28](200/2500): Loss: 0.2792
===> Epoch[28](300/2500): Loss: 0.3023
===> Epoch[28](400/2500): Loss: 0.2901
===> Epoch[28](500/2500): Loss: 0.2766
===> Epoch[28](600/2500): Loss: 0.2938
===> Epoch[28](700/2500): Loss: 0.3015
===> Epoch[28](800/2500): Loss: 0.2867
===> Epoch[28](900/2500): Loss: 0.2902
===> Epoch[28](1000/2500): Loss: 0.2701
===> Epoch[28](1100/2500): Loss: 0.2973
===> Epoch[28](1200/2500): Loss: 0.2575
===> Epoch[28](1300/2500): Loss: 0.3000
===> Epoch[28](1400/2500): Loss: 0.2869
===> Epoch[28](1500/2500): Loss: 0.2729
===> Epoch[28](1600/2500): Loss: 0.2737
===> Epoch[28](1700/2500): Loss: 0.2886
===> Epoch[28](1800/2500): Loss: 0.3086
===> Epoch[28](1900/2500): Loss: 0.2941
===> Epoch[28](2000/2500): Loss: 0.2765
===> Epoch[28](2100/2500): Loss: 0.2702
===> Epoch[28](2200/2500): Loss: 0.2813
===> Epoch[28](2300/2500): Loss: 0.2728
===> Epoch[28](2400/2500): Loss: 0.2681
===> Epoch[28](2500/2500): Loss: 0.2800
===> Epoch 28 Complete: Avg. Loss: 0.2880
===> Timestamp: [2025-08-03 21:39:05]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.3124
===> Epoch[28](200/2500): Loss: 0.2792
===> Epoch[28](300/2500): Loss: 0.3023
===> Epoch[28](400/2500): Loss: 0.2901
===> Epoch[28](500/2500): Loss: 0.2766
===> Epoch[28](600/2500): Loss: 0.2938
===> Epoch[28](700/2500): Loss: 0.3015
===> Epoch[28](800/2500): Loss: 0.2867
===> Epoch[28](900/2500): Loss: 0.2902
===> Epoch[28](1000/2500): Loss: 0.2701
===> Epoch[28](1100/2500): Loss: 0.2973
===> Epoch[28](1200/2500): Loss: 0.2575
===> Epoch[28](1300/2500): Loss: 0.3000
===> Epoch[28](1400/2500): Loss: 0.2869
===> Epoch[28](1500/2500): Loss: 0.2729
===> Epoch[28](1600/2500): Loss: 0.2737
===> Epoch[28](1700/2500): Loss: 0.2886
===> Epoch[28](1800/2500): Loss: 0.3086
===> Epoch[28](1900/2500): Loss: 0.2941
===> Epoch[28](2000/2500): Loss: 0.2765
===> Epoch[28](2100/2500): Loss: 0.2702
===> Epoch[28](2200/2500): Loss: 0.2813
===> Epoch[28](2300/2500): Loss: 0.2728
===> Epoch[28](2400/2500): Loss: 0.2681
===> Epoch[28](2500/2500): Loss: 0.2800
===> Epoch 28 Complete: Avg. Loss: 0.2880
===> Timestamp: [2025-08-03 21:39:05]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.3124
===> Epoch[28](200/2500): Loss: 0.2792
===> Epoch[28](300/2500): Loss: 0.3023
===> Epoch[28](400/2500): Loss: 0.2901
===> Epoch[28](500/2500): Loss: 0.2766
===> Epoch[28](600/2500): Loss: 0.2938
===> Epoch[28](700/2500): Loss: 0.3015
===> Epoch[28](800/2500): Loss: 0.2867
===> Epoch[28](900/2500): Loss: 0.2902
===> Epoch[28](1000/2500): Loss: 0.2701
===> Epoch[28](1100/2500): Loss: 0.2973
===> Epoch[28](1200/2500): Loss: 0.2575
===> Epoch[28](1300/2500): Loss: 0.3000
===> Epoch[28](1400/2500): Loss: 0.2869
===> Epoch[28](1500/2500): Loss: 0.2729
===> Epoch[28](1600/2500): Loss: 0.2737
===> Epoch[28](1700/2500): Loss: 0.2886
===> Epoch[28](1800/2500): Loss: 0.3086
===> Epoch[28](1900/2500): Loss: 0.2941
===> Epoch[28](2000/2500): Loss: 0.2765
===> Epoch[28](2100/2500): Loss: 0.2702
===> Epoch[28](2200/2500): Loss: 0.2813
===> Epoch[28](2300/2500): Loss: 0.2728
===> Epoch[28](2400/2500): Loss: 0.2681
===> Epoch[28](2500/2500): Loss: 0.2800
===> Epoch 28 Complete: Avg. Loss: 0.2880
===> Timestamp: [2025-08-03 21:39:05]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.3124
===> Epoch[28](200/2500): Loss: 0.2792
===> Epoch[28](300/2500): Loss: 0.3023
===> Epoch[28](400/2500): Loss: 0.2901
===> Epoch[28](500/2500): Loss: 0.2766
===> Epoch[28](600/2500): Loss: 0.2938
===> Epoch[28](700/2500): Loss: 0.3015
===> Epoch[28](800/2500): Loss: 0.2867
===> Epoch[28](900/2500): Loss: 0.2902
===> Epoch[28](1000/2500): Loss: 0.2701
===> Epoch[28](1100/2500): Loss: 0.2973
===> Epoch[28](1200/2500): Loss: 0.2575
===> Epoch[28](1300/2500): Loss: 0.3000
===> Epoch[28](1400/2500): Loss: 0.2869
===> Epoch[28](1500/2500): Loss: 0.2729
===> Epoch[28](1600/2500): Loss: 0.2737
===> Epoch[28](1700/2500): Loss: 0.2886
===> Epoch[28](1800/2500): Loss: 0.3086
===> Epoch[28](1900/2500): Loss: 0.2941
===> Epoch[28](2000/2500): Loss: 0.2765
===> Epoch[28](2100/2500): Loss: 0.2702
===> Epoch[28](2200/2500): Loss: 0.2813
===> Epoch[28](2300/2500): Loss: 0.2728
===> Epoch[28](2400/2500): Loss: 0.2681
===> Epoch[28](2500/2500): Loss: 0.2800
===> Epoch 28 Complete: Avg. Loss: 0.2880
===> Timestamp: [2025-08-03 21:39:05]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.3124
===> Epoch[28](200/2500): Loss: 0.2792
===> Epoch[28](300/2500): Loss: 0.3023
===> Epoch[28](400/2500): Loss: 0.2901
===> Epoch[28](500/2500): Loss: 0.2766
===> Epoch[28](600/2500): Loss: 0.2938
===> Epoch[28](700/2500): Loss: 0.3015
===> Epoch[28](800/2500): Loss: 0.2867
===> Epoch[28](900/2500): Loss: 0.2902
===> Epoch[28](1000/2500): Loss: 0.2701
===> Epoch[28](1100/2500): Loss: 0.2973
===> Epoch[28](1200/2500): Loss: 0.2575
===> Epoch[28](1300/2500): Loss: 0.3000
===> Epoch[28](1400/2500): Loss: 0.2869
===> Epoch[28](1500/2500): Loss: 0.2729
===> Epoch[28](1600/2500): Loss: 0.2737
===> Epoch[28](1700/2500): Loss: 0.2886
===> Epoch[28](1800/2500): Loss: 0.3086
===> Epoch[28](1900/2500): Loss: 0.2941
===> Epoch[28](2000/2500): Loss: 0.2765
===> Epoch[28](2100/2500): Loss: 0.2702
===> Epoch[28](2200/2500): Loss: 0.2813
===> Epoch[28](2300/2500): Loss: 0.2728
===> Epoch[28](2400/2500): Loss: 0.2681
===> Epoch[28](2500/2500): Loss: 0.2800
===> Epoch 28 Complete: Avg. Loss: 0.2880
===> Timestamp: [2025-08-03 21:39:05]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.3124
===> Epoch[28](200/2500): Loss: 0.2792
===> Epoch[28](300/2500): Loss: 0.3023
===> Epoch[28](400/2500): Loss: 0.2901
===> Epoch[28](500/2500): Loss: 0.2766
===> Epoch[28](600/2500): Loss: 0.2938
===> Epoch[28](700/2500): Loss: 0.3015
===> Epoch[28](800/2500): Loss: 0.2867
===> Epoch[28](900/2500): Loss: 0.2902
===> Epoch[28](1000/2500): Loss: 0.2701
===> Epoch[28](1100/2500): Loss: 0.2973
===> Epoch[28](1200/2500): Loss: 0.2575
===> Epoch[28](1300/2500): Loss: 0.3000
===> Epoch[28](1400/2500): Loss: 0.2869
===> Epoch[28](1500/2500): Loss: 0.2729
===> Epoch[28](1600/2500): Loss: 0.2737
===> Epoch[28](1700/2500): Loss: 0.2886
===> Epoch[28](1800/2500): Loss: 0.3086
===> Epoch[28](1900/2500): Loss: 0.2941
===> Epoch[28](2000/2500): Loss: 0.2765
===> Epoch[28](2100/2500): Loss: 0.2702
===> Epoch[28](2200/2500): Loss: 0.2813
===> Epoch[28](2300/2500): Loss: 0.2728
===> Epoch[28](2400/2500): Loss: 0.2681
===> Epoch[28](2500/2500): Loss: 0.2800
===> Epoch 28 Complete: Avg. Loss: 0.2880
===> Timestamp: [2025-08-03 21:39:05]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.3124
===> Epoch[28](200/2500): Loss: 0.2792
===> Epoch[28](300/2500): Loss: 0.3023
===> Epoch[28](400/2500): Loss: 0.2901
===> Epoch[28](500/2500): Loss: 0.2766
===> Epoch[28](600/2500): Loss: 0.2938
===> Epoch[28](700/2500): Loss: 0.3015
===> Epoch[28](800/2500): Loss: 0.2867
===> Epoch[28](900/2500): Loss: 0.2902
===> Epoch[28](1000/2500): Loss: 0.2701
===> Epoch[28](1100/2500): Loss: 0.2973
===> Epoch[28](1200/2500): Loss: 0.2575
===> Epoch[28](1300/2500): Loss: 0.3000
===> Epoch[28](1400/2500): Loss: 0.2869
===> Epoch[28](1500/2500): Loss: 0.2729
===> Epoch[28](1600/2500): Loss: 0.2737
===> Epoch[28](1700/2500): Loss: 0.2886
===> Epoch[28](1800/2500): Loss: 0.3086
===> Epoch[28](1900/2500): Loss: 0.2941
===> Epoch[28](2000/2500): Loss: 0.2765
===> Epoch[28](2100/2500): Loss: 0.2702
===> Epoch[28](2200/2500): Loss: 0.2813
===> Epoch[28](2300/2500): Loss: 0.2728
===> Epoch[28](2400/2500): Loss: 0.2681
===> Epoch[28](2500/2500): Loss: 0.2800
===> Epoch 28 Complete: Avg. Loss: 0.2880
===> Timestamp: [2025-08-03 21:39:05]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.3124
===> Epoch[28](200/2500): Loss: 0.2792
===> Epoch[28](300/2500): Loss: 0.3023
===> Epoch[28](400/2500): Loss: 0.2901
===> Epoch[28](500/2500): Loss: 0.2766
===> Epoch[28](600/2500): Loss: 0.2938
===> Epoch[28](700/2500): Loss: 0.3015
===> Epoch[28](800/2500): Loss: 0.2867
===> Epoch[28](900/2500): Loss: 0.2902
===> Epoch[28](1000/2500): Loss: 0.2701
===> Epoch[28](1100/2500): Loss: 0.2973
===> Epoch[28](1200/2500): Loss: 0.2575
===> Epoch[28](1300/2500): Loss: 0.3000
===> Epoch[28](1400/2500): Loss: 0.2869
===> Epoch[28](1500/2500): Loss: 0.2729
===> Epoch[28](1600/2500): Loss: 0.2737
===> Epoch[28](1700/2500): Loss: 0.2886
===> Epoch[28](1800/2500): Loss: 0.3086
===> Epoch[28](1900/2500): Loss: 0.2941
===> Epoch[28](2000/2500): Loss: 0.2765
===> Epoch[28](2100/2500): Loss: 0.2702
===> Epoch[28](2200/2500): Loss: 0.2813
===> Epoch[28](2300/2500): Loss: 0.2728
===> Epoch[28](2400/2500): Loss: 0.2681
===> Epoch[28](2500/2500): Loss: 0.2800
===> Epoch 28 Complete: Avg. Loss: 0.2880
===> Timestamp: [2025-08-03 21:39:05]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.3124
===> Epoch[28](200/2500): Loss: 0.2792
===> Epoch[28](300/2500): Loss: 0.3023
===> Epoch[28](400/2500): Loss: 0.2901
===> Epoch[28](500/2500): Loss: 0.2766
===> Epoch[28](600/2500): Loss: 0.2938
===> Epoch[28](700/2500): Loss: 0.3015
===> Epoch[28](800/2500): Loss: 0.2867
===> Epoch[28](900/2500): Loss: 0.2902
===> Epoch[28](1000/2500): Loss: 0.2701
===> Epoch[28](1100/2500): Loss: 0.2973
===> Epoch[28](1200/2500): Loss: 0.2575
===> Epoch[28](1300/2500): Loss: 0.3000
===> Epoch[28](1400/2500): Loss: 0.2869
===> Epoch[28](1500/2500): Loss: 0.2729
===> Epoch[28](1600/2500): Loss: 0.2737
===> Epoch[28](1700/2500): Loss: 0.2886
===> Epoch[28](1800/2500): Loss: 0.3086
===> Epoch[28](1900/2500): Loss: 0.2941
===> Epoch[28](2000/2500): Loss: 0.2765
===> Epoch[28](2100/2500): Loss: 0.2702
===> Epoch[28](2200/2500): Loss: 0.2813
===> Epoch[28](2300/2500): Loss: 0.2728
===> Epoch[28](2400/2500): Loss: 0.2681
===> Epoch[28](2500/2500): Loss: 0.2800
===> Epoch 28 Complete: Avg. Loss: 0.2880
===> Timestamp: [2025-08-03 21:39:05]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.3124
===> Epoch[28](200/2500): Loss: 0.2792
===> Epoch[28](300/2500): Loss: 0.3023
===> Epoch[28](400/2500): Loss: 0.2901
===> Epoch[28](500/2500): Loss: 0.2766
===> Epoch[28](600/2500): Loss: 0.2938
===> Epoch[28](700/2500): Loss: 0.3015
===> Epoch[28](800/2500): Loss: 0.2867
===> Epoch[28](900/2500): Loss: 0.2902
===> Epoch[28](1000/2500): Loss: 0.2701
===> Epoch[28](1100/2500): Loss: 0.2973
===> Epoch[28](1200/2500): Loss: 0.2575
===> Epoch[28](1300/2500): Loss: 0.3000
===> Epoch[28](1400/2500): Loss: 0.2869
===> Epoch[28](1500/2500): Loss: 0.2729
===> Epoch[28](1600/2500): Loss: 0.2737
===> Epoch[28](1700/2500): Loss: 0.2886
===> Epoch[28](1800/2500): Loss: 0.3086
===> Epoch[28](1900/2500): Loss: 0.2941
===> Epoch[28](2000/2500): Loss: 0.2765
===> Epoch[28](2100/2500): Loss: 0.2702
===> Epoch[28](2200/2500): Loss: 0.2813
===> Epoch[28](2300/2500): Loss: 0.2728
===> Epoch[28](2400/2500): Loss: 0.2681
===> Epoch[28](2500/2500): Loss: 0.2800
===> Epoch 28 Complete: Avg. Loss: 0.2880
===> Timestamp: [2025-08-03 21:39:05]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.3124
===> Epoch[28](200/2500): Loss: 0.2792
===> Epoch[28](300/2500): Loss: 0.3023
===> Epoch[28](400/2500): Loss: 0.2901
===> Epoch[28](500/2500): Loss: 0.2766
===> Epoch[28](600/2500): Loss: 0.2938
===> Epoch[28](700/2500): Loss: 0.3015
===> Epoch[28](800/2500): Loss: 0.2867
===> Epoch[28](900/2500): Loss: 0.2902
===> Epoch[28](1000/2500): Loss: 0.2701
===> Epoch[28](1100/2500): Loss: 0.2973
===> Epoch[28](1200/2500): Loss: 0.2575
===> Epoch[28](1300/2500): Loss: 0.3000
===> Epoch[28](1400/2500): Loss: 0.2869
===> Epoch[28](1500/2500): Loss: 0.2729
===> Epoch[28](1600/2500): Loss: 0.2737
===> Epoch[28](1700/2500): Loss: 0.2886
===> Epoch[28](1800/2500): Loss: 0.3086
===> Epoch[28](1900/2500): Loss: 0.2941
===> Epoch[28](2000/2500): Loss: 0.2765
===> Epoch[28](2100/2500): Loss: 0.2702
===> Epoch[28](2200/2500): Loss: 0.2813
===> Epoch[28](2300/2500): Loss: 0.2728
===> Epoch[28](2400/2500): Loss: 0.2681
===> Epoch[28](2500/2500): Loss: 0.2800
===> Epoch 28 Complete: Avg. Loss: 0.2880
===> Timestamp: [2025-08-03 21:39:05]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.3124
===> Epoch[28](200/2500): Loss: 0.2792
===> Epoch[28](300/2500): Loss: 0.3023
===> Epoch[28](400/2500): Loss: 0.2901
===> Epoch[28](500/2500): Loss: 0.2766
===> Epoch[28](600/2500): Loss: 0.2938
===> Epoch[28](700/2500): Loss: 0.3015
===> Epoch[28](800/2500): Loss: 0.2867
===> Epoch[28](900/2500): Loss: 0.2902
===> Epoch[28](1000/2500): Loss: 0.2701
===> Epoch[28](1100/2500): Loss: 0.2973
===> Epoch[28](1200/2500): Loss: 0.2575
===> Epoch[28](1300/2500): Loss: 0.3000
===> Epoch[28](1400/2500): Loss: 0.2869
===> Epoch[28](1500/2500): Loss: 0.2729
===> Epoch[28](1600/2500): Loss: 0.2737
===> Epoch[28](1700/2500): Loss: 0.2886
===> Epoch[28](1800/2500): Loss: 0.3086
===> Epoch[28](1900/2500): Loss: 0.2941
===> Epoch[28](2000/2500): Loss: 0.2765
===> Epoch[28](2100/2500): Loss: 0.2702
===> Epoch[28](2200/2500): Loss: 0.2813
===> Epoch[28](2300/2500): Loss: 0.2728
===> Epoch[28](2400/2500): Loss: 0.2681
===> Epoch[28](2500/2500): Loss: 0.2800
===> Epoch 28 Complete: Avg. Loss: 0.2880
===> Timestamp: [2025-08-03 21:39:05]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.3124
===> Epoch[28](200/2500): Loss: 0.2792
===> Epoch[28](300/2500): Loss: 0.3023
===> Epoch[28](400/2500): Loss: 0.2901
===> Epoch[28](500/2500): Loss: 0.2766
===> Epoch[28](600/2500): Loss: 0.2938
===> Epoch[28](700/2500): Loss: 0.3015
===> Epoch[28](800/2500): Loss: 0.2867
===> Epoch[28](900/2500): Loss: 0.2902
===> Epoch[28](1000/2500): Loss: 0.2701
===> Epoch[28](1100/2500): Loss: 0.2973
===> Epoch[28](1200/2500): Loss: 0.2575
===> Epoch[28](1300/2500): Loss: 0.3000
===> Epoch[28](1400/2500): Loss: 0.2869
===> Epoch[28](1500/2500): Loss: 0.2729
===> Epoch[28](1600/2500): Loss: 0.2737
===> Epoch[28](1700/2500): Loss: 0.2886
===> Epoch[28](1800/2500): Loss: 0.3086
===> Epoch[28](1900/2500): Loss: 0.2941
===> Epoch[28](2000/2500): Loss: 0.2765
===> Epoch[28](2100/2500): Loss: 0.2702
===> Epoch[28](2200/2500): Loss: 0.2813
===> Epoch[28](2300/2500): Loss: 0.2728
===> Epoch[28](2400/2500): Loss: 0.2681
===> Epoch[28](2500/2500): Loss: 0.2800
===> Epoch 28 Complete: Avg. Loss: 0.2880
===> Timestamp: [2025-08-03 21:39:05]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.3124
===> Epoch[28](200/2500): Loss: 0.2792
===> Epoch[28](300/2500): Loss: 0.3023
===> Epoch[28](400/2500): Loss: 0.2901
===> Epoch[28](500/2500): Loss: 0.2766
===> Epoch[28](600/2500): Loss: 0.2938
===> Epoch[28](700/2500): Loss: 0.3015
===> Epoch[28](800/2500): Loss: 0.2867
===> Epoch[28](900/2500): Loss: 0.2902
===> Epoch[28](1000/2500): Loss: 0.2701
===> Epoch[28](1100/2500): Loss: 0.2973
===> Epoch[28](1200/2500): Loss: 0.2575
===> Epoch[28](1300/2500): Loss: 0.3000
===> Epoch[28](1400/2500): Loss: 0.2869
===> Epoch[28](1500/2500): Loss: 0.2729
===> Epoch[28](1600/2500): Loss: 0.2737
===> Epoch[28](1700/2500): Loss: 0.2886
===> Epoch[28](1800/2500): Loss: 0.3086
===> Epoch[28](1900/2500): Loss: 0.2941
===> Epoch[28](2000/2500): Loss: 0.2765
===> Epoch[28](2100/2500): Loss: 0.2702
===> Epoch[28](2200/2500): Loss: 0.2813
===> Epoch[28](2300/2500): Loss: 0.2728
===> Epoch[28](2400/2500): Loss: 0.2681
===> Epoch[28](2500/2500): Loss: 0.2800
===> Epoch 28 Complete: Avg. Loss: 0.2880
===> Timestamp: [2025-08-03 21:39:05]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.3124
===> Epoch[28](200/2500): Loss: 0.2792
===> Epoch[28](300/2500): Loss: 0.3023
===> Epoch[28](400/2500): Loss: 0.2901
===> Epoch[28](500/2500): Loss: 0.2766
===> Epoch[28](600/2500): Loss: 0.2938
===> Epoch[28](700/2500): Loss: 0.3015
===> Epoch[28](800/2500): Loss: 0.2867
===> Epoch[28](900/2500): Loss: 0.2902
===> Epoch[28](1000/2500): Loss: 0.2701
===> Epoch[28](1100/2500): Loss: 0.2973
===> Epoch[28](1200/2500): Loss: 0.2575
===> Epoch[28](1300/2500): Loss: 0.3000
===> Epoch[28](1400/2500): Loss: 0.2869
===> Epoch[28](1500/2500): Loss: 0.2729
===> Epoch[28](1600/2500): Loss: 0.2737
===> Epoch[28](1700/2500): Loss: 0.2886
===> Epoch[28](1800/2500): Loss: 0.3086
===> Epoch[28](1900/2500): Loss: 0.2941
===> Epoch[28](2000/2500): Loss: 0.2765
===> Epoch[28](2100/2500): Loss: 0.2702
===> Epoch[28](2200/2500): Loss: 0.2813
===> Epoch[28](2300/2500): Loss: 0.2728
===> Epoch[28](2400/2500): Loss: 0.2681
===> Epoch[28](2500/2500): Loss: 0.2800
===> Epoch 28 Complete: Avg. Loss: 0.2880
===> Timestamp: [2025-08-03 21:39:05]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.3124
===> Epoch[28](200/2500): Loss: 0.2792
===> Epoch[28](300/2500): Loss: 0.3023
===> Epoch[28](400/2500): Loss: 0.2901
===> Epoch[28](500/2500): Loss: 0.2766
===> Epoch[28](600/2500): Loss: 0.2938
===> Epoch[28](700/2500): Loss: 0.3015
===> Epoch[28](800/2500): Loss: 0.2867
===> Epoch[28](900/2500): Loss: 0.2902
===> Epoch[28](1000/2500): Loss: 0.2701
===> Epoch[28](1100/2500): Loss: 0.2973
===> Epoch[28](1200/2500): Loss: 0.2575
===> Epoch[28](1300/2500): Loss: 0.3000
===> Epoch[28](1400/2500): Loss: 0.2869
===> Epoch[28](1500/2500): Loss: 0.2729
===> Epoch[28](1600/2500): Loss: 0.2737
===> Epoch[28](1700/2500): Loss: 0.2886
===> Epoch[28](1800/2500): Loss: 0.3086
===> Epoch[28](1900/2500): Loss: 0.2941
===> Epoch[28](2000/2500): Loss: 0.2765
===> Epoch[28](2100/2500): Loss: 0.2702
===> Epoch[28](2200/2500): Loss: 0.2813
===> Epoch[28](2300/2500): Loss: 0.2728
===> Epoch[28](2400/2500): Loss: 0.2681
===> Epoch[28](2500/2500): Loss: 0.2800
===> Epoch 28 Complete: Avg. Loss: 0.2880
===> Timestamp: [2025-08-03 21:39:05]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.3124
===> Epoch[28](200/2500): Loss: 0.2792
===> Epoch[28](300/2500): Loss: 0.3023
===> Epoch[28](400/2500): Loss: 0.2901
===> Epoch[28](500/2500): Loss: 0.2766
===> Epoch[28](600/2500): Loss: 0.2938
===> Epoch[28](700/2500): Loss: 0.3015
===> Epoch[28](800/2500): Loss: 0.2867
===> Epoch[28](900/2500): Loss: 0.2902
===> Epoch[28](1000/2500): Loss: 0.2701
===> Epoch[28](1100/2500): Loss: 0.2973
===> Epoch[28](1200/2500): Loss: 0.2575
===> Epoch[28](1300/2500): Loss: 0.3000
===> Epoch[28](1400/2500): Loss: 0.2869
===> Epoch[28](1500/2500): Loss: 0.2729
===> Epoch[28](1600/2500): Loss: 0.2737
===> Epoch[28](1700/2500): Loss: 0.2886
===> Epoch[28](1800/2500): Loss: 0.3086
===> Epoch[28](1900/2500): Loss: 0.2941
===> Epoch[28](2000/2500): Loss: 0.2765
===> Epoch[28](2100/2500): Loss: 0.2702
===> Epoch[28](2200/2500): Loss: 0.2813
===> Epoch[28](2300/2500): Loss: 0.2728
===> Epoch[28](2400/2500): Loss: 0.2681
===> Epoch[28](2500/2500): Loss: 0.2800
===> Epoch 28 Complete: Avg. Loss: 0.2880
===> Timestamp: [2025-08-03 21:39:05]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.3124
===> Epoch[28](200/2500): Loss: 0.2792
===> Epoch[28](300/2500): Loss: 0.3023
===> Epoch[28](400/2500): Loss: 0.2901
===> Epoch[28](500/2500): Loss: 0.2766
===> Epoch[28](600/2500): Loss: 0.2938
===> Epoch[28](700/2500): Loss: 0.3015
===> Epoch[28](800/2500): Loss: 0.2867
===> Epoch[28](900/2500): Loss: 0.2902
===> Epoch[28](1000/2500): Loss: 0.2701
===> Epoch[28](1100/2500): Loss: 0.2973
===> Epoch[28](1200/2500): Loss: 0.2575
===> Epoch[28](1300/2500): Loss: 0.3000
===> Epoch[28](1400/2500): Loss: 0.2869
===> Epoch[28](1500/2500): Loss: 0.2729
===> Epoch[28](1600/2500): Loss: 0.2737
===> Epoch[28](1700/2500): Loss: 0.2886
===> Epoch[28](1800/2500): Loss: 0.3086
===> Epoch[28](1900/2500): Loss: 0.2941
===> Epoch[28](2000/2500): Loss: 0.2765
===> Epoch[28](2100/2500): Loss: 0.2702
===> Epoch[28](2200/2500): Loss: 0.2813
===> Epoch[28](2300/2500): Loss: 0.2728
===> Epoch[28](2400/2500): Loss: 0.2681
===> Epoch[28](2500/2500): Loss: 0.2800
===> Epoch 28 Complete: Avg. Loss: 0.2880
===> Timestamp: [2025-08-03 21:39:05]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.3124
===> Epoch[28](200/2500): Loss: 0.2792
===> Epoch[28](300/2500): Loss: 0.3023
===> Epoch[28](400/2500): Loss: 0.2901
===> Epoch[28](500/2500): Loss: 0.2766
===> Epoch[28](600/2500): Loss: 0.2938
===> Epoch[28](700/2500): Loss: 0.3015
===> Epoch[28](800/2500): Loss: 0.2867
===> Epoch[28](900/2500): Loss: 0.2902
===> Epoch[28](1000/2500): Loss: 0.2701
===> Epoch[28](1100/2500): Loss: 0.2973
===> Epoch[28](1200/2500): Loss: 0.2575
===> Epoch[28](1300/2500): Loss: 0.3000
===> Epoch[28](1400/2500): Loss: 0.2869
===> Epoch[28](1500/2500): Loss: 0.2729
===> Epoch[28](1600/2500): Loss: 0.2737
===> Epoch[28](1700/2500): Loss: 0.2886
===> Epoch[28](1800/2500): Loss: 0.3086
===> Epoch[28](1900/2500): Loss: 0.2941
===> Epoch[28](2000/2500): Loss: 0.2765
===> Epoch[28](2100/2500): Loss: 0.2702
===> Epoch[28](2200/2500): Loss: 0.2813
===> Epoch[28](2300/2500): Loss: 0.2728
===> Epoch[28](2400/2500): Loss: 0.2681
===> Epoch[28](2500/2500): Loss: 0.2800
===> Epoch 28 Complete: Avg. Loss: 0.2880
===> Timestamp: [2025-08-03 21:39:05]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.3124
===> Epoch[28](200/2500): Loss: 0.2792
===> Epoch[28](300/2500): Loss: 0.3023
===> Epoch[28](400/2500): Loss: 0.2901
===> Epoch[28](500/2500): Loss: 0.2766
===> Epoch[28](600/2500): Loss: 0.2938
===> Epoch[28](700/2500): Loss: 0.3015
===> Epoch[28](800/2500): Loss: 0.2867
===> Epoch[28](900/2500): Loss: 0.2902
===> Epoch[28](1000/2500): Loss: 0.2701
===> Epoch[28](1100/2500): Loss: 0.2973
===> Epoch[28](1200/2500): Loss: 0.2575
===> Epoch[28](1300/2500): Loss: 0.3000
===> Epoch[28](1400/2500): Loss: 0.2869
===> Epoch[28](1500/2500): Loss: 0.2729
===> Epoch[28](1600/2500): Loss: 0.2737
===> Epoch[28](1700/2500): Loss: 0.2886
===> Epoch[28](1800/2500): Loss: 0.3086
===> Epoch[28](1900/2500): Loss: 0.2941
===> Epoch[28](2000/2500): Loss: 0.2765
===> Epoch[28](2100/2500): Loss: 0.2702
===> Epoch[28](2200/2500): Loss: 0.2813
===> Epoch[28](2300/2500): Loss: 0.2728
===> Epoch[28](2400/2500): Loss: 0.2681
===> Epoch[28](2500/2500): Loss: 0.2800
===> Epoch 28 Complete: Avg. Loss: 0.2880
===> Timestamp: [2025-08-03 21:39:05]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.3124
===> Epoch[28](200/2500): Loss: 0.2792
===> Epoch[28](300/2500): Loss: 0.3023
===> Epoch[28](400/2500): Loss: 0.2901
===> Epoch[28](500/2500): Loss: 0.2766
===> Epoch[28](600/2500): Loss: 0.2938
===> Epoch[28](700/2500): Loss: 0.3015
===> Epoch[28](800/2500): Loss: 0.2867
===> Epoch[28](900/2500): Loss: 0.2902
===> Epoch[28](1000/2500): Loss: 0.2701
===> Epoch[28](1100/2500): Loss: 0.2973
===> Epoch[28](1200/2500): Loss: 0.2575
===> Epoch[28](1300/2500): Loss: 0.3000
===> Epoch[28](1400/2500): Loss: 0.2869
===> Epoch[28](1500/2500): Loss: 0.2729
===> Epoch[28](1600/2500): Loss: 0.2737
===> Epoch[28](1700/2500): Loss: 0.2886
===> Epoch[28](1800/2500): Loss: 0.3086
===> Epoch[28](1900/2500): Loss: 0.2941
===> Epoch[28](2000/2500): Loss: 0.2765
===> Epoch[28](2100/2500): Loss: 0.2702
===> Epoch[28](2200/2500): Loss: 0.2813
===> Epoch[28](2300/2500): Loss: 0.2728
===> Epoch[28](2400/2500): Loss: 0.2681
===> Epoch[28](2500/2500): Loss: 0.2800
===> Epoch 28 Complete: Avg. Loss: 0.2880
===> Timestamp: [2025-08-03 21:39:05]
===> Loading train datasets
===> Epoch[28](100/2500): Loss: 0.3124
===> Epoch[28](200/2500): Loss: 0.2792
===> Epoch[28](300/2500): Loss: 0.3023
===> Epoch[28](400/2500): Loss: 0.2901
===> Epoch[28](500/2500): Loss: 0.2766
===> Epoch[28](600/2500): Loss: 0.2938
===> Epoch[28](700/2500): Loss: 0.3015
===> Epoch[28](800/2500): Loss: 0.2867
===> Epoch[28](900/2500): Loss: 0.2902
===> Epoch[28](1000/2500): Loss: 0.2701
===> Epoch[28](1100/2500): Loss: 0.2973
===> Epoch[28](1200/2500): Loss: 0.2575
===> Epoch[28](1300/2500): Loss: 0.3000
===> Epoch[28](1400/2500): Loss: 0.2869
===> Epoch[28](1500/2500): Loss: 0.2729
===> Epoch[28](1600/2500): Loss: 0.2737
===> Epoch[28](1700/2500): Loss: 0.2886
===> Epoch[28](1800/2500): Loss: 0.3086
===> Epoch[28](1900/2500): Loss: 0.2941
===> Epoch[28](2000/2500): Loss: 0.2765
===> Epoch[28](2100/2500): Loss: 0.2702
===> Epoch[28](2200/2500): Loss: 0.2813
===> Epoch[28](2300/2500): Loss: 0.2728
===> Epoch[28](2400/2500): Loss: 0.2681
===> Epoch[28](2500/2500): Loss: 0.2800
===> Epoch 28 Complete: Avg. Loss: 0.2880
===> Timestamp: [2025-08-03 21:39:05]
===> Loading train datasets
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2997
===> Epoch[29](200/2500): Loss: 0.2805
===> Epoch[29](300/2500): Loss: 0.2771
===> Epoch[29](400/2500): Loss: 0.2879
===> Epoch[29](500/2500): Loss: 0.2924
===> Epoch[29](600/2500): Loss: 0.2876
===> Epoch[29](700/2500): Loss: 0.2877
===> Epoch[29](800/2500): Loss: 0.2851
===> Epoch[29](900/2500): Loss: 0.2637
===> Epoch[29](1000/2500): Loss: 0.2772
===> Epoch[29](1100/2500): Loss: 0.2842
===> Epoch[29](1200/2500): Loss: 0.2967
===> Epoch[29](1300/2500): Loss: 0.2759
===> Epoch[29](1400/2500): Loss: 0.3074
===> Epoch[29](1500/2500): Loss: 0.3044
===> Epoch[29](1600/2500): Loss: 0.2801
===> Epoch[29](1700/2500): Loss: 0.3051
===> Epoch[29](1800/2500): Loss: 0.3182
===> Epoch[29](1900/2500): Loss: 0.3083
===> Epoch[29](2000/2500): Loss: 0.2885
===> Epoch[29](2100/2500): Loss: 0.2833
===> Epoch[29](2200/2500): Loss: 0.3116
===> Epoch[29](2300/2500): Loss: 0.3041
===> Epoch[29](2400/2500): Loss: 0.3050
===> Epoch[29](2500/2500): Loss: 0.2816
===> Epoch 29 Complete: Avg. Loss: 0.2869
===> Timestamp: [2025-08-03 21:43:40]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2997
===> Epoch[29](200/2500): Loss: 0.2805
===> Epoch[29](300/2500): Loss: 0.2771
===> Epoch[29](400/2500): Loss: 0.2879
===> Epoch[29](500/2500): Loss: 0.2924
===> Epoch[29](600/2500): Loss: 0.2876
===> Epoch[29](700/2500): Loss: 0.2877
===> Epoch[29](800/2500): Loss: 0.2851
===> Epoch[29](900/2500): Loss: 0.2637
===> Epoch[29](1000/2500): Loss: 0.2772
===> Epoch[29](1100/2500): Loss: 0.2842
===> Epoch[29](1200/2500): Loss: 0.2967
===> Epoch[29](1300/2500): Loss: 0.2759
===> Epoch[29](1400/2500): Loss: 0.3074
===> Epoch[29](1500/2500): Loss: 0.3044
===> Epoch[29](1600/2500): Loss: 0.2801
===> Epoch[29](1700/2500): Loss: 0.3051
===> Epoch[29](1800/2500): Loss: 0.3182
===> Epoch[29](1900/2500): Loss: 0.3083
===> Epoch[29](2000/2500): Loss: 0.2885
===> Epoch[29](2100/2500): Loss: 0.2833
===> Epoch[29](2200/2500): Loss: 0.3116
===> Epoch[29](2300/2500): Loss: 0.3041
===> Epoch[29](2400/2500): Loss: 0.3050
===> Epoch[29](2500/2500): Loss: 0.2816
===> Epoch 29 Complete: Avg. Loss: 0.2869
===> Timestamp: [2025-08-03 21:43:40]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2997
===> Epoch[29](200/2500): Loss: 0.2805
===> Epoch[29](300/2500): Loss: 0.2771
===> Epoch[29](400/2500): Loss: 0.2879
===> Epoch[29](500/2500): Loss: 0.2924
===> Epoch[29](600/2500): Loss: 0.2876
===> Epoch[29](700/2500): Loss: 0.2877
===> Epoch[29](800/2500): Loss: 0.2851
===> Epoch[29](900/2500): Loss: 0.2637
===> Epoch[29](1000/2500): Loss: 0.2772
===> Epoch[29](1100/2500): Loss: 0.2842
===> Epoch[29](1200/2500): Loss: 0.2967
===> Epoch[29](1300/2500): Loss: 0.2759
===> Epoch[29](1400/2500): Loss: 0.3074
===> Epoch[29](1500/2500): Loss: 0.3044
===> Epoch[29](1600/2500): Loss: 0.2801
===> Epoch[29](1700/2500): Loss: 0.3051
===> Epoch[29](1800/2500): Loss: 0.3182
===> Epoch[29](1900/2500): Loss: 0.3083
===> Epoch[29](2000/2500): Loss: 0.2885
===> Epoch[29](2100/2500): Loss: 0.2833
===> Epoch[29](2200/2500): Loss: 0.3116
===> Epoch[29](2300/2500): Loss: 0.3041
===> Epoch[29](2400/2500): Loss: 0.3050
===> Epoch[29](2500/2500): Loss: 0.2816
===> Epoch 29 Complete: Avg. Loss: 0.2869
===> Timestamp: [2025-08-03 21:43:40]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2997
===> Epoch[29](200/2500): Loss: 0.2805
===> Epoch[29](300/2500): Loss: 0.2771
===> Epoch[29](400/2500): Loss: 0.2879
===> Epoch[29](500/2500): Loss: 0.2924
===> Epoch[29](600/2500): Loss: 0.2876
===> Epoch[29](700/2500): Loss: 0.2877
===> Epoch[29](800/2500): Loss: 0.2851
===> Epoch[29](900/2500): Loss: 0.2637
===> Epoch[29](1000/2500): Loss: 0.2772
===> Epoch[29](1100/2500): Loss: 0.2842
===> Epoch[29](1200/2500): Loss: 0.2967
===> Epoch[29](1300/2500): Loss: 0.2759
===> Epoch[29](1400/2500): Loss: 0.3074
===> Epoch[29](1500/2500): Loss: 0.3044
===> Epoch[29](1600/2500): Loss: 0.2801
===> Epoch[29](1700/2500): Loss: 0.3051
===> Epoch[29](1800/2500): Loss: 0.3182
===> Epoch[29](1900/2500): Loss: 0.3083
===> Epoch[29](2000/2500): Loss: 0.2885
===> Epoch[29](2100/2500): Loss: 0.2833
===> Epoch[29](2200/2500): Loss: 0.3116
===> Epoch[29](2300/2500): Loss: 0.3041
===> Epoch[29](2400/2500): Loss: 0.3050
===> Epoch[29](2500/2500): Loss: 0.2816
===> Epoch 29 Complete: Avg. Loss: 0.2869
===> Timestamp: [2025-08-03 21:43:40]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2997
===> Epoch[29](200/2500): Loss: 0.2805
===> Epoch[29](300/2500): Loss: 0.2771
===> Epoch[29](400/2500): Loss: 0.2879
===> Epoch[29](500/2500): Loss: 0.2924
===> Epoch[29](600/2500): Loss: 0.2876
===> Epoch[29](700/2500): Loss: 0.2877
===> Epoch[29](800/2500): Loss: 0.2851
===> Epoch[29](900/2500): Loss: 0.2637
===> Epoch[29](1000/2500): Loss: 0.2772
===> Epoch[29](1100/2500): Loss: 0.2842
===> Epoch[29](1200/2500): Loss: 0.2967
===> Epoch[29](1300/2500): Loss: 0.2759
===> Epoch[29](1400/2500): Loss: 0.3074
===> Epoch[29](1500/2500): Loss: 0.3044
===> Epoch[29](1600/2500): Loss: 0.2801
===> Epoch[29](1700/2500): Loss: 0.3051
===> Epoch[29](1800/2500): Loss: 0.3182
===> Epoch[29](1900/2500): Loss: 0.3083
===> Epoch[29](2000/2500): Loss: 0.2885
===> Epoch[29](2100/2500): Loss: 0.2833
===> Epoch[29](2200/2500): Loss: 0.3116
===> Epoch[29](2300/2500): Loss: 0.3041
===> Epoch[29](2400/2500): Loss: 0.3050
===> Epoch[29](2500/2500): Loss: 0.2816
===> Epoch 29 Complete: Avg. Loss: 0.2869
===> Timestamp: [2025-08-03 21:43:40]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2997
===> Epoch[29](200/2500): Loss: 0.2805
===> Epoch[29](300/2500): Loss: 0.2771
===> Epoch[29](400/2500): Loss: 0.2879
===> Epoch[29](500/2500): Loss: 0.2924
===> Epoch[29](600/2500): Loss: 0.2876
===> Epoch[29](700/2500): Loss: 0.2877
===> Epoch[29](800/2500): Loss: 0.2851
===> Epoch[29](900/2500): Loss: 0.2637
===> Epoch[29](1000/2500): Loss: 0.2772
===> Epoch[29](1100/2500): Loss: 0.2842
===> Epoch[29](1200/2500): Loss: 0.2967
===> Epoch[29](1300/2500): Loss: 0.2759
===> Epoch[29](1400/2500): Loss: 0.3074
===> Epoch[29](1500/2500): Loss: 0.3044
===> Epoch[29](1600/2500): Loss: 0.2801
===> Epoch[29](1700/2500): Loss: 0.3051
===> Epoch[29](1800/2500): Loss: 0.3182
===> Epoch[29](1900/2500): Loss: 0.3083
===> Epoch[29](2000/2500): Loss: 0.2885
===> Epoch[29](2100/2500): Loss: 0.2833
===> Epoch[29](2200/2500): Loss: 0.3116
===> Epoch[29](2300/2500): Loss: 0.3041
===> Epoch[29](2400/2500): Loss: 0.3050
===> Epoch[29](2500/2500): Loss: 0.2816
===> Epoch 29 Complete: Avg. Loss: 0.2869
===> Timestamp: [2025-08-03 21:43:40]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2997
===> Epoch[29](200/2500): Loss: 0.2805
===> Epoch[29](300/2500): Loss: 0.2771
===> Epoch[29](400/2500): Loss: 0.2879
===> Epoch[29](500/2500): Loss: 0.2924
===> Epoch[29](600/2500): Loss: 0.2876
===> Epoch[29](700/2500): Loss: 0.2877
===> Epoch[29](800/2500): Loss: 0.2851
===> Epoch[29](900/2500): Loss: 0.2637
===> Epoch[29](1000/2500): Loss: 0.2772
===> Epoch[29](1100/2500): Loss: 0.2842
===> Epoch[29](1200/2500): Loss: 0.2967
===> Epoch[29](1300/2500): Loss: 0.2759
===> Epoch[29](1400/2500): Loss: 0.3074
===> Epoch[29](1500/2500): Loss: 0.3044
===> Epoch[29](1600/2500): Loss: 0.2801
===> Epoch[29](1700/2500): Loss: 0.3051
===> Epoch[29](1800/2500): Loss: 0.3182
===> Epoch[29](1900/2500): Loss: 0.3083
===> Epoch[29](2000/2500): Loss: 0.2885
===> Epoch[29](2100/2500): Loss: 0.2833
===> Epoch[29](2200/2500): Loss: 0.3116
===> Epoch[29](2300/2500): Loss: 0.3041
===> Epoch[29](2400/2500): Loss: 0.3050
===> Epoch[29](2500/2500): Loss: 0.2816
===> Epoch 29 Complete: Avg. Loss: 0.2869
===> Timestamp: [2025-08-03 21:43:40]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2997
===> Epoch[29](200/2500): Loss: 0.2805
===> Epoch[29](300/2500): Loss: 0.2771
===> Epoch[29](400/2500): Loss: 0.2879
===> Epoch[29](500/2500): Loss: 0.2924
===> Epoch[29](600/2500): Loss: 0.2876
===> Epoch[29](700/2500): Loss: 0.2877
===> Epoch[29](800/2500): Loss: 0.2851
===> Epoch[29](900/2500): Loss: 0.2637
===> Epoch[29](1000/2500): Loss: 0.2772
===> Epoch[29](1100/2500): Loss: 0.2842
===> Epoch[29](1200/2500): Loss: 0.2967
===> Epoch[29](1300/2500): Loss: 0.2759
===> Epoch[29](1400/2500): Loss: 0.3074
===> Epoch[29](1500/2500): Loss: 0.3044
===> Epoch[29](1600/2500): Loss: 0.2801
===> Epoch[29](1700/2500): Loss: 0.3051
===> Epoch[29](1800/2500): Loss: 0.3182
===> Epoch[29](1900/2500): Loss: 0.3083
===> Epoch[29](2000/2500): Loss: 0.2885
===> Epoch[29](2100/2500): Loss: 0.2833
===> Epoch[29](2200/2500): Loss: 0.3116
===> Epoch[29](2300/2500): Loss: 0.3041
===> Epoch[29](2400/2500): Loss: 0.3050
===> Epoch[29](2500/2500): Loss: 0.2816
===> Epoch 29 Complete: Avg. Loss: 0.2869
===> Timestamp: [2025-08-03 21:43:40]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2997
===> Epoch[29](200/2500): Loss: 0.2805
===> Epoch[29](300/2500): Loss: 0.2771
===> Epoch[29](400/2500): Loss: 0.2879
===> Epoch[29](500/2500): Loss: 0.2924
===> Epoch[29](600/2500): Loss: 0.2876
===> Epoch[29](700/2500): Loss: 0.2877
===> Epoch[29](800/2500): Loss: 0.2851
===> Epoch[29](900/2500): Loss: 0.2637
===> Epoch[29](1000/2500): Loss: 0.2772
===> Epoch[29](1100/2500): Loss: 0.2842
===> Epoch[29](1200/2500): Loss: 0.2967
===> Epoch[29](1300/2500): Loss: 0.2759
===> Epoch[29](1400/2500): Loss: 0.3074
===> Epoch[29](1500/2500): Loss: 0.3044
===> Epoch[29](1600/2500): Loss: 0.2801
===> Epoch[29](1700/2500): Loss: 0.3051
===> Epoch[29](1800/2500): Loss: 0.3182
===> Epoch[29](1900/2500): Loss: 0.3083
===> Epoch[29](2000/2500): Loss: 0.2885
===> Epoch[29](2100/2500): Loss: 0.2833
===> Epoch[29](2200/2500): Loss: 0.3116
===> Epoch[29](2300/2500): Loss: 0.3041
===> Epoch[29](2400/2500): Loss: 0.3050
===> Epoch[29](2500/2500): Loss: 0.2816
===> Epoch 29 Complete: Avg. Loss: 0.2869
===> Timestamp: [2025-08-03 21:43:40]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2997
===> Epoch[29](200/2500): Loss: 0.2805
===> Epoch[29](300/2500): Loss: 0.2771
===> Epoch[29](400/2500): Loss: 0.2879
===> Epoch[29](500/2500): Loss: 0.2924
===> Epoch[29](600/2500): Loss: 0.2876
===> Epoch[29](700/2500): Loss: 0.2877
===> Epoch[29](800/2500): Loss: 0.2851
===> Epoch[29](900/2500): Loss: 0.2637
===> Epoch[29](1000/2500): Loss: 0.2772
===> Epoch[29](1100/2500): Loss: 0.2842
===> Epoch[29](1200/2500): Loss: 0.2967
===> Epoch[29](1300/2500): Loss: 0.2759
===> Epoch[29](1400/2500): Loss: 0.3074
===> Epoch[29](1500/2500): Loss: 0.3044
===> Epoch[29](1600/2500): Loss: 0.2801
===> Epoch[29](1700/2500): Loss: 0.3051
===> Epoch[29](1800/2500): Loss: 0.3182
===> Epoch[29](1900/2500): Loss: 0.3083
===> Epoch[29](2000/2500): Loss: 0.2885
===> Epoch[29](2100/2500): Loss: 0.2833
===> Epoch[29](2200/2500): Loss: 0.3116
===> Epoch[29](2300/2500): Loss: 0.3041
===> Epoch[29](2400/2500): Loss: 0.3050
===> Epoch[29](2500/2500): Loss: 0.2816
===> Epoch 29 Complete: Avg. Loss: 0.2869
===> Timestamp: [2025-08-03 21:43:40]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2997
===> Epoch[29](200/2500): Loss: 0.2805
===> Epoch[29](300/2500): Loss: 0.2771
===> Epoch[29](400/2500): Loss: 0.2879
===> Epoch[29](500/2500): Loss: 0.2924
===> Epoch[29](600/2500): Loss: 0.2876
===> Epoch[29](700/2500): Loss: 0.2877
===> Epoch[29](800/2500): Loss: 0.2851
===> Epoch[29](900/2500): Loss: 0.2637
===> Epoch[29](1000/2500): Loss: 0.2772
===> Epoch[29](1100/2500): Loss: 0.2842
===> Epoch[29](1200/2500): Loss: 0.2967
===> Epoch[29](1300/2500): Loss: 0.2759
===> Epoch[29](1400/2500): Loss: 0.3074
===> Epoch[29](1500/2500): Loss: 0.3044
===> Epoch[29](1600/2500): Loss: 0.2801
===> Epoch[29](1700/2500): Loss: 0.3051
===> Epoch[29](1800/2500): Loss: 0.3182
===> Epoch[29](1900/2500): Loss: 0.3083
===> Epoch[29](2000/2500): Loss: 0.2885
===> Epoch[29](2100/2500): Loss: 0.2833
===> Epoch[29](2200/2500): Loss: 0.3116
===> Epoch[29](2300/2500): Loss: 0.3041
===> Epoch[29](2400/2500): Loss: 0.3050
===> Epoch[29](2500/2500): Loss: 0.2816
===> Epoch 29 Complete: Avg. Loss: 0.2869
===> Timestamp: [2025-08-03 21:43:40]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2997
===> Epoch[29](200/2500): Loss: 0.2805
===> Epoch[29](300/2500): Loss: 0.2771
===> Epoch[29](400/2500): Loss: 0.2879
===> Epoch[29](500/2500): Loss: 0.2924
===> Epoch[29](600/2500): Loss: 0.2876
===> Epoch[29](700/2500): Loss: 0.2877
===> Epoch[29](800/2500): Loss: 0.2851
===> Epoch[29](900/2500): Loss: 0.2637
===> Epoch[29](1000/2500): Loss: 0.2772
===> Epoch[29](1100/2500): Loss: 0.2842
===> Epoch[29](1200/2500): Loss: 0.2967
===> Epoch[29](1300/2500): Loss: 0.2759
===> Epoch[29](1400/2500): Loss: 0.3074
===> Epoch[29](1500/2500): Loss: 0.3044
===> Epoch[29](1600/2500): Loss: 0.2801
===> Epoch[29](1700/2500): Loss: 0.3051
===> Epoch[29](1800/2500): Loss: 0.3182
===> Epoch[29](1900/2500): Loss: 0.3083
===> Epoch[29](2000/2500): Loss: 0.2885
===> Epoch[29](2100/2500): Loss: 0.2833
===> Epoch[29](2200/2500): Loss: 0.3116
===> Epoch[29](2300/2500): Loss: 0.3041
===> Epoch[29](2400/2500): Loss: 0.3050
===> Epoch[29](2500/2500): Loss: 0.2816
===> Epoch 29 Complete: Avg. Loss: 0.2869
===> Timestamp: [2025-08-03 21:43:40]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2997
===> Epoch[29](200/2500): Loss: 0.2805
===> Epoch[29](300/2500): Loss: 0.2771
===> Epoch[29](400/2500): Loss: 0.2879
===> Epoch[29](500/2500): Loss: 0.2924
===> Epoch[29](600/2500): Loss: 0.2876
===> Epoch[29](700/2500): Loss: 0.2877
===> Epoch[29](800/2500): Loss: 0.2851
===> Epoch[29](900/2500): Loss: 0.2637
===> Epoch[29](1000/2500): Loss: 0.2772
===> Epoch[29](1100/2500): Loss: 0.2842
===> Epoch[29](1200/2500): Loss: 0.2967
===> Epoch[29](1300/2500): Loss: 0.2759
===> Epoch[29](1400/2500): Loss: 0.3074
===> Epoch[29](1500/2500): Loss: 0.3044
===> Epoch[29](1600/2500): Loss: 0.2801
===> Epoch[29](1700/2500): Loss: 0.3051
===> Epoch[29](1800/2500): Loss: 0.3182
===> Epoch[29](1900/2500): Loss: 0.3083
===> Epoch[29](2000/2500): Loss: 0.2885
===> Epoch[29](2100/2500): Loss: 0.2833
===> Epoch[29](2200/2500): Loss: 0.3116
===> Epoch[29](2300/2500): Loss: 0.3041
===> Epoch[29](2400/2500): Loss: 0.3050
===> Epoch[29](2500/2500): Loss: 0.2816
===> Epoch 29 Complete: Avg. Loss: 0.2869
===> Timestamp: [2025-08-03 21:43:40]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2997
===> Epoch[29](200/2500): Loss: 0.2805
===> Epoch[29](300/2500): Loss: 0.2771
===> Epoch[29](400/2500): Loss: 0.2879
===> Epoch[29](500/2500): Loss: 0.2924
===> Epoch[29](600/2500): Loss: 0.2876
===> Epoch[29](700/2500): Loss: 0.2877
===> Epoch[29](800/2500): Loss: 0.2851
===> Epoch[29](900/2500): Loss: 0.2637
===> Epoch[29](1000/2500): Loss: 0.2772
===> Epoch[29](1100/2500): Loss: 0.2842
===> Epoch[29](1200/2500): Loss: 0.2967
===> Epoch[29](1300/2500): Loss: 0.2759
===> Epoch[29](1400/2500): Loss: 0.3074
===> Epoch[29](1500/2500): Loss: 0.3044
===> Epoch[29](1600/2500): Loss: 0.2801
===> Epoch[29](1700/2500): Loss: 0.3051
===> Epoch[29](1800/2500): Loss: 0.3182
===> Epoch[29](1900/2500): Loss: 0.3083
===> Epoch[29](2000/2500): Loss: 0.2885
===> Epoch[29](2100/2500): Loss: 0.2833
===> Epoch[29](2200/2500): Loss: 0.3116
===> Epoch[29](2300/2500): Loss: 0.3041
===> Epoch[29](2400/2500): Loss: 0.3050
===> Epoch[29](2500/2500): Loss: 0.2816
===> Epoch 29 Complete: Avg. Loss: 0.2869
===> Timestamp: [2025-08-03 21:43:40]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2997
===> Epoch[29](200/2500): Loss: 0.2805
===> Epoch[29](300/2500): Loss: 0.2771
===> Epoch[29](400/2500): Loss: 0.2879
===> Epoch[29](500/2500): Loss: 0.2924
===> Epoch[29](600/2500): Loss: 0.2876
===> Epoch[29](700/2500): Loss: 0.2877
===> Epoch[29](800/2500): Loss: 0.2851
===> Epoch[29](900/2500): Loss: 0.2637
===> Epoch[29](1000/2500): Loss: 0.2772
===> Epoch[29](1100/2500): Loss: 0.2842
===> Epoch[29](1200/2500): Loss: 0.2967
===> Epoch[29](1300/2500): Loss: 0.2759
===> Epoch[29](1400/2500): Loss: 0.3074
===> Epoch[29](1500/2500): Loss: 0.3044
===> Epoch[29](1600/2500): Loss: 0.2801
===> Epoch[29](1700/2500): Loss: 0.3051
===> Epoch[29](1800/2500): Loss: 0.3182
===> Epoch[29](1900/2500): Loss: 0.3083
===> Epoch[29](2000/2500): Loss: 0.2885
===> Epoch[29](2100/2500): Loss: 0.2833
===> Epoch[29](2200/2500): Loss: 0.3116
===> Epoch[29](2300/2500): Loss: 0.3041
===> Epoch[29](2400/2500): Loss: 0.3050
===> Epoch[29](2500/2500): Loss: 0.2816
===> Epoch 29 Complete: Avg. Loss: 0.2869
===> Timestamp: [2025-08-03 21:43:40]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2997
===> Epoch[29](200/2500): Loss: 0.2805
===> Epoch[29](300/2500): Loss: 0.2771
===> Epoch[29](400/2500): Loss: 0.2879
===> Epoch[29](500/2500): Loss: 0.2924
===> Epoch[29](600/2500): Loss: 0.2876
===> Epoch[29](700/2500): Loss: 0.2877
===> Epoch[29](800/2500): Loss: 0.2851
===> Epoch[29](900/2500): Loss: 0.2637
===> Epoch[29](1000/2500): Loss: 0.2772
===> Epoch[29](1100/2500): Loss: 0.2842
===> Epoch[29](1200/2500): Loss: 0.2967
===> Epoch[29](1300/2500): Loss: 0.2759
===> Epoch[29](1400/2500): Loss: 0.3074
===> Epoch[29](1500/2500): Loss: 0.3044
===> Epoch[29](1600/2500): Loss: 0.2801
===> Epoch[29](1700/2500): Loss: 0.3051
===> Epoch[29](1800/2500): Loss: 0.3182
===> Epoch[29](1900/2500): Loss: 0.3083
===> Epoch[29](2000/2500): Loss: 0.2885
===> Epoch[29](2100/2500): Loss: 0.2833
===> Epoch[29](2200/2500): Loss: 0.3116
===> Epoch[29](2300/2500): Loss: 0.3041
===> Epoch[29](2400/2500): Loss: 0.3050
===> Epoch[29](2500/2500): Loss: 0.2816
===> Epoch 29 Complete: Avg. Loss: 0.2869
===> Timestamp: [2025-08-03 21:43:40]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2997
===> Epoch[29](200/2500): Loss: 0.2805
===> Epoch[29](300/2500): Loss: 0.2771
===> Epoch[29](400/2500): Loss: 0.2879
===> Epoch[29](500/2500): Loss: 0.2924
===> Epoch[29](600/2500): Loss: 0.2876
===> Epoch[29](700/2500): Loss: 0.2877
===> Epoch[29](800/2500): Loss: 0.2851
===> Epoch[29](900/2500): Loss: 0.2637
===> Epoch[29](1000/2500): Loss: 0.2772
===> Epoch[29](1100/2500): Loss: 0.2842
===> Epoch[29](1200/2500): Loss: 0.2967
===> Epoch[29](1300/2500): Loss: 0.2759
===> Epoch[29](1400/2500): Loss: 0.3074
===> Epoch[29](1500/2500): Loss: 0.3044
===> Epoch[29](1600/2500): Loss: 0.2801
===> Epoch[29](1700/2500): Loss: 0.3051
===> Epoch[29](1800/2500): Loss: 0.3182
===> Epoch[29](1900/2500): Loss: 0.3083
===> Epoch[29](2000/2500): Loss: 0.2885
===> Epoch[29](2100/2500): Loss: 0.2833
===> Epoch[29](2200/2500): Loss: 0.3116
===> Epoch[29](2300/2500): Loss: 0.3041
===> Epoch[29](2400/2500): Loss: 0.3050
===> Epoch[29](2500/2500): Loss: 0.2816
===> Epoch 29 Complete: Avg. Loss: 0.2869
===> Timestamp: [2025-08-03 21:43:40]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2997
===> Epoch[29](200/2500): Loss: 0.2805
===> Epoch[29](300/2500): Loss: 0.2771
===> Epoch[29](400/2500): Loss: 0.2879
===> Epoch[29](500/2500): Loss: 0.2924
===> Epoch[29](600/2500): Loss: 0.2876
===> Epoch[29](700/2500): Loss: 0.2877
===> Epoch[29](800/2500): Loss: 0.2851
===> Epoch[29](900/2500): Loss: 0.2637
===> Epoch[29](1000/2500): Loss: 0.2772
===> Epoch[29](1100/2500): Loss: 0.2842
===> Epoch[29](1200/2500): Loss: 0.2967
===> Epoch[29](1300/2500): Loss: 0.2759
===> Epoch[29](1400/2500): Loss: 0.3074
===> Epoch[29](1500/2500): Loss: 0.3044
===> Epoch[29](1600/2500): Loss: 0.2801
===> Epoch[29](1700/2500): Loss: 0.3051
===> Epoch[29](1800/2500): Loss: 0.3182
===> Epoch[29](1900/2500): Loss: 0.3083
===> Epoch[29](2000/2500): Loss: 0.2885
===> Epoch[29](2100/2500): Loss: 0.2833
===> Epoch[29](2200/2500): Loss: 0.3116
===> Epoch[29](2300/2500): Loss: 0.3041
===> Epoch[29](2400/2500): Loss: 0.3050
===> Epoch[29](2500/2500): Loss: 0.2816
===> Epoch 29 Complete: Avg. Loss: 0.2869
===> Timestamp: [2025-08-03 21:43:40]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2997
===> Epoch[29](200/2500): Loss: 0.2805
===> Epoch[29](300/2500): Loss: 0.2771
===> Epoch[29](400/2500): Loss: 0.2879
===> Epoch[29](500/2500): Loss: 0.2924
===> Epoch[29](600/2500): Loss: 0.2876
===> Epoch[29](700/2500): Loss: 0.2877
===> Epoch[29](800/2500): Loss: 0.2851
===> Epoch[29](900/2500): Loss: 0.2637
===> Epoch[29](1000/2500): Loss: 0.2772
===> Epoch[29](1100/2500): Loss: 0.2842
===> Epoch[29](1200/2500): Loss: 0.2967
===> Epoch[29](1300/2500): Loss: 0.2759
===> Epoch[29](1400/2500): Loss: 0.3074
===> Epoch[29](1500/2500): Loss: 0.3044
===> Epoch[29](1600/2500): Loss: 0.2801
===> Epoch[29](1700/2500): Loss: 0.3051
===> Epoch[29](1800/2500): Loss: 0.3182
===> Epoch[29](1900/2500): Loss: 0.3083
===> Epoch[29](2000/2500): Loss: 0.2885
===> Epoch[29](2100/2500): Loss: 0.2833
===> Epoch[29](2200/2500): Loss: 0.3116
===> Epoch[29](2300/2500): Loss: 0.3041
===> Epoch[29](2400/2500): Loss: 0.3050
===> Epoch[29](2500/2500): Loss: 0.2816
===> Epoch 29 Complete: Avg. Loss: 0.2869
===> Timestamp: [2025-08-03 21:43:40]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2997
===> Epoch[29](200/2500): Loss: 0.2805
===> Epoch[29](300/2500): Loss: 0.2771
===> Epoch[29](400/2500): Loss: 0.2879
===> Epoch[29](500/2500): Loss: 0.2924
===> Epoch[29](600/2500): Loss: 0.2876
===> Epoch[29](700/2500): Loss: 0.2877
===> Epoch[29](800/2500): Loss: 0.2851
===> Epoch[29](900/2500): Loss: 0.2637
===> Epoch[29](1000/2500): Loss: 0.2772
===> Epoch[29](1100/2500): Loss: 0.2842
===> Epoch[29](1200/2500): Loss: 0.2967
===> Epoch[29](1300/2500): Loss: 0.2759
===> Epoch[29](1400/2500): Loss: 0.3074
===> Epoch[29](1500/2500): Loss: 0.3044
===> Epoch[29](1600/2500): Loss: 0.2801
===> Epoch[29](1700/2500): Loss: 0.3051
===> Epoch[29](1800/2500): Loss: 0.3182
===> Epoch[29](1900/2500): Loss: 0.3083
===> Epoch[29](2000/2500): Loss: 0.2885
===> Epoch[29](2100/2500): Loss: 0.2833
===> Epoch[29](2200/2500): Loss: 0.3116
===> Epoch[29](2300/2500): Loss: 0.3041
===> Epoch[29](2400/2500): Loss: 0.3050
===> Epoch[29](2500/2500): Loss: 0.2816
===> Epoch 29 Complete: Avg. Loss: 0.2869
===> Timestamp: [2025-08-03 21:43:40]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2997
===> Epoch[29](200/2500): Loss: 0.2805
===> Epoch[29](300/2500): Loss: 0.2771
===> Epoch[29](400/2500): Loss: 0.2879
===> Epoch[29](500/2500): Loss: 0.2924
===> Epoch[29](600/2500): Loss: 0.2876
===> Epoch[29](700/2500): Loss: 0.2877
===> Epoch[29](800/2500): Loss: 0.2851
===> Epoch[29](900/2500): Loss: 0.2637
===> Epoch[29](1000/2500): Loss: 0.2772
===> Epoch[29](1100/2500): Loss: 0.2842
===> Epoch[29](1200/2500): Loss: 0.2967
===> Epoch[29](1300/2500): Loss: 0.2759
===> Epoch[29](1400/2500): Loss: 0.3074
===> Epoch[29](1500/2500): Loss: 0.3044
===> Epoch[29](1600/2500): Loss: 0.2801
===> Epoch[29](1700/2500): Loss: 0.3051
===> Epoch[29](1800/2500): Loss: 0.3182
===> Epoch[29](1900/2500): Loss: 0.3083
===> Epoch[29](2000/2500): Loss: 0.2885
===> Epoch[29](2100/2500): Loss: 0.2833
===> Epoch[29](2200/2500): Loss: 0.3116
===> Epoch[29](2300/2500): Loss: 0.3041
===> Epoch[29](2400/2500): Loss: 0.3050
===> Epoch[29](2500/2500): Loss: 0.2816
===> Epoch 29 Complete: Avg. Loss: 0.2869
===> Timestamp: [2025-08-03 21:43:40]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2997
===> Epoch[29](200/2500): Loss: 0.2805
===> Epoch[29](300/2500): Loss: 0.2771
===> Epoch[29](400/2500): Loss: 0.2879
===> Epoch[29](500/2500): Loss: 0.2924
===> Epoch[29](600/2500): Loss: 0.2876
===> Epoch[29](700/2500): Loss: 0.2877
===> Epoch[29](800/2500): Loss: 0.2851
===> Epoch[29](900/2500): Loss: 0.2637
===> Epoch[29](1000/2500): Loss: 0.2772
===> Epoch[29](1100/2500): Loss: 0.2842
===> Epoch[29](1200/2500): Loss: 0.2967
===> Epoch[29](1300/2500): Loss: 0.2759
===> Epoch[29](1400/2500): Loss: 0.3074
===> Epoch[29](1500/2500): Loss: 0.3044
===> Epoch[29](1600/2500): Loss: 0.2801
===> Epoch[29](1700/2500): Loss: 0.3051
===> Epoch[29](1800/2500): Loss: 0.3182
===> Epoch[29](1900/2500): Loss: 0.3083
===> Epoch[29](2000/2500): Loss: 0.2885
===> Epoch[29](2100/2500): Loss: 0.2833
===> Epoch[29](2200/2500): Loss: 0.3116
===> Epoch[29](2300/2500): Loss: 0.3041
===> Epoch[29](2400/2500): Loss: 0.3050
===> Epoch[29](2500/2500): Loss: 0.2816
===> Epoch 29 Complete: Avg. Loss: 0.2869
===> Timestamp: [2025-08-03 21:43:40]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2997
===> Epoch[29](200/2500): Loss: 0.2805
===> Epoch[29](300/2500): Loss: 0.2771
===> Epoch[29](400/2500): Loss: 0.2879
===> Epoch[29](500/2500): Loss: 0.2924
===> Epoch[29](600/2500): Loss: 0.2876
===> Epoch[29](700/2500): Loss: 0.2877
===> Epoch[29](800/2500): Loss: 0.2851
===> Epoch[29](900/2500): Loss: 0.2637
===> Epoch[29](1000/2500): Loss: 0.2772
===> Epoch[29](1100/2500): Loss: 0.2842
===> Epoch[29](1200/2500): Loss: 0.2967
===> Epoch[29](1300/2500): Loss: 0.2759
===> Epoch[29](1400/2500): Loss: 0.3074
===> Epoch[29](1500/2500): Loss: 0.3044
===> Epoch[29](1600/2500): Loss: 0.2801
===> Epoch[29](1700/2500): Loss: 0.3051
===> Epoch[29](1800/2500): Loss: 0.3182
===> Epoch[29](1900/2500): Loss: 0.3083
===> Epoch[29](2000/2500): Loss: 0.2885
===> Epoch[29](2100/2500): Loss: 0.2833
===> Epoch[29](2200/2500): Loss: 0.3116
===> Epoch[29](2300/2500): Loss: 0.3041
===> Epoch[29](2400/2500): Loss: 0.3050
===> Epoch[29](2500/2500): Loss: 0.2816
===> Epoch 29 Complete: Avg. Loss: 0.2869
===> Timestamp: [2025-08-03 21:43:40]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2997
===> Epoch[29](200/2500): Loss: 0.2805
===> Epoch[29](300/2500): Loss: 0.2771
===> Epoch[29](400/2500): Loss: 0.2879
===> Epoch[29](500/2500): Loss: 0.2924
===> Epoch[29](600/2500): Loss: 0.2876
===> Epoch[29](700/2500): Loss: 0.2877
===> Epoch[29](800/2500): Loss: 0.2851
===> Epoch[29](900/2500): Loss: 0.2637
===> Epoch[29](1000/2500): Loss: 0.2772
===> Epoch[29](1100/2500): Loss: 0.2842
===> Epoch[29](1200/2500): Loss: 0.2967
===> Epoch[29](1300/2500): Loss: 0.2759
===> Epoch[29](1400/2500): Loss: 0.3074
===> Epoch[29](1500/2500): Loss: 0.3044
===> Epoch[29](1600/2500): Loss: 0.2801
===> Epoch[29](1700/2500): Loss: 0.3051
===> Epoch[29](1800/2500): Loss: 0.3182
===> Epoch[29](1900/2500): Loss: 0.3083
===> Epoch[29](2000/2500): Loss: 0.2885
===> Epoch[29](2100/2500): Loss: 0.2833
===> Epoch[29](2200/2500): Loss: 0.3116
===> Epoch[29](2300/2500): Loss: 0.3041
===> Epoch[29](2400/2500): Loss: 0.3050
===> Epoch[29](2500/2500): Loss: 0.2816
===> Epoch 29 Complete: Avg. Loss: 0.2869
===> Timestamp: [2025-08-03 21:43:40]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2997
===> Epoch[29](200/2500): Loss: 0.2805
===> Epoch[29](300/2500): Loss: 0.2771
===> Epoch[29](400/2500): Loss: 0.2879
===> Epoch[29](500/2500): Loss: 0.2924
===> Epoch[29](600/2500): Loss: 0.2876
===> Epoch[29](700/2500): Loss: 0.2877
===> Epoch[29](800/2500): Loss: 0.2851
===> Epoch[29](900/2500): Loss: 0.2637
===> Epoch[29](1000/2500): Loss: 0.2772
===> Epoch[29](1100/2500): Loss: 0.2842
===> Epoch[29](1200/2500): Loss: 0.2967
===> Epoch[29](1300/2500): Loss: 0.2759
===> Epoch[29](1400/2500): Loss: 0.3074
===> Epoch[29](1500/2500): Loss: 0.3044
===> Epoch[29](1600/2500): Loss: 0.2801
===> Epoch[29](1700/2500): Loss: 0.3051
===> Epoch[29](1800/2500): Loss: 0.3182
===> Epoch[29](1900/2500): Loss: 0.3083
===> Epoch[29](2000/2500): Loss: 0.2885
===> Epoch[29](2100/2500): Loss: 0.2833
===> Epoch[29](2200/2500): Loss: 0.3116
===> Epoch[29](2300/2500): Loss: 0.3041
===> Epoch[29](2400/2500): Loss: 0.3050
===> Epoch[29](2500/2500): Loss: 0.2816
===> Epoch 29 Complete: Avg. Loss: 0.2869
===> Timestamp: [2025-08-03 21:43:40]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2997
===> Epoch[29](200/2500): Loss: 0.2805
===> Epoch[29](300/2500): Loss: 0.2771
===> Epoch[29](400/2500): Loss: 0.2879
===> Epoch[29](500/2500): Loss: 0.2924
===> Epoch[29](600/2500): Loss: 0.2876
===> Epoch[29](700/2500): Loss: 0.2877
===> Epoch[29](800/2500): Loss: 0.2851
===> Epoch[29](900/2500): Loss: 0.2637
===> Epoch[29](1000/2500): Loss: 0.2772
===> Epoch[29](1100/2500): Loss: 0.2842
===> Epoch[29](1200/2500): Loss: 0.2967
===> Epoch[29](1300/2500): Loss: 0.2759
===> Epoch[29](1400/2500): Loss: 0.3074
===> Epoch[29](1500/2500): Loss: 0.3044
===> Epoch[29](1600/2500): Loss: 0.2801
===> Epoch[29](1700/2500): Loss: 0.3051
===> Epoch[29](1800/2500): Loss: 0.3182
===> Epoch[29](1900/2500): Loss: 0.3083
===> Epoch[29](2000/2500): Loss: 0.2885
===> Epoch[29](2100/2500): Loss: 0.2833
===> Epoch[29](2200/2500): Loss: 0.3116
===> Epoch[29](2300/2500): Loss: 0.3041
===> Epoch[29](2400/2500): Loss: 0.3050
===> Epoch[29](2500/2500): Loss: 0.2816
===> Epoch 29 Complete: Avg. Loss: 0.2869
===> Timestamp: [2025-08-03 21:43:40]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2997
===> Epoch[29](200/2500): Loss: 0.2805
===> Epoch[29](300/2500): Loss: 0.2771
===> Epoch[29](400/2500): Loss: 0.2879
===> Epoch[29](500/2500): Loss: 0.2924
===> Epoch[29](600/2500): Loss: 0.2876
===> Epoch[29](700/2500): Loss: 0.2877
===> Epoch[29](800/2500): Loss: 0.2851
===> Epoch[29](900/2500): Loss: 0.2637
===> Epoch[29](1000/2500): Loss: 0.2772
===> Epoch[29](1100/2500): Loss: 0.2842
===> Epoch[29](1200/2500): Loss: 0.2967
===> Epoch[29](1300/2500): Loss: 0.2759
===> Epoch[29](1400/2500): Loss: 0.3074
===> Epoch[29](1500/2500): Loss: 0.3044
===> Epoch[29](1600/2500): Loss: 0.2801
===> Epoch[29](1700/2500): Loss: 0.3051
===> Epoch[29](1800/2500): Loss: 0.3182
===> Epoch[29](1900/2500): Loss: 0.3083
===> Epoch[29](2000/2500): Loss: 0.2885
===> Epoch[29](2100/2500): Loss: 0.2833
===> Epoch[29](2200/2500): Loss: 0.3116
===> Epoch[29](2300/2500): Loss: 0.3041
===> Epoch[29](2400/2500): Loss: 0.3050
===> Epoch[29](2500/2500): Loss: 0.2816
===> Epoch 29 Complete: Avg. Loss: 0.2869
===> Timestamp: [2025-08-03 21:43:40]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2997
===> Epoch[29](200/2500): Loss: 0.2805
===> Epoch[29](300/2500): Loss: 0.2771
===> Epoch[29](400/2500): Loss: 0.2879
===> Epoch[29](500/2500): Loss: 0.2924
===> Epoch[29](600/2500): Loss: 0.2876
===> Epoch[29](700/2500): Loss: 0.2877
===> Epoch[29](800/2500): Loss: 0.2851
===> Epoch[29](900/2500): Loss: 0.2637
===> Epoch[29](1000/2500): Loss: 0.2772
===> Epoch[29](1100/2500): Loss: 0.2842
===> Epoch[29](1200/2500): Loss: 0.2967
===> Epoch[29](1300/2500): Loss: 0.2759
===> Epoch[29](1400/2500): Loss: 0.3074
===> Epoch[29](1500/2500): Loss: 0.3044
===> Epoch[29](1600/2500): Loss: 0.2801
===> Epoch[29](1700/2500): Loss: 0.3051
===> Epoch[29](1800/2500): Loss: 0.3182
===> Epoch[29](1900/2500): Loss: 0.3083
===> Epoch[29](2000/2500): Loss: 0.2885
===> Epoch[29](2100/2500): Loss: 0.2833
===> Epoch[29](2200/2500): Loss: 0.3116
===> Epoch[29](2300/2500): Loss: 0.3041
===> Epoch[29](2400/2500): Loss: 0.3050
===> Epoch[29](2500/2500): Loss: 0.2816
===> Epoch 29 Complete: Avg. Loss: 0.2869
===> Timestamp: [2025-08-03 21:43:40]
===> Loading train datasets
===> Epoch[29](100/2500): Loss: 0.2997
===> Epoch[29](200/2500): Loss: 0.2805
===> Epoch[29](300/2500): Loss: 0.2771
===> Epoch[29](400/2500): Loss: 0.2879
===> Epoch[29](500/2500): Loss: 0.2924
===> Epoch[29](600/2500): Loss: 0.2876
===> Epoch[29](700/2500): Loss: 0.2877
===> Epoch[29](800/2500): Loss: 0.2851
===> Epoch[29](900/2500): Loss: 0.2637
===> Epoch[29](1000/2500): Loss: 0.2772
===> Epoch[29](1100/2500): Loss: 0.2842
===> Epoch[29](1200/2500): Loss: 0.2967
===> Epoch[29](1300/2500): Loss: 0.2759
===> Epoch[29](1400/2500): Loss: 0.3074
===> Epoch[29](1500/2500): Loss: 0.3044
===> Epoch[29](1600/2500): Loss: 0.2801
===> Epoch[29](1700/2500): Loss: 0.3051
===> Epoch[29](1800/2500): Loss: 0.3182
===> Epoch[29](1900/2500): Loss: 0.3083
===> Epoch[29](2000/2500): Loss: 0.2885
===> Epoch[29](2100/2500): Loss: 0.2833
===> Epoch[29](2200/2500): Loss: 0.3116
===> Epoch[29](2300/2500): Loss: 0.3041
===> Epoch[29](2400/2500): Loss: 0.3050
===> Epoch[29](2500/2500): Loss: 0.2816
===> Epoch 29 Complete: Avg. Loss: 0.2869
===> Timestamp: [2025-08-03 21:43:40]
===> Loading train datasets
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2888
===> Epoch[30](200/2500): Loss: 0.2922
===> Epoch[30](300/2500): Loss: 0.3007
===> Epoch[30](400/2500): Loss: 0.2819
===> Epoch[30](500/2500): Loss: 0.2966
===> Epoch[30](600/2500): Loss: 0.2922
===> Epoch[30](700/2500): Loss: 0.2794
===> Epoch[30](800/2500): Loss: 0.3044
===> Epoch[30](900/2500): Loss: 0.2853
===> Epoch[30](1000/2500): Loss: 0.3087
===> Epoch[30](1100/2500): Loss: 0.2876
===> Epoch[30](1200/2500): Loss: 0.2801
===> Epoch[30](1300/2500): Loss: 0.2804
===> Epoch[30](1400/2500): Loss: 0.3014
===> Epoch[30](1500/2500): Loss: 0.2915
===> Epoch[30](1600/2500): Loss: 0.2800
===> Epoch[30](1700/2500): Loss: 0.2757
===> Epoch[30](1800/2500): Loss: 0.2845
===> Epoch[30](1900/2500): Loss: 0.2754
===> Epoch[30](2000/2500): Loss: 0.2683
===> Epoch[30](2100/2500): Loss: 0.2795
===> Epoch[30](2200/2500): Loss: 0.2801
===> Epoch[30](2300/2500): Loss: 0.2998
===> Epoch[30](2400/2500): Loss: 0.2912
===> Epoch[30](2500/2500): Loss: 0.2746
===> Epoch 30 Complete: Avg. Loss: 0.2866
===> Timestamp: [2025-08-03 21:48:14]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2888
===> Epoch[30](200/2500): Loss: 0.2922
===> Epoch[30](300/2500): Loss: 0.3007
===> Epoch[30](400/2500): Loss: 0.2819
===> Epoch[30](500/2500): Loss: 0.2966
===> Epoch[30](600/2500): Loss: 0.2922
===> Epoch[30](700/2500): Loss: 0.2794
===> Epoch[30](800/2500): Loss: 0.3044
===> Epoch[30](900/2500): Loss: 0.2853
===> Epoch[30](1000/2500): Loss: 0.3087
===> Epoch[30](1100/2500): Loss: 0.2876
===> Epoch[30](1200/2500): Loss: 0.2801
===> Epoch[30](1300/2500): Loss: 0.2804
===> Epoch[30](1400/2500): Loss: 0.3014
===> Epoch[30](1500/2500): Loss: 0.2915
===> Epoch[30](1600/2500): Loss: 0.2800
===> Epoch[30](1700/2500): Loss: 0.2757
===> Epoch[30](1800/2500): Loss: 0.2845
===> Epoch[30](1900/2500): Loss: 0.2754
===> Epoch[30](2000/2500): Loss: 0.2683
===> Epoch[30](2100/2500): Loss: 0.2795
===> Epoch[30](2200/2500): Loss: 0.2801
===> Epoch[30](2300/2500): Loss: 0.2998
===> Epoch[30](2400/2500): Loss: 0.2912
===> Epoch[30](2500/2500): Loss: 0.2746
===> Epoch 30 Complete: Avg. Loss: 0.2866
===> Timestamp: [2025-08-03 21:48:14]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2888
===> Epoch[30](200/2500): Loss: 0.2922
===> Epoch[30](300/2500): Loss: 0.3007
===> Epoch[30](400/2500): Loss: 0.2819
===> Epoch[30](500/2500): Loss: 0.2966
===> Epoch[30](600/2500): Loss: 0.2922
===> Epoch[30](700/2500): Loss: 0.2794
===> Epoch[30](800/2500): Loss: 0.3044
===> Epoch[30](900/2500): Loss: 0.2853
===> Epoch[30](1000/2500): Loss: 0.3087
===> Epoch[30](1100/2500): Loss: 0.2876
===> Epoch[30](1200/2500): Loss: 0.2801
===> Epoch[30](1300/2500): Loss: 0.2804
===> Epoch[30](1400/2500): Loss: 0.3014
===> Epoch[30](1500/2500): Loss: 0.2915
===> Epoch[30](1600/2500): Loss: 0.2800
===> Epoch[30](1700/2500): Loss: 0.2757
===> Epoch[30](1800/2500): Loss: 0.2845
===> Epoch[30](1900/2500): Loss: 0.2754
===> Epoch[30](2000/2500): Loss: 0.2683
===> Epoch[30](2100/2500): Loss: 0.2795
===> Epoch[30](2200/2500): Loss: 0.2801
===> Epoch[30](2300/2500): Loss: 0.2998
===> Epoch[30](2400/2500): Loss: 0.2912
===> Epoch[30](2500/2500): Loss: 0.2746
===> Epoch 30 Complete: Avg. Loss: 0.2866
===> Timestamp: [2025-08-03 21:48:14]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2888
===> Epoch[30](200/2500): Loss: 0.2922
===> Epoch[30](300/2500): Loss: 0.3007
===> Epoch[30](400/2500): Loss: 0.2819
===> Epoch[30](500/2500): Loss: 0.2966
===> Epoch[30](600/2500): Loss: 0.2922
===> Epoch[30](700/2500): Loss: 0.2794
===> Epoch[30](800/2500): Loss: 0.3044
===> Epoch[30](900/2500): Loss: 0.2853
===> Epoch[30](1000/2500): Loss: 0.3087
===> Epoch[30](1100/2500): Loss: 0.2876
===> Epoch[30](1200/2500): Loss: 0.2801
===> Epoch[30](1300/2500): Loss: 0.2804
===> Epoch[30](1400/2500): Loss: 0.3014
===> Epoch[30](1500/2500): Loss: 0.2915
===> Epoch[30](1600/2500): Loss: 0.2800
===> Epoch[30](1700/2500): Loss: 0.2757
===> Epoch[30](1800/2500): Loss: 0.2845
===> Epoch[30](1900/2500): Loss: 0.2754
===> Epoch[30](2000/2500): Loss: 0.2683
===> Epoch[30](2100/2500): Loss: 0.2795
===> Epoch[30](2200/2500): Loss: 0.2801
===> Epoch[30](2300/2500): Loss: 0.2998
===> Epoch[30](2400/2500): Loss: 0.2912
===> Epoch[30](2500/2500): Loss: 0.2746
===> Epoch 30 Complete: Avg. Loss: 0.2866
===> Timestamp: [2025-08-03 21:48:14]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2888
===> Epoch[30](200/2500): Loss: 0.2922
===> Epoch[30](300/2500): Loss: 0.3007
===> Epoch[30](400/2500): Loss: 0.2819
===> Epoch[30](500/2500): Loss: 0.2966
===> Epoch[30](600/2500): Loss: 0.2922
===> Epoch[30](700/2500): Loss: 0.2794
===> Epoch[30](800/2500): Loss: 0.3044
===> Epoch[30](900/2500): Loss: 0.2853
===> Epoch[30](1000/2500): Loss: 0.3087
===> Epoch[30](1100/2500): Loss: 0.2876
===> Epoch[30](1200/2500): Loss: 0.2801
===> Epoch[30](1300/2500): Loss: 0.2804
===> Epoch[30](1400/2500): Loss: 0.3014
===> Epoch[30](1500/2500): Loss: 0.2915
===> Epoch[30](1600/2500): Loss: 0.2800
===> Epoch[30](1700/2500): Loss: 0.2757
===> Epoch[30](1800/2500): Loss: 0.2845
===> Epoch[30](1900/2500): Loss: 0.2754
===> Epoch[30](2000/2500): Loss: 0.2683
===> Epoch[30](2100/2500): Loss: 0.2795
===> Epoch[30](2200/2500): Loss: 0.2801
===> Epoch[30](2300/2500): Loss: 0.2998
===> Epoch[30](2400/2500): Loss: 0.2912
===> Epoch[30](2500/2500): Loss: 0.2746
===> Epoch 30 Complete: Avg. Loss: 0.2866
===> Timestamp: [2025-08-03 21:48:14]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2888
===> Epoch[30](200/2500): Loss: 0.2922
===> Epoch[30](300/2500): Loss: 0.3007
===> Epoch[30](400/2500): Loss: 0.2819
===> Epoch[30](500/2500): Loss: 0.2966
===> Epoch[30](600/2500): Loss: 0.2922
===> Epoch[30](700/2500): Loss: 0.2794
===> Epoch[30](800/2500): Loss: 0.3044
===> Epoch[30](900/2500): Loss: 0.2853
===> Epoch[30](1000/2500): Loss: 0.3087
===> Epoch[30](1100/2500): Loss: 0.2876
===> Epoch[30](1200/2500): Loss: 0.2801
===> Epoch[30](1300/2500): Loss: 0.2804
===> Epoch[30](1400/2500): Loss: 0.3014
===> Epoch[30](1500/2500): Loss: 0.2915
===> Epoch[30](1600/2500): Loss: 0.2800
===> Epoch[30](1700/2500): Loss: 0.2757
===> Epoch[30](1800/2500): Loss: 0.2845
===> Epoch[30](1900/2500): Loss: 0.2754
===> Epoch[30](2000/2500): Loss: 0.2683
===> Epoch[30](2100/2500): Loss: 0.2795
===> Epoch[30](2200/2500): Loss: 0.2801
===> Epoch[30](2300/2500): Loss: 0.2998
===> Epoch[30](2400/2500): Loss: 0.2912
===> Epoch[30](2500/2500): Loss: 0.2746
===> Epoch 30 Complete: Avg. Loss: 0.2866
===> Timestamp: [2025-08-03 21:48:14]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2888
===> Epoch[30](200/2500): Loss: 0.2922
===> Epoch[30](300/2500): Loss: 0.3007
===> Epoch[30](400/2500): Loss: 0.2819
===> Epoch[30](500/2500): Loss: 0.2966
===> Epoch[30](600/2500): Loss: 0.2922
===> Epoch[30](700/2500): Loss: 0.2794
===> Epoch[30](800/2500): Loss: 0.3044
===> Epoch[30](900/2500): Loss: 0.2853
===> Epoch[30](1000/2500): Loss: 0.3087
===> Epoch[30](1100/2500): Loss: 0.2876
===> Epoch[30](1200/2500): Loss: 0.2801
===> Epoch[30](1300/2500): Loss: 0.2804
===> Epoch[30](1400/2500): Loss: 0.3014
===> Epoch[30](1500/2500): Loss: 0.2915
===> Epoch[30](1600/2500): Loss: 0.2800
===> Epoch[30](1700/2500): Loss: 0.2757
===> Epoch[30](1800/2500): Loss: 0.2845
===> Epoch[30](1900/2500): Loss: 0.2754
===> Epoch[30](2000/2500): Loss: 0.2683
===> Epoch[30](2100/2500): Loss: 0.2795
===> Epoch[30](2200/2500): Loss: 0.2801
===> Epoch[30](2300/2500): Loss: 0.2998
===> Epoch[30](2400/2500): Loss: 0.2912
===> Epoch[30](2500/2500): Loss: 0.2746
===> Epoch 30 Complete: Avg. Loss: 0.2866
===> Timestamp: [2025-08-03 21:48:14]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2888
===> Epoch[30](200/2500): Loss: 0.2922
===> Epoch[30](300/2500): Loss: 0.3007
===> Epoch[30](400/2500): Loss: 0.2819
===> Epoch[30](500/2500): Loss: 0.2966
===> Epoch[30](600/2500): Loss: 0.2922
===> Epoch[30](700/2500): Loss: 0.2794
===> Epoch[30](800/2500): Loss: 0.3044
===> Epoch[30](900/2500): Loss: 0.2853
===> Epoch[30](1000/2500): Loss: 0.3087
===> Epoch[30](1100/2500): Loss: 0.2876
===> Epoch[30](1200/2500): Loss: 0.2801
===> Epoch[30](1300/2500): Loss: 0.2804
===> Epoch[30](1400/2500): Loss: 0.3014
===> Epoch[30](1500/2500): Loss: 0.2915
===> Epoch[30](1600/2500): Loss: 0.2800
===> Epoch[30](1700/2500): Loss: 0.2757
===> Epoch[30](1800/2500): Loss: 0.2845
===> Epoch[30](1900/2500): Loss: 0.2754
===> Epoch[30](2000/2500): Loss: 0.2683
===> Epoch[30](2100/2500): Loss: 0.2795
===> Epoch[30](2200/2500): Loss: 0.2801
===> Epoch[30](2300/2500): Loss: 0.2998
===> Epoch[30](2400/2500): Loss: 0.2912
===> Epoch[30](2500/2500): Loss: 0.2746
===> Epoch 30 Complete: Avg. Loss: 0.2866
===> Timestamp: [2025-08-03 21:48:14]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2888
===> Epoch[30](200/2500): Loss: 0.2922
===> Epoch[30](300/2500): Loss: 0.3007
===> Epoch[30](400/2500): Loss: 0.2819
===> Epoch[30](500/2500): Loss: 0.2966
===> Epoch[30](600/2500): Loss: 0.2922
===> Epoch[30](700/2500): Loss: 0.2794
===> Epoch[30](800/2500): Loss: 0.3044
===> Epoch[30](900/2500): Loss: 0.2853
===> Epoch[30](1000/2500): Loss: 0.3087
===> Epoch[30](1100/2500): Loss: 0.2876
===> Epoch[30](1200/2500): Loss: 0.2801
===> Epoch[30](1300/2500): Loss: 0.2804
===> Epoch[30](1400/2500): Loss: 0.3014
===> Epoch[30](1500/2500): Loss: 0.2915
===> Epoch[30](1600/2500): Loss: 0.2800
===> Epoch[30](1700/2500): Loss: 0.2757
===> Epoch[30](1800/2500): Loss: 0.2845
===> Epoch[30](1900/2500): Loss: 0.2754
===> Epoch[30](2000/2500): Loss: 0.2683
===> Epoch[30](2100/2500): Loss: 0.2795
===> Epoch[30](2200/2500): Loss: 0.2801
===> Epoch[30](2300/2500): Loss: 0.2998
===> Epoch[30](2400/2500): Loss: 0.2912
===> Epoch[30](2500/2500): Loss: 0.2746
===> Epoch 30 Complete: Avg. Loss: 0.2866
===> Timestamp: [2025-08-03 21:48:14]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2888
===> Epoch[30](200/2500): Loss: 0.2922
===> Epoch[30](300/2500): Loss: 0.3007
===> Epoch[30](400/2500): Loss: 0.2819
===> Epoch[30](500/2500): Loss: 0.2966
===> Epoch[30](600/2500): Loss: 0.2922
===> Epoch[30](700/2500): Loss: 0.2794
===> Epoch[30](800/2500): Loss: 0.3044
===> Epoch[30](900/2500): Loss: 0.2853
===> Epoch[30](1000/2500): Loss: 0.3087
===> Epoch[30](1100/2500): Loss: 0.2876
===> Epoch[30](1200/2500): Loss: 0.2801
===> Epoch[30](1300/2500): Loss: 0.2804
===> Epoch[30](1400/2500): Loss: 0.3014
===> Epoch[30](1500/2500): Loss: 0.2915
===> Epoch[30](1600/2500): Loss: 0.2800
===> Epoch[30](1700/2500): Loss: 0.2757
===> Epoch[30](1800/2500): Loss: 0.2845
===> Epoch[30](1900/2500): Loss: 0.2754
===> Epoch[30](2000/2500): Loss: 0.2683
===> Epoch[30](2100/2500): Loss: 0.2795
===> Epoch[30](2200/2500): Loss: 0.2801
===> Epoch[30](2300/2500): Loss: 0.2998
===> Epoch[30](2400/2500): Loss: 0.2912
===> Epoch[30](2500/2500): Loss: 0.2746
===> Epoch 30 Complete: Avg. Loss: 0.2866
===> Timestamp: [2025-08-03 21:48:14]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2888
===> Epoch[30](200/2500): Loss: 0.2922
===> Epoch[30](300/2500): Loss: 0.3007
===> Epoch[30](400/2500): Loss: 0.2819
===> Epoch[30](500/2500): Loss: 0.2966
===> Epoch[30](600/2500): Loss: 0.2922
===> Epoch[30](700/2500): Loss: 0.2794
===> Epoch[30](800/2500): Loss: 0.3044
===> Epoch[30](900/2500): Loss: 0.2853
===> Epoch[30](1000/2500): Loss: 0.3087
===> Epoch[30](1100/2500): Loss: 0.2876
===> Epoch[30](1200/2500): Loss: 0.2801
===> Epoch[30](1300/2500): Loss: 0.2804
===> Epoch[30](1400/2500): Loss: 0.3014
===> Epoch[30](1500/2500): Loss: 0.2915
===> Epoch[30](1600/2500): Loss: 0.2800
===> Epoch[30](1700/2500): Loss: 0.2757
===> Epoch[30](1800/2500): Loss: 0.2845
===> Epoch[30](1900/2500): Loss: 0.2754
===> Epoch[30](2000/2500): Loss: 0.2683
===> Epoch[30](2100/2500): Loss: 0.2795
===> Epoch[30](2200/2500): Loss: 0.2801
===> Epoch[30](2300/2500): Loss: 0.2998
===> Epoch[30](2400/2500): Loss: 0.2912
===> Epoch[30](2500/2500): Loss: 0.2746
===> Epoch 30 Complete: Avg. Loss: 0.2866
===> Timestamp: [2025-08-03 21:48:14]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2888
===> Epoch[30](200/2500): Loss: 0.2922
===> Epoch[30](300/2500): Loss: 0.3007
===> Epoch[30](400/2500): Loss: 0.2819
===> Epoch[30](500/2500): Loss: 0.2966
===> Epoch[30](600/2500): Loss: 0.2922
===> Epoch[30](700/2500): Loss: 0.2794
===> Epoch[30](800/2500): Loss: 0.3044
===> Epoch[30](900/2500): Loss: 0.2853
===> Epoch[30](1000/2500): Loss: 0.3087
===> Epoch[30](1100/2500): Loss: 0.2876
===> Epoch[30](1200/2500): Loss: 0.2801
===> Epoch[30](1300/2500): Loss: 0.2804
===> Epoch[30](1400/2500): Loss: 0.3014
===> Epoch[30](1500/2500): Loss: 0.2915
===> Epoch[30](1600/2500): Loss: 0.2800
===> Epoch[30](1700/2500): Loss: 0.2757
===> Epoch[30](1800/2500): Loss: 0.2845
===> Epoch[30](1900/2500): Loss: 0.2754
===> Epoch[30](2000/2500): Loss: 0.2683
===> Epoch[30](2100/2500): Loss: 0.2795
===> Epoch[30](2200/2500): Loss: 0.2801
===> Epoch[30](2300/2500): Loss: 0.2998
===> Epoch[30](2400/2500): Loss: 0.2912
===> Epoch[30](2500/2500): Loss: 0.2746
===> Epoch 30 Complete: Avg. Loss: 0.2866
===> Timestamp: [2025-08-03 21:48:14]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2888
===> Epoch[30](200/2500): Loss: 0.2922
===> Epoch[30](300/2500): Loss: 0.3007
===> Epoch[30](400/2500): Loss: 0.2819
===> Epoch[30](500/2500): Loss: 0.2966
===> Epoch[30](600/2500): Loss: 0.2922
===> Epoch[30](700/2500): Loss: 0.2794
===> Epoch[30](800/2500): Loss: 0.3044
===> Epoch[30](900/2500): Loss: 0.2853
===> Epoch[30](1000/2500): Loss: 0.3087
===> Epoch[30](1100/2500): Loss: 0.2876
===> Epoch[30](1200/2500): Loss: 0.2801
===> Epoch[30](1300/2500): Loss: 0.2804
===> Epoch[30](1400/2500): Loss: 0.3014
===> Epoch[30](1500/2500): Loss: 0.2915
===> Epoch[30](1600/2500): Loss: 0.2800
===> Epoch[30](1700/2500): Loss: 0.2757
===> Epoch[30](1800/2500): Loss: 0.2845
===> Epoch[30](1900/2500): Loss: 0.2754
===> Epoch[30](2000/2500): Loss: 0.2683
===> Epoch[30](2100/2500): Loss: 0.2795
===> Epoch[30](2200/2500): Loss: 0.2801
===> Epoch[30](2300/2500): Loss: 0.2998
===> Epoch[30](2400/2500): Loss: 0.2912
===> Epoch[30](2500/2500): Loss: 0.2746
===> Epoch 30 Complete: Avg. Loss: 0.2866
===> Timestamp: [2025-08-03 21:48:14]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2888
===> Epoch[30](200/2500): Loss: 0.2922
===> Epoch[30](300/2500): Loss: 0.3007
===> Epoch[30](400/2500): Loss: 0.2819
===> Epoch[30](500/2500): Loss: 0.2966
===> Epoch[30](600/2500): Loss: 0.2922
===> Epoch[30](700/2500): Loss: 0.2794
===> Epoch[30](800/2500): Loss: 0.3044
===> Epoch[30](900/2500): Loss: 0.2853
===> Epoch[30](1000/2500): Loss: 0.3087
===> Epoch[30](1100/2500): Loss: 0.2876
===> Epoch[30](1200/2500): Loss: 0.2801
===> Epoch[30](1300/2500): Loss: 0.2804
===> Epoch[30](1400/2500): Loss: 0.3014
===> Epoch[30](1500/2500): Loss: 0.2915
===> Epoch[30](1600/2500): Loss: 0.2800
===> Epoch[30](1700/2500): Loss: 0.2757
===> Epoch[30](1800/2500): Loss: 0.2845
===> Epoch[30](1900/2500): Loss: 0.2754
===> Epoch[30](2000/2500): Loss: 0.2683
===> Epoch[30](2100/2500): Loss: 0.2795
===> Epoch[30](2200/2500): Loss: 0.2801
===> Epoch[30](2300/2500): Loss: 0.2998
===> Epoch[30](2400/2500): Loss: 0.2912
===> Epoch[30](2500/2500): Loss: 0.2746
===> Epoch 30 Complete: Avg. Loss: 0.2866
===> Timestamp: [2025-08-03 21:48:14]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2888
===> Epoch[30](200/2500): Loss: 0.2922
===> Epoch[30](300/2500): Loss: 0.3007
===> Epoch[30](400/2500): Loss: 0.2819
===> Epoch[30](500/2500): Loss: 0.2966
===> Epoch[30](600/2500): Loss: 0.2922
===> Epoch[30](700/2500): Loss: 0.2794
===> Epoch[30](800/2500): Loss: 0.3044
===> Epoch[30](900/2500): Loss: 0.2853
===> Epoch[30](1000/2500): Loss: 0.3087
===> Epoch[30](1100/2500): Loss: 0.2876
===> Epoch[30](1200/2500): Loss: 0.2801
===> Epoch[30](1300/2500): Loss: 0.2804
===> Epoch[30](1400/2500): Loss: 0.3014
===> Epoch[30](1500/2500): Loss: 0.2915
===> Epoch[30](1600/2500): Loss: 0.2800
===> Epoch[30](1700/2500): Loss: 0.2757
===> Epoch[30](1800/2500): Loss: 0.2845
===> Epoch[30](1900/2500): Loss: 0.2754
===> Epoch[30](2000/2500): Loss: 0.2683
===> Epoch[30](2100/2500): Loss: 0.2795
===> Epoch[30](2200/2500): Loss: 0.2801
===> Epoch[30](2300/2500): Loss: 0.2998
===> Epoch[30](2400/2500): Loss: 0.2912
===> Epoch[30](2500/2500): Loss: 0.2746
===> Epoch 30 Complete: Avg. Loss: 0.2866
===> Timestamp: [2025-08-03 21:48:14]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2888
===> Epoch[30](200/2500): Loss: 0.2922
===> Epoch[30](300/2500): Loss: 0.3007
===> Epoch[30](400/2500): Loss: 0.2819
===> Epoch[30](500/2500): Loss: 0.2966
===> Epoch[30](600/2500): Loss: 0.2922
===> Epoch[30](700/2500): Loss: 0.2794
===> Epoch[30](800/2500): Loss: 0.3044
===> Epoch[30](900/2500): Loss: 0.2853
===> Epoch[30](1000/2500): Loss: 0.3087
===> Epoch[30](1100/2500): Loss: 0.2876
===> Epoch[30](1200/2500): Loss: 0.2801
===> Epoch[30](1300/2500): Loss: 0.2804
===> Epoch[30](1400/2500): Loss: 0.3014
===> Epoch[30](1500/2500): Loss: 0.2915
===> Epoch[30](1600/2500): Loss: 0.2800
===> Epoch[30](1700/2500): Loss: 0.2757
===> Epoch[30](1800/2500): Loss: 0.2845
===> Epoch[30](1900/2500): Loss: 0.2754
===> Epoch[30](2000/2500): Loss: 0.2683
===> Epoch[30](2100/2500): Loss: 0.2795
===> Epoch[30](2200/2500): Loss: 0.2801
===> Epoch[30](2300/2500): Loss: 0.2998
===> Epoch[30](2400/2500): Loss: 0.2912
===> Epoch[30](2500/2500): Loss: 0.2746
===> Epoch 30 Complete: Avg. Loss: 0.2866
===> Timestamp: [2025-08-03 21:48:14]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2888
===> Epoch[30](200/2500): Loss: 0.2922
===> Epoch[30](300/2500): Loss: 0.3007
===> Epoch[30](400/2500): Loss: 0.2819
===> Epoch[30](500/2500): Loss: 0.2966
===> Epoch[30](600/2500): Loss: 0.2922
===> Epoch[30](700/2500): Loss: 0.2794
===> Epoch[30](800/2500): Loss: 0.3044
===> Epoch[30](900/2500): Loss: 0.2853
===> Epoch[30](1000/2500): Loss: 0.3087
===> Epoch[30](1100/2500): Loss: 0.2876
===> Epoch[30](1200/2500): Loss: 0.2801
===> Epoch[30](1300/2500): Loss: 0.2804
===> Epoch[30](1400/2500): Loss: 0.3014
===> Epoch[30](1500/2500): Loss: 0.2915
===> Epoch[30](1600/2500): Loss: 0.2800
===> Epoch[30](1700/2500): Loss: 0.2757
===> Epoch[30](1800/2500): Loss: 0.2845
===> Epoch[30](1900/2500): Loss: 0.2754
===> Epoch[30](2000/2500): Loss: 0.2683
===> Epoch[30](2100/2500): Loss: 0.2795
===> Epoch[30](2200/2500): Loss: 0.2801
===> Epoch[30](2300/2500): Loss: 0.2998
===> Epoch[30](2400/2500): Loss: 0.2912
===> Epoch[30](2500/2500): Loss: 0.2746
===> Epoch 30 Complete: Avg. Loss: 0.2866
===> Timestamp: [2025-08-03 21:48:14]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2888
===> Epoch[30](200/2500): Loss: 0.2922
===> Epoch[30](300/2500): Loss: 0.3007
===> Epoch[30](400/2500): Loss: 0.2819
===> Epoch[30](500/2500): Loss: 0.2966
===> Epoch[30](600/2500): Loss: 0.2922
===> Epoch[30](700/2500): Loss: 0.2794
===> Epoch[30](800/2500): Loss: 0.3044
===> Epoch[30](900/2500): Loss: 0.2853
===> Epoch[30](1000/2500): Loss: 0.3087
===> Epoch[30](1100/2500): Loss: 0.2876
===> Epoch[30](1200/2500): Loss: 0.2801
===> Epoch[30](1300/2500): Loss: 0.2804
===> Epoch[30](1400/2500): Loss: 0.3014
===> Epoch[30](1500/2500): Loss: 0.2915
===> Epoch[30](1600/2500): Loss: 0.2800
===> Epoch[30](1700/2500): Loss: 0.2757
===> Epoch[30](1800/2500): Loss: 0.2845
===> Epoch[30](1900/2500): Loss: 0.2754
===> Epoch[30](2000/2500): Loss: 0.2683
===> Epoch[30](2100/2500): Loss: 0.2795
===> Epoch[30](2200/2500): Loss: 0.2801
===> Epoch[30](2300/2500): Loss: 0.2998
===> Epoch[30](2400/2500): Loss: 0.2912
===> Epoch[30](2500/2500): Loss: 0.2746
===> Epoch 30 Complete: Avg. Loss: 0.2866
===> Timestamp: [2025-08-03 21:48:14]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2888
===> Epoch[30](200/2500): Loss: 0.2922
===> Epoch[30](300/2500): Loss: 0.3007
===> Epoch[30](400/2500): Loss: 0.2819
===> Epoch[30](500/2500): Loss: 0.2966
===> Epoch[30](600/2500): Loss: 0.2922
===> Epoch[30](700/2500): Loss: 0.2794
===> Epoch[30](800/2500): Loss: 0.3044
===> Epoch[30](900/2500): Loss: 0.2853
===> Epoch[30](1000/2500): Loss: 0.3087
===> Epoch[30](1100/2500): Loss: 0.2876
===> Epoch[30](1200/2500): Loss: 0.2801
===> Epoch[30](1300/2500): Loss: 0.2804
===> Epoch[30](1400/2500): Loss: 0.3014
===> Epoch[30](1500/2500): Loss: 0.2915
===> Epoch[30](1600/2500): Loss: 0.2800
===> Epoch[30](1700/2500): Loss: 0.2757
===> Epoch[30](1800/2500): Loss: 0.2845
===> Epoch[30](1900/2500): Loss: 0.2754
===> Epoch[30](2000/2500): Loss: 0.2683
===> Epoch[30](2100/2500): Loss: 0.2795
===> Epoch[30](2200/2500): Loss: 0.2801
===> Epoch[30](2300/2500): Loss: 0.2998
===> Epoch[30](2400/2500): Loss: 0.2912
===> Epoch[30](2500/2500): Loss: 0.2746
===> Epoch 30 Complete: Avg. Loss: 0.2866
===> Timestamp: [2025-08-03 21:48:14]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2888
===> Epoch[30](200/2500): Loss: 0.2922
===> Epoch[30](300/2500): Loss: 0.3007
===> Epoch[30](400/2500): Loss: 0.2819
===> Epoch[30](500/2500): Loss: 0.2966
===> Epoch[30](600/2500): Loss: 0.2922
===> Epoch[30](700/2500): Loss: 0.2794
===> Epoch[30](800/2500): Loss: 0.3044
===> Epoch[30](900/2500): Loss: 0.2853
===> Epoch[30](1000/2500): Loss: 0.3087
===> Epoch[30](1100/2500): Loss: 0.2876
===> Epoch[30](1200/2500): Loss: 0.2801
===> Epoch[30](1300/2500): Loss: 0.2804
===> Epoch[30](1400/2500): Loss: 0.3014
===> Epoch[30](1500/2500): Loss: 0.2915
===> Epoch[30](1600/2500): Loss: 0.2800
===> Epoch[30](1700/2500): Loss: 0.2757
===> Epoch[30](1800/2500): Loss: 0.2845
===> Epoch[30](1900/2500): Loss: 0.2754
===> Epoch[30](2000/2500): Loss: 0.2683
===> Epoch[30](2100/2500): Loss: 0.2795
===> Epoch[30](2200/2500): Loss: 0.2801
===> Epoch[30](2300/2500): Loss: 0.2998
===> Epoch[30](2400/2500): Loss: 0.2912
===> Epoch[30](2500/2500): Loss: 0.2746
===> Epoch 30 Complete: Avg. Loss: 0.2866
===> Timestamp: [2025-08-03 21:48:14]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2888
===> Epoch[30](200/2500): Loss: 0.2922
===> Epoch[30](300/2500): Loss: 0.3007
===> Epoch[30](400/2500): Loss: 0.2819
===> Epoch[30](500/2500): Loss: 0.2966
===> Epoch[30](600/2500): Loss: 0.2922
===> Epoch[30](700/2500): Loss: 0.2794
===> Epoch[30](800/2500): Loss: 0.3044
===> Epoch[30](900/2500): Loss: 0.2853
===> Epoch[30](1000/2500): Loss: 0.3087
===> Epoch[30](1100/2500): Loss: 0.2876
===> Epoch[30](1200/2500): Loss: 0.2801
===> Epoch[30](1300/2500): Loss: 0.2804
===> Epoch[30](1400/2500): Loss: 0.3014
===> Epoch[30](1500/2500): Loss: 0.2915
===> Epoch[30](1600/2500): Loss: 0.2800
===> Epoch[30](1700/2500): Loss: 0.2757
===> Epoch[30](1800/2500): Loss: 0.2845
===> Epoch[30](1900/2500): Loss: 0.2754
===> Epoch[30](2000/2500): Loss: 0.2683
===> Epoch[30](2100/2500): Loss: 0.2795
===> Epoch[30](2200/2500): Loss: 0.2801
===> Epoch[30](2300/2500): Loss: 0.2998
===> Epoch[30](2400/2500): Loss: 0.2912
===> Epoch[30](2500/2500): Loss: 0.2746
===> Epoch 30 Complete: Avg. Loss: 0.2866
===> Timestamp: [2025-08-03 21:48:14]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2888
===> Epoch[30](200/2500): Loss: 0.2922
===> Epoch[30](300/2500): Loss: 0.3007
===> Epoch[30](400/2500): Loss: 0.2819
===> Epoch[30](500/2500): Loss: 0.2966
===> Epoch[30](600/2500): Loss: 0.2922
===> Epoch[30](700/2500): Loss: 0.2794
===> Epoch[30](800/2500): Loss: 0.3044
===> Epoch[30](900/2500): Loss: 0.2853
===> Epoch[30](1000/2500): Loss: 0.3087
===> Epoch[30](1100/2500): Loss: 0.2876
===> Epoch[30](1200/2500): Loss: 0.2801
===> Epoch[30](1300/2500): Loss: 0.2804
===> Epoch[30](1400/2500): Loss: 0.3014
===> Epoch[30](1500/2500): Loss: 0.2915
===> Epoch[30](1600/2500): Loss: 0.2800
===> Epoch[30](1700/2500): Loss: 0.2757
===> Epoch[30](1800/2500): Loss: 0.2845
===> Epoch[30](1900/2500): Loss: 0.2754
===> Epoch[30](2000/2500): Loss: 0.2683
===> Epoch[30](2100/2500): Loss: 0.2795
===> Epoch[30](2200/2500): Loss: 0.2801
===> Epoch[30](2300/2500): Loss: 0.2998
===> Epoch[30](2400/2500): Loss: 0.2912
===> Epoch[30](2500/2500): Loss: 0.2746
===> Epoch 30 Complete: Avg. Loss: 0.2866
===> Timestamp: [2025-08-03 21:48:14]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2888
===> Epoch[30](200/2500): Loss: 0.2922
===> Epoch[30](300/2500): Loss: 0.3007
===> Epoch[30](400/2500): Loss: 0.2819
===> Epoch[30](500/2500): Loss: 0.2966
===> Epoch[30](600/2500): Loss: 0.2922
===> Epoch[30](700/2500): Loss: 0.2794
===> Epoch[30](800/2500): Loss: 0.3044
===> Epoch[30](900/2500): Loss: 0.2853
===> Epoch[30](1000/2500): Loss: 0.3087
===> Epoch[30](1100/2500): Loss: 0.2876
===> Epoch[30](1200/2500): Loss: 0.2801
===> Epoch[30](1300/2500): Loss: 0.2804
===> Epoch[30](1400/2500): Loss: 0.3014
===> Epoch[30](1500/2500): Loss: 0.2915
===> Epoch[30](1600/2500): Loss: 0.2800
===> Epoch[30](1700/2500): Loss: 0.2757
===> Epoch[30](1800/2500): Loss: 0.2845
===> Epoch[30](1900/2500): Loss: 0.2754
===> Epoch[30](2000/2500): Loss: 0.2683
===> Epoch[30](2100/2500): Loss: 0.2795
===> Epoch[30](2200/2500): Loss: 0.2801
===> Epoch[30](2300/2500): Loss: 0.2998
===> Epoch[30](2400/2500): Loss: 0.2912
===> Epoch[30](2500/2500): Loss: 0.2746
===> Epoch 30 Complete: Avg. Loss: 0.2866
===> Timestamp: [2025-08-03 21:48:14]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2888
===> Epoch[30](200/2500): Loss: 0.2922
===> Epoch[30](300/2500): Loss: 0.3007
===> Epoch[30](400/2500): Loss: 0.2819
===> Epoch[30](500/2500): Loss: 0.2966
===> Epoch[30](600/2500): Loss: 0.2922
===> Epoch[30](700/2500): Loss: 0.2794
===> Epoch[30](800/2500): Loss: 0.3044
===> Epoch[30](900/2500): Loss: 0.2853
===> Epoch[30](1000/2500): Loss: 0.3087
===> Epoch[30](1100/2500): Loss: 0.2876
===> Epoch[30](1200/2500): Loss: 0.2801
===> Epoch[30](1300/2500): Loss: 0.2804
===> Epoch[30](1400/2500): Loss: 0.3014
===> Epoch[30](1500/2500): Loss: 0.2915
===> Epoch[30](1600/2500): Loss: 0.2800
===> Epoch[30](1700/2500): Loss: 0.2757
===> Epoch[30](1800/2500): Loss: 0.2845
===> Epoch[30](1900/2500): Loss: 0.2754
===> Epoch[30](2000/2500): Loss: 0.2683
===> Epoch[30](2100/2500): Loss: 0.2795
===> Epoch[30](2200/2500): Loss: 0.2801
===> Epoch[30](2300/2500): Loss: 0.2998
===> Epoch[30](2400/2500): Loss: 0.2912
===> Epoch[30](2500/2500): Loss: 0.2746
===> Epoch 30 Complete: Avg. Loss: 0.2866
===> Timestamp: [2025-08-03 21:48:14]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2888
===> Epoch[30](200/2500): Loss: 0.2922
===> Epoch[30](300/2500): Loss: 0.3007
===> Epoch[30](400/2500): Loss: 0.2819
===> Epoch[30](500/2500): Loss: 0.2966
===> Epoch[30](600/2500): Loss: 0.2922
===> Epoch[30](700/2500): Loss: 0.2794
===> Epoch[30](800/2500): Loss: 0.3044
===> Epoch[30](900/2500): Loss: 0.2853
===> Epoch[30](1000/2500): Loss: 0.3087
===> Epoch[30](1100/2500): Loss: 0.2876
===> Epoch[30](1200/2500): Loss: 0.2801
===> Epoch[30](1300/2500): Loss: 0.2804
===> Epoch[30](1400/2500): Loss: 0.3014
===> Epoch[30](1500/2500): Loss: 0.2915
===> Epoch[30](1600/2500): Loss: 0.2800
===> Epoch[30](1700/2500): Loss: 0.2757
===> Epoch[30](1800/2500): Loss: 0.2845
===> Epoch[30](1900/2500): Loss: 0.2754
===> Epoch[30](2000/2500): Loss: 0.2683
===> Epoch[30](2100/2500): Loss: 0.2795
===> Epoch[30](2200/2500): Loss: 0.2801
===> Epoch[30](2300/2500): Loss: 0.2998
===> Epoch[30](2400/2500): Loss: 0.2912
===> Epoch[30](2500/2500): Loss: 0.2746
===> Epoch 30 Complete: Avg. Loss: 0.2866
===> Timestamp: [2025-08-03 21:48:14]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2888
===> Epoch[30](200/2500): Loss: 0.2922
===> Epoch[30](300/2500): Loss: 0.3007
===> Epoch[30](400/2500): Loss: 0.2819
===> Epoch[30](500/2500): Loss: 0.2966
===> Epoch[30](600/2500): Loss: 0.2922
===> Epoch[30](700/2500): Loss: 0.2794
===> Epoch[30](800/2500): Loss: 0.3044
===> Epoch[30](900/2500): Loss: 0.2853
===> Epoch[30](1000/2500): Loss: 0.3087
===> Epoch[30](1100/2500): Loss: 0.2876
===> Epoch[30](1200/2500): Loss: 0.2801
===> Epoch[30](1300/2500): Loss: 0.2804
===> Epoch[30](1400/2500): Loss: 0.3014
===> Epoch[30](1500/2500): Loss: 0.2915
===> Epoch[30](1600/2500): Loss: 0.2800
===> Epoch[30](1700/2500): Loss: 0.2757
===> Epoch[30](1800/2500): Loss: 0.2845
===> Epoch[30](1900/2500): Loss: 0.2754
===> Epoch[30](2000/2500): Loss: 0.2683
===> Epoch[30](2100/2500): Loss: 0.2795
===> Epoch[30](2200/2500): Loss: 0.2801
===> Epoch[30](2300/2500): Loss: 0.2998
===> Epoch[30](2400/2500): Loss: 0.2912
===> Epoch[30](2500/2500): Loss: 0.2746
===> Epoch 30 Complete: Avg. Loss: 0.2866
===> Timestamp: [2025-08-03 21:48:14]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2888
===> Epoch[30](200/2500): Loss: 0.2922
===> Epoch[30](300/2500): Loss: 0.3007
===> Epoch[30](400/2500): Loss: 0.2819
===> Epoch[30](500/2500): Loss: 0.2966
===> Epoch[30](600/2500): Loss: 0.2922
===> Epoch[30](700/2500): Loss: 0.2794
===> Epoch[30](800/2500): Loss: 0.3044
===> Epoch[30](900/2500): Loss: 0.2853
===> Epoch[30](1000/2500): Loss: 0.3087
===> Epoch[30](1100/2500): Loss: 0.2876
===> Epoch[30](1200/2500): Loss: 0.2801
===> Epoch[30](1300/2500): Loss: 0.2804
===> Epoch[30](1400/2500): Loss: 0.3014
===> Epoch[30](1500/2500): Loss: 0.2915
===> Epoch[30](1600/2500): Loss: 0.2800
===> Epoch[30](1700/2500): Loss: 0.2757
===> Epoch[30](1800/2500): Loss: 0.2845
===> Epoch[30](1900/2500): Loss: 0.2754
===> Epoch[30](2000/2500): Loss: 0.2683
===> Epoch[30](2100/2500): Loss: 0.2795
===> Epoch[30](2200/2500): Loss: 0.2801
===> Epoch[30](2300/2500): Loss: 0.2998
===> Epoch[30](2400/2500): Loss: 0.2912
===> Epoch[30](2500/2500): Loss: 0.2746
===> Epoch 30 Complete: Avg. Loss: 0.2866
===> Timestamp: [2025-08-03 21:48:14]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2888
===> Epoch[30](200/2500): Loss: 0.2922
===> Epoch[30](300/2500): Loss: 0.3007
===> Epoch[30](400/2500): Loss: 0.2819
===> Epoch[30](500/2500): Loss: 0.2966
===> Epoch[30](600/2500): Loss: 0.2922
===> Epoch[30](700/2500): Loss: 0.2794
===> Epoch[30](800/2500): Loss: 0.3044
===> Epoch[30](900/2500): Loss: 0.2853
===> Epoch[30](1000/2500): Loss: 0.3087
===> Epoch[30](1100/2500): Loss: 0.2876
===> Epoch[30](1200/2500): Loss: 0.2801
===> Epoch[30](1300/2500): Loss: 0.2804
===> Epoch[30](1400/2500): Loss: 0.3014
===> Epoch[30](1500/2500): Loss: 0.2915
===> Epoch[30](1600/2500): Loss: 0.2800
===> Epoch[30](1700/2500): Loss: 0.2757
===> Epoch[30](1800/2500): Loss: 0.2845
===> Epoch[30](1900/2500): Loss: 0.2754
===> Epoch[30](2000/2500): Loss: 0.2683
===> Epoch[30](2100/2500): Loss: 0.2795
===> Epoch[30](2200/2500): Loss: 0.2801
===> Epoch[30](2300/2500): Loss: 0.2998
===> Epoch[30](2400/2500): Loss: 0.2912
===> Epoch[30](2500/2500): Loss: 0.2746
===> Epoch 30 Complete: Avg. Loss: 0.2866
===> Timestamp: [2025-08-03 21:48:14]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2888
===> Epoch[30](200/2500): Loss: 0.2922
===> Epoch[30](300/2500): Loss: 0.3007
===> Epoch[30](400/2500): Loss: 0.2819
===> Epoch[30](500/2500): Loss: 0.2966
===> Epoch[30](600/2500): Loss: 0.2922
===> Epoch[30](700/2500): Loss: 0.2794
===> Epoch[30](800/2500): Loss: 0.3044
===> Epoch[30](900/2500): Loss: 0.2853
===> Epoch[30](1000/2500): Loss: 0.3087
===> Epoch[30](1100/2500): Loss: 0.2876
===> Epoch[30](1200/2500): Loss: 0.2801
===> Epoch[30](1300/2500): Loss: 0.2804
===> Epoch[30](1400/2500): Loss: 0.3014
===> Epoch[30](1500/2500): Loss: 0.2915
===> Epoch[30](1600/2500): Loss: 0.2800
===> Epoch[30](1700/2500): Loss: 0.2757
===> Epoch[30](1800/2500): Loss: 0.2845
===> Epoch[30](1900/2500): Loss: 0.2754
===> Epoch[30](2000/2500): Loss: 0.2683
===> Epoch[30](2100/2500): Loss: 0.2795
===> Epoch[30](2200/2500): Loss: 0.2801
===> Epoch[30](2300/2500): Loss: 0.2998
===> Epoch[30](2400/2500): Loss: 0.2912
===> Epoch[30](2500/2500): Loss: 0.2746
===> Epoch 30 Complete: Avg. Loss: 0.2866
===> Timestamp: [2025-08-03 21:48:14]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Epoch[30](100/2500): Loss: 0.2888
===> Epoch[30](200/2500): Loss: 0.2922
===> Epoch[30](300/2500): Loss: 0.3007
===> Epoch[30](400/2500): Loss: 0.2819
===> Epoch[30](500/2500): Loss: 0.2966
===> Epoch[30](600/2500): Loss: 0.2922
===> Epoch[30](700/2500): Loss: 0.2794
===> Epoch[30](800/2500): Loss: 0.3044
===> Epoch[30](900/2500): Loss: 0.2853
===> Epoch[30](1000/2500): Loss: 0.3087
===> Epoch[30](1100/2500): Loss: 0.2876
===> Epoch[30](1200/2500): Loss: 0.2801
===> Epoch[30](1300/2500): Loss: 0.2804
===> Epoch[30](1400/2500): Loss: 0.3014
===> Epoch[30](1500/2500): Loss: 0.2915
===> Epoch[30](1600/2500): Loss: 0.2800
===> Epoch[30](1700/2500): Loss: 0.2757
===> Epoch[30](1800/2500): Loss: 0.2845
===> Epoch[30](1900/2500): Loss: 0.2754
===> Epoch[30](2000/2500): Loss: 0.2683
===> Epoch[30](2100/2500): Loss: 0.2795
===> Epoch[30](2200/2500): Loss: 0.2801
===> Epoch[30](2300/2500): Loss: 0.2998
===> Epoch[30](2400/2500): Loss: 0.2912
===> Epoch[30](2500/2500): Loss: 0.2746
===> Epoch 30 Complete: Avg. Loss: 0.2866
===> Timestamp: [2025-08-03 21:48:14]
Checkpoint saved to TrainedNet/_epoch_30.pth
===> Loading train datasets
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2745
===> Epoch[31](200/2500): Loss: 0.3068
===> Epoch[31](300/2500): Loss: 0.2942
===> Epoch[31](400/2500): Loss: 0.3031
===> Epoch[31](500/2500): Loss: 0.3067
===> Epoch[31](600/2500): Loss: 0.2694
===> Epoch[31](700/2500): Loss: 0.2870
===> Epoch[31](800/2500): Loss: 0.2977
===> Epoch[31](900/2500): Loss: 0.2798
===> Epoch[31](1000/2500): Loss: 0.2825
===> Epoch[31](1100/2500): Loss: 0.3035
===> Epoch[31](1200/2500): Loss: 0.2791
===> Epoch[31](1300/2500): Loss: 0.2794
===> Epoch[31](1400/2500): Loss: 0.2793
===> Epoch[31](1500/2500): Loss: 0.2634
===> Epoch[31](1600/2500): Loss: 0.2765
===> Epoch[31](1700/2500): Loss: 0.2717
===> Epoch[31](1800/2500): Loss: 0.2826
===> Epoch[31](1900/2500): Loss: 0.3034
===> Epoch[31](2000/2500): Loss: 0.2670
===> Epoch[31](2100/2500): Loss: 0.2959
===> Epoch[31](2200/2500): Loss: 0.2668
===> Epoch[31](2300/2500): Loss: 0.2749
===> Epoch[31](2400/2500): Loss: 0.2828
===> Epoch[31](2500/2500): Loss: 0.2708
===> Epoch 31 Complete: Avg. Loss: 0.2857
===> Timestamp: [2025-08-03 21:52:49]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2745
===> Epoch[31](200/2500): Loss: 0.3068
===> Epoch[31](300/2500): Loss: 0.2942
===> Epoch[31](400/2500): Loss: 0.3031
===> Epoch[31](500/2500): Loss: 0.3067
===> Epoch[31](600/2500): Loss: 0.2694
===> Epoch[31](700/2500): Loss: 0.2870
===> Epoch[31](800/2500): Loss: 0.2977
===> Epoch[31](900/2500): Loss: 0.2798
===> Epoch[31](1000/2500): Loss: 0.2825
===> Epoch[31](1100/2500): Loss: 0.3035
===> Epoch[31](1200/2500): Loss: 0.2791
===> Epoch[31](1300/2500): Loss: 0.2794
===> Epoch[31](1400/2500): Loss: 0.2793
===> Epoch[31](1500/2500): Loss: 0.2634
===> Epoch[31](1600/2500): Loss: 0.2765
===> Epoch[31](1700/2500): Loss: 0.2717
===> Epoch[31](1800/2500): Loss: 0.2826
===> Epoch[31](1900/2500): Loss: 0.3034
===> Epoch[31](2000/2500): Loss: 0.2670
===> Epoch[31](2100/2500): Loss: 0.2959
===> Epoch[31](2200/2500): Loss: 0.2668
===> Epoch[31](2300/2500): Loss: 0.2749
===> Epoch[31](2400/2500): Loss: 0.2828
===> Epoch[31](2500/2500): Loss: 0.2708
===> Epoch 31 Complete: Avg. Loss: 0.2857
===> Timestamp: [2025-08-03 21:52:49]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2745
===> Epoch[31](200/2500): Loss: 0.3068
===> Epoch[31](300/2500): Loss: 0.2942
===> Epoch[31](400/2500): Loss: 0.3031
===> Epoch[31](500/2500): Loss: 0.3067
===> Epoch[31](600/2500): Loss: 0.2694
===> Epoch[31](700/2500): Loss: 0.2870
===> Epoch[31](800/2500): Loss: 0.2977
===> Epoch[31](900/2500): Loss: 0.2798
===> Epoch[31](1000/2500): Loss: 0.2825
===> Epoch[31](1100/2500): Loss: 0.3035
===> Epoch[31](1200/2500): Loss: 0.2791
===> Epoch[31](1300/2500): Loss: 0.2794
===> Epoch[31](1400/2500): Loss: 0.2793
===> Epoch[31](1500/2500): Loss: 0.2634
===> Epoch[31](1600/2500): Loss: 0.2765
===> Epoch[31](1700/2500): Loss: 0.2717
===> Epoch[31](1800/2500): Loss: 0.2826
===> Epoch[31](1900/2500): Loss: 0.3034
===> Epoch[31](2000/2500): Loss: 0.2670
===> Epoch[31](2100/2500): Loss: 0.2959
===> Epoch[31](2200/2500): Loss: 0.2668
===> Epoch[31](2300/2500): Loss: 0.2749
===> Epoch[31](2400/2500): Loss: 0.2828
===> Epoch[31](2500/2500): Loss: 0.2708
===> Epoch 31 Complete: Avg. Loss: 0.2857
===> Timestamp: [2025-08-03 21:52:49]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2745
===> Epoch[31](200/2500): Loss: 0.3068
===> Epoch[31](300/2500): Loss: 0.2942
===> Epoch[31](400/2500): Loss: 0.3031
===> Epoch[31](500/2500): Loss: 0.3067
===> Epoch[31](600/2500): Loss: 0.2694
===> Epoch[31](700/2500): Loss: 0.2870
===> Epoch[31](800/2500): Loss: 0.2977
===> Epoch[31](900/2500): Loss: 0.2798
===> Epoch[31](1000/2500): Loss: 0.2825
===> Epoch[31](1100/2500): Loss: 0.3035
===> Epoch[31](1200/2500): Loss: 0.2791
===> Epoch[31](1300/2500): Loss: 0.2794
===> Epoch[31](1400/2500): Loss: 0.2793
===> Epoch[31](1500/2500): Loss: 0.2634
===> Epoch[31](1600/2500): Loss: 0.2765
===> Epoch[31](1700/2500): Loss: 0.2717
===> Epoch[31](1800/2500): Loss: 0.2826
===> Epoch[31](1900/2500): Loss: 0.3034
===> Epoch[31](2000/2500): Loss: 0.2670
===> Epoch[31](2100/2500): Loss: 0.2959
===> Epoch[31](2200/2500): Loss: 0.2668
===> Epoch[31](2300/2500): Loss: 0.2749
===> Epoch[31](2400/2500): Loss: 0.2828
===> Epoch[31](2500/2500): Loss: 0.2708
===> Epoch 31 Complete: Avg. Loss: 0.2857
===> Timestamp: [2025-08-03 21:52:49]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2745
===> Epoch[31](200/2500): Loss: 0.3068
===> Epoch[31](300/2500): Loss: 0.2942
===> Epoch[31](400/2500): Loss: 0.3031
===> Epoch[31](500/2500): Loss: 0.3067
===> Epoch[31](600/2500): Loss: 0.2694
===> Epoch[31](700/2500): Loss: 0.2870
===> Epoch[31](800/2500): Loss: 0.2977
===> Epoch[31](900/2500): Loss: 0.2798
===> Epoch[31](1000/2500): Loss: 0.2825
===> Epoch[31](1100/2500): Loss: 0.3035
===> Epoch[31](1200/2500): Loss: 0.2791
===> Epoch[31](1300/2500): Loss: 0.2794
===> Epoch[31](1400/2500): Loss: 0.2793
===> Epoch[31](1500/2500): Loss: 0.2634
===> Epoch[31](1600/2500): Loss: 0.2765
===> Epoch[31](1700/2500): Loss: 0.2717
===> Epoch[31](1800/2500): Loss: 0.2826
===> Epoch[31](1900/2500): Loss: 0.3034
===> Epoch[31](2000/2500): Loss: 0.2670
===> Epoch[31](2100/2500): Loss: 0.2959
===> Epoch[31](2200/2500): Loss: 0.2668
===> Epoch[31](2300/2500): Loss: 0.2749
===> Epoch[31](2400/2500): Loss: 0.2828
===> Epoch[31](2500/2500): Loss: 0.2708
===> Epoch 31 Complete: Avg. Loss: 0.2857
===> Timestamp: [2025-08-03 21:52:49]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2745
===> Epoch[31](200/2500): Loss: 0.3068
===> Epoch[31](300/2500): Loss: 0.2942
===> Epoch[31](400/2500): Loss: 0.3031
===> Epoch[31](500/2500): Loss: 0.3067
===> Epoch[31](600/2500): Loss: 0.2694
===> Epoch[31](700/2500): Loss: 0.2870
===> Epoch[31](800/2500): Loss: 0.2977
===> Epoch[31](900/2500): Loss: 0.2798
===> Epoch[31](1000/2500): Loss: 0.2825
===> Epoch[31](1100/2500): Loss: 0.3035
===> Epoch[31](1200/2500): Loss: 0.2791
===> Epoch[31](1300/2500): Loss: 0.2794
===> Epoch[31](1400/2500): Loss: 0.2793
===> Epoch[31](1500/2500): Loss: 0.2634
===> Epoch[31](1600/2500): Loss: 0.2765
===> Epoch[31](1700/2500): Loss: 0.2717
===> Epoch[31](1800/2500): Loss: 0.2826
===> Epoch[31](1900/2500): Loss: 0.3034
===> Epoch[31](2000/2500): Loss: 0.2670
===> Epoch[31](2100/2500): Loss: 0.2959
===> Epoch[31](2200/2500): Loss: 0.2668
===> Epoch[31](2300/2500): Loss: 0.2749
===> Epoch[31](2400/2500): Loss: 0.2828
===> Epoch[31](2500/2500): Loss: 0.2708
===> Epoch 31 Complete: Avg. Loss: 0.2857
===> Timestamp: [2025-08-03 21:52:49]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2745
===> Epoch[31](200/2500): Loss: 0.3068
===> Epoch[31](300/2500): Loss: 0.2942
===> Epoch[31](400/2500): Loss: 0.3031
===> Epoch[31](500/2500): Loss: 0.3067
===> Epoch[31](600/2500): Loss: 0.2694
===> Epoch[31](700/2500): Loss: 0.2870
===> Epoch[31](800/2500): Loss: 0.2977
===> Epoch[31](900/2500): Loss: 0.2798
===> Epoch[31](1000/2500): Loss: 0.2825
===> Epoch[31](1100/2500): Loss: 0.3035
===> Epoch[31](1200/2500): Loss: 0.2791
===> Epoch[31](1300/2500): Loss: 0.2794
===> Epoch[31](1400/2500): Loss: 0.2793
===> Epoch[31](1500/2500): Loss: 0.2634
===> Epoch[31](1600/2500): Loss: 0.2765
===> Epoch[31](1700/2500): Loss: 0.2717
===> Epoch[31](1800/2500): Loss: 0.2826
===> Epoch[31](1900/2500): Loss: 0.3034
===> Epoch[31](2000/2500): Loss: 0.2670
===> Epoch[31](2100/2500): Loss: 0.2959
===> Epoch[31](2200/2500): Loss: 0.2668
===> Epoch[31](2300/2500): Loss: 0.2749
===> Epoch[31](2400/2500): Loss: 0.2828
===> Epoch[31](2500/2500): Loss: 0.2708
===> Epoch 31 Complete: Avg. Loss: 0.2857
===> Timestamp: [2025-08-03 21:52:49]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2745
===> Epoch[31](200/2500): Loss: 0.3068
===> Epoch[31](300/2500): Loss: 0.2942
===> Epoch[31](400/2500): Loss: 0.3031
===> Epoch[31](500/2500): Loss: 0.3067
===> Epoch[31](600/2500): Loss: 0.2694
===> Epoch[31](700/2500): Loss: 0.2870
===> Epoch[31](800/2500): Loss: 0.2977
===> Epoch[31](900/2500): Loss: 0.2798
===> Epoch[31](1000/2500): Loss: 0.2825
===> Epoch[31](1100/2500): Loss: 0.3035
===> Epoch[31](1200/2500): Loss: 0.2791
===> Epoch[31](1300/2500): Loss: 0.2794
===> Epoch[31](1400/2500): Loss: 0.2793
===> Epoch[31](1500/2500): Loss: 0.2634
===> Epoch[31](1600/2500): Loss: 0.2765
===> Epoch[31](1700/2500): Loss: 0.2717
===> Epoch[31](1800/2500): Loss: 0.2826
===> Epoch[31](1900/2500): Loss: 0.3034
===> Epoch[31](2000/2500): Loss: 0.2670
===> Epoch[31](2100/2500): Loss: 0.2959
===> Epoch[31](2200/2500): Loss: 0.2668
===> Epoch[31](2300/2500): Loss: 0.2749
===> Epoch[31](2400/2500): Loss: 0.2828
===> Epoch[31](2500/2500): Loss: 0.2708
===> Epoch 31 Complete: Avg. Loss: 0.2857
===> Timestamp: [2025-08-03 21:52:49]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2745
===> Epoch[31](200/2500): Loss: 0.3068
===> Epoch[31](300/2500): Loss: 0.2942
===> Epoch[31](400/2500): Loss: 0.3031
===> Epoch[31](500/2500): Loss: 0.3067
===> Epoch[31](600/2500): Loss: 0.2694
===> Epoch[31](700/2500): Loss: 0.2870
===> Epoch[31](800/2500): Loss: 0.2977
===> Epoch[31](900/2500): Loss: 0.2798
===> Epoch[31](1000/2500): Loss: 0.2825
===> Epoch[31](1100/2500): Loss: 0.3035
===> Epoch[31](1200/2500): Loss: 0.2791
===> Epoch[31](1300/2500): Loss: 0.2794
===> Epoch[31](1400/2500): Loss: 0.2793
===> Epoch[31](1500/2500): Loss: 0.2634
===> Epoch[31](1600/2500): Loss: 0.2765
===> Epoch[31](1700/2500): Loss: 0.2717
===> Epoch[31](1800/2500): Loss: 0.2826
===> Epoch[31](1900/2500): Loss: 0.3034
===> Epoch[31](2000/2500): Loss: 0.2670
===> Epoch[31](2100/2500): Loss: 0.2959
===> Epoch[31](2200/2500): Loss: 0.2668
===> Epoch[31](2300/2500): Loss: 0.2749
===> Epoch[31](2400/2500): Loss: 0.2828
===> Epoch[31](2500/2500): Loss: 0.2708
===> Epoch 31 Complete: Avg. Loss: 0.2857
===> Timestamp: [2025-08-03 21:52:49]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2745
===> Epoch[31](200/2500): Loss: 0.3068
===> Epoch[31](300/2500): Loss: 0.2942
===> Epoch[31](400/2500): Loss: 0.3031
===> Epoch[31](500/2500): Loss: 0.3067
===> Epoch[31](600/2500): Loss: 0.2694
===> Epoch[31](700/2500): Loss: 0.2870
===> Epoch[31](800/2500): Loss: 0.2977
===> Epoch[31](900/2500): Loss: 0.2798
===> Epoch[31](1000/2500): Loss: 0.2825
===> Epoch[31](1100/2500): Loss: 0.3035
===> Epoch[31](1200/2500): Loss: 0.2791
===> Epoch[31](1300/2500): Loss: 0.2794
===> Epoch[31](1400/2500): Loss: 0.2793
===> Epoch[31](1500/2500): Loss: 0.2634
===> Epoch[31](1600/2500): Loss: 0.2765
===> Epoch[31](1700/2500): Loss: 0.2717
===> Epoch[31](1800/2500): Loss: 0.2826
===> Epoch[31](1900/2500): Loss: 0.3034
===> Epoch[31](2000/2500): Loss: 0.2670
===> Epoch[31](2100/2500): Loss: 0.2959
===> Epoch[31](2200/2500): Loss: 0.2668
===> Epoch[31](2300/2500): Loss: 0.2749
===> Epoch[31](2400/2500): Loss: 0.2828
===> Epoch[31](2500/2500): Loss: 0.2708
===> Epoch 31 Complete: Avg. Loss: 0.2857
===> Timestamp: [2025-08-03 21:52:49]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2745
===> Epoch[31](200/2500): Loss: 0.3068
===> Epoch[31](300/2500): Loss: 0.2942
===> Epoch[31](400/2500): Loss: 0.3031
===> Epoch[31](500/2500): Loss: 0.3067
===> Epoch[31](600/2500): Loss: 0.2694
===> Epoch[31](700/2500): Loss: 0.2870
===> Epoch[31](800/2500): Loss: 0.2977
===> Epoch[31](900/2500): Loss: 0.2798
===> Epoch[31](1000/2500): Loss: 0.2825
===> Epoch[31](1100/2500): Loss: 0.3035
===> Epoch[31](1200/2500): Loss: 0.2791
===> Epoch[31](1300/2500): Loss: 0.2794
===> Epoch[31](1400/2500): Loss: 0.2793
===> Epoch[31](1500/2500): Loss: 0.2634
===> Epoch[31](1600/2500): Loss: 0.2765
===> Epoch[31](1700/2500): Loss: 0.2717
===> Epoch[31](1800/2500): Loss: 0.2826
===> Epoch[31](1900/2500): Loss: 0.3034
===> Epoch[31](2000/2500): Loss: 0.2670
===> Epoch[31](2100/2500): Loss: 0.2959
===> Epoch[31](2200/2500): Loss: 0.2668
===> Epoch[31](2300/2500): Loss: 0.2749
===> Epoch[31](2400/2500): Loss: 0.2828
===> Epoch[31](2500/2500): Loss: 0.2708
===> Epoch 31 Complete: Avg. Loss: 0.2857
===> Timestamp: [2025-08-03 21:52:49]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2745
===> Epoch[31](200/2500): Loss: 0.3068
===> Epoch[31](300/2500): Loss: 0.2942
===> Epoch[31](400/2500): Loss: 0.3031
===> Epoch[31](500/2500): Loss: 0.3067
===> Epoch[31](600/2500): Loss: 0.2694
===> Epoch[31](700/2500): Loss: 0.2870
===> Epoch[31](800/2500): Loss: 0.2977
===> Epoch[31](900/2500): Loss: 0.2798
===> Epoch[31](1000/2500): Loss: 0.2825
===> Epoch[31](1100/2500): Loss: 0.3035
===> Epoch[31](1200/2500): Loss: 0.2791
===> Epoch[31](1300/2500): Loss: 0.2794
===> Epoch[31](1400/2500): Loss: 0.2793
===> Epoch[31](1500/2500): Loss: 0.2634
===> Epoch[31](1600/2500): Loss: 0.2765
===> Epoch[31](1700/2500): Loss: 0.2717
===> Epoch[31](1800/2500): Loss: 0.2826
===> Epoch[31](1900/2500): Loss: 0.3034
===> Epoch[31](2000/2500): Loss: 0.2670
===> Epoch[31](2100/2500): Loss: 0.2959
===> Epoch[31](2200/2500): Loss: 0.2668
===> Epoch[31](2300/2500): Loss: 0.2749
===> Epoch[31](2400/2500): Loss: 0.2828
===> Epoch[31](2500/2500): Loss: 0.2708
===> Epoch 31 Complete: Avg. Loss: 0.2857
===> Timestamp: [2025-08-03 21:52:49]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2745
===> Epoch[31](200/2500): Loss: 0.3068
===> Epoch[31](300/2500): Loss: 0.2942
===> Epoch[31](400/2500): Loss: 0.3031
===> Epoch[31](500/2500): Loss: 0.3067
===> Epoch[31](600/2500): Loss: 0.2694
===> Epoch[31](700/2500): Loss: 0.2870
===> Epoch[31](800/2500): Loss: 0.2977
===> Epoch[31](900/2500): Loss: 0.2798
===> Epoch[31](1000/2500): Loss: 0.2825
===> Epoch[31](1100/2500): Loss: 0.3035
===> Epoch[31](1200/2500): Loss: 0.2791
===> Epoch[31](1300/2500): Loss: 0.2794
===> Epoch[31](1400/2500): Loss: 0.2793
===> Epoch[31](1500/2500): Loss: 0.2634
===> Epoch[31](1600/2500): Loss: 0.2765
===> Epoch[31](1700/2500): Loss: 0.2717
===> Epoch[31](1800/2500): Loss: 0.2826
===> Epoch[31](1900/2500): Loss: 0.3034
===> Epoch[31](2000/2500): Loss: 0.2670
===> Epoch[31](2100/2500): Loss: 0.2959
===> Epoch[31](2200/2500): Loss: 0.2668
===> Epoch[31](2300/2500): Loss: 0.2749
===> Epoch[31](2400/2500): Loss: 0.2828
===> Epoch[31](2500/2500): Loss: 0.2708
===> Epoch 31 Complete: Avg. Loss: 0.2857
===> Timestamp: [2025-08-03 21:52:49]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2745
===> Epoch[31](200/2500): Loss: 0.3068
===> Epoch[31](300/2500): Loss: 0.2942
===> Epoch[31](400/2500): Loss: 0.3031
===> Epoch[31](500/2500): Loss: 0.3067
===> Epoch[31](600/2500): Loss: 0.2694
===> Epoch[31](700/2500): Loss: 0.2870
===> Epoch[31](800/2500): Loss: 0.2977
===> Epoch[31](900/2500): Loss: 0.2798
===> Epoch[31](1000/2500): Loss: 0.2825
===> Epoch[31](1100/2500): Loss: 0.3035
===> Epoch[31](1200/2500): Loss: 0.2791
===> Epoch[31](1300/2500): Loss: 0.2794
===> Epoch[31](1400/2500): Loss: 0.2793
===> Epoch[31](1500/2500): Loss: 0.2634
===> Epoch[31](1600/2500): Loss: 0.2765
===> Epoch[31](1700/2500): Loss: 0.2717
===> Epoch[31](1800/2500): Loss: 0.2826
===> Epoch[31](1900/2500): Loss: 0.3034
===> Epoch[31](2000/2500): Loss: 0.2670
===> Epoch[31](2100/2500): Loss: 0.2959
===> Epoch[31](2200/2500): Loss: 0.2668
===> Epoch[31](2300/2500): Loss: 0.2749
===> Epoch[31](2400/2500): Loss: 0.2828
===> Epoch[31](2500/2500): Loss: 0.2708
===> Epoch 31 Complete: Avg. Loss: 0.2857
===> Timestamp: [2025-08-03 21:52:49]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2745
===> Epoch[31](200/2500): Loss: 0.3068
===> Epoch[31](300/2500): Loss: 0.2942
===> Epoch[31](400/2500): Loss: 0.3031
===> Epoch[31](500/2500): Loss: 0.3067
===> Epoch[31](600/2500): Loss: 0.2694
===> Epoch[31](700/2500): Loss: 0.2870
===> Epoch[31](800/2500): Loss: 0.2977
===> Epoch[31](900/2500): Loss: 0.2798
===> Epoch[31](1000/2500): Loss: 0.2825
===> Epoch[31](1100/2500): Loss: 0.3035
===> Epoch[31](1200/2500): Loss: 0.2791
===> Epoch[31](1300/2500): Loss: 0.2794
===> Epoch[31](1400/2500): Loss: 0.2793
===> Epoch[31](1500/2500): Loss: 0.2634
===> Epoch[31](1600/2500): Loss: 0.2765
===> Epoch[31](1700/2500): Loss: 0.2717
===> Epoch[31](1800/2500): Loss: 0.2826
===> Epoch[31](1900/2500): Loss: 0.3034
===> Epoch[31](2000/2500): Loss: 0.2670
===> Epoch[31](2100/2500): Loss: 0.2959
===> Epoch[31](2200/2500): Loss: 0.2668
===> Epoch[31](2300/2500): Loss: 0.2749
===> Epoch[31](2400/2500): Loss: 0.2828
===> Epoch[31](2500/2500): Loss: 0.2708
===> Epoch 31 Complete: Avg. Loss: 0.2857
===> Timestamp: [2025-08-03 21:52:49]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2745
===> Epoch[31](200/2500): Loss: 0.3068
===> Epoch[31](300/2500): Loss: 0.2942
===> Epoch[31](400/2500): Loss: 0.3031
===> Epoch[31](500/2500): Loss: 0.3067
===> Epoch[31](600/2500): Loss: 0.2694
===> Epoch[31](700/2500): Loss: 0.2870
===> Epoch[31](800/2500): Loss: 0.2977
===> Epoch[31](900/2500): Loss: 0.2798
===> Epoch[31](1000/2500): Loss: 0.2825
===> Epoch[31](1100/2500): Loss: 0.3035
===> Epoch[31](1200/2500): Loss: 0.2791
===> Epoch[31](1300/2500): Loss: 0.2794
===> Epoch[31](1400/2500): Loss: 0.2793
===> Epoch[31](1500/2500): Loss: 0.2634
===> Epoch[31](1600/2500): Loss: 0.2765
===> Epoch[31](1700/2500): Loss: 0.2717
===> Epoch[31](1800/2500): Loss: 0.2826
===> Epoch[31](1900/2500): Loss: 0.3034
===> Epoch[31](2000/2500): Loss: 0.2670
===> Epoch[31](2100/2500): Loss: 0.2959
===> Epoch[31](2200/2500): Loss: 0.2668
===> Epoch[31](2300/2500): Loss: 0.2749
===> Epoch[31](2400/2500): Loss: 0.2828
===> Epoch[31](2500/2500): Loss: 0.2708
===> Epoch 31 Complete: Avg. Loss: 0.2857
===> Timestamp: [2025-08-03 21:52:49]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2745
===> Epoch[31](200/2500): Loss: 0.3068
===> Epoch[31](300/2500): Loss: 0.2942
===> Epoch[31](400/2500): Loss: 0.3031
===> Epoch[31](500/2500): Loss: 0.3067
===> Epoch[31](600/2500): Loss: 0.2694
===> Epoch[31](700/2500): Loss: 0.2870
===> Epoch[31](800/2500): Loss: 0.2977
===> Epoch[31](900/2500): Loss: 0.2798
===> Epoch[31](1000/2500): Loss: 0.2825
===> Epoch[31](1100/2500): Loss: 0.3035
===> Epoch[31](1200/2500): Loss: 0.2791
===> Epoch[31](1300/2500): Loss: 0.2794
===> Epoch[31](1400/2500): Loss: 0.2793
===> Epoch[31](1500/2500): Loss: 0.2634
===> Epoch[31](1600/2500): Loss: 0.2765
===> Epoch[31](1700/2500): Loss: 0.2717
===> Epoch[31](1800/2500): Loss: 0.2826
===> Epoch[31](1900/2500): Loss: 0.3034
===> Epoch[31](2000/2500): Loss: 0.2670
===> Epoch[31](2100/2500): Loss: 0.2959
===> Epoch[31](2200/2500): Loss: 0.2668
===> Epoch[31](2300/2500): Loss: 0.2749
===> Epoch[31](2400/2500): Loss: 0.2828
===> Epoch[31](2500/2500): Loss: 0.2708
===> Epoch 31 Complete: Avg. Loss: 0.2857
===> Timestamp: [2025-08-03 21:52:49]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2745
===> Epoch[31](200/2500): Loss: 0.3068
===> Epoch[31](300/2500): Loss: 0.2942
===> Epoch[31](400/2500): Loss: 0.3031
===> Epoch[31](500/2500): Loss: 0.3067
===> Epoch[31](600/2500): Loss: 0.2694
===> Epoch[31](700/2500): Loss: 0.2870
===> Epoch[31](800/2500): Loss: 0.2977
===> Epoch[31](900/2500): Loss: 0.2798
===> Epoch[31](1000/2500): Loss: 0.2825
===> Epoch[31](1100/2500): Loss: 0.3035
===> Epoch[31](1200/2500): Loss: 0.2791
===> Epoch[31](1300/2500): Loss: 0.2794
===> Epoch[31](1400/2500): Loss: 0.2793
===> Epoch[31](1500/2500): Loss: 0.2634
===> Epoch[31](1600/2500): Loss: 0.2765
===> Epoch[31](1700/2500): Loss: 0.2717
===> Epoch[31](1800/2500): Loss: 0.2826
===> Epoch[31](1900/2500): Loss: 0.3034
===> Epoch[31](2000/2500): Loss: 0.2670
===> Epoch[31](2100/2500): Loss: 0.2959
===> Epoch[31](2200/2500): Loss: 0.2668
===> Epoch[31](2300/2500): Loss: 0.2749
===> Epoch[31](2400/2500): Loss: 0.2828
===> Epoch[31](2500/2500): Loss: 0.2708
===> Epoch 31 Complete: Avg. Loss: 0.2857
===> Timestamp: [2025-08-03 21:52:49]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2745
===> Epoch[31](200/2500): Loss: 0.3068
===> Epoch[31](300/2500): Loss: 0.2942
===> Epoch[31](400/2500): Loss: 0.3031
===> Epoch[31](500/2500): Loss: 0.3067
===> Epoch[31](600/2500): Loss: 0.2694
===> Epoch[31](700/2500): Loss: 0.2870
===> Epoch[31](800/2500): Loss: 0.2977
===> Epoch[31](900/2500): Loss: 0.2798
===> Epoch[31](1000/2500): Loss: 0.2825
===> Epoch[31](1100/2500): Loss: 0.3035
===> Epoch[31](1200/2500): Loss: 0.2791
===> Epoch[31](1300/2500): Loss: 0.2794
===> Epoch[31](1400/2500): Loss: 0.2793
===> Epoch[31](1500/2500): Loss: 0.2634
===> Epoch[31](1600/2500): Loss: 0.2765
===> Epoch[31](1700/2500): Loss: 0.2717
===> Epoch[31](1800/2500): Loss: 0.2826
===> Epoch[31](1900/2500): Loss: 0.3034
===> Epoch[31](2000/2500): Loss: 0.2670
===> Epoch[31](2100/2500): Loss: 0.2959
===> Epoch[31](2200/2500): Loss: 0.2668
===> Epoch[31](2300/2500): Loss: 0.2749
===> Epoch[31](2400/2500): Loss: 0.2828
===> Epoch[31](2500/2500): Loss: 0.2708
===> Epoch 31 Complete: Avg. Loss: 0.2857
===> Timestamp: [2025-08-03 21:52:49]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2745
===> Epoch[31](200/2500): Loss: 0.3068
===> Epoch[31](300/2500): Loss: 0.2942
===> Epoch[31](400/2500): Loss: 0.3031
===> Epoch[31](500/2500): Loss: 0.3067
===> Epoch[31](600/2500): Loss: 0.2694
===> Epoch[31](700/2500): Loss: 0.2870
===> Epoch[31](800/2500): Loss: 0.2977
===> Epoch[31](900/2500): Loss: 0.2798
===> Epoch[31](1000/2500): Loss: 0.2825
===> Epoch[31](1100/2500): Loss: 0.3035
===> Epoch[31](1200/2500): Loss: 0.2791
===> Epoch[31](1300/2500): Loss: 0.2794
===> Epoch[31](1400/2500): Loss: 0.2793
===> Epoch[31](1500/2500): Loss: 0.2634
===> Epoch[31](1600/2500): Loss: 0.2765
===> Epoch[31](1700/2500): Loss: 0.2717
===> Epoch[31](1800/2500): Loss: 0.2826
===> Epoch[31](1900/2500): Loss: 0.3034
===> Epoch[31](2000/2500): Loss: 0.2670
===> Epoch[31](2100/2500): Loss: 0.2959
===> Epoch[31](2200/2500): Loss: 0.2668
===> Epoch[31](2300/2500): Loss: 0.2749
===> Epoch[31](2400/2500): Loss: 0.2828
===> Epoch[31](2500/2500): Loss: 0.2708
===> Epoch 31 Complete: Avg. Loss: 0.2857
===> Timestamp: [2025-08-03 21:52:49]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2745
===> Epoch[31](200/2500): Loss: 0.3068
===> Epoch[31](300/2500): Loss: 0.2942
===> Epoch[31](400/2500): Loss: 0.3031
===> Epoch[31](500/2500): Loss: 0.3067
===> Epoch[31](600/2500): Loss: 0.2694
===> Epoch[31](700/2500): Loss: 0.2870
===> Epoch[31](800/2500): Loss: 0.2977
===> Epoch[31](900/2500): Loss: 0.2798
===> Epoch[31](1000/2500): Loss: 0.2825
===> Epoch[31](1100/2500): Loss: 0.3035
===> Epoch[31](1200/2500): Loss: 0.2791
===> Epoch[31](1300/2500): Loss: 0.2794
===> Epoch[31](1400/2500): Loss: 0.2793
===> Epoch[31](1500/2500): Loss: 0.2634
===> Epoch[31](1600/2500): Loss: 0.2765
===> Epoch[31](1700/2500): Loss: 0.2717
===> Epoch[31](1800/2500): Loss: 0.2826
===> Epoch[31](1900/2500): Loss: 0.3034
===> Epoch[31](2000/2500): Loss: 0.2670
===> Epoch[31](2100/2500): Loss: 0.2959
===> Epoch[31](2200/2500): Loss: 0.2668
===> Epoch[31](2300/2500): Loss: 0.2749
===> Epoch[31](2400/2500): Loss: 0.2828
===> Epoch[31](2500/2500): Loss: 0.2708
===> Epoch 31 Complete: Avg. Loss: 0.2857
===> Timestamp: [2025-08-03 21:52:49]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2745
===> Epoch[31](200/2500): Loss: 0.3068
===> Epoch[31](300/2500): Loss: 0.2942
===> Epoch[31](400/2500): Loss: 0.3031
===> Epoch[31](500/2500): Loss: 0.3067
===> Epoch[31](600/2500): Loss: 0.2694
===> Epoch[31](700/2500): Loss: 0.2870
===> Epoch[31](800/2500): Loss: 0.2977
===> Epoch[31](900/2500): Loss: 0.2798
===> Epoch[31](1000/2500): Loss: 0.2825
===> Epoch[31](1100/2500): Loss: 0.3035
===> Epoch[31](1200/2500): Loss: 0.2791
===> Epoch[31](1300/2500): Loss: 0.2794
===> Epoch[31](1400/2500): Loss: 0.2793
===> Epoch[31](1500/2500): Loss: 0.2634
===> Epoch[31](1600/2500): Loss: 0.2765
===> Epoch[31](1700/2500): Loss: 0.2717
===> Epoch[31](1800/2500): Loss: 0.2826
===> Epoch[31](1900/2500): Loss: 0.3034
===> Epoch[31](2000/2500): Loss: 0.2670
===> Epoch[31](2100/2500): Loss: 0.2959
===> Epoch[31](2200/2500): Loss: 0.2668
===> Epoch[31](2300/2500): Loss: 0.2749
===> Epoch[31](2400/2500): Loss: 0.2828
===> Epoch[31](2500/2500): Loss: 0.2708
===> Epoch 31 Complete: Avg. Loss: 0.2857
===> Timestamp: [2025-08-03 21:52:49]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2745
===> Epoch[31](200/2500): Loss: 0.3068
===> Epoch[31](300/2500): Loss: 0.2942
===> Epoch[31](400/2500): Loss: 0.3031
===> Epoch[31](500/2500): Loss: 0.3067
===> Epoch[31](600/2500): Loss: 0.2694
===> Epoch[31](700/2500): Loss: 0.2870
===> Epoch[31](800/2500): Loss: 0.2977
===> Epoch[31](900/2500): Loss: 0.2798
===> Epoch[31](1000/2500): Loss: 0.2825
===> Epoch[31](1100/2500): Loss: 0.3035
===> Epoch[31](1200/2500): Loss: 0.2791
===> Epoch[31](1300/2500): Loss: 0.2794
===> Epoch[31](1400/2500): Loss: 0.2793
===> Epoch[31](1500/2500): Loss: 0.2634
===> Epoch[31](1600/2500): Loss: 0.2765
===> Epoch[31](1700/2500): Loss: 0.2717
===> Epoch[31](1800/2500): Loss: 0.2826
===> Epoch[31](1900/2500): Loss: 0.3034
===> Epoch[31](2000/2500): Loss: 0.2670
===> Epoch[31](2100/2500): Loss: 0.2959
===> Epoch[31](2200/2500): Loss: 0.2668
===> Epoch[31](2300/2500): Loss: 0.2749
===> Epoch[31](2400/2500): Loss: 0.2828
===> Epoch[31](2500/2500): Loss: 0.2708
===> Epoch 31 Complete: Avg. Loss: 0.2857
===> Timestamp: [2025-08-03 21:52:49]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2745
===> Epoch[31](200/2500): Loss: 0.3068
===> Epoch[31](300/2500): Loss: 0.2942
===> Epoch[31](400/2500): Loss: 0.3031
===> Epoch[31](500/2500): Loss: 0.3067
===> Epoch[31](600/2500): Loss: 0.2694
===> Epoch[31](700/2500): Loss: 0.2870
===> Epoch[31](800/2500): Loss: 0.2977
===> Epoch[31](900/2500): Loss: 0.2798
===> Epoch[31](1000/2500): Loss: 0.2825
===> Epoch[31](1100/2500): Loss: 0.3035
===> Epoch[31](1200/2500): Loss: 0.2791
===> Epoch[31](1300/2500): Loss: 0.2794
===> Epoch[31](1400/2500): Loss: 0.2793
===> Epoch[31](1500/2500): Loss: 0.2634
===> Epoch[31](1600/2500): Loss: 0.2765
===> Epoch[31](1700/2500): Loss: 0.2717
===> Epoch[31](1800/2500): Loss: 0.2826
===> Epoch[31](1900/2500): Loss: 0.3034
===> Epoch[31](2000/2500): Loss: 0.2670
===> Epoch[31](2100/2500): Loss: 0.2959
===> Epoch[31](2200/2500): Loss: 0.2668
===> Epoch[31](2300/2500): Loss: 0.2749
===> Epoch[31](2400/2500): Loss: 0.2828
===> Epoch[31](2500/2500): Loss: 0.2708
===> Epoch 31 Complete: Avg. Loss: 0.2857
===> Timestamp: [2025-08-03 21:52:49]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2745
===> Epoch[31](200/2500): Loss: 0.3068
===> Epoch[31](300/2500): Loss: 0.2942
===> Epoch[31](400/2500): Loss: 0.3031
===> Epoch[31](500/2500): Loss: 0.3067
===> Epoch[31](600/2500): Loss: 0.2694
===> Epoch[31](700/2500): Loss: 0.2870
===> Epoch[31](800/2500): Loss: 0.2977
===> Epoch[31](900/2500): Loss: 0.2798
===> Epoch[31](1000/2500): Loss: 0.2825
===> Epoch[31](1100/2500): Loss: 0.3035
===> Epoch[31](1200/2500): Loss: 0.2791
===> Epoch[31](1300/2500): Loss: 0.2794
===> Epoch[31](1400/2500): Loss: 0.2793
===> Epoch[31](1500/2500): Loss: 0.2634
===> Epoch[31](1600/2500): Loss: 0.2765
===> Epoch[31](1700/2500): Loss: 0.2717
===> Epoch[31](1800/2500): Loss: 0.2826
===> Epoch[31](1900/2500): Loss: 0.3034
===> Epoch[31](2000/2500): Loss: 0.2670
===> Epoch[31](2100/2500): Loss: 0.2959
===> Epoch[31](2200/2500): Loss: 0.2668
===> Epoch[31](2300/2500): Loss: 0.2749
===> Epoch[31](2400/2500): Loss: 0.2828
===> Epoch[31](2500/2500): Loss: 0.2708
===> Epoch 31 Complete: Avg. Loss: 0.2857
===> Timestamp: [2025-08-03 21:52:49]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2745
===> Epoch[31](200/2500): Loss: 0.3068
===> Epoch[31](300/2500): Loss: 0.2942
===> Epoch[31](400/2500): Loss: 0.3031
===> Epoch[31](500/2500): Loss: 0.3067
===> Epoch[31](600/2500): Loss: 0.2694
===> Epoch[31](700/2500): Loss: 0.2870
===> Epoch[31](800/2500): Loss: 0.2977
===> Epoch[31](900/2500): Loss: 0.2798
===> Epoch[31](1000/2500): Loss: 0.2825
===> Epoch[31](1100/2500): Loss: 0.3035
===> Epoch[31](1200/2500): Loss: 0.2791
===> Epoch[31](1300/2500): Loss: 0.2794
===> Epoch[31](1400/2500): Loss: 0.2793
===> Epoch[31](1500/2500): Loss: 0.2634
===> Epoch[31](1600/2500): Loss: 0.2765
===> Epoch[31](1700/2500): Loss: 0.2717
===> Epoch[31](1800/2500): Loss: 0.2826
===> Epoch[31](1900/2500): Loss: 0.3034
===> Epoch[31](2000/2500): Loss: 0.2670
===> Epoch[31](2100/2500): Loss: 0.2959
===> Epoch[31](2200/2500): Loss: 0.2668
===> Epoch[31](2300/2500): Loss: 0.2749
===> Epoch[31](2400/2500): Loss: 0.2828
===> Epoch[31](2500/2500): Loss: 0.2708
===> Epoch 31 Complete: Avg. Loss: 0.2857
===> Timestamp: [2025-08-03 21:52:49]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2745
===> Epoch[31](200/2500): Loss: 0.3068
===> Epoch[31](300/2500): Loss: 0.2942
===> Epoch[31](400/2500): Loss: 0.3031
===> Epoch[31](500/2500): Loss: 0.3067
===> Epoch[31](600/2500): Loss: 0.2694
===> Epoch[31](700/2500): Loss: 0.2870
===> Epoch[31](800/2500): Loss: 0.2977
===> Epoch[31](900/2500): Loss: 0.2798
===> Epoch[31](1000/2500): Loss: 0.2825
===> Epoch[31](1100/2500): Loss: 0.3035
===> Epoch[31](1200/2500): Loss: 0.2791
===> Epoch[31](1300/2500): Loss: 0.2794
===> Epoch[31](1400/2500): Loss: 0.2793
===> Epoch[31](1500/2500): Loss: 0.2634
===> Epoch[31](1600/2500): Loss: 0.2765
===> Epoch[31](1700/2500): Loss: 0.2717
===> Epoch[31](1800/2500): Loss: 0.2826
===> Epoch[31](1900/2500): Loss: 0.3034
===> Epoch[31](2000/2500): Loss: 0.2670
===> Epoch[31](2100/2500): Loss: 0.2959
===> Epoch[31](2200/2500): Loss: 0.2668
===> Epoch[31](2300/2500): Loss: 0.2749
===> Epoch[31](2400/2500): Loss: 0.2828
===> Epoch[31](2500/2500): Loss: 0.2708
===> Epoch 31 Complete: Avg. Loss: 0.2857
===> Timestamp: [2025-08-03 21:52:49]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2745
===> Epoch[31](200/2500): Loss: 0.3068
===> Epoch[31](300/2500): Loss: 0.2942
===> Epoch[31](400/2500): Loss: 0.3031
===> Epoch[31](500/2500): Loss: 0.3067
===> Epoch[31](600/2500): Loss: 0.2694
===> Epoch[31](700/2500): Loss: 0.2870
===> Epoch[31](800/2500): Loss: 0.2977
===> Epoch[31](900/2500): Loss: 0.2798
===> Epoch[31](1000/2500): Loss: 0.2825
===> Epoch[31](1100/2500): Loss: 0.3035
===> Epoch[31](1200/2500): Loss: 0.2791
===> Epoch[31](1300/2500): Loss: 0.2794
===> Epoch[31](1400/2500): Loss: 0.2793
===> Epoch[31](1500/2500): Loss: 0.2634
===> Epoch[31](1600/2500): Loss: 0.2765
===> Epoch[31](1700/2500): Loss: 0.2717
===> Epoch[31](1800/2500): Loss: 0.2826
===> Epoch[31](1900/2500): Loss: 0.3034
===> Epoch[31](2000/2500): Loss: 0.2670
===> Epoch[31](2100/2500): Loss: 0.2959
===> Epoch[31](2200/2500): Loss: 0.2668
===> Epoch[31](2300/2500): Loss: 0.2749
===> Epoch[31](2400/2500): Loss: 0.2828
===> Epoch[31](2500/2500): Loss: 0.2708
===> Epoch 31 Complete: Avg. Loss: 0.2857
===> Timestamp: [2025-08-03 21:52:49]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2745
===> Epoch[31](200/2500): Loss: 0.3068
===> Epoch[31](300/2500): Loss: 0.2942
===> Epoch[31](400/2500): Loss: 0.3031
===> Epoch[31](500/2500): Loss: 0.3067
===> Epoch[31](600/2500): Loss: 0.2694
===> Epoch[31](700/2500): Loss: 0.2870
===> Epoch[31](800/2500): Loss: 0.2977
===> Epoch[31](900/2500): Loss: 0.2798
===> Epoch[31](1000/2500): Loss: 0.2825
===> Epoch[31](1100/2500): Loss: 0.3035
===> Epoch[31](1200/2500): Loss: 0.2791
===> Epoch[31](1300/2500): Loss: 0.2794
===> Epoch[31](1400/2500): Loss: 0.2793
===> Epoch[31](1500/2500): Loss: 0.2634
===> Epoch[31](1600/2500): Loss: 0.2765
===> Epoch[31](1700/2500): Loss: 0.2717
===> Epoch[31](1800/2500): Loss: 0.2826
===> Epoch[31](1900/2500): Loss: 0.3034
===> Epoch[31](2000/2500): Loss: 0.2670
===> Epoch[31](2100/2500): Loss: 0.2959
===> Epoch[31](2200/2500): Loss: 0.2668
===> Epoch[31](2300/2500): Loss: 0.2749
===> Epoch[31](2400/2500): Loss: 0.2828
===> Epoch[31](2500/2500): Loss: 0.2708
===> Epoch 31 Complete: Avg. Loss: 0.2857
===> Timestamp: [2025-08-03 21:52:49]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2745
===> Epoch[31](200/2500): Loss: 0.3068
===> Epoch[31](300/2500): Loss: 0.2942
===> Epoch[31](400/2500): Loss: 0.3031
===> Epoch[31](500/2500): Loss: 0.3067
===> Epoch[31](600/2500): Loss: 0.2694
===> Epoch[31](700/2500): Loss: 0.2870
===> Epoch[31](800/2500): Loss: 0.2977
===> Epoch[31](900/2500): Loss: 0.2798
===> Epoch[31](1000/2500): Loss: 0.2825
===> Epoch[31](1100/2500): Loss: 0.3035
===> Epoch[31](1200/2500): Loss: 0.2791
===> Epoch[31](1300/2500): Loss: 0.2794
===> Epoch[31](1400/2500): Loss: 0.2793
===> Epoch[31](1500/2500): Loss: 0.2634
===> Epoch[31](1600/2500): Loss: 0.2765
===> Epoch[31](1700/2500): Loss: 0.2717
===> Epoch[31](1800/2500): Loss: 0.2826
===> Epoch[31](1900/2500): Loss: 0.3034
===> Epoch[31](2000/2500): Loss: 0.2670
===> Epoch[31](2100/2500): Loss: 0.2959
===> Epoch[31](2200/2500): Loss: 0.2668
===> Epoch[31](2300/2500): Loss: 0.2749
===> Epoch[31](2400/2500): Loss: 0.2828
===> Epoch[31](2500/2500): Loss: 0.2708
===> Epoch 31 Complete: Avg. Loss: 0.2857
===> Timestamp: [2025-08-03 21:52:49]
===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.2745
===> Epoch[31](200/2500): Loss: 0.3068
===> Epoch[31](300/2500): Loss: 0.2942
===> Epoch[31](400/2500): Loss: 0.3031
===> Epoch[31](500/2500): Loss: 0.3067
===> Epoch[31](600/2500): Loss: 0.2694
===> Epoch[31](700/2500): Loss: 0.2870
===> Epoch[31](800/2500): Loss: 0.2977
===> Epoch[31](900/2500): Loss: 0.2798
===> Epoch[31](1000/2500): Loss: 0.2825
===> Epoch[31](1100/2500): Loss: 0.3035
===> Epoch[31](1200/2500): Loss: 0.2791
===> Epoch[31](1300/2500): Loss: 0.2794
===> Epoch[31](1400/2500): Loss: 0.2793
===> Epoch[31](1500/2500): Loss: 0.2634
===> Epoch[31](1600/2500): Loss: 0.2765
===> Epoch[31](1700/2500): Loss: 0.2717
===> Epoch[31](1800/2500): Loss: 0.2826
===> Epoch[31](1900/2500): Loss: 0.3034
===> Epoch[31](2000/2500): Loss: 0.2670
===> Epoch[31](2100/2500): Loss: 0.2959
===> Epoch[31](2200/2500): Loss: 0.2668
===> Epoch[31](2300/2500): Loss: 0.2749
===> Epoch[31](2400/2500): Loss: 0.2828
===> Epoch[31](2500/2500): Loss: 0.2708
===> Epoch 31 Complete: Avg. Loss: 0.2857
===> Timestamp: [2025-08-03 21:52:49]
===> Loading train datasets
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.3001
===> Epoch[32](200/2500): Loss: 0.2744
===> Epoch[32](300/2500): Loss: 0.2987
===> Epoch[32](400/2500): Loss: 0.3138
===> Epoch[32](500/2500): Loss: 0.2779
===> Epoch[32](600/2500): Loss: 0.2885
===> Epoch[32](700/2500): Loss: 0.2859
===> Epoch[32](800/2500): Loss: 0.2775
===> Epoch[32](900/2500): Loss: 0.2672
===> Epoch[32](1000/2500): Loss: 0.3106
===> Epoch[32](1100/2500): Loss: 0.2743
===> Epoch[32](1200/2500): Loss: 0.2905
===> Epoch[32](1300/2500): Loss: 0.2987
===> Epoch[32](1400/2500): Loss: 0.3024
===> Epoch[32](1500/2500): Loss: 0.2711
===> Epoch[32](1600/2500): Loss: 0.2958
===> Epoch[32](1700/2500): Loss: 0.2866
===> Epoch[32](1800/2500): Loss: 0.2774
===> Epoch[32](1900/2500): Loss: 0.2793
===> Epoch[32](2000/2500): Loss: 0.3077
===> Epoch[32](2100/2500): Loss: 0.2934
===> Epoch[32](2200/2500): Loss: 0.2954
===> Epoch[32](2300/2500): Loss: 0.2416
===> Epoch[32](2400/2500): Loss: 0.2993
===> Epoch[32](2500/2500): Loss: 0.2816
===> Epoch 32 Complete: Avg. Loss: 0.2856
===> Timestamp: [2025-08-03 21:57:23]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.3001
===> Epoch[32](200/2500): Loss: 0.2744
===> Epoch[32](300/2500): Loss: 0.2987
===> Epoch[32](400/2500): Loss: 0.3138
===> Epoch[32](500/2500): Loss: 0.2779
===> Epoch[32](600/2500): Loss: 0.2885
===> Epoch[32](700/2500): Loss: 0.2859
===> Epoch[32](800/2500): Loss: 0.2775
===> Epoch[32](900/2500): Loss: 0.2672
===> Epoch[32](1000/2500): Loss: 0.3106
===> Epoch[32](1100/2500): Loss: 0.2743
===> Epoch[32](1200/2500): Loss: 0.2905
===> Epoch[32](1300/2500): Loss: 0.2987
===> Epoch[32](1400/2500): Loss: 0.3024
===> Epoch[32](1500/2500): Loss: 0.2711
===> Epoch[32](1600/2500): Loss: 0.2958
===> Epoch[32](1700/2500): Loss: 0.2866
===> Epoch[32](1800/2500): Loss: 0.2774
===> Epoch[32](1900/2500): Loss: 0.2793
===> Epoch[32](2000/2500): Loss: 0.3077
===> Epoch[32](2100/2500): Loss: 0.2934
===> Epoch[32](2200/2500): Loss: 0.2954
===> Epoch[32](2300/2500): Loss: 0.2416
===> Epoch[32](2400/2500): Loss: 0.2993
===> Epoch[32](2500/2500): Loss: 0.2816
===> Epoch 32 Complete: Avg. Loss: 0.2856
===> Timestamp: [2025-08-03 21:57:23]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.3001
===> Epoch[32](200/2500): Loss: 0.2744
===> Epoch[32](300/2500): Loss: 0.2987
===> Epoch[32](400/2500): Loss: 0.3138
===> Epoch[32](500/2500): Loss: 0.2779
===> Epoch[32](600/2500): Loss: 0.2885
===> Epoch[32](700/2500): Loss: 0.2859
===> Epoch[32](800/2500): Loss: 0.2775
===> Epoch[32](900/2500): Loss: 0.2672
===> Epoch[32](1000/2500): Loss: 0.3106
===> Epoch[32](1100/2500): Loss: 0.2743
===> Epoch[32](1200/2500): Loss: 0.2905
===> Epoch[32](1300/2500): Loss: 0.2987
===> Epoch[32](1400/2500): Loss: 0.3024
===> Epoch[32](1500/2500): Loss: 0.2711
===> Epoch[32](1600/2500): Loss: 0.2958
===> Epoch[32](1700/2500): Loss: 0.2866
===> Epoch[32](1800/2500): Loss: 0.2774
===> Epoch[32](1900/2500): Loss: 0.2793
===> Epoch[32](2000/2500): Loss: 0.3077
===> Epoch[32](2100/2500): Loss: 0.2934
===> Epoch[32](2200/2500): Loss: 0.2954
===> Epoch[32](2300/2500): Loss: 0.2416
===> Epoch[32](2400/2500): Loss: 0.2993
===> Epoch[32](2500/2500): Loss: 0.2816
===> Epoch 32 Complete: Avg. Loss: 0.2856
===> Timestamp: [2025-08-03 21:57:23]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.3001
===> Epoch[32](200/2500): Loss: 0.2744
===> Epoch[32](300/2500): Loss: 0.2987
===> Epoch[32](400/2500): Loss: 0.3138
===> Epoch[32](500/2500): Loss: 0.2779
===> Epoch[32](600/2500): Loss: 0.2885
===> Epoch[32](700/2500): Loss: 0.2859
===> Epoch[32](800/2500): Loss: 0.2775
===> Epoch[32](900/2500): Loss: 0.2672
===> Epoch[32](1000/2500): Loss: 0.3106
===> Epoch[32](1100/2500): Loss: 0.2743
===> Epoch[32](1200/2500): Loss: 0.2905
===> Epoch[32](1300/2500): Loss: 0.2987
===> Epoch[32](1400/2500): Loss: 0.3024
===> Epoch[32](1500/2500): Loss: 0.2711
===> Epoch[32](1600/2500): Loss: 0.2958
===> Epoch[32](1700/2500): Loss: 0.2866
===> Epoch[32](1800/2500): Loss: 0.2774
===> Epoch[32](1900/2500): Loss: 0.2793
===> Epoch[32](2000/2500): Loss: 0.3077
===> Epoch[32](2100/2500): Loss: 0.2934
===> Epoch[32](2200/2500): Loss: 0.2954
===> Epoch[32](2300/2500): Loss: 0.2416
===> Epoch[32](2400/2500): Loss: 0.2993
===> Epoch[32](2500/2500): Loss: 0.2816
===> Epoch 32 Complete: Avg. Loss: 0.2856
===> Timestamp: [2025-08-03 21:57:23]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.3001
===> Epoch[32](200/2500): Loss: 0.2744
===> Epoch[32](300/2500): Loss: 0.2987
===> Epoch[32](400/2500): Loss: 0.3138
===> Epoch[32](500/2500): Loss: 0.2779
===> Epoch[32](600/2500): Loss: 0.2885
===> Epoch[32](700/2500): Loss: 0.2859
===> Epoch[32](800/2500): Loss: 0.2775
===> Epoch[32](900/2500): Loss: 0.2672
===> Epoch[32](1000/2500): Loss: 0.3106
===> Epoch[32](1100/2500): Loss: 0.2743
===> Epoch[32](1200/2500): Loss: 0.2905
===> Epoch[32](1300/2500): Loss: 0.2987
===> Epoch[32](1400/2500): Loss: 0.3024
===> Epoch[32](1500/2500): Loss: 0.2711
===> Epoch[32](1600/2500): Loss: 0.2958
===> Epoch[32](1700/2500): Loss: 0.2866
===> Epoch[32](1800/2500): Loss: 0.2774
===> Epoch[32](1900/2500): Loss: 0.2793
===> Epoch[32](2000/2500): Loss: 0.3077
===> Epoch[32](2100/2500): Loss: 0.2934
===> Epoch[32](2200/2500): Loss: 0.2954
===> Epoch[32](2300/2500): Loss: 0.2416
===> Epoch[32](2400/2500): Loss: 0.2993
===> Epoch[32](2500/2500): Loss: 0.2816
===> Epoch 32 Complete: Avg. Loss: 0.2856
===> Timestamp: [2025-08-03 21:57:23]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.3001
===> Epoch[32](200/2500): Loss: 0.2744
===> Epoch[32](300/2500): Loss: 0.2987
===> Epoch[32](400/2500): Loss: 0.3138
===> Epoch[32](500/2500): Loss: 0.2779
===> Epoch[32](600/2500): Loss: 0.2885
===> Epoch[32](700/2500): Loss: 0.2859
===> Epoch[32](800/2500): Loss: 0.2775
===> Epoch[32](900/2500): Loss: 0.2672
===> Epoch[32](1000/2500): Loss: 0.3106
===> Epoch[32](1100/2500): Loss: 0.2743
===> Epoch[32](1200/2500): Loss: 0.2905
===> Epoch[32](1300/2500): Loss: 0.2987
===> Epoch[32](1400/2500): Loss: 0.3024
===> Epoch[32](1500/2500): Loss: 0.2711
===> Epoch[32](1600/2500): Loss: 0.2958
===> Epoch[32](1700/2500): Loss: 0.2866
===> Epoch[32](1800/2500): Loss: 0.2774
===> Epoch[32](1900/2500): Loss: 0.2793
===> Epoch[32](2000/2500): Loss: 0.3077
===> Epoch[32](2100/2500): Loss: 0.2934
===> Epoch[32](2200/2500): Loss: 0.2954
===> Epoch[32](2300/2500): Loss: 0.2416
===> Epoch[32](2400/2500): Loss: 0.2993
===> Epoch[32](2500/2500): Loss: 0.2816
===> Epoch 32 Complete: Avg. Loss: 0.2856
===> Timestamp: [2025-08-03 21:57:23]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.3001
===> Epoch[32](200/2500): Loss: 0.2744
===> Epoch[32](300/2500): Loss: 0.2987
===> Epoch[32](400/2500): Loss: 0.3138
===> Epoch[32](500/2500): Loss: 0.2779
===> Epoch[32](600/2500): Loss: 0.2885
===> Epoch[32](700/2500): Loss: 0.2859
===> Epoch[32](800/2500): Loss: 0.2775
===> Epoch[32](900/2500): Loss: 0.2672
===> Epoch[32](1000/2500): Loss: 0.3106
===> Epoch[32](1100/2500): Loss: 0.2743
===> Epoch[32](1200/2500): Loss: 0.2905
===> Epoch[32](1300/2500): Loss: 0.2987
===> Epoch[32](1400/2500): Loss: 0.3024
===> Epoch[32](1500/2500): Loss: 0.2711
===> Epoch[32](1600/2500): Loss: 0.2958
===> Epoch[32](1700/2500): Loss: 0.2866
===> Epoch[32](1800/2500): Loss: 0.2774
===> Epoch[32](1900/2500): Loss: 0.2793
===> Epoch[32](2000/2500): Loss: 0.3077
===> Epoch[32](2100/2500): Loss: 0.2934
===> Epoch[32](2200/2500): Loss: 0.2954
===> Epoch[32](2300/2500): Loss: 0.2416
===> Epoch[32](2400/2500): Loss: 0.2993
===> Epoch[32](2500/2500): Loss: 0.2816
===> Epoch 32 Complete: Avg. Loss: 0.2856
===> Timestamp: [2025-08-03 21:57:23]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.3001
===> Epoch[32](200/2500): Loss: 0.2744
===> Epoch[32](300/2500): Loss: 0.2987
===> Epoch[32](400/2500): Loss: 0.3138
===> Epoch[32](500/2500): Loss: 0.2779
===> Epoch[32](600/2500): Loss: 0.2885
===> Epoch[32](700/2500): Loss: 0.2859
===> Epoch[32](800/2500): Loss: 0.2775
===> Epoch[32](900/2500): Loss: 0.2672
===> Epoch[32](1000/2500): Loss: 0.3106
===> Epoch[32](1100/2500): Loss: 0.2743
===> Epoch[32](1200/2500): Loss: 0.2905
===> Epoch[32](1300/2500): Loss: 0.2987
===> Epoch[32](1400/2500): Loss: 0.3024
===> Epoch[32](1500/2500): Loss: 0.2711
===> Epoch[32](1600/2500): Loss: 0.2958
===> Epoch[32](1700/2500): Loss: 0.2866
===> Epoch[32](1800/2500): Loss: 0.2774
===> Epoch[32](1900/2500): Loss: 0.2793
===> Epoch[32](2000/2500): Loss: 0.3077
===> Epoch[32](2100/2500): Loss: 0.2934
===> Epoch[32](2200/2500): Loss: 0.2954
===> Epoch[32](2300/2500): Loss: 0.2416
===> Epoch[32](2400/2500): Loss: 0.2993
===> Epoch[32](2500/2500): Loss: 0.2816
===> Epoch 32 Complete: Avg. Loss: 0.2856
===> Timestamp: [2025-08-03 21:57:23]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.3001
===> Epoch[32](200/2500): Loss: 0.2744
===> Epoch[32](300/2500): Loss: 0.2987
===> Epoch[32](400/2500): Loss: 0.3138
===> Epoch[32](500/2500): Loss: 0.2779
===> Epoch[32](600/2500): Loss: 0.2885
===> Epoch[32](700/2500): Loss: 0.2859
===> Epoch[32](800/2500): Loss: 0.2775
===> Epoch[32](900/2500): Loss: 0.2672
===> Epoch[32](1000/2500): Loss: 0.3106
===> Epoch[32](1100/2500): Loss: 0.2743
===> Epoch[32](1200/2500): Loss: 0.2905
===> Epoch[32](1300/2500): Loss: 0.2987
===> Epoch[32](1400/2500): Loss: 0.3024
===> Epoch[32](1500/2500): Loss: 0.2711
===> Epoch[32](1600/2500): Loss: 0.2958
===> Epoch[32](1700/2500): Loss: 0.2866
===> Epoch[32](1800/2500): Loss: 0.2774
===> Epoch[32](1900/2500): Loss: 0.2793
===> Epoch[32](2000/2500): Loss: 0.3077
===> Epoch[32](2100/2500): Loss: 0.2934
===> Epoch[32](2200/2500): Loss: 0.2954
===> Epoch[32](2300/2500): Loss: 0.2416
===> Epoch[32](2400/2500): Loss: 0.2993
===> Epoch[32](2500/2500): Loss: 0.2816
===> Epoch 32 Complete: Avg. Loss: 0.2856
===> Timestamp: [2025-08-03 21:57:23]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.3001
===> Epoch[32](200/2500): Loss: 0.2744
===> Epoch[32](300/2500): Loss: 0.2987
===> Epoch[32](400/2500): Loss: 0.3138
===> Epoch[32](500/2500): Loss: 0.2779
===> Epoch[32](600/2500): Loss: 0.2885
===> Epoch[32](700/2500): Loss: 0.2859
===> Epoch[32](800/2500): Loss: 0.2775
===> Epoch[32](900/2500): Loss: 0.2672
===> Epoch[32](1000/2500): Loss: 0.3106
===> Epoch[32](1100/2500): Loss: 0.2743
===> Epoch[32](1200/2500): Loss: 0.2905
===> Epoch[32](1300/2500): Loss: 0.2987
===> Epoch[32](1400/2500): Loss: 0.3024
===> Epoch[32](1500/2500): Loss: 0.2711
===> Epoch[32](1600/2500): Loss: 0.2958
===> Epoch[32](1700/2500): Loss: 0.2866
===> Epoch[32](1800/2500): Loss: 0.2774
===> Epoch[32](1900/2500): Loss: 0.2793
===> Epoch[32](2000/2500): Loss: 0.3077
===> Epoch[32](2100/2500): Loss: 0.2934
===> Epoch[32](2200/2500): Loss: 0.2954
===> Epoch[32](2300/2500): Loss: 0.2416
===> Epoch[32](2400/2500): Loss: 0.2993
===> Epoch[32](2500/2500): Loss: 0.2816
===> Epoch 32 Complete: Avg. Loss: 0.2856
===> Timestamp: [2025-08-03 21:57:23]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.3001
===> Epoch[32](200/2500): Loss: 0.2744
===> Epoch[32](300/2500): Loss: 0.2987
===> Epoch[32](400/2500): Loss: 0.3138
===> Epoch[32](500/2500): Loss: 0.2779
===> Epoch[32](600/2500): Loss: 0.2885
===> Epoch[32](700/2500): Loss: 0.2859
===> Epoch[32](800/2500): Loss: 0.2775
===> Epoch[32](900/2500): Loss: 0.2672
===> Epoch[32](1000/2500): Loss: 0.3106
===> Epoch[32](1100/2500): Loss: 0.2743
===> Epoch[32](1200/2500): Loss: 0.2905
===> Epoch[32](1300/2500): Loss: 0.2987
===> Epoch[32](1400/2500): Loss: 0.3024
===> Epoch[32](1500/2500): Loss: 0.2711
===> Epoch[32](1600/2500): Loss: 0.2958
===> Epoch[32](1700/2500): Loss: 0.2866
===> Epoch[32](1800/2500): Loss: 0.2774
===> Epoch[32](1900/2500): Loss: 0.2793
===> Epoch[32](2000/2500): Loss: 0.3077
===> Epoch[32](2100/2500): Loss: 0.2934
===> Epoch[32](2200/2500): Loss: 0.2954
===> Epoch[32](2300/2500): Loss: 0.2416
===> Epoch[32](2400/2500): Loss: 0.2993
===> Epoch[32](2500/2500): Loss: 0.2816
===> Epoch 32 Complete: Avg. Loss: 0.2856
===> Timestamp: [2025-08-03 21:57:23]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.3001
===> Epoch[32](200/2500): Loss: 0.2744
===> Epoch[32](300/2500): Loss: 0.2987
===> Epoch[32](400/2500): Loss: 0.3138
===> Epoch[32](500/2500): Loss: 0.2779
===> Epoch[32](600/2500): Loss: 0.2885
===> Epoch[32](700/2500): Loss: 0.2859
===> Epoch[32](800/2500): Loss: 0.2775
===> Epoch[32](900/2500): Loss: 0.2672
===> Epoch[32](1000/2500): Loss: 0.3106
===> Epoch[32](1100/2500): Loss: 0.2743
===> Epoch[32](1200/2500): Loss: 0.2905
===> Epoch[32](1300/2500): Loss: 0.2987
===> Epoch[32](1400/2500): Loss: 0.3024
===> Epoch[32](1500/2500): Loss: 0.2711
===> Epoch[32](1600/2500): Loss: 0.2958
===> Epoch[32](1700/2500): Loss: 0.2866
===> Epoch[32](1800/2500): Loss: 0.2774
===> Epoch[32](1900/2500): Loss: 0.2793
===> Epoch[32](2000/2500): Loss: 0.3077
===> Epoch[32](2100/2500): Loss: 0.2934
===> Epoch[32](2200/2500): Loss: 0.2954
===> Epoch[32](2300/2500): Loss: 0.2416
===> Epoch[32](2400/2500): Loss: 0.2993
===> Epoch[32](2500/2500): Loss: 0.2816
===> Epoch 32 Complete: Avg. Loss: 0.2856
===> Timestamp: [2025-08-03 21:57:23]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.3001
===> Epoch[32](200/2500): Loss: 0.2744
===> Epoch[32](300/2500): Loss: 0.2987
===> Epoch[32](400/2500): Loss: 0.3138
===> Epoch[32](500/2500): Loss: 0.2779
===> Epoch[32](600/2500): Loss: 0.2885
===> Epoch[32](700/2500): Loss: 0.2859
===> Epoch[32](800/2500): Loss: 0.2775
===> Epoch[32](900/2500): Loss: 0.2672
===> Epoch[32](1000/2500): Loss: 0.3106
===> Epoch[32](1100/2500): Loss: 0.2743
===> Epoch[32](1200/2500): Loss: 0.2905
===> Epoch[32](1300/2500): Loss: 0.2987
===> Epoch[32](1400/2500): Loss: 0.3024
===> Epoch[32](1500/2500): Loss: 0.2711
===> Epoch[32](1600/2500): Loss: 0.2958
===> Epoch[32](1700/2500): Loss: 0.2866
===> Epoch[32](1800/2500): Loss: 0.2774
===> Epoch[32](1900/2500): Loss: 0.2793
===> Epoch[32](2000/2500): Loss: 0.3077
===> Epoch[32](2100/2500): Loss: 0.2934
===> Epoch[32](2200/2500): Loss: 0.2954
===> Epoch[32](2300/2500): Loss: 0.2416
===> Epoch[32](2400/2500): Loss: 0.2993
===> Epoch[32](2500/2500): Loss: 0.2816
===> Epoch 32 Complete: Avg. Loss: 0.2856
===> Timestamp: [2025-08-03 21:57:23]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.3001
===> Epoch[32](200/2500): Loss: 0.2744
===> Epoch[32](300/2500): Loss: 0.2987
===> Epoch[32](400/2500): Loss: 0.3138
===> Epoch[32](500/2500): Loss: 0.2779
===> Epoch[32](600/2500): Loss: 0.2885
===> Epoch[32](700/2500): Loss: 0.2859
===> Epoch[32](800/2500): Loss: 0.2775
===> Epoch[32](900/2500): Loss: 0.2672
===> Epoch[32](1000/2500): Loss: 0.3106
===> Epoch[32](1100/2500): Loss: 0.2743
===> Epoch[32](1200/2500): Loss: 0.2905
===> Epoch[32](1300/2500): Loss: 0.2987
===> Epoch[32](1400/2500): Loss: 0.3024
===> Epoch[32](1500/2500): Loss: 0.2711
===> Epoch[32](1600/2500): Loss: 0.2958
===> Epoch[32](1700/2500): Loss: 0.2866
===> Epoch[32](1800/2500): Loss: 0.2774
===> Epoch[32](1900/2500): Loss: 0.2793
===> Epoch[32](2000/2500): Loss: 0.3077
===> Epoch[32](2100/2500): Loss: 0.2934
===> Epoch[32](2200/2500): Loss: 0.2954
===> Epoch[32](2300/2500): Loss: 0.2416
===> Epoch[32](2400/2500): Loss: 0.2993
===> Epoch[32](2500/2500): Loss: 0.2816
===> Epoch 32 Complete: Avg. Loss: 0.2856
===> Timestamp: [2025-08-03 21:57:23]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.3001
===> Epoch[32](200/2500): Loss: 0.2744
===> Epoch[32](300/2500): Loss: 0.2987
===> Epoch[32](400/2500): Loss: 0.3138
===> Epoch[32](500/2500): Loss: 0.2779
===> Epoch[32](600/2500): Loss: 0.2885
===> Epoch[32](700/2500): Loss: 0.2859
===> Epoch[32](800/2500): Loss: 0.2775
===> Epoch[32](900/2500): Loss: 0.2672
===> Epoch[32](1000/2500): Loss: 0.3106
===> Epoch[32](1100/2500): Loss: 0.2743
===> Epoch[32](1200/2500): Loss: 0.2905
===> Epoch[32](1300/2500): Loss: 0.2987
===> Epoch[32](1400/2500): Loss: 0.3024
===> Epoch[32](1500/2500): Loss: 0.2711
===> Epoch[32](1600/2500): Loss: 0.2958
===> Epoch[32](1700/2500): Loss: 0.2866
===> Epoch[32](1800/2500): Loss: 0.2774
===> Epoch[32](1900/2500): Loss: 0.2793
===> Epoch[32](2000/2500): Loss: 0.3077
===> Epoch[32](2100/2500): Loss: 0.2934
===> Epoch[32](2200/2500): Loss: 0.2954
===> Epoch[32](2300/2500): Loss: 0.2416
===> Epoch[32](2400/2500): Loss: 0.2993
===> Epoch[32](2500/2500): Loss: 0.2816
===> Epoch 32 Complete: Avg. Loss: 0.2856
===> Timestamp: [2025-08-03 21:57:23]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.3001
===> Epoch[32](200/2500): Loss: 0.2744
===> Epoch[32](300/2500): Loss: 0.2987
===> Epoch[32](400/2500): Loss: 0.3138
===> Epoch[32](500/2500): Loss: 0.2779
===> Epoch[32](600/2500): Loss: 0.2885
===> Epoch[32](700/2500): Loss: 0.2859
===> Epoch[32](800/2500): Loss: 0.2775
===> Epoch[32](900/2500): Loss: 0.2672
===> Epoch[32](1000/2500): Loss: 0.3106
===> Epoch[32](1100/2500): Loss: 0.2743
===> Epoch[32](1200/2500): Loss: 0.2905
===> Epoch[32](1300/2500): Loss: 0.2987
===> Epoch[32](1400/2500): Loss: 0.3024
===> Epoch[32](1500/2500): Loss: 0.2711
===> Epoch[32](1600/2500): Loss: 0.2958
===> Epoch[32](1700/2500): Loss: 0.2866
===> Epoch[32](1800/2500): Loss: 0.2774
===> Epoch[32](1900/2500): Loss: 0.2793
===> Epoch[32](2000/2500): Loss: 0.3077
===> Epoch[32](2100/2500): Loss: 0.2934
===> Epoch[32](2200/2500): Loss: 0.2954
===> Epoch[32](2300/2500): Loss: 0.2416
===> Epoch[32](2400/2500): Loss: 0.2993
===> Epoch[32](2500/2500): Loss: 0.2816
===> Epoch 32 Complete: Avg. Loss: 0.2856
===> Timestamp: [2025-08-03 21:57:23]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.3001
===> Epoch[32](200/2500): Loss: 0.2744
===> Epoch[32](300/2500): Loss: 0.2987
===> Epoch[32](400/2500): Loss: 0.3138
===> Epoch[32](500/2500): Loss: 0.2779
===> Epoch[32](600/2500): Loss: 0.2885
===> Epoch[32](700/2500): Loss: 0.2859
===> Epoch[32](800/2500): Loss: 0.2775
===> Epoch[32](900/2500): Loss: 0.2672
===> Epoch[32](1000/2500): Loss: 0.3106
===> Epoch[32](1100/2500): Loss: 0.2743
===> Epoch[32](1200/2500): Loss: 0.2905
===> Epoch[32](1300/2500): Loss: 0.2987
===> Epoch[32](1400/2500): Loss: 0.3024
===> Epoch[32](1500/2500): Loss: 0.2711
===> Epoch[32](1600/2500): Loss: 0.2958
===> Epoch[32](1700/2500): Loss: 0.2866
===> Epoch[32](1800/2500): Loss: 0.2774
===> Epoch[32](1900/2500): Loss: 0.2793
===> Epoch[32](2000/2500): Loss: 0.3077
===> Epoch[32](2100/2500): Loss: 0.2934
===> Epoch[32](2200/2500): Loss: 0.2954
===> Epoch[32](2300/2500): Loss: 0.2416
===> Epoch[32](2400/2500): Loss: 0.2993
===> Epoch[32](2500/2500): Loss: 0.2816
===> Epoch 32 Complete: Avg. Loss: 0.2856
===> Timestamp: [2025-08-03 21:57:23]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.3001
===> Epoch[32](200/2500): Loss: 0.2744
===> Epoch[32](300/2500): Loss: 0.2987
===> Epoch[32](400/2500): Loss: 0.3138
===> Epoch[32](500/2500): Loss: 0.2779
===> Epoch[32](600/2500): Loss: 0.2885
===> Epoch[32](700/2500): Loss: 0.2859
===> Epoch[32](800/2500): Loss: 0.2775
===> Epoch[32](900/2500): Loss: 0.2672
===> Epoch[32](1000/2500): Loss: 0.3106
===> Epoch[32](1100/2500): Loss: 0.2743
===> Epoch[32](1200/2500): Loss: 0.2905
===> Epoch[32](1300/2500): Loss: 0.2987
===> Epoch[32](1400/2500): Loss: 0.3024
===> Epoch[32](1500/2500): Loss: 0.2711
===> Epoch[32](1600/2500): Loss: 0.2958
===> Epoch[32](1700/2500): Loss: 0.2866
===> Epoch[32](1800/2500): Loss: 0.2774
===> Epoch[32](1900/2500): Loss: 0.2793
===> Epoch[32](2000/2500): Loss: 0.3077
===> Epoch[32](2100/2500): Loss: 0.2934
===> Epoch[32](2200/2500): Loss: 0.2954
===> Epoch[32](2300/2500): Loss: 0.2416
===> Epoch[32](2400/2500): Loss: 0.2993
===> Epoch[32](2500/2500): Loss: 0.2816
===> Epoch 32 Complete: Avg. Loss: 0.2856
===> Timestamp: [2025-08-03 21:57:23]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.3001
===> Epoch[32](200/2500): Loss: 0.2744
===> Epoch[32](300/2500): Loss: 0.2987
===> Epoch[32](400/2500): Loss: 0.3138
===> Epoch[32](500/2500): Loss: 0.2779
===> Epoch[32](600/2500): Loss: 0.2885
===> Epoch[32](700/2500): Loss: 0.2859
===> Epoch[32](800/2500): Loss: 0.2775
===> Epoch[32](900/2500): Loss: 0.2672
===> Epoch[32](1000/2500): Loss: 0.3106
===> Epoch[32](1100/2500): Loss: 0.2743
===> Epoch[32](1200/2500): Loss: 0.2905
===> Epoch[32](1300/2500): Loss: 0.2987
===> Epoch[32](1400/2500): Loss: 0.3024
===> Epoch[32](1500/2500): Loss: 0.2711
===> Epoch[32](1600/2500): Loss: 0.2958
===> Epoch[32](1700/2500): Loss: 0.2866
===> Epoch[32](1800/2500): Loss: 0.2774
===> Epoch[32](1900/2500): Loss: 0.2793
===> Epoch[32](2000/2500): Loss: 0.3077
===> Epoch[32](2100/2500): Loss: 0.2934
===> Epoch[32](2200/2500): Loss: 0.2954
===> Epoch[32](2300/2500): Loss: 0.2416
===> Epoch[32](2400/2500): Loss: 0.2993
===> Epoch[32](2500/2500): Loss: 0.2816
===> Epoch 32 Complete: Avg. Loss: 0.2856
===> Timestamp: [2025-08-03 21:57:23]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.3001
===> Epoch[32](200/2500): Loss: 0.2744
===> Epoch[32](300/2500): Loss: 0.2987
===> Epoch[32](400/2500): Loss: 0.3138
===> Epoch[32](500/2500): Loss: 0.2779
===> Epoch[32](600/2500): Loss: 0.2885
===> Epoch[32](700/2500): Loss: 0.2859
===> Epoch[32](800/2500): Loss: 0.2775
===> Epoch[32](900/2500): Loss: 0.2672
===> Epoch[32](1000/2500): Loss: 0.3106
===> Epoch[32](1100/2500): Loss: 0.2743
===> Epoch[32](1200/2500): Loss: 0.2905
===> Epoch[32](1300/2500): Loss: 0.2987
===> Epoch[32](1400/2500): Loss: 0.3024
===> Epoch[32](1500/2500): Loss: 0.2711
===> Epoch[32](1600/2500): Loss: 0.2958
===> Epoch[32](1700/2500): Loss: 0.2866
===> Epoch[32](1800/2500): Loss: 0.2774
===> Epoch[32](1900/2500): Loss: 0.2793
===> Epoch[32](2000/2500): Loss: 0.3077
===> Epoch[32](2100/2500): Loss: 0.2934
===> Epoch[32](2200/2500): Loss: 0.2954
===> Epoch[32](2300/2500): Loss: 0.2416
===> Epoch[32](2400/2500): Loss: 0.2993
===> Epoch[32](2500/2500): Loss: 0.2816
===> Epoch 32 Complete: Avg. Loss: 0.2856
===> Timestamp: [2025-08-03 21:57:23]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.3001
===> Epoch[32](200/2500): Loss: 0.2744
===> Epoch[32](300/2500): Loss: 0.2987
===> Epoch[32](400/2500): Loss: 0.3138
===> Epoch[32](500/2500): Loss: 0.2779
===> Epoch[32](600/2500): Loss: 0.2885
===> Epoch[32](700/2500): Loss: 0.2859
===> Epoch[32](800/2500): Loss: 0.2775
===> Epoch[32](900/2500): Loss: 0.2672
===> Epoch[32](1000/2500): Loss: 0.3106
===> Epoch[32](1100/2500): Loss: 0.2743
===> Epoch[32](1200/2500): Loss: 0.2905
===> Epoch[32](1300/2500): Loss: 0.2987
===> Epoch[32](1400/2500): Loss: 0.3024
===> Epoch[32](1500/2500): Loss: 0.2711
===> Epoch[32](1600/2500): Loss: 0.2958
===> Epoch[32](1700/2500): Loss: 0.2866
===> Epoch[32](1800/2500): Loss: 0.2774
===> Epoch[32](1900/2500): Loss: 0.2793
===> Epoch[32](2000/2500): Loss: 0.3077
===> Epoch[32](2100/2500): Loss: 0.2934
===> Epoch[32](2200/2500): Loss: 0.2954
===> Epoch[32](2300/2500): Loss: 0.2416
===> Epoch[32](2400/2500): Loss: 0.2993
===> Epoch[32](2500/2500): Loss: 0.2816
===> Epoch 32 Complete: Avg. Loss: 0.2856
===> Timestamp: [2025-08-03 21:57:23]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.3001
===> Epoch[32](200/2500): Loss: 0.2744
===> Epoch[32](300/2500): Loss: 0.2987
===> Epoch[32](400/2500): Loss: 0.3138
===> Epoch[32](500/2500): Loss: 0.2779
===> Epoch[32](600/2500): Loss: 0.2885
===> Epoch[32](700/2500): Loss: 0.2859
===> Epoch[32](800/2500): Loss: 0.2775
===> Epoch[32](900/2500): Loss: 0.2672
===> Epoch[32](1000/2500): Loss: 0.3106
===> Epoch[32](1100/2500): Loss: 0.2743
===> Epoch[32](1200/2500): Loss: 0.2905
===> Epoch[32](1300/2500): Loss: 0.2987
===> Epoch[32](1400/2500): Loss: 0.3024
===> Epoch[32](1500/2500): Loss: 0.2711
===> Epoch[32](1600/2500): Loss: 0.2958
===> Epoch[32](1700/2500): Loss: 0.2866
===> Epoch[32](1800/2500): Loss: 0.2774
===> Epoch[32](1900/2500): Loss: 0.2793
===> Epoch[32](2000/2500): Loss: 0.3077
===> Epoch[32](2100/2500): Loss: 0.2934
===> Epoch[32](2200/2500): Loss: 0.2954
===> Epoch[32](2300/2500): Loss: 0.2416
===> Epoch[32](2400/2500): Loss: 0.2993
===> Epoch[32](2500/2500): Loss: 0.2816
===> Epoch 32 Complete: Avg. Loss: 0.2856
===> Timestamp: [2025-08-03 21:57:23]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.3001
===> Epoch[32](200/2500): Loss: 0.2744
===> Epoch[32](300/2500): Loss: 0.2987
===> Epoch[32](400/2500): Loss: 0.3138
===> Epoch[32](500/2500): Loss: 0.2779
===> Epoch[32](600/2500): Loss: 0.2885
===> Epoch[32](700/2500): Loss: 0.2859
===> Epoch[32](800/2500): Loss: 0.2775
===> Epoch[32](900/2500): Loss: 0.2672
===> Epoch[32](1000/2500): Loss: 0.3106
===> Epoch[32](1100/2500): Loss: 0.2743
===> Epoch[32](1200/2500): Loss: 0.2905
===> Epoch[32](1300/2500): Loss: 0.2987
===> Epoch[32](1400/2500): Loss: 0.3024
===> Epoch[32](1500/2500): Loss: 0.2711
===> Epoch[32](1600/2500): Loss: 0.2958
===> Epoch[32](1700/2500): Loss: 0.2866
===> Epoch[32](1800/2500): Loss: 0.2774
===> Epoch[32](1900/2500): Loss: 0.2793
===> Epoch[32](2000/2500): Loss: 0.3077
===> Epoch[32](2100/2500): Loss: 0.2934
===> Epoch[32](2200/2500): Loss: 0.2954
===> Epoch[32](2300/2500): Loss: 0.2416
===> Epoch[32](2400/2500): Loss: 0.2993
===> Epoch[32](2500/2500): Loss: 0.2816
===> Epoch 32 Complete: Avg. Loss: 0.2856
===> Timestamp: [2025-08-03 21:57:23]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.3001
===> Epoch[32](200/2500): Loss: 0.2744
===> Epoch[32](300/2500): Loss: 0.2987
===> Epoch[32](400/2500): Loss: 0.3138
===> Epoch[32](500/2500): Loss: 0.2779
===> Epoch[32](600/2500): Loss: 0.2885
===> Epoch[32](700/2500): Loss: 0.2859
===> Epoch[32](800/2500): Loss: 0.2775
===> Epoch[32](900/2500): Loss: 0.2672
===> Epoch[32](1000/2500): Loss: 0.3106
===> Epoch[32](1100/2500): Loss: 0.2743
===> Epoch[32](1200/2500): Loss: 0.2905
===> Epoch[32](1300/2500): Loss: 0.2987
===> Epoch[32](1400/2500): Loss: 0.3024
===> Epoch[32](1500/2500): Loss: 0.2711
===> Epoch[32](1600/2500): Loss: 0.2958
===> Epoch[32](1700/2500): Loss: 0.2866
===> Epoch[32](1800/2500): Loss: 0.2774
===> Epoch[32](1900/2500): Loss: 0.2793
===> Epoch[32](2000/2500): Loss: 0.3077
===> Epoch[32](2100/2500): Loss: 0.2934
===> Epoch[32](2200/2500): Loss: 0.2954
===> Epoch[32](2300/2500): Loss: 0.2416
===> Epoch[32](2400/2500): Loss: 0.2993
===> Epoch[32](2500/2500): Loss: 0.2816
===> Epoch 32 Complete: Avg. Loss: 0.2856
===> Timestamp: [2025-08-03 21:57:23]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.3001
===> Epoch[32](200/2500): Loss: 0.2744
===> Epoch[32](300/2500): Loss: 0.2987
===> Epoch[32](400/2500): Loss: 0.3138
===> Epoch[32](500/2500): Loss: 0.2779
===> Epoch[32](600/2500): Loss: 0.2885
===> Epoch[32](700/2500): Loss: 0.2859
===> Epoch[32](800/2500): Loss: 0.2775
===> Epoch[32](900/2500): Loss: 0.2672
===> Epoch[32](1000/2500): Loss: 0.3106
===> Epoch[32](1100/2500): Loss: 0.2743
===> Epoch[32](1200/2500): Loss: 0.2905
===> Epoch[32](1300/2500): Loss: 0.2987
===> Epoch[32](1400/2500): Loss: 0.3024
===> Epoch[32](1500/2500): Loss: 0.2711
===> Epoch[32](1600/2500): Loss: 0.2958
===> Epoch[32](1700/2500): Loss: 0.2866
===> Epoch[32](1800/2500): Loss: 0.2774
===> Epoch[32](1900/2500): Loss: 0.2793
===> Epoch[32](2000/2500): Loss: 0.3077
===> Epoch[32](2100/2500): Loss: 0.2934
===> Epoch[32](2200/2500): Loss: 0.2954
===> Epoch[32](2300/2500): Loss: 0.2416
===> Epoch[32](2400/2500): Loss: 0.2993
===> Epoch[32](2500/2500): Loss: 0.2816
===> Epoch 32 Complete: Avg. Loss: 0.2856
===> Timestamp: [2025-08-03 21:57:23]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.3001
===> Epoch[32](200/2500): Loss: 0.2744
===> Epoch[32](300/2500): Loss: 0.2987
===> Epoch[32](400/2500): Loss: 0.3138
===> Epoch[32](500/2500): Loss: 0.2779
===> Epoch[32](600/2500): Loss: 0.2885
===> Epoch[32](700/2500): Loss: 0.2859
===> Epoch[32](800/2500): Loss: 0.2775
===> Epoch[32](900/2500): Loss: 0.2672
===> Epoch[32](1000/2500): Loss: 0.3106
===> Epoch[32](1100/2500): Loss: 0.2743
===> Epoch[32](1200/2500): Loss: 0.2905
===> Epoch[32](1300/2500): Loss: 0.2987
===> Epoch[32](1400/2500): Loss: 0.3024
===> Epoch[32](1500/2500): Loss: 0.2711
===> Epoch[32](1600/2500): Loss: 0.2958
===> Epoch[32](1700/2500): Loss: 0.2866
===> Epoch[32](1800/2500): Loss: 0.2774
===> Epoch[32](1900/2500): Loss: 0.2793
===> Epoch[32](2000/2500): Loss: 0.3077
===> Epoch[32](2100/2500): Loss: 0.2934
===> Epoch[32](2200/2500): Loss: 0.2954
===> Epoch[32](2300/2500): Loss: 0.2416
===> Epoch[32](2400/2500): Loss: 0.2993
===> Epoch[32](2500/2500): Loss: 0.2816
===> Epoch 32 Complete: Avg. Loss: 0.2856
===> Timestamp: [2025-08-03 21:57:23]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.3001
===> Epoch[32](200/2500): Loss: 0.2744
===> Epoch[32](300/2500): Loss: 0.2987
===> Epoch[32](400/2500): Loss: 0.3138
===> Epoch[32](500/2500): Loss: 0.2779
===> Epoch[32](600/2500): Loss: 0.2885
===> Epoch[32](700/2500): Loss: 0.2859
===> Epoch[32](800/2500): Loss: 0.2775
===> Epoch[32](900/2500): Loss: 0.2672
===> Epoch[32](1000/2500): Loss: 0.3106
===> Epoch[32](1100/2500): Loss: 0.2743
===> Epoch[32](1200/2500): Loss: 0.2905
===> Epoch[32](1300/2500): Loss: 0.2987
===> Epoch[32](1400/2500): Loss: 0.3024
===> Epoch[32](1500/2500): Loss: 0.2711
===> Epoch[32](1600/2500): Loss: 0.2958
===> Epoch[32](1700/2500): Loss: 0.2866
===> Epoch[32](1800/2500): Loss: 0.2774
===> Epoch[32](1900/2500): Loss: 0.2793
===> Epoch[32](2000/2500): Loss: 0.3077
===> Epoch[32](2100/2500): Loss: 0.2934
===> Epoch[32](2200/2500): Loss: 0.2954
===> Epoch[32](2300/2500): Loss: 0.2416
===> Epoch[32](2400/2500): Loss: 0.2993
===> Epoch[32](2500/2500): Loss: 0.2816
===> Epoch 32 Complete: Avg. Loss: 0.2856
===> Timestamp: [2025-08-03 21:57:23]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.3001
===> Epoch[32](200/2500): Loss: 0.2744
===> Epoch[32](300/2500): Loss: 0.2987
===> Epoch[32](400/2500): Loss: 0.3138
===> Epoch[32](500/2500): Loss: 0.2779
===> Epoch[32](600/2500): Loss: 0.2885
===> Epoch[32](700/2500): Loss: 0.2859
===> Epoch[32](800/2500): Loss: 0.2775
===> Epoch[32](900/2500): Loss: 0.2672
===> Epoch[32](1000/2500): Loss: 0.3106
===> Epoch[32](1100/2500): Loss: 0.2743
===> Epoch[32](1200/2500): Loss: 0.2905
===> Epoch[32](1300/2500): Loss: 0.2987
===> Epoch[32](1400/2500): Loss: 0.3024
===> Epoch[32](1500/2500): Loss: 0.2711
===> Epoch[32](1600/2500): Loss: 0.2958
===> Epoch[32](1700/2500): Loss: 0.2866
===> Epoch[32](1800/2500): Loss: 0.2774
===> Epoch[32](1900/2500): Loss: 0.2793
===> Epoch[32](2000/2500): Loss: 0.3077
===> Epoch[32](2100/2500): Loss: 0.2934
===> Epoch[32](2200/2500): Loss: 0.2954
===> Epoch[32](2300/2500): Loss: 0.2416
===> Epoch[32](2400/2500): Loss: 0.2993
===> Epoch[32](2500/2500): Loss: 0.2816
===> Epoch 32 Complete: Avg. Loss: 0.2856
===> Timestamp: [2025-08-03 21:57:23]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.3001
===> Epoch[32](200/2500): Loss: 0.2744
===> Epoch[32](300/2500): Loss: 0.2987
===> Epoch[32](400/2500): Loss: 0.3138
===> Epoch[32](500/2500): Loss: 0.2779
===> Epoch[32](600/2500): Loss: 0.2885
===> Epoch[32](700/2500): Loss: 0.2859
===> Epoch[32](800/2500): Loss: 0.2775
===> Epoch[32](900/2500): Loss: 0.2672
===> Epoch[32](1000/2500): Loss: 0.3106
===> Epoch[32](1100/2500): Loss: 0.2743
===> Epoch[32](1200/2500): Loss: 0.2905
===> Epoch[32](1300/2500): Loss: 0.2987
===> Epoch[32](1400/2500): Loss: 0.3024
===> Epoch[32](1500/2500): Loss: 0.2711
===> Epoch[32](1600/2500): Loss: 0.2958
===> Epoch[32](1700/2500): Loss: 0.2866
===> Epoch[32](1800/2500): Loss: 0.2774
===> Epoch[32](1900/2500): Loss: 0.2793
===> Epoch[32](2000/2500): Loss: 0.3077
===> Epoch[32](2100/2500): Loss: 0.2934
===> Epoch[32](2200/2500): Loss: 0.2954
===> Epoch[32](2300/2500): Loss: 0.2416
===> Epoch[32](2400/2500): Loss: 0.2993
===> Epoch[32](2500/2500): Loss: 0.2816
===> Epoch 32 Complete: Avg. Loss: 0.2856
===> Timestamp: [2025-08-03 21:57:23]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.3001
===> Epoch[32](200/2500): Loss: 0.2744
===> Epoch[32](300/2500): Loss: 0.2987
===> Epoch[32](400/2500): Loss: 0.3138
===> Epoch[32](500/2500): Loss: 0.2779
===> Epoch[32](600/2500): Loss: 0.2885
===> Epoch[32](700/2500): Loss: 0.2859
===> Epoch[32](800/2500): Loss: 0.2775
===> Epoch[32](900/2500): Loss: 0.2672
===> Epoch[32](1000/2500): Loss: 0.3106
===> Epoch[32](1100/2500): Loss: 0.2743
===> Epoch[32](1200/2500): Loss: 0.2905
===> Epoch[32](1300/2500): Loss: 0.2987
===> Epoch[32](1400/2500): Loss: 0.3024
===> Epoch[32](1500/2500): Loss: 0.2711
===> Epoch[32](1600/2500): Loss: 0.2958
===> Epoch[32](1700/2500): Loss: 0.2866
===> Epoch[32](1800/2500): Loss: 0.2774
===> Epoch[32](1900/2500): Loss: 0.2793
===> Epoch[32](2000/2500): Loss: 0.3077
===> Epoch[32](2100/2500): Loss: 0.2934
===> Epoch[32](2200/2500): Loss: 0.2954
===> Epoch[32](2300/2500): Loss: 0.2416
===> Epoch[32](2400/2500): Loss: 0.2993
===> Epoch[32](2500/2500): Loss: 0.2816
===> Epoch 32 Complete: Avg. Loss: 0.2856
===> Timestamp: [2025-08-03 21:57:23]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.3001
===> Epoch[32](200/2500): Loss: 0.2744
===> Epoch[32](300/2500): Loss: 0.2987
===> Epoch[32](400/2500): Loss: 0.3138
===> Epoch[32](500/2500): Loss: 0.2779
===> Epoch[32](600/2500): Loss: 0.2885
===> Epoch[32](700/2500): Loss: 0.2859
===> Epoch[32](800/2500): Loss: 0.2775
===> Epoch[32](900/2500): Loss: 0.2672
===> Epoch[32](1000/2500): Loss: 0.3106
===> Epoch[32](1100/2500): Loss: 0.2743
===> Epoch[32](1200/2500): Loss: 0.2905
===> Epoch[32](1300/2500): Loss: 0.2987
===> Epoch[32](1400/2500): Loss: 0.3024
===> Epoch[32](1500/2500): Loss: 0.2711
===> Epoch[32](1600/2500): Loss: 0.2958
===> Epoch[32](1700/2500): Loss: 0.2866
===> Epoch[32](1800/2500): Loss: 0.2774
===> Epoch[32](1900/2500): Loss: 0.2793
===> Epoch[32](2000/2500): Loss: 0.3077
===> Epoch[32](2100/2500): Loss: 0.2934
===> Epoch[32](2200/2500): Loss: 0.2954
===> Epoch[32](2300/2500): Loss: 0.2416
===> Epoch[32](2400/2500): Loss: 0.2993
===> Epoch[32](2500/2500): Loss: 0.2816
===> Epoch 32 Complete: Avg. Loss: 0.2856
===> Timestamp: [2025-08-03 21:57:23]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.3001
===> Epoch[32](200/2500): Loss: 0.2744
===> Epoch[32](300/2500): Loss: 0.2987
===> Epoch[32](400/2500): Loss: 0.3138
===> Epoch[32](500/2500): Loss: 0.2779
===> Epoch[32](600/2500): Loss: 0.2885
===> Epoch[32](700/2500): Loss: 0.2859
===> Epoch[32](800/2500): Loss: 0.2775
===> Epoch[32](900/2500): Loss: 0.2672
===> Epoch[32](1000/2500): Loss: 0.3106
===> Epoch[32](1100/2500): Loss: 0.2743
===> Epoch[32](1200/2500): Loss: 0.2905
===> Epoch[32](1300/2500): Loss: 0.2987
===> Epoch[32](1400/2500): Loss: 0.3024
===> Epoch[32](1500/2500): Loss: 0.2711
===> Epoch[32](1600/2500): Loss: 0.2958
===> Epoch[32](1700/2500): Loss: 0.2866
===> Epoch[32](1800/2500): Loss: 0.2774
===> Epoch[32](1900/2500): Loss: 0.2793
===> Epoch[32](2000/2500): Loss: 0.3077
===> Epoch[32](2100/2500): Loss: 0.2934
===> Epoch[32](2200/2500): Loss: 0.2954
===> Epoch[32](2300/2500): Loss: 0.2416
===> Epoch[32](2400/2500): Loss: 0.2993
===> Epoch[32](2500/2500): Loss: 0.2816
===> Epoch 32 Complete: Avg. Loss: 0.2856
===> Timestamp: [2025-08-03 21:57:23]
===> Loading train datasets
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2910
===> Epoch[33](200/2500): Loss: 0.2598
===> Epoch[33](300/2500): Loss: 0.2798
===> Epoch[33](400/2500): Loss: 0.3055
===> Epoch[33](500/2500): Loss: 0.3038
===> Epoch[33](600/2500): Loss: 0.2914
===> Epoch[33](700/2500): Loss: 0.2910
===> Epoch[33](800/2500): Loss: 0.2699
===> Epoch[33](900/2500): Loss: 0.2833
===> Epoch[33](1000/2500): Loss: 0.2859
===> Epoch[33](1100/2500): Loss: 0.2865
===> Epoch[33](1200/2500): Loss: 0.2794
===> Epoch[33](1300/2500): Loss: 0.3056
===> Epoch[33](1400/2500): Loss: 0.2905
===> Epoch[33](1500/2500): Loss: 0.2860
===> Epoch[33](1600/2500): Loss: 0.2936
===> Epoch[33](1700/2500): Loss: 0.2988
===> Epoch[33](1800/2500): Loss: 0.2705
===> Epoch[33](1900/2500): Loss: 0.2668
===> Epoch[33](2000/2500): Loss: 0.2710
===> Epoch[33](2100/2500): Loss: 0.2546
===> Epoch[33](2200/2500): Loss: 0.3055
===> Epoch[33](2300/2500): Loss: 0.2910
===> Epoch[33](2400/2500): Loss: 0.2866
===> Epoch[33](2500/2500): Loss: 0.2836
===> Epoch 33 Complete: Avg. Loss: 0.2853
===> Timestamp: [2025-08-03 22:01:57]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2910
===> Epoch[33](200/2500): Loss: 0.2598
===> Epoch[33](300/2500): Loss: 0.2798
===> Epoch[33](400/2500): Loss: 0.3055
===> Epoch[33](500/2500): Loss: 0.3038
===> Epoch[33](600/2500): Loss: 0.2914
===> Epoch[33](700/2500): Loss: 0.2910
===> Epoch[33](800/2500): Loss: 0.2699
===> Epoch[33](900/2500): Loss: 0.2833
===> Epoch[33](1000/2500): Loss: 0.2859
===> Epoch[33](1100/2500): Loss: 0.2865
===> Epoch[33](1200/2500): Loss: 0.2794
===> Epoch[33](1300/2500): Loss: 0.3056
===> Epoch[33](1400/2500): Loss: 0.2905
===> Epoch[33](1500/2500): Loss: 0.2860
===> Epoch[33](1600/2500): Loss: 0.2936
===> Epoch[33](1700/2500): Loss: 0.2988
===> Epoch[33](1800/2500): Loss: 0.2705
===> Epoch[33](1900/2500): Loss: 0.2668
===> Epoch[33](2000/2500): Loss: 0.2710
===> Epoch[33](2100/2500): Loss: 0.2546
===> Epoch[33](2200/2500): Loss: 0.3055
===> Epoch[33](2300/2500): Loss: 0.2910
===> Epoch[33](2400/2500): Loss: 0.2866
===> Epoch[33](2500/2500): Loss: 0.2836
===> Epoch 33 Complete: Avg. Loss: 0.2853
===> Timestamp: [2025-08-03 22:01:57]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2910
===> Epoch[33](200/2500): Loss: 0.2598
===> Epoch[33](300/2500): Loss: 0.2798
===> Epoch[33](400/2500): Loss: 0.3055
===> Epoch[33](500/2500): Loss: 0.3038
===> Epoch[33](600/2500): Loss: 0.2914
===> Epoch[33](700/2500): Loss: 0.2910
===> Epoch[33](800/2500): Loss: 0.2699
===> Epoch[33](900/2500): Loss: 0.2833
===> Epoch[33](1000/2500): Loss: 0.2859
===> Epoch[33](1100/2500): Loss: 0.2865
===> Epoch[33](1200/2500): Loss: 0.2794
===> Epoch[33](1300/2500): Loss: 0.3056
===> Epoch[33](1400/2500): Loss: 0.2905
===> Epoch[33](1500/2500): Loss: 0.2860
===> Epoch[33](1600/2500): Loss: 0.2936
===> Epoch[33](1700/2500): Loss: 0.2988
===> Epoch[33](1800/2500): Loss: 0.2705
===> Epoch[33](1900/2500): Loss: 0.2668
===> Epoch[33](2000/2500): Loss: 0.2710
===> Epoch[33](2100/2500): Loss: 0.2546
===> Epoch[33](2200/2500): Loss: 0.3055
===> Epoch[33](2300/2500): Loss: 0.2910
===> Epoch[33](2400/2500): Loss: 0.2866
===> Epoch[33](2500/2500): Loss: 0.2836
===> Epoch 33 Complete: Avg. Loss: 0.2853
===> Timestamp: [2025-08-03 22:01:57]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2910
===> Epoch[33](200/2500): Loss: 0.2598
===> Epoch[33](300/2500): Loss: 0.2798
===> Epoch[33](400/2500): Loss: 0.3055
===> Epoch[33](500/2500): Loss: 0.3038
===> Epoch[33](600/2500): Loss: 0.2914
===> Epoch[33](700/2500): Loss: 0.2910
===> Epoch[33](800/2500): Loss: 0.2699
===> Epoch[33](900/2500): Loss: 0.2833
===> Epoch[33](1000/2500): Loss: 0.2859
===> Epoch[33](1100/2500): Loss: 0.2865
===> Epoch[33](1200/2500): Loss: 0.2794
===> Epoch[33](1300/2500): Loss: 0.3056
===> Epoch[33](1400/2500): Loss: 0.2905
===> Epoch[33](1500/2500): Loss: 0.2860
===> Epoch[33](1600/2500): Loss: 0.2936
===> Epoch[33](1700/2500): Loss: 0.2988
===> Epoch[33](1800/2500): Loss: 0.2705
===> Epoch[33](1900/2500): Loss: 0.2668
===> Epoch[33](2000/2500): Loss: 0.2710
===> Epoch[33](2100/2500): Loss: 0.2546
===> Epoch[33](2200/2500): Loss: 0.3055
===> Epoch[33](2300/2500): Loss: 0.2910
===> Epoch[33](2400/2500): Loss: 0.2866
===> Epoch[33](2500/2500): Loss: 0.2836
===> Epoch 33 Complete: Avg. Loss: 0.2853
===> Timestamp: [2025-08-03 22:01:57]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2910
===> Epoch[33](200/2500): Loss: 0.2598
===> Epoch[33](300/2500): Loss: 0.2798
===> Epoch[33](400/2500): Loss: 0.3055
===> Epoch[33](500/2500): Loss: 0.3038
===> Epoch[33](600/2500): Loss: 0.2914
===> Epoch[33](700/2500): Loss: 0.2910
===> Epoch[33](800/2500): Loss: 0.2699
===> Epoch[33](900/2500): Loss: 0.2833
===> Epoch[33](1000/2500): Loss: 0.2859
===> Epoch[33](1100/2500): Loss: 0.2865
===> Epoch[33](1200/2500): Loss: 0.2794
===> Epoch[33](1300/2500): Loss: 0.3056
===> Epoch[33](1400/2500): Loss: 0.2905
===> Epoch[33](1500/2500): Loss: 0.2860
===> Epoch[33](1600/2500): Loss: 0.2936
===> Epoch[33](1700/2500): Loss: 0.2988
===> Epoch[33](1800/2500): Loss: 0.2705
===> Epoch[33](1900/2500): Loss: 0.2668
===> Epoch[33](2000/2500): Loss: 0.2710
===> Epoch[33](2100/2500): Loss: 0.2546
===> Epoch[33](2200/2500): Loss: 0.3055
===> Epoch[33](2300/2500): Loss: 0.2910
===> Epoch[33](2400/2500): Loss: 0.2866
===> Epoch[33](2500/2500): Loss: 0.2836
===> Epoch 33 Complete: Avg. Loss: 0.2853
===> Timestamp: [2025-08-03 22:01:57]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2910
===> Epoch[33](200/2500): Loss: 0.2598
===> Epoch[33](300/2500): Loss: 0.2798
===> Epoch[33](400/2500): Loss: 0.3055
===> Epoch[33](500/2500): Loss: 0.3038
===> Epoch[33](600/2500): Loss: 0.2914
===> Epoch[33](700/2500): Loss: 0.2910
===> Epoch[33](800/2500): Loss: 0.2699
===> Epoch[33](900/2500): Loss: 0.2833
===> Epoch[33](1000/2500): Loss: 0.2859
===> Epoch[33](1100/2500): Loss: 0.2865
===> Epoch[33](1200/2500): Loss: 0.2794
===> Epoch[33](1300/2500): Loss: 0.3056
===> Epoch[33](1400/2500): Loss: 0.2905
===> Epoch[33](1500/2500): Loss: 0.2860
===> Epoch[33](1600/2500): Loss: 0.2936
===> Epoch[33](1700/2500): Loss: 0.2988
===> Epoch[33](1800/2500): Loss: 0.2705
===> Epoch[33](1900/2500): Loss: 0.2668
===> Epoch[33](2000/2500): Loss: 0.2710
===> Epoch[33](2100/2500): Loss: 0.2546
===> Epoch[33](2200/2500): Loss: 0.3055
===> Epoch[33](2300/2500): Loss: 0.2910
===> Epoch[33](2400/2500): Loss: 0.2866
===> Epoch[33](2500/2500): Loss: 0.2836
===> Epoch 33 Complete: Avg. Loss: 0.2853
===> Timestamp: [2025-08-03 22:01:57]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2910
===> Epoch[33](200/2500): Loss: 0.2598
===> Epoch[33](300/2500): Loss: 0.2798
===> Epoch[33](400/2500): Loss: 0.3055
===> Epoch[33](500/2500): Loss: 0.3038
===> Epoch[33](600/2500): Loss: 0.2914
===> Epoch[33](700/2500): Loss: 0.2910
===> Epoch[33](800/2500): Loss: 0.2699
===> Epoch[33](900/2500): Loss: 0.2833
===> Epoch[33](1000/2500): Loss: 0.2859
===> Epoch[33](1100/2500): Loss: 0.2865
===> Epoch[33](1200/2500): Loss: 0.2794
===> Epoch[33](1300/2500): Loss: 0.3056
===> Epoch[33](1400/2500): Loss: 0.2905
===> Epoch[33](1500/2500): Loss: 0.2860
===> Epoch[33](1600/2500): Loss: 0.2936
===> Epoch[33](1700/2500): Loss: 0.2988
===> Epoch[33](1800/2500): Loss: 0.2705
===> Epoch[33](1900/2500): Loss: 0.2668
===> Epoch[33](2000/2500): Loss: 0.2710
===> Epoch[33](2100/2500): Loss: 0.2546
===> Epoch[33](2200/2500): Loss: 0.3055
===> Epoch[33](2300/2500): Loss: 0.2910
===> Epoch[33](2400/2500): Loss: 0.2866
===> Epoch[33](2500/2500): Loss: 0.2836
===> Epoch 33 Complete: Avg. Loss: 0.2853
===> Timestamp: [2025-08-03 22:01:57]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2910
===> Epoch[33](200/2500): Loss: 0.2598
===> Epoch[33](300/2500): Loss: 0.2798
===> Epoch[33](400/2500): Loss: 0.3055
===> Epoch[33](500/2500): Loss: 0.3038
===> Epoch[33](600/2500): Loss: 0.2914
===> Epoch[33](700/2500): Loss: 0.2910
===> Epoch[33](800/2500): Loss: 0.2699
===> Epoch[33](900/2500): Loss: 0.2833
===> Epoch[33](1000/2500): Loss: 0.2859
===> Epoch[33](1100/2500): Loss: 0.2865
===> Epoch[33](1200/2500): Loss: 0.2794
===> Epoch[33](1300/2500): Loss: 0.3056
===> Epoch[33](1400/2500): Loss: 0.2905
===> Epoch[33](1500/2500): Loss: 0.2860
===> Epoch[33](1600/2500): Loss: 0.2936
===> Epoch[33](1700/2500): Loss: 0.2988
===> Epoch[33](1800/2500): Loss: 0.2705
===> Epoch[33](1900/2500): Loss: 0.2668
===> Epoch[33](2000/2500): Loss: 0.2710
===> Epoch[33](2100/2500): Loss: 0.2546
===> Epoch[33](2200/2500): Loss: 0.3055
===> Epoch[33](2300/2500): Loss: 0.2910
===> Epoch[33](2400/2500): Loss: 0.2866
===> Epoch[33](2500/2500): Loss: 0.2836
===> Epoch 33 Complete: Avg. Loss: 0.2853
===> Timestamp: [2025-08-03 22:01:57]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2910
===> Epoch[33](200/2500): Loss: 0.2598
===> Epoch[33](300/2500): Loss: 0.2798
===> Epoch[33](400/2500): Loss: 0.3055
===> Epoch[33](500/2500): Loss: 0.3038
===> Epoch[33](600/2500): Loss: 0.2914
===> Epoch[33](700/2500): Loss: 0.2910
===> Epoch[33](800/2500): Loss: 0.2699
===> Epoch[33](900/2500): Loss: 0.2833
===> Epoch[33](1000/2500): Loss: 0.2859
===> Epoch[33](1100/2500): Loss: 0.2865
===> Epoch[33](1200/2500): Loss: 0.2794
===> Epoch[33](1300/2500): Loss: 0.3056
===> Epoch[33](1400/2500): Loss: 0.2905
===> Epoch[33](1500/2500): Loss: 0.2860
===> Epoch[33](1600/2500): Loss: 0.2936
===> Epoch[33](1700/2500): Loss: 0.2988
===> Epoch[33](1800/2500): Loss: 0.2705
===> Epoch[33](1900/2500): Loss: 0.2668
===> Epoch[33](2000/2500): Loss: 0.2710
===> Epoch[33](2100/2500): Loss: 0.2546
===> Epoch[33](2200/2500): Loss: 0.3055
===> Epoch[33](2300/2500): Loss: 0.2910
===> Epoch[33](2400/2500): Loss: 0.2866
===> Epoch[33](2500/2500): Loss: 0.2836
===> Epoch 33 Complete: Avg. Loss: 0.2853
===> Timestamp: [2025-08-03 22:01:57]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2910
===> Epoch[33](200/2500): Loss: 0.2598
===> Epoch[33](300/2500): Loss: 0.2798
===> Epoch[33](400/2500): Loss: 0.3055
===> Epoch[33](500/2500): Loss: 0.3038
===> Epoch[33](600/2500): Loss: 0.2914
===> Epoch[33](700/2500): Loss: 0.2910
===> Epoch[33](800/2500): Loss: 0.2699
===> Epoch[33](900/2500): Loss: 0.2833
===> Epoch[33](1000/2500): Loss: 0.2859
===> Epoch[33](1100/2500): Loss: 0.2865
===> Epoch[33](1200/2500): Loss: 0.2794
===> Epoch[33](1300/2500): Loss: 0.3056
===> Epoch[33](1400/2500): Loss: 0.2905
===> Epoch[33](1500/2500): Loss: 0.2860
===> Epoch[33](1600/2500): Loss: 0.2936
===> Epoch[33](1700/2500): Loss: 0.2988
===> Epoch[33](1800/2500): Loss: 0.2705
===> Epoch[33](1900/2500): Loss: 0.2668
===> Epoch[33](2000/2500): Loss: 0.2710
===> Epoch[33](2100/2500): Loss: 0.2546
===> Epoch[33](2200/2500): Loss: 0.3055
===> Epoch[33](2300/2500): Loss: 0.2910
===> Epoch[33](2400/2500): Loss: 0.2866
===> Epoch[33](2500/2500): Loss: 0.2836
===> Epoch 33 Complete: Avg. Loss: 0.2853
===> Timestamp: [2025-08-03 22:01:57]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2910
===> Epoch[33](200/2500): Loss: 0.2598
===> Epoch[33](300/2500): Loss: 0.2798
===> Epoch[33](400/2500): Loss: 0.3055
===> Epoch[33](500/2500): Loss: 0.3038
===> Epoch[33](600/2500): Loss: 0.2914
===> Epoch[33](700/2500): Loss: 0.2910
===> Epoch[33](800/2500): Loss: 0.2699
===> Epoch[33](900/2500): Loss: 0.2833
===> Epoch[33](1000/2500): Loss: 0.2859
===> Epoch[33](1100/2500): Loss: 0.2865
===> Epoch[33](1200/2500): Loss: 0.2794
===> Epoch[33](1300/2500): Loss: 0.3056
===> Epoch[33](1400/2500): Loss: 0.2905
===> Epoch[33](1500/2500): Loss: 0.2860
===> Epoch[33](1600/2500): Loss: 0.2936
===> Epoch[33](1700/2500): Loss: 0.2988
===> Epoch[33](1800/2500): Loss: 0.2705
===> Epoch[33](1900/2500): Loss: 0.2668
===> Epoch[33](2000/2500): Loss: 0.2710
===> Epoch[33](2100/2500): Loss: 0.2546
===> Epoch[33](2200/2500): Loss: 0.3055
===> Epoch[33](2300/2500): Loss: 0.2910
===> Epoch[33](2400/2500): Loss: 0.2866
===> Epoch[33](2500/2500): Loss: 0.2836
===> Epoch 33 Complete: Avg. Loss: 0.2853
===> Timestamp: [2025-08-03 22:01:57]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2910
===> Epoch[33](200/2500): Loss: 0.2598
===> Epoch[33](300/2500): Loss: 0.2798
===> Epoch[33](400/2500): Loss: 0.3055
===> Epoch[33](500/2500): Loss: 0.3038
===> Epoch[33](600/2500): Loss: 0.2914
===> Epoch[33](700/2500): Loss: 0.2910
===> Epoch[33](800/2500): Loss: 0.2699
===> Epoch[33](900/2500): Loss: 0.2833
===> Epoch[33](1000/2500): Loss: 0.2859
===> Epoch[33](1100/2500): Loss: 0.2865
===> Epoch[33](1200/2500): Loss: 0.2794
===> Epoch[33](1300/2500): Loss: 0.3056
===> Epoch[33](1400/2500): Loss: 0.2905
===> Epoch[33](1500/2500): Loss: 0.2860
===> Epoch[33](1600/2500): Loss: 0.2936
===> Epoch[33](1700/2500): Loss: 0.2988
===> Epoch[33](1800/2500): Loss: 0.2705
===> Epoch[33](1900/2500): Loss: 0.2668
===> Epoch[33](2000/2500): Loss: 0.2710
===> Epoch[33](2100/2500): Loss: 0.2546
===> Epoch[33](2200/2500): Loss: 0.3055
===> Epoch[33](2300/2500): Loss: 0.2910
===> Epoch[33](2400/2500): Loss: 0.2866
===> Epoch[33](2500/2500): Loss: 0.2836
===> Epoch 33 Complete: Avg. Loss: 0.2853
===> Timestamp: [2025-08-03 22:01:57]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2910
===> Epoch[33](200/2500): Loss: 0.2598
===> Epoch[33](300/2500): Loss: 0.2798
===> Epoch[33](400/2500): Loss: 0.3055
===> Epoch[33](500/2500): Loss: 0.3038
===> Epoch[33](600/2500): Loss: 0.2914
===> Epoch[33](700/2500): Loss: 0.2910
===> Epoch[33](800/2500): Loss: 0.2699
===> Epoch[33](900/2500): Loss: 0.2833
===> Epoch[33](1000/2500): Loss: 0.2859
===> Epoch[33](1100/2500): Loss: 0.2865
===> Epoch[33](1200/2500): Loss: 0.2794
===> Epoch[33](1300/2500): Loss: 0.3056
===> Epoch[33](1400/2500): Loss: 0.2905
===> Epoch[33](1500/2500): Loss: 0.2860
===> Epoch[33](1600/2500): Loss: 0.2936
===> Epoch[33](1700/2500): Loss: 0.2988
===> Epoch[33](1800/2500): Loss: 0.2705
===> Epoch[33](1900/2500): Loss: 0.2668
===> Epoch[33](2000/2500): Loss: 0.2710
===> Epoch[33](2100/2500): Loss: 0.2546
===> Epoch[33](2200/2500): Loss: 0.3055
===> Epoch[33](2300/2500): Loss: 0.2910
===> Epoch[33](2400/2500): Loss: 0.2866
===> Epoch[33](2500/2500): Loss: 0.2836
===> Epoch 33 Complete: Avg. Loss: 0.2853
===> Timestamp: [2025-08-03 22:01:57]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2910
===> Epoch[33](200/2500): Loss: 0.2598
===> Epoch[33](300/2500): Loss: 0.2798
===> Epoch[33](400/2500): Loss: 0.3055
===> Epoch[33](500/2500): Loss: 0.3038
===> Epoch[33](600/2500): Loss: 0.2914
===> Epoch[33](700/2500): Loss: 0.2910
===> Epoch[33](800/2500): Loss: 0.2699
===> Epoch[33](900/2500): Loss: 0.2833
===> Epoch[33](1000/2500): Loss: 0.2859
===> Epoch[33](1100/2500): Loss: 0.2865
===> Epoch[33](1200/2500): Loss: 0.2794
===> Epoch[33](1300/2500): Loss: 0.3056
===> Epoch[33](1400/2500): Loss: 0.2905
===> Epoch[33](1500/2500): Loss: 0.2860
===> Epoch[33](1600/2500): Loss: 0.2936
===> Epoch[33](1700/2500): Loss: 0.2988
===> Epoch[33](1800/2500): Loss: 0.2705
===> Epoch[33](1900/2500): Loss: 0.2668
===> Epoch[33](2000/2500): Loss: 0.2710
===> Epoch[33](2100/2500): Loss: 0.2546
===> Epoch[33](2200/2500): Loss: 0.3055
===> Epoch[33](2300/2500): Loss: 0.2910
===> Epoch[33](2400/2500): Loss: 0.2866
===> Epoch[33](2500/2500): Loss: 0.2836
===> Epoch 33 Complete: Avg. Loss: 0.2853
===> Timestamp: [2025-08-03 22:01:57]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2910
===> Epoch[33](200/2500): Loss: 0.2598
===> Epoch[33](300/2500): Loss: 0.2798
===> Epoch[33](400/2500): Loss: 0.3055
===> Epoch[33](500/2500): Loss: 0.3038
===> Epoch[33](600/2500): Loss: 0.2914
===> Epoch[33](700/2500): Loss: 0.2910
===> Epoch[33](800/2500): Loss: 0.2699
===> Epoch[33](900/2500): Loss: 0.2833
===> Epoch[33](1000/2500): Loss: 0.2859
===> Epoch[33](1100/2500): Loss: 0.2865
===> Epoch[33](1200/2500): Loss: 0.2794
===> Epoch[33](1300/2500): Loss: 0.3056
===> Epoch[33](1400/2500): Loss: 0.2905
===> Epoch[33](1500/2500): Loss: 0.2860
===> Epoch[33](1600/2500): Loss: 0.2936
===> Epoch[33](1700/2500): Loss: 0.2988
===> Epoch[33](1800/2500): Loss: 0.2705
===> Epoch[33](1900/2500): Loss: 0.2668
===> Epoch[33](2000/2500): Loss: 0.2710
===> Epoch[33](2100/2500): Loss: 0.2546
===> Epoch[33](2200/2500): Loss: 0.3055
===> Epoch[33](2300/2500): Loss: 0.2910
===> Epoch[33](2400/2500): Loss: 0.2866
===> Epoch[33](2500/2500): Loss: 0.2836
===> Epoch 33 Complete: Avg. Loss: 0.2853
===> Timestamp: [2025-08-03 22:01:57]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2910
===> Epoch[33](200/2500): Loss: 0.2598
===> Epoch[33](300/2500): Loss: 0.2798
===> Epoch[33](400/2500): Loss: 0.3055
===> Epoch[33](500/2500): Loss: 0.3038
===> Epoch[33](600/2500): Loss: 0.2914
===> Epoch[33](700/2500): Loss: 0.2910
===> Epoch[33](800/2500): Loss: 0.2699
===> Epoch[33](900/2500): Loss: 0.2833
===> Epoch[33](1000/2500): Loss: 0.2859
===> Epoch[33](1100/2500): Loss: 0.2865
===> Epoch[33](1200/2500): Loss: 0.2794
===> Epoch[33](1300/2500): Loss: 0.3056
===> Epoch[33](1400/2500): Loss: 0.2905
===> Epoch[33](1500/2500): Loss: 0.2860
===> Epoch[33](1600/2500): Loss: 0.2936
===> Epoch[33](1700/2500): Loss: 0.2988
===> Epoch[33](1800/2500): Loss: 0.2705
===> Epoch[33](1900/2500): Loss: 0.2668
===> Epoch[33](2000/2500): Loss: 0.2710
===> Epoch[33](2100/2500): Loss: 0.2546
===> Epoch[33](2200/2500): Loss: 0.3055
===> Epoch[33](2300/2500): Loss: 0.2910
===> Epoch[33](2400/2500): Loss: 0.2866
===> Epoch[33](2500/2500): Loss: 0.2836
===> Epoch 33 Complete: Avg. Loss: 0.2853
===> Timestamp: [2025-08-03 22:01:57]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2910
===> Epoch[33](200/2500): Loss: 0.2598
===> Epoch[33](300/2500): Loss: 0.2798
===> Epoch[33](400/2500): Loss: 0.3055
===> Epoch[33](500/2500): Loss: 0.3038
===> Epoch[33](600/2500): Loss: 0.2914
===> Epoch[33](700/2500): Loss: 0.2910
===> Epoch[33](800/2500): Loss: 0.2699
===> Epoch[33](900/2500): Loss: 0.2833
===> Epoch[33](1000/2500): Loss: 0.2859
===> Epoch[33](1100/2500): Loss: 0.2865
===> Epoch[33](1200/2500): Loss: 0.2794
===> Epoch[33](1300/2500): Loss: 0.3056
===> Epoch[33](1400/2500): Loss: 0.2905
===> Epoch[33](1500/2500): Loss: 0.2860
===> Epoch[33](1600/2500): Loss: 0.2936
===> Epoch[33](1700/2500): Loss: 0.2988
===> Epoch[33](1800/2500): Loss: 0.2705
===> Epoch[33](1900/2500): Loss: 0.2668
===> Epoch[33](2000/2500): Loss: 0.2710
===> Epoch[33](2100/2500): Loss: 0.2546
===> Epoch[33](2200/2500): Loss: 0.3055
===> Epoch[33](2300/2500): Loss: 0.2910
===> Epoch[33](2400/2500): Loss: 0.2866
===> Epoch[33](2500/2500): Loss: 0.2836
===> Epoch 33 Complete: Avg. Loss: 0.2853
===> Timestamp: [2025-08-03 22:01:57]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2910
===> Epoch[33](200/2500): Loss: 0.2598
===> Epoch[33](300/2500): Loss: 0.2798
===> Epoch[33](400/2500): Loss: 0.3055
===> Epoch[33](500/2500): Loss: 0.3038
===> Epoch[33](600/2500): Loss: 0.2914
===> Epoch[33](700/2500): Loss: 0.2910
===> Epoch[33](800/2500): Loss: 0.2699
===> Epoch[33](900/2500): Loss: 0.2833
===> Epoch[33](1000/2500): Loss: 0.2859
===> Epoch[33](1100/2500): Loss: 0.2865
===> Epoch[33](1200/2500): Loss: 0.2794
===> Epoch[33](1300/2500): Loss: 0.3056
===> Epoch[33](1400/2500): Loss: 0.2905
===> Epoch[33](1500/2500): Loss: 0.2860
===> Epoch[33](1600/2500): Loss: 0.2936
===> Epoch[33](1700/2500): Loss: 0.2988
===> Epoch[33](1800/2500): Loss: 0.2705
===> Epoch[33](1900/2500): Loss: 0.2668
===> Epoch[33](2000/2500): Loss: 0.2710
===> Epoch[33](2100/2500): Loss: 0.2546
===> Epoch[33](2200/2500): Loss: 0.3055
===> Epoch[33](2300/2500): Loss: 0.2910
===> Epoch[33](2400/2500): Loss: 0.2866
===> Epoch[33](2500/2500): Loss: 0.2836
===> Epoch 33 Complete: Avg. Loss: 0.2853
===> Timestamp: [2025-08-03 22:01:57]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2910
===> Epoch[33](200/2500): Loss: 0.2598
===> Epoch[33](300/2500): Loss: 0.2798
===> Epoch[33](400/2500): Loss: 0.3055
===> Epoch[33](500/2500): Loss: 0.3038
===> Epoch[33](600/2500): Loss: 0.2914
===> Epoch[33](700/2500): Loss: 0.2910
===> Epoch[33](800/2500): Loss: 0.2699
===> Epoch[33](900/2500): Loss: 0.2833
===> Epoch[33](1000/2500): Loss: 0.2859
===> Epoch[33](1100/2500): Loss: 0.2865
===> Epoch[33](1200/2500): Loss: 0.2794
===> Epoch[33](1300/2500): Loss: 0.3056
===> Epoch[33](1400/2500): Loss: 0.2905
===> Epoch[33](1500/2500): Loss: 0.2860
===> Epoch[33](1600/2500): Loss: 0.2936
===> Epoch[33](1700/2500): Loss: 0.2988
===> Epoch[33](1800/2500): Loss: 0.2705
===> Epoch[33](1900/2500): Loss: 0.2668
===> Epoch[33](2000/2500): Loss: 0.2710
===> Epoch[33](2100/2500): Loss: 0.2546
===> Epoch[33](2200/2500): Loss: 0.3055
===> Epoch[33](2300/2500): Loss: 0.2910
===> Epoch[33](2400/2500): Loss: 0.2866
===> Epoch[33](2500/2500): Loss: 0.2836
===> Epoch 33 Complete: Avg. Loss: 0.2853
===> Timestamp: [2025-08-03 22:01:57]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2910
===> Epoch[33](200/2500): Loss: 0.2598
===> Epoch[33](300/2500): Loss: 0.2798
===> Epoch[33](400/2500): Loss: 0.3055
===> Epoch[33](500/2500): Loss: 0.3038
===> Epoch[33](600/2500): Loss: 0.2914
===> Epoch[33](700/2500): Loss: 0.2910
===> Epoch[33](800/2500): Loss: 0.2699
===> Epoch[33](900/2500): Loss: 0.2833
===> Epoch[33](1000/2500): Loss: 0.2859
===> Epoch[33](1100/2500): Loss: 0.2865
===> Epoch[33](1200/2500): Loss: 0.2794
===> Epoch[33](1300/2500): Loss: 0.3056
===> Epoch[33](1400/2500): Loss: 0.2905
===> Epoch[33](1500/2500): Loss: 0.2860
===> Epoch[33](1600/2500): Loss: 0.2936
===> Epoch[33](1700/2500): Loss: 0.2988
===> Epoch[33](1800/2500): Loss: 0.2705
===> Epoch[33](1900/2500): Loss: 0.2668
===> Epoch[33](2000/2500): Loss: 0.2710
===> Epoch[33](2100/2500): Loss: 0.2546
===> Epoch[33](2200/2500): Loss: 0.3055
===> Epoch[33](2300/2500): Loss: 0.2910
===> Epoch[33](2400/2500): Loss: 0.2866
===> Epoch[33](2500/2500): Loss: 0.2836
===> Epoch 33 Complete: Avg. Loss: 0.2853
===> Timestamp: [2025-08-03 22:01:57]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2910
===> Epoch[33](200/2500): Loss: 0.2598
===> Epoch[33](300/2500): Loss: 0.2798
===> Epoch[33](400/2500): Loss: 0.3055
===> Epoch[33](500/2500): Loss: 0.3038
===> Epoch[33](600/2500): Loss: 0.2914
===> Epoch[33](700/2500): Loss: 0.2910
===> Epoch[33](800/2500): Loss: 0.2699
===> Epoch[33](900/2500): Loss: 0.2833
===> Epoch[33](1000/2500): Loss: 0.2859
===> Epoch[33](1100/2500): Loss: 0.2865
===> Epoch[33](1200/2500): Loss: 0.2794
===> Epoch[33](1300/2500): Loss: 0.3056
===> Epoch[33](1400/2500): Loss: 0.2905
===> Epoch[33](1500/2500): Loss: 0.2860
===> Epoch[33](1600/2500): Loss: 0.2936
===> Epoch[33](1700/2500): Loss: 0.2988
===> Epoch[33](1800/2500): Loss: 0.2705
===> Epoch[33](1900/2500): Loss: 0.2668
===> Epoch[33](2000/2500): Loss: 0.2710
===> Epoch[33](2100/2500): Loss: 0.2546
===> Epoch[33](2200/2500): Loss: 0.3055
===> Epoch[33](2300/2500): Loss: 0.2910
===> Epoch[33](2400/2500): Loss: 0.2866
===> Epoch[33](2500/2500): Loss: 0.2836
===> Epoch 33 Complete: Avg. Loss: 0.2853
===> Timestamp: [2025-08-03 22:01:57]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2910
===> Epoch[33](200/2500): Loss: 0.2598
===> Epoch[33](300/2500): Loss: 0.2798
===> Epoch[33](400/2500): Loss: 0.3055
===> Epoch[33](500/2500): Loss: 0.3038
===> Epoch[33](600/2500): Loss: 0.2914
===> Epoch[33](700/2500): Loss: 0.2910
===> Epoch[33](800/2500): Loss: 0.2699
===> Epoch[33](900/2500): Loss: 0.2833
===> Epoch[33](1000/2500): Loss: 0.2859
===> Epoch[33](1100/2500): Loss: 0.2865
===> Epoch[33](1200/2500): Loss: 0.2794
===> Epoch[33](1300/2500): Loss: 0.3056
===> Epoch[33](1400/2500): Loss: 0.2905
===> Epoch[33](1500/2500): Loss: 0.2860
===> Epoch[33](1600/2500): Loss: 0.2936
===> Epoch[33](1700/2500): Loss: 0.2988
===> Epoch[33](1800/2500): Loss: 0.2705
===> Epoch[33](1900/2500): Loss: 0.2668
===> Epoch[33](2000/2500): Loss: 0.2710
===> Epoch[33](2100/2500): Loss: 0.2546
===> Epoch[33](2200/2500): Loss: 0.3055
===> Epoch[33](2300/2500): Loss: 0.2910
===> Epoch[33](2400/2500): Loss: 0.2866
===> Epoch[33](2500/2500): Loss: 0.2836
===> Epoch 33 Complete: Avg. Loss: 0.2853
===> Timestamp: [2025-08-03 22:01:57]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2910
===> Epoch[33](200/2500): Loss: 0.2598
===> Epoch[33](300/2500): Loss: 0.2798
===> Epoch[33](400/2500): Loss: 0.3055
===> Epoch[33](500/2500): Loss: 0.3038
===> Epoch[33](600/2500): Loss: 0.2914
===> Epoch[33](700/2500): Loss: 0.2910
===> Epoch[33](800/2500): Loss: 0.2699
===> Epoch[33](900/2500): Loss: 0.2833
===> Epoch[33](1000/2500): Loss: 0.2859
===> Epoch[33](1100/2500): Loss: 0.2865
===> Epoch[33](1200/2500): Loss: 0.2794
===> Epoch[33](1300/2500): Loss: 0.3056
===> Epoch[33](1400/2500): Loss: 0.2905
===> Epoch[33](1500/2500): Loss: 0.2860
===> Epoch[33](1600/2500): Loss: 0.2936
===> Epoch[33](1700/2500): Loss: 0.2988
===> Epoch[33](1800/2500): Loss: 0.2705
===> Epoch[33](1900/2500): Loss: 0.2668
===> Epoch[33](2000/2500): Loss: 0.2710
===> Epoch[33](2100/2500): Loss: 0.2546
===> Epoch[33](2200/2500): Loss: 0.3055
===> Epoch[33](2300/2500): Loss: 0.2910
===> Epoch[33](2400/2500): Loss: 0.2866
===> Epoch[33](2500/2500): Loss: 0.2836
===> Epoch 33 Complete: Avg. Loss: 0.2853
===> Timestamp: [2025-08-03 22:01:57]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2910
===> Epoch[33](200/2500): Loss: 0.2598
===> Epoch[33](300/2500): Loss: 0.2798
===> Epoch[33](400/2500): Loss: 0.3055
===> Epoch[33](500/2500): Loss: 0.3038
===> Epoch[33](600/2500): Loss: 0.2914
===> Epoch[33](700/2500): Loss: 0.2910
===> Epoch[33](800/2500): Loss: 0.2699
===> Epoch[33](900/2500): Loss: 0.2833
===> Epoch[33](1000/2500): Loss: 0.2859
===> Epoch[33](1100/2500): Loss: 0.2865
===> Epoch[33](1200/2500): Loss: 0.2794
===> Epoch[33](1300/2500): Loss: 0.3056
===> Epoch[33](1400/2500): Loss: 0.2905
===> Epoch[33](1500/2500): Loss: 0.2860
===> Epoch[33](1600/2500): Loss: 0.2936
===> Epoch[33](1700/2500): Loss: 0.2988
===> Epoch[33](1800/2500): Loss: 0.2705
===> Epoch[33](1900/2500): Loss: 0.2668
===> Epoch[33](2000/2500): Loss: 0.2710
===> Epoch[33](2100/2500): Loss: 0.2546
===> Epoch[33](2200/2500): Loss: 0.3055
===> Epoch[33](2300/2500): Loss: 0.2910
===> Epoch[33](2400/2500): Loss: 0.2866
===> Epoch[33](2500/2500): Loss: 0.2836
===> Epoch 33 Complete: Avg. Loss: 0.2853
===> Timestamp: [2025-08-03 22:01:57]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2910
===> Epoch[33](200/2500): Loss: 0.2598
===> Epoch[33](300/2500): Loss: 0.2798
===> Epoch[33](400/2500): Loss: 0.3055
===> Epoch[33](500/2500): Loss: 0.3038
===> Epoch[33](600/2500): Loss: 0.2914
===> Epoch[33](700/2500): Loss: 0.2910
===> Epoch[33](800/2500): Loss: 0.2699
===> Epoch[33](900/2500): Loss: 0.2833
===> Epoch[33](1000/2500): Loss: 0.2859
===> Epoch[33](1100/2500): Loss: 0.2865
===> Epoch[33](1200/2500): Loss: 0.2794
===> Epoch[33](1300/2500): Loss: 0.3056
===> Epoch[33](1400/2500): Loss: 0.2905
===> Epoch[33](1500/2500): Loss: 0.2860
===> Epoch[33](1600/2500): Loss: 0.2936
===> Epoch[33](1700/2500): Loss: 0.2988
===> Epoch[33](1800/2500): Loss: 0.2705
===> Epoch[33](1900/2500): Loss: 0.2668
===> Epoch[33](2000/2500): Loss: 0.2710
===> Epoch[33](2100/2500): Loss: 0.2546
===> Epoch[33](2200/2500): Loss: 0.3055
===> Epoch[33](2300/2500): Loss: 0.2910
===> Epoch[33](2400/2500): Loss: 0.2866
===> Epoch[33](2500/2500): Loss: 0.2836
===> Epoch 33 Complete: Avg. Loss: 0.2853
===> Timestamp: [2025-08-03 22:01:57]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2910
===> Epoch[33](200/2500): Loss: 0.2598
===> Epoch[33](300/2500): Loss: 0.2798
===> Epoch[33](400/2500): Loss: 0.3055
===> Epoch[33](500/2500): Loss: 0.3038
===> Epoch[33](600/2500): Loss: 0.2914
===> Epoch[33](700/2500): Loss: 0.2910
===> Epoch[33](800/2500): Loss: 0.2699
===> Epoch[33](900/2500): Loss: 0.2833
===> Epoch[33](1000/2500): Loss: 0.2859
===> Epoch[33](1100/2500): Loss: 0.2865
===> Epoch[33](1200/2500): Loss: 0.2794
===> Epoch[33](1300/2500): Loss: 0.3056
===> Epoch[33](1400/2500): Loss: 0.2905
===> Epoch[33](1500/2500): Loss: 0.2860
===> Epoch[33](1600/2500): Loss: 0.2936
===> Epoch[33](1700/2500): Loss: 0.2988
===> Epoch[33](1800/2500): Loss: 0.2705
===> Epoch[33](1900/2500): Loss: 0.2668
===> Epoch[33](2000/2500): Loss: 0.2710
===> Epoch[33](2100/2500): Loss: 0.2546
===> Epoch[33](2200/2500): Loss: 0.3055
===> Epoch[33](2300/2500): Loss: 0.2910
===> Epoch[33](2400/2500): Loss: 0.2866
===> Epoch[33](2500/2500): Loss: 0.2836
===> Epoch 33 Complete: Avg. Loss: 0.2853
===> Timestamp: [2025-08-03 22:01:57]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2910
===> Epoch[33](200/2500): Loss: 0.2598
===> Epoch[33](300/2500): Loss: 0.2798
===> Epoch[33](400/2500): Loss: 0.3055
===> Epoch[33](500/2500): Loss: 0.3038
===> Epoch[33](600/2500): Loss: 0.2914
===> Epoch[33](700/2500): Loss: 0.2910
===> Epoch[33](800/2500): Loss: 0.2699
===> Epoch[33](900/2500): Loss: 0.2833
===> Epoch[33](1000/2500): Loss: 0.2859
===> Epoch[33](1100/2500): Loss: 0.2865
===> Epoch[33](1200/2500): Loss: 0.2794
===> Epoch[33](1300/2500): Loss: 0.3056
===> Epoch[33](1400/2500): Loss: 0.2905
===> Epoch[33](1500/2500): Loss: 0.2860
===> Epoch[33](1600/2500): Loss: 0.2936
===> Epoch[33](1700/2500): Loss: 0.2988
===> Epoch[33](1800/2500): Loss: 0.2705
===> Epoch[33](1900/2500): Loss: 0.2668
===> Epoch[33](2000/2500): Loss: 0.2710
===> Epoch[33](2100/2500): Loss: 0.2546
===> Epoch[33](2200/2500): Loss: 0.3055
===> Epoch[33](2300/2500): Loss: 0.2910
===> Epoch[33](2400/2500): Loss: 0.2866
===> Epoch[33](2500/2500): Loss: 0.2836
===> Epoch 33 Complete: Avg. Loss: 0.2853
===> Timestamp: [2025-08-03 22:01:57]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2910
===> Epoch[33](200/2500): Loss: 0.2598
===> Epoch[33](300/2500): Loss: 0.2798
===> Epoch[33](400/2500): Loss: 0.3055
===> Epoch[33](500/2500): Loss: 0.3038
===> Epoch[33](600/2500): Loss: 0.2914
===> Epoch[33](700/2500): Loss: 0.2910
===> Epoch[33](800/2500): Loss: 0.2699
===> Epoch[33](900/2500): Loss: 0.2833
===> Epoch[33](1000/2500): Loss: 0.2859
===> Epoch[33](1100/2500): Loss: 0.2865
===> Epoch[33](1200/2500): Loss: 0.2794
===> Epoch[33](1300/2500): Loss: 0.3056
===> Epoch[33](1400/2500): Loss: 0.2905
===> Epoch[33](1500/2500): Loss: 0.2860
===> Epoch[33](1600/2500): Loss: 0.2936
===> Epoch[33](1700/2500): Loss: 0.2988
===> Epoch[33](1800/2500): Loss: 0.2705
===> Epoch[33](1900/2500): Loss: 0.2668
===> Epoch[33](2000/2500): Loss: 0.2710
===> Epoch[33](2100/2500): Loss: 0.2546
===> Epoch[33](2200/2500): Loss: 0.3055
===> Epoch[33](2300/2500): Loss: 0.2910
===> Epoch[33](2400/2500): Loss: 0.2866
===> Epoch[33](2500/2500): Loss: 0.2836
===> Epoch 33 Complete: Avg. Loss: 0.2853
===> Timestamp: [2025-08-03 22:01:57]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2910
===> Epoch[33](200/2500): Loss: 0.2598
===> Epoch[33](300/2500): Loss: 0.2798
===> Epoch[33](400/2500): Loss: 0.3055
===> Epoch[33](500/2500): Loss: 0.3038
===> Epoch[33](600/2500): Loss: 0.2914
===> Epoch[33](700/2500): Loss: 0.2910
===> Epoch[33](800/2500): Loss: 0.2699
===> Epoch[33](900/2500): Loss: 0.2833
===> Epoch[33](1000/2500): Loss: 0.2859
===> Epoch[33](1100/2500): Loss: 0.2865
===> Epoch[33](1200/2500): Loss: 0.2794
===> Epoch[33](1300/2500): Loss: 0.3056
===> Epoch[33](1400/2500): Loss: 0.2905
===> Epoch[33](1500/2500): Loss: 0.2860
===> Epoch[33](1600/2500): Loss: 0.2936
===> Epoch[33](1700/2500): Loss: 0.2988
===> Epoch[33](1800/2500): Loss: 0.2705
===> Epoch[33](1900/2500): Loss: 0.2668
===> Epoch[33](2000/2500): Loss: 0.2710
===> Epoch[33](2100/2500): Loss: 0.2546
===> Epoch[33](2200/2500): Loss: 0.3055
===> Epoch[33](2300/2500): Loss: 0.2910
===> Epoch[33](2400/2500): Loss: 0.2866
===> Epoch[33](2500/2500): Loss: 0.2836
===> Epoch 33 Complete: Avg. Loss: 0.2853
===> Timestamp: [2025-08-03 22:01:57]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2910
===> Epoch[33](200/2500): Loss: 0.2598
===> Epoch[33](300/2500): Loss: 0.2798
===> Epoch[33](400/2500): Loss: 0.3055
===> Epoch[33](500/2500): Loss: 0.3038
===> Epoch[33](600/2500): Loss: 0.2914
===> Epoch[33](700/2500): Loss: 0.2910
===> Epoch[33](800/2500): Loss: 0.2699
===> Epoch[33](900/2500): Loss: 0.2833
===> Epoch[33](1000/2500): Loss: 0.2859
===> Epoch[33](1100/2500): Loss: 0.2865
===> Epoch[33](1200/2500): Loss: 0.2794
===> Epoch[33](1300/2500): Loss: 0.3056
===> Epoch[33](1400/2500): Loss: 0.2905
===> Epoch[33](1500/2500): Loss: 0.2860
===> Epoch[33](1600/2500): Loss: 0.2936
===> Epoch[33](1700/2500): Loss: 0.2988
===> Epoch[33](1800/2500): Loss: 0.2705
===> Epoch[33](1900/2500): Loss: 0.2668
===> Epoch[33](2000/2500): Loss: 0.2710
===> Epoch[33](2100/2500): Loss: 0.2546
===> Epoch[33](2200/2500): Loss: 0.3055
===> Epoch[33](2300/2500): Loss: 0.2910
===> Epoch[33](2400/2500): Loss: 0.2866
===> Epoch[33](2500/2500): Loss: 0.2836
===> Epoch 33 Complete: Avg. Loss: 0.2853
===> Timestamp: [2025-08-03 22:01:57]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2910
===> Epoch[33](200/2500): Loss: 0.2598
===> Epoch[33](300/2500): Loss: 0.2798
===> Epoch[33](400/2500): Loss: 0.3055
===> Epoch[33](500/2500): Loss: 0.3038
===> Epoch[33](600/2500): Loss: 0.2914
===> Epoch[33](700/2500): Loss: 0.2910
===> Epoch[33](800/2500): Loss: 0.2699
===> Epoch[33](900/2500): Loss: 0.2833
===> Epoch[33](1000/2500): Loss: 0.2859
===> Epoch[33](1100/2500): Loss: 0.2865
===> Epoch[33](1200/2500): Loss: 0.2794
===> Epoch[33](1300/2500): Loss: 0.3056
===> Epoch[33](1400/2500): Loss: 0.2905
===> Epoch[33](1500/2500): Loss: 0.2860
===> Epoch[33](1600/2500): Loss: 0.2936
===> Epoch[33](1700/2500): Loss: 0.2988
===> Epoch[33](1800/2500): Loss: 0.2705
===> Epoch[33](1900/2500): Loss: 0.2668
===> Epoch[33](2000/2500): Loss: 0.2710
===> Epoch[33](2100/2500): Loss: 0.2546
===> Epoch[33](2200/2500): Loss: 0.3055
===> Epoch[33](2300/2500): Loss: 0.2910
===> Epoch[33](2400/2500): Loss: 0.2866
===> Epoch[33](2500/2500): Loss: 0.2836
===> Epoch 33 Complete: Avg. Loss: 0.2853
===> Timestamp: [2025-08-03 22:01:57]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2910
===> Epoch[33](200/2500): Loss: 0.2598
===> Epoch[33](300/2500): Loss: 0.2798
===> Epoch[33](400/2500): Loss: 0.3055
===> Epoch[33](500/2500): Loss: 0.3038
===> Epoch[33](600/2500): Loss: 0.2914
===> Epoch[33](700/2500): Loss: 0.2910
===> Epoch[33](800/2500): Loss: 0.2699
===> Epoch[33](900/2500): Loss: 0.2833
===> Epoch[33](1000/2500): Loss: 0.2859
===> Epoch[33](1100/2500): Loss: 0.2865
===> Epoch[33](1200/2500): Loss: 0.2794
===> Epoch[33](1300/2500): Loss: 0.3056
===> Epoch[33](1400/2500): Loss: 0.2905
===> Epoch[33](1500/2500): Loss: 0.2860
===> Epoch[33](1600/2500): Loss: 0.2936
===> Epoch[33](1700/2500): Loss: 0.2988
===> Epoch[33](1800/2500): Loss: 0.2705
===> Epoch[33](1900/2500): Loss: 0.2668
===> Epoch[33](2000/2500): Loss: 0.2710
===> Epoch[33](2100/2500): Loss: 0.2546
===> Epoch[33](2200/2500): Loss: 0.3055
===> Epoch[33](2300/2500): Loss: 0.2910
===> Epoch[33](2400/2500): Loss: 0.2866
===> Epoch[33](2500/2500): Loss: 0.2836
===> Epoch 33 Complete: Avg. Loss: 0.2853
===> Timestamp: [2025-08-03 22:01:57]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.2910
===> Epoch[33](200/2500): Loss: 0.2598
===> Epoch[33](300/2500): Loss: 0.2798
===> Epoch[33](400/2500): Loss: 0.3055
===> Epoch[33](500/2500): Loss: 0.3038
===> Epoch[33](600/2500): Loss: 0.2914
===> Epoch[33](700/2500): Loss: 0.2910
===> Epoch[33](800/2500): Loss: 0.2699
===> Epoch[33](900/2500): Loss: 0.2833
===> Epoch[33](1000/2500): Loss: 0.2859
===> Epoch[33](1100/2500): Loss: 0.2865
===> Epoch[33](1200/2500): Loss: 0.2794
===> Epoch[33](1300/2500): Loss: 0.3056
===> Epoch[33](1400/2500): Loss: 0.2905
===> Epoch[33](1500/2500): Loss: 0.2860
===> Epoch[33](1600/2500): Loss: 0.2936
===> Epoch[33](1700/2500): Loss: 0.2988
===> Epoch[33](1800/2500): Loss: 0.2705
===> Epoch[33](1900/2500): Loss: 0.2668
===> Epoch[33](2000/2500): Loss: 0.2710
===> Epoch[33](2100/2500): Loss: 0.2546
===> Epoch[33](2200/2500): Loss: 0.3055
===> Epoch[33](2300/2500): Loss: 0.2910
===> Epoch[33](2400/2500): Loss: 0.2866
===> Epoch[33](2500/2500): Loss: 0.2836
===> Epoch 33 Complete: Avg. Loss: 0.2853
===> Timestamp: [2025-08-03 22:01:57]
===> Loading train datasets
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2821
===> Epoch[34](200/2500): Loss: 0.2707
===> Epoch[34](300/2500): Loss: 0.2663
===> Epoch[34](400/2500): Loss: 0.3112
===> Epoch[34](500/2500): Loss: 0.3026
===> Epoch[34](600/2500): Loss: 0.2814
===> Epoch[34](700/2500): Loss: 0.2833
===> Epoch[34](800/2500): Loss: 0.2549
===> Epoch[34](900/2500): Loss: 0.2715
===> Epoch[34](1000/2500): Loss: 0.2739
===> Epoch[34](1100/2500): Loss: 0.2790
===> Epoch[34](1200/2500): Loss: 0.2459
===> Epoch[34](1300/2500): Loss: 0.2822
===> Epoch[34](1400/2500): Loss: 0.2787
===> Epoch[34](1500/2500): Loss: 0.2836
===> Epoch[34](1600/2500): Loss: 0.2936
===> Epoch[34](1700/2500): Loss: 0.2658
===> Epoch[34](1800/2500): Loss: 0.2820
===> Epoch[34](1900/2500): Loss: 0.2703
===> Epoch[34](2000/2500): Loss: 0.2948
===> Epoch[34](2100/2500): Loss: 0.2753
===> Epoch[34](2200/2500): Loss: 0.3049
===> Epoch[34](2300/2500): Loss: 0.2978
===> Epoch[34](2400/2500): Loss: 0.2864
===> Epoch[34](2500/2500): Loss: 0.2864
===> Epoch 34 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:06:31]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2821
===> Epoch[34](200/2500): Loss: 0.2707
===> Epoch[34](300/2500): Loss: 0.2663
===> Epoch[34](400/2500): Loss: 0.3112
===> Epoch[34](500/2500): Loss: 0.3026
===> Epoch[34](600/2500): Loss: 0.2814
===> Epoch[34](700/2500): Loss: 0.2833
===> Epoch[34](800/2500): Loss: 0.2549
===> Epoch[34](900/2500): Loss: 0.2715
===> Epoch[34](1000/2500): Loss: 0.2739
===> Epoch[34](1100/2500): Loss: 0.2790
===> Epoch[34](1200/2500): Loss: 0.2459
===> Epoch[34](1300/2500): Loss: 0.2822
===> Epoch[34](1400/2500): Loss: 0.2787
===> Epoch[34](1500/2500): Loss: 0.2836
===> Epoch[34](1600/2500): Loss: 0.2936
===> Epoch[34](1700/2500): Loss: 0.2658
===> Epoch[34](1800/2500): Loss: 0.2820
===> Epoch[34](1900/2500): Loss: 0.2703
===> Epoch[34](2000/2500): Loss: 0.2948
===> Epoch[34](2100/2500): Loss: 0.2753
===> Epoch[34](2200/2500): Loss: 0.3049
===> Epoch[34](2300/2500): Loss: 0.2978
===> Epoch[34](2400/2500): Loss: 0.2864
===> Epoch[34](2500/2500): Loss: 0.2864
===> Epoch 34 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:06:31]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2821
===> Epoch[34](200/2500): Loss: 0.2707
===> Epoch[34](300/2500): Loss: 0.2663
===> Epoch[34](400/2500): Loss: 0.3112
===> Epoch[34](500/2500): Loss: 0.3026
===> Epoch[34](600/2500): Loss: 0.2814
===> Epoch[34](700/2500): Loss: 0.2833
===> Epoch[34](800/2500): Loss: 0.2549
===> Epoch[34](900/2500): Loss: 0.2715
===> Epoch[34](1000/2500): Loss: 0.2739
===> Epoch[34](1100/2500): Loss: 0.2790
===> Epoch[34](1200/2500): Loss: 0.2459
===> Epoch[34](1300/2500): Loss: 0.2822
===> Epoch[34](1400/2500): Loss: 0.2787
===> Epoch[34](1500/2500): Loss: 0.2836
===> Epoch[34](1600/2500): Loss: 0.2936
===> Epoch[34](1700/2500): Loss: 0.2658
===> Epoch[34](1800/2500): Loss: 0.2820
===> Epoch[34](1900/2500): Loss: 0.2703
===> Epoch[34](2000/2500): Loss: 0.2948
===> Epoch[34](2100/2500): Loss: 0.2753
===> Epoch[34](2200/2500): Loss: 0.3049
===> Epoch[34](2300/2500): Loss: 0.2978
===> Epoch[34](2400/2500): Loss: 0.2864
===> Epoch[34](2500/2500): Loss: 0.2864
===> Epoch 34 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:06:31]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2821
===> Epoch[34](200/2500): Loss: 0.2707
===> Epoch[34](300/2500): Loss: 0.2663
===> Epoch[34](400/2500): Loss: 0.3112
===> Epoch[34](500/2500): Loss: 0.3026
===> Epoch[34](600/2500): Loss: 0.2814
===> Epoch[34](700/2500): Loss: 0.2833
===> Epoch[34](800/2500): Loss: 0.2549
===> Epoch[34](900/2500): Loss: 0.2715
===> Epoch[34](1000/2500): Loss: 0.2739
===> Epoch[34](1100/2500): Loss: 0.2790
===> Epoch[34](1200/2500): Loss: 0.2459
===> Epoch[34](1300/2500): Loss: 0.2822
===> Epoch[34](1400/2500): Loss: 0.2787
===> Epoch[34](1500/2500): Loss: 0.2836
===> Epoch[34](1600/2500): Loss: 0.2936
===> Epoch[34](1700/2500): Loss: 0.2658
===> Epoch[34](1800/2500): Loss: 0.2820
===> Epoch[34](1900/2500): Loss: 0.2703
===> Epoch[34](2000/2500): Loss: 0.2948
===> Epoch[34](2100/2500): Loss: 0.2753
===> Epoch[34](2200/2500): Loss: 0.3049
===> Epoch[34](2300/2500): Loss: 0.2978
===> Epoch[34](2400/2500): Loss: 0.2864
===> Epoch[34](2500/2500): Loss: 0.2864
===> Epoch 34 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:06:31]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2821
===> Epoch[34](200/2500): Loss: 0.2707
===> Epoch[34](300/2500): Loss: 0.2663
===> Epoch[34](400/2500): Loss: 0.3112
===> Epoch[34](500/2500): Loss: 0.3026
===> Epoch[34](600/2500): Loss: 0.2814
===> Epoch[34](700/2500): Loss: 0.2833
===> Epoch[34](800/2500): Loss: 0.2549
===> Epoch[34](900/2500): Loss: 0.2715
===> Epoch[34](1000/2500): Loss: 0.2739
===> Epoch[34](1100/2500): Loss: 0.2790
===> Epoch[34](1200/2500): Loss: 0.2459
===> Epoch[34](1300/2500): Loss: 0.2822
===> Epoch[34](1400/2500): Loss: 0.2787
===> Epoch[34](1500/2500): Loss: 0.2836
===> Epoch[34](1600/2500): Loss: 0.2936
===> Epoch[34](1700/2500): Loss: 0.2658
===> Epoch[34](1800/2500): Loss: 0.2820
===> Epoch[34](1900/2500): Loss: 0.2703
===> Epoch[34](2000/2500): Loss: 0.2948
===> Epoch[34](2100/2500): Loss: 0.2753
===> Epoch[34](2200/2500): Loss: 0.3049
===> Epoch[34](2300/2500): Loss: 0.2978
===> Epoch[34](2400/2500): Loss: 0.2864
===> Epoch[34](2500/2500): Loss: 0.2864
===> Epoch 34 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:06:31]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2821
===> Epoch[34](200/2500): Loss: 0.2707
===> Epoch[34](300/2500): Loss: 0.2663
===> Epoch[34](400/2500): Loss: 0.3112
===> Epoch[34](500/2500): Loss: 0.3026
===> Epoch[34](600/2500): Loss: 0.2814
===> Epoch[34](700/2500): Loss: 0.2833
===> Epoch[34](800/2500): Loss: 0.2549
===> Epoch[34](900/2500): Loss: 0.2715
===> Epoch[34](1000/2500): Loss: 0.2739
===> Epoch[34](1100/2500): Loss: 0.2790
===> Epoch[34](1200/2500): Loss: 0.2459
===> Epoch[34](1300/2500): Loss: 0.2822
===> Epoch[34](1400/2500): Loss: 0.2787
===> Epoch[34](1500/2500): Loss: 0.2836
===> Epoch[34](1600/2500): Loss: 0.2936
===> Epoch[34](1700/2500): Loss: 0.2658
===> Epoch[34](1800/2500): Loss: 0.2820
===> Epoch[34](1900/2500): Loss: 0.2703
===> Epoch[34](2000/2500): Loss: 0.2948
===> Epoch[34](2100/2500): Loss: 0.2753
===> Epoch[34](2200/2500): Loss: 0.3049
===> Epoch[34](2300/2500): Loss: 0.2978
===> Epoch[34](2400/2500): Loss: 0.2864
===> Epoch[34](2500/2500): Loss: 0.2864
===> Epoch 34 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:06:31]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2821
===> Epoch[34](200/2500): Loss: 0.2707
===> Epoch[34](300/2500): Loss: 0.2663
===> Epoch[34](400/2500): Loss: 0.3112
===> Epoch[34](500/2500): Loss: 0.3026
===> Epoch[34](600/2500): Loss: 0.2814
===> Epoch[34](700/2500): Loss: 0.2833
===> Epoch[34](800/2500): Loss: 0.2549
===> Epoch[34](900/2500): Loss: 0.2715
===> Epoch[34](1000/2500): Loss: 0.2739
===> Epoch[34](1100/2500): Loss: 0.2790
===> Epoch[34](1200/2500): Loss: 0.2459
===> Epoch[34](1300/2500): Loss: 0.2822
===> Epoch[34](1400/2500): Loss: 0.2787
===> Epoch[34](1500/2500): Loss: 0.2836
===> Epoch[34](1600/2500): Loss: 0.2936
===> Epoch[34](1700/2500): Loss: 0.2658
===> Epoch[34](1800/2500): Loss: 0.2820
===> Epoch[34](1900/2500): Loss: 0.2703
===> Epoch[34](2000/2500): Loss: 0.2948
===> Epoch[34](2100/2500): Loss: 0.2753
===> Epoch[34](2200/2500): Loss: 0.3049
===> Epoch[34](2300/2500): Loss: 0.2978
===> Epoch[34](2400/2500): Loss: 0.2864
===> Epoch[34](2500/2500): Loss: 0.2864
===> Epoch 34 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:06:31]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2821
===> Epoch[34](200/2500): Loss: 0.2707
===> Epoch[34](300/2500): Loss: 0.2663
===> Epoch[34](400/2500): Loss: 0.3112
===> Epoch[34](500/2500): Loss: 0.3026
===> Epoch[34](600/2500): Loss: 0.2814
===> Epoch[34](700/2500): Loss: 0.2833
===> Epoch[34](800/2500): Loss: 0.2549
===> Epoch[34](900/2500): Loss: 0.2715
===> Epoch[34](1000/2500): Loss: 0.2739
===> Epoch[34](1100/2500): Loss: 0.2790
===> Epoch[34](1200/2500): Loss: 0.2459
===> Epoch[34](1300/2500): Loss: 0.2822
===> Epoch[34](1400/2500): Loss: 0.2787
===> Epoch[34](1500/2500): Loss: 0.2836
===> Epoch[34](1600/2500): Loss: 0.2936
===> Epoch[34](1700/2500): Loss: 0.2658
===> Epoch[34](1800/2500): Loss: 0.2820
===> Epoch[34](1900/2500): Loss: 0.2703
===> Epoch[34](2000/2500): Loss: 0.2948
===> Epoch[34](2100/2500): Loss: 0.2753
===> Epoch[34](2200/2500): Loss: 0.3049
===> Epoch[34](2300/2500): Loss: 0.2978
===> Epoch[34](2400/2500): Loss: 0.2864
===> Epoch[34](2500/2500): Loss: 0.2864
===> Epoch 34 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:06:31]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2821
===> Epoch[34](200/2500): Loss: 0.2707
===> Epoch[34](300/2500): Loss: 0.2663
===> Epoch[34](400/2500): Loss: 0.3112
===> Epoch[34](500/2500): Loss: 0.3026
===> Epoch[34](600/2500): Loss: 0.2814
===> Epoch[34](700/2500): Loss: 0.2833
===> Epoch[34](800/2500): Loss: 0.2549
===> Epoch[34](900/2500): Loss: 0.2715
===> Epoch[34](1000/2500): Loss: 0.2739
===> Epoch[34](1100/2500): Loss: 0.2790
===> Epoch[34](1200/2500): Loss: 0.2459
===> Epoch[34](1300/2500): Loss: 0.2822
===> Epoch[34](1400/2500): Loss: 0.2787
===> Epoch[34](1500/2500): Loss: 0.2836
===> Epoch[34](1600/2500): Loss: 0.2936
===> Epoch[34](1700/2500): Loss: 0.2658
===> Epoch[34](1800/2500): Loss: 0.2820
===> Epoch[34](1900/2500): Loss: 0.2703
===> Epoch[34](2000/2500): Loss: 0.2948
===> Epoch[34](2100/2500): Loss: 0.2753
===> Epoch[34](2200/2500): Loss: 0.3049
===> Epoch[34](2300/2500): Loss: 0.2978
===> Epoch[34](2400/2500): Loss: 0.2864
===> Epoch[34](2500/2500): Loss: 0.2864
===> Epoch 34 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:06:31]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2821
===> Epoch[34](200/2500): Loss: 0.2707
===> Epoch[34](300/2500): Loss: 0.2663
===> Epoch[34](400/2500): Loss: 0.3112
===> Epoch[34](500/2500): Loss: 0.3026
===> Epoch[34](600/2500): Loss: 0.2814
===> Epoch[34](700/2500): Loss: 0.2833
===> Epoch[34](800/2500): Loss: 0.2549
===> Epoch[34](900/2500): Loss: 0.2715
===> Epoch[34](1000/2500): Loss: 0.2739
===> Epoch[34](1100/2500): Loss: 0.2790
===> Epoch[34](1200/2500): Loss: 0.2459
===> Epoch[34](1300/2500): Loss: 0.2822
===> Epoch[34](1400/2500): Loss: 0.2787
===> Epoch[34](1500/2500): Loss: 0.2836
===> Epoch[34](1600/2500): Loss: 0.2936
===> Epoch[34](1700/2500): Loss: 0.2658
===> Epoch[34](1800/2500): Loss: 0.2820
===> Epoch[34](1900/2500): Loss: 0.2703
===> Epoch[34](2000/2500): Loss: 0.2948
===> Epoch[34](2100/2500): Loss: 0.2753
===> Epoch[34](2200/2500): Loss: 0.3049
===> Epoch[34](2300/2500): Loss: 0.2978
===> Epoch[34](2400/2500): Loss: 0.2864
===> Epoch[34](2500/2500): Loss: 0.2864
===> Epoch 34 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:06:31]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2821
===> Epoch[34](200/2500): Loss: 0.2707
===> Epoch[34](300/2500): Loss: 0.2663
===> Epoch[34](400/2500): Loss: 0.3112
===> Epoch[34](500/2500): Loss: 0.3026
===> Epoch[34](600/2500): Loss: 0.2814
===> Epoch[34](700/2500): Loss: 0.2833
===> Epoch[34](800/2500): Loss: 0.2549
===> Epoch[34](900/2500): Loss: 0.2715
===> Epoch[34](1000/2500): Loss: 0.2739
===> Epoch[34](1100/2500): Loss: 0.2790
===> Epoch[34](1200/2500): Loss: 0.2459
===> Epoch[34](1300/2500): Loss: 0.2822
===> Epoch[34](1400/2500): Loss: 0.2787
===> Epoch[34](1500/2500): Loss: 0.2836
===> Epoch[34](1600/2500): Loss: 0.2936
===> Epoch[34](1700/2500): Loss: 0.2658
===> Epoch[34](1800/2500): Loss: 0.2820
===> Epoch[34](1900/2500): Loss: 0.2703
===> Epoch[34](2000/2500): Loss: 0.2948
===> Epoch[34](2100/2500): Loss: 0.2753
===> Epoch[34](2200/2500): Loss: 0.3049
===> Epoch[34](2300/2500): Loss: 0.2978
===> Epoch[34](2400/2500): Loss: 0.2864
===> Epoch[34](2500/2500): Loss: 0.2864
===> Epoch 34 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:06:31]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2821
===> Epoch[34](200/2500): Loss: 0.2707
===> Epoch[34](300/2500): Loss: 0.2663
===> Epoch[34](400/2500): Loss: 0.3112
===> Epoch[34](500/2500): Loss: 0.3026
===> Epoch[34](600/2500): Loss: 0.2814
===> Epoch[34](700/2500): Loss: 0.2833
===> Epoch[34](800/2500): Loss: 0.2549
===> Epoch[34](900/2500): Loss: 0.2715
===> Epoch[34](1000/2500): Loss: 0.2739
===> Epoch[34](1100/2500): Loss: 0.2790
===> Epoch[34](1200/2500): Loss: 0.2459
===> Epoch[34](1300/2500): Loss: 0.2822
===> Epoch[34](1400/2500): Loss: 0.2787
===> Epoch[34](1500/2500): Loss: 0.2836
===> Epoch[34](1600/2500): Loss: 0.2936
===> Epoch[34](1700/2500): Loss: 0.2658
===> Epoch[34](1800/2500): Loss: 0.2820
===> Epoch[34](1900/2500): Loss: 0.2703
===> Epoch[34](2000/2500): Loss: 0.2948
===> Epoch[34](2100/2500): Loss: 0.2753
===> Epoch[34](2200/2500): Loss: 0.3049
===> Epoch[34](2300/2500): Loss: 0.2978
===> Epoch[34](2400/2500): Loss: 0.2864
===> Epoch[34](2500/2500): Loss: 0.2864
===> Epoch 34 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:06:31]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2821
===> Epoch[34](200/2500): Loss: 0.2707
===> Epoch[34](300/2500): Loss: 0.2663
===> Epoch[34](400/2500): Loss: 0.3112
===> Epoch[34](500/2500): Loss: 0.3026
===> Epoch[34](600/2500): Loss: 0.2814
===> Epoch[34](700/2500): Loss: 0.2833
===> Epoch[34](800/2500): Loss: 0.2549
===> Epoch[34](900/2500): Loss: 0.2715
===> Epoch[34](1000/2500): Loss: 0.2739
===> Epoch[34](1100/2500): Loss: 0.2790
===> Epoch[34](1200/2500): Loss: 0.2459
===> Epoch[34](1300/2500): Loss: 0.2822
===> Epoch[34](1400/2500): Loss: 0.2787
===> Epoch[34](1500/2500): Loss: 0.2836
===> Epoch[34](1600/2500): Loss: 0.2936
===> Epoch[34](1700/2500): Loss: 0.2658
===> Epoch[34](1800/2500): Loss: 0.2820
===> Epoch[34](1900/2500): Loss: 0.2703
===> Epoch[34](2000/2500): Loss: 0.2948
===> Epoch[34](2100/2500): Loss: 0.2753
===> Epoch[34](2200/2500): Loss: 0.3049
===> Epoch[34](2300/2500): Loss: 0.2978
===> Epoch[34](2400/2500): Loss: 0.2864
===> Epoch[34](2500/2500): Loss: 0.2864
===> Epoch 34 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:06:31]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2821
===> Epoch[34](200/2500): Loss: 0.2707
===> Epoch[34](300/2500): Loss: 0.2663
===> Epoch[34](400/2500): Loss: 0.3112
===> Epoch[34](500/2500): Loss: 0.3026
===> Epoch[34](600/2500): Loss: 0.2814
===> Epoch[34](700/2500): Loss: 0.2833
===> Epoch[34](800/2500): Loss: 0.2549
===> Epoch[34](900/2500): Loss: 0.2715
===> Epoch[34](1000/2500): Loss: 0.2739
===> Epoch[34](1100/2500): Loss: 0.2790
===> Epoch[34](1200/2500): Loss: 0.2459
===> Epoch[34](1300/2500): Loss: 0.2822
===> Epoch[34](1400/2500): Loss: 0.2787
===> Epoch[34](1500/2500): Loss: 0.2836
===> Epoch[34](1600/2500): Loss: 0.2936
===> Epoch[34](1700/2500): Loss: 0.2658
===> Epoch[34](1800/2500): Loss: 0.2820
===> Epoch[34](1900/2500): Loss: 0.2703
===> Epoch[34](2000/2500): Loss: 0.2948
===> Epoch[34](2100/2500): Loss: 0.2753
===> Epoch[34](2200/2500): Loss: 0.3049
===> Epoch[34](2300/2500): Loss: 0.2978
===> Epoch[34](2400/2500): Loss: 0.2864
===> Epoch[34](2500/2500): Loss: 0.2864
===> Epoch 34 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:06:31]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2821
===> Epoch[34](200/2500): Loss: 0.2707
===> Epoch[34](300/2500): Loss: 0.2663
===> Epoch[34](400/2500): Loss: 0.3112
===> Epoch[34](500/2500): Loss: 0.3026
===> Epoch[34](600/2500): Loss: 0.2814
===> Epoch[34](700/2500): Loss: 0.2833
===> Epoch[34](800/2500): Loss: 0.2549
===> Epoch[34](900/2500): Loss: 0.2715
===> Epoch[34](1000/2500): Loss: 0.2739
===> Epoch[34](1100/2500): Loss: 0.2790
===> Epoch[34](1200/2500): Loss: 0.2459
===> Epoch[34](1300/2500): Loss: 0.2822
===> Epoch[34](1400/2500): Loss: 0.2787
===> Epoch[34](1500/2500): Loss: 0.2836
===> Epoch[34](1600/2500): Loss: 0.2936
===> Epoch[34](1700/2500): Loss: 0.2658
===> Epoch[34](1800/2500): Loss: 0.2820
===> Epoch[34](1900/2500): Loss: 0.2703
===> Epoch[34](2000/2500): Loss: 0.2948
===> Epoch[34](2100/2500): Loss: 0.2753
===> Epoch[34](2200/2500): Loss: 0.3049
===> Epoch[34](2300/2500): Loss: 0.2978
===> Epoch[34](2400/2500): Loss: 0.2864
===> Epoch[34](2500/2500): Loss: 0.2864
===> Epoch 34 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:06:31]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2821
===> Epoch[34](200/2500): Loss: 0.2707
===> Epoch[34](300/2500): Loss: 0.2663
===> Epoch[34](400/2500): Loss: 0.3112
===> Epoch[34](500/2500): Loss: 0.3026
===> Epoch[34](600/2500): Loss: 0.2814
===> Epoch[34](700/2500): Loss: 0.2833
===> Epoch[34](800/2500): Loss: 0.2549
===> Epoch[34](900/2500): Loss: 0.2715
===> Epoch[34](1000/2500): Loss: 0.2739
===> Epoch[34](1100/2500): Loss: 0.2790
===> Epoch[34](1200/2500): Loss: 0.2459
===> Epoch[34](1300/2500): Loss: 0.2822
===> Epoch[34](1400/2500): Loss: 0.2787
===> Epoch[34](1500/2500): Loss: 0.2836
===> Epoch[34](1600/2500): Loss: 0.2936
===> Epoch[34](1700/2500): Loss: 0.2658
===> Epoch[34](1800/2500): Loss: 0.2820
===> Epoch[34](1900/2500): Loss: 0.2703
===> Epoch[34](2000/2500): Loss: 0.2948
===> Epoch[34](2100/2500): Loss: 0.2753
===> Epoch[34](2200/2500): Loss: 0.3049
===> Epoch[34](2300/2500): Loss: 0.2978
===> Epoch[34](2400/2500): Loss: 0.2864
===> Epoch[34](2500/2500): Loss: 0.2864
===> Epoch 34 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:06:31]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2821
===> Epoch[34](200/2500): Loss: 0.2707
===> Epoch[34](300/2500): Loss: 0.2663
===> Epoch[34](400/2500): Loss: 0.3112
===> Epoch[34](500/2500): Loss: 0.3026
===> Epoch[34](600/2500): Loss: 0.2814
===> Epoch[34](700/2500): Loss: 0.2833
===> Epoch[34](800/2500): Loss: 0.2549
===> Epoch[34](900/2500): Loss: 0.2715
===> Epoch[34](1000/2500): Loss: 0.2739
===> Epoch[34](1100/2500): Loss: 0.2790
===> Epoch[34](1200/2500): Loss: 0.2459
===> Epoch[34](1300/2500): Loss: 0.2822
===> Epoch[34](1400/2500): Loss: 0.2787
===> Epoch[34](1500/2500): Loss: 0.2836
===> Epoch[34](1600/2500): Loss: 0.2936
===> Epoch[34](1700/2500): Loss: 0.2658
===> Epoch[34](1800/2500): Loss: 0.2820
===> Epoch[34](1900/2500): Loss: 0.2703
===> Epoch[34](2000/2500): Loss: 0.2948
===> Epoch[34](2100/2500): Loss: 0.2753
===> Epoch[34](2200/2500): Loss: 0.3049
===> Epoch[34](2300/2500): Loss: 0.2978
===> Epoch[34](2400/2500): Loss: 0.2864
===> Epoch[34](2500/2500): Loss: 0.2864
===> Epoch 34 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:06:31]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2821
===> Epoch[34](200/2500): Loss: 0.2707
===> Epoch[34](300/2500): Loss: 0.2663
===> Epoch[34](400/2500): Loss: 0.3112
===> Epoch[34](500/2500): Loss: 0.3026
===> Epoch[34](600/2500): Loss: 0.2814
===> Epoch[34](700/2500): Loss: 0.2833
===> Epoch[34](800/2500): Loss: 0.2549
===> Epoch[34](900/2500): Loss: 0.2715
===> Epoch[34](1000/2500): Loss: 0.2739
===> Epoch[34](1100/2500): Loss: 0.2790
===> Epoch[34](1200/2500): Loss: 0.2459
===> Epoch[34](1300/2500): Loss: 0.2822
===> Epoch[34](1400/2500): Loss: 0.2787
===> Epoch[34](1500/2500): Loss: 0.2836
===> Epoch[34](1600/2500): Loss: 0.2936
===> Epoch[34](1700/2500): Loss: 0.2658
===> Epoch[34](1800/2500): Loss: 0.2820
===> Epoch[34](1900/2500): Loss: 0.2703
===> Epoch[34](2000/2500): Loss: 0.2948
===> Epoch[34](2100/2500): Loss: 0.2753
===> Epoch[34](2200/2500): Loss: 0.3049
===> Epoch[34](2300/2500): Loss: 0.2978
===> Epoch[34](2400/2500): Loss: 0.2864
===> Epoch[34](2500/2500): Loss: 0.2864
===> Epoch 34 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:06:31]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2821
===> Epoch[34](200/2500): Loss: 0.2707
===> Epoch[34](300/2500): Loss: 0.2663
===> Epoch[34](400/2500): Loss: 0.3112
===> Epoch[34](500/2500): Loss: 0.3026
===> Epoch[34](600/2500): Loss: 0.2814
===> Epoch[34](700/2500): Loss: 0.2833
===> Epoch[34](800/2500): Loss: 0.2549
===> Epoch[34](900/2500): Loss: 0.2715
===> Epoch[34](1000/2500): Loss: 0.2739
===> Epoch[34](1100/2500): Loss: 0.2790
===> Epoch[34](1200/2500): Loss: 0.2459
===> Epoch[34](1300/2500): Loss: 0.2822
===> Epoch[34](1400/2500): Loss: 0.2787
===> Epoch[34](1500/2500): Loss: 0.2836
===> Epoch[34](1600/2500): Loss: 0.2936
===> Epoch[34](1700/2500): Loss: 0.2658
===> Epoch[34](1800/2500): Loss: 0.2820
===> Epoch[34](1900/2500): Loss: 0.2703
===> Epoch[34](2000/2500): Loss: 0.2948
===> Epoch[34](2100/2500): Loss: 0.2753
===> Epoch[34](2200/2500): Loss: 0.3049
===> Epoch[34](2300/2500): Loss: 0.2978
===> Epoch[34](2400/2500): Loss: 0.2864
===> Epoch[34](2500/2500): Loss: 0.2864
===> Epoch 34 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:06:31]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2821
===> Epoch[34](200/2500): Loss: 0.2707
===> Epoch[34](300/2500): Loss: 0.2663
===> Epoch[34](400/2500): Loss: 0.3112
===> Epoch[34](500/2500): Loss: 0.3026
===> Epoch[34](600/2500): Loss: 0.2814
===> Epoch[34](700/2500): Loss: 0.2833
===> Epoch[34](800/2500): Loss: 0.2549
===> Epoch[34](900/2500): Loss: 0.2715
===> Epoch[34](1000/2500): Loss: 0.2739
===> Epoch[34](1100/2500): Loss: 0.2790
===> Epoch[34](1200/2500): Loss: 0.2459
===> Epoch[34](1300/2500): Loss: 0.2822
===> Epoch[34](1400/2500): Loss: 0.2787
===> Epoch[34](1500/2500): Loss: 0.2836
===> Epoch[34](1600/2500): Loss: 0.2936
===> Epoch[34](1700/2500): Loss: 0.2658
===> Epoch[34](1800/2500): Loss: 0.2820
===> Epoch[34](1900/2500): Loss: 0.2703
===> Epoch[34](2000/2500): Loss: 0.2948
===> Epoch[34](2100/2500): Loss: 0.2753
===> Epoch[34](2200/2500): Loss: 0.3049
===> Epoch[34](2300/2500): Loss: 0.2978
===> Epoch[34](2400/2500): Loss: 0.2864
===> Epoch[34](2500/2500): Loss: 0.2864
===> Epoch 34 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:06:31]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2821
===> Epoch[34](200/2500): Loss: 0.2707
===> Epoch[34](300/2500): Loss: 0.2663
===> Epoch[34](400/2500): Loss: 0.3112
===> Epoch[34](500/2500): Loss: 0.3026
===> Epoch[34](600/2500): Loss: 0.2814
===> Epoch[34](700/2500): Loss: 0.2833
===> Epoch[34](800/2500): Loss: 0.2549
===> Epoch[34](900/2500): Loss: 0.2715
===> Epoch[34](1000/2500): Loss: 0.2739
===> Epoch[34](1100/2500): Loss: 0.2790
===> Epoch[34](1200/2500): Loss: 0.2459
===> Epoch[34](1300/2500): Loss: 0.2822
===> Epoch[34](1400/2500): Loss: 0.2787
===> Epoch[34](1500/2500): Loss: 0.2836
===> Epoch[34](1600/2500): Loss: 0.2936
===> Epoch[34](1700/2500): Loss: 0.2658
===> Epoch[34](1800/2500): Loss: 0.2820
===> Epoch[34](1900/2500): Loss: 0.2703
===> Epoch[34](2000/2500): Loss: 0.2948
===> Epoch[34](2100/2500): Loss: 0.2753
===> Epoch[34](2200/2500): Loss: 0.3049
===> Epoch[34](2300/2500): Loss: 0.2978
===> Epoch[34](2400/2500): Loss: 0.2864
===> Epoch[34](2500/2500): Loss: 0.2864
===> Epoch 34 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:06:31]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2821
===> Epoch[34](200/2500): Loss: 0.2707
===> Epoch[34](300/2500): Loss: 0.2663
===> Epoch[34](400/2500): Loss: 0.3112
===> Epoch[34](500/2500): Loss: 0.3026
===> Epoch[34](600/2500): Loss: 0.2814
===> Epoch[34](700/2500): Loss: 0.2833
===> Epoch[34](800/2500): Loss: 0.2549
===> Epoch[34](900/2500): Loss: 0.2715
===> Epoch[34](1000/2500): Loss: 0.2739
===> Epoch[34](1100/2500): Loss: 0.2790
===> Epoch[34](1200/2500): Loss: 0.2459
===> Epoch[34](1300/2500): Loss: 0.2822
===> Epoch[34](1400/2500): Loss: 0.2787
===> Epoch[34](1500/2500): Loss: 0.2836
===> Epoch[34](1600/2500): Loss: 0.2936
===> Epoch[34](1700/2500): Loss: 0.2658
===> Epoch[34](1800/2500): Loss: 0.2820
===> Epoch[34](1900/2500): Loss: 0.2703
===> Epoch[34](2000/2500): Loss: 0.2948
===> Epoch[34](2100/2500): Loss: 0.2753
===> Epoch[34](2200/2500): Loss: 0.3049
===> Epoch[34](2300/2500): Loss: 0.2978
===> Epoch[34](2400/2500): Loss: 0.2864
===> Epoch[34](2500/2500): Loss: 0.2864
===> Epoch 34 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:06:31]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2821
===> Epoch[34](200/2500): Loss: 0.2707
===> Epoch[34](300/2500): Loss: 0.2663
===> Epoch[34](400/2500): Loss: 0.3112
===> Epoch[34](500/2500): Loss: 0.3026
===> Epoch[34](600/2500): Loss: 0.2814
===> Epoch[34](700/2500): Loss: 0.2833
===> Epoch[34](800/2500): Loss: 0.2549
===> Epoch[34](900/2500): Loss: 0.2715
===> Epoch[34](1000/2500): Loss: 0.2739
===> Epoch[34](1100/2500): Loss: 0.2790
===> Epoch[34](1200/2500): Loss: 0.2459
===> Epoch[34](1300/2500): Loss: 0.2822
===> Epoch[34](1400/2500): Loss: 0.2787
===> Epoch[34](1500/2500): Loss: 0.2836
===> Epoch[34](1600/2500): Loss: 0.2936
===> Epoch[34](1700/2500): Loss: 0.2658
===> Epoch[34](1800/2500): Loss: 0.2820
===> Epoch[34](1900/2500): Loss: 0.2703
===> Epoch[34](2000/2500): Loss: 0.2948
===> Epoch[34](2100/2500): Loss: 0.2753
===> Epoch[34](2200/2500): Loss: 0.3049
===> Epoch[34](2300/2500): Loss: 0.2978
===> Epoch[34](2400/2500): Loss: 0.2864
===> Epoch[34](2500/2500): Loss: 0.2864
===> Epoch 34 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:06:31]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2821
===> Epoch[34](200/2500): Loss: 0.2707
===> Epoch[34](300/2500): Loss: 0.2663
===> Epoch[34](400/2500): Loss: 0.3112
===> Epoch[34](500/2500): Loss: 0.3026
===> Epoch[34](600/2500): Loss: 0.2814
===> Epoch[34](700/2500): Loss: 0.2833
===> Epoch[34](800/2500): Loss: 0.2549
===> Epoch[34](900/2500): Loss: 0.2715
===> Epoch[34](1000/2500): Loss: 0.2739
===> Epoch[34](1100/2500): Loss: 0.2790
===> Epoch[34](1200/2500): Loss: 0.2459
===> Epoch[34](1300/2500): Loss: 0.2822
===> Epoch[34](1400/2500): Loss: 0.2787
===> Epoch[34](1500/2500): Loss: 0.2836
===> Epoch[34](1600/2500): Loss: 0.2936
===> Epoch[34](1700/2500): Loss: 0.2658
===> Epoch[34](1800/2500): Loss: 0.2820
===> Epoch[34](1900/2500): Loss: 0.2703
===> Epoch[34](2000/2500): Loss: 0.2948
===> Epoch[34](2100/2500): Loss: 0.2753
===> Epoch[34](2200/2500): Loss: 0.3049
===> Epoch[34](2300/2500): Loss: 0.2978
===> Epoch[34](2400/2500): Loss: 0.2864
===> Epoch[34](2500/2500): Loss: 0.2864
===> Epoch 34 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:06:31]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2821
===> Epoch[34](200/2500): Loss: 0.2707
===> Epoch[34](300/2500): Loss: 0.2663
===> Epoch[34](400/2500): Loss: 0.3112
===> Epoch[34](500/2500): Loss: 0.3026
===> Epoch[34](600/2500): Loss: 0.2814
===> Epoch[34](700/2500): Loss: 0.2833
===> Epoch[34](800/2500): Loss: 0.2549
===> Epoch[34](900/2500): Loss: 0.2715
===> Epoch[34](1000/2500): Loss: 0.2739
===> Epoch[34](1100/2500): Loss: 0.2790
===> Epoch[34](1200/2500): Loss: 0.2459
===> Epoch[34](1300/2500): Loss: 0.2822
===> Epoch[34](1400/2500): Loss: 0.2787
===> Epoch[34](1500/2500): Loss: 0.2836
===> Epoch[34](1600/2500): Loss: 0.2936
===> Epoch[34](1700/2500): Loss: 0.2658
===> Epoch[34](1800/2500): Loss: 0.2820
===> Epoch[34](1900/2500): Loss: 0.2703
===> Epoch[34](2000/2500): Loss: 0.2948
===> Epoch[34](2100/2500): Loss: 0.2753
===> Epoch[34](2200/2500): Loss: 0.3049
===> Epoch[34](2300/2500): Loss: 0.2978
===> Epoch[34](2400/2500): Loss: 0.2864
===> Epoch[34](2500/2500): Loss: 0.2864
===> Epoch 34 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:06:31]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2821
===> Epoch[34](200/2500): Loss: 0.2707
===> Epoch[34](300/2500): Loss: 0.2663
===> Epoch[34](400/2500): Loss: 0.3112
===> Epoch[34](500/2500): Loss: 0.3026
===> Epoch[34](600/2500): Loss: 0.2814
===> Epoch[34](700/2500): Loss: 0.2833
===> Epoch[34](800/2500): Loss: 0.2549
===> Epoch[34](900/2500): Loss: 0.2715
===> Epoch[34](1000/2500): Loss: 0.2739
===> Epoch[34](1100/2500): Loss: 0.2790
===> Epoch[34](1200/2500): Loss: 0.2459
===> Epoch[34](1300/2500): Loss: 0.2822
===> Epoch[34](1400/2500): Loss: 0.2787
===> Epoch[34](1500/2500): Loss: 0.2836
===> Epoch[34](1600/2500): Loss: 0.2936
===> Epoch[34](1700/2500): Loss: 0.2658
===> Epoch[34](1800/2500): Loss: 0.2820
===> Epoch[34](1900/2500): Loss: 0.2703
===> Epoch[34](2000/2500): Loss: 0.2948
===> Epoch[34](2100/2500): Loss: 0.2753
===> Epoch[34](2200/2500): Loss: 0.3049
===> Epoch[34](2300/2500): Loss: 0.2978
===> Epoch[34](2400/2500): Loss: 0.2864
===> Epoch[34](2500/2500): Loss: 0.2864
===> Epoch 34 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:06:31]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2821
===> Epoch[34](200/2500): Loss: 0.2707
===> Epoch[34](300/2500): Loss: 0.2663
===> Epoch[34](400/2500): Loss: 0.3112
===> Epoch[34](500/2500): Loss: 0.3026
===> Epoch[34](600/2500): Loss: 0.2814
===> Epoch[34](700/2500): Loss: 0.2833
===> Epoch[34](800/2500): Loss: 0.2549
===> Epoch[34](900/2500): Loss: 0.2715
===> Epoch[34](1000/2500): Loss: 0.2739
===> Epoch[34](1100/2500): Loss: 0.2790
===> Epoch[34](1200/2500): Loss: 0.2459
===> Epoch[34](1300/2500): Loss: 0.2822
===> Epoch[34](1400/2500): Loss: 0.2787
===> Epoch[34](1500/2500): Loss: 0.2836
===> Epoch[34](1600/2500): Loss: 0.2936
===> Epoch[34](1700/2500): Loss: 0.2658
===> Epoch[34](1800/2500): Loss: 0.2820
===> Epoch[34](1900/2500): Loss: 0.2703
===> Epoch[34](2000/2500): Loss: 0.2948
===> Epoch[34](2100/2500): Loss: 0.2753
===> Epoch[34](2200/2500): Loss: 0.3049
===> Epoch[34](2300/2500): Loss: 0.2978
===> Epoch[34](2400/2500): Loss: 0.2864
===> Epoch[34](2500/2500): Loss: 0.2864
===> Epoch 34 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:06:31]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2821
===> Epoch[34](200/2500): Loss: 0.2707
===> Epoch[34](300/2500): Loss: 0.2663
===> Epoch[34](400/2500): Loss: 0.3112
===> Epoch[34](500/2500): Loss: 0.3026
===> Epoch[34](600/2500): Loss: 0.2814
===> Epoch[34](700/2500): Loss: 0.2833
===> Epoch[34](800/2500): Loss: 0.2549
===> Epoch[34](900/2500): Loss: 0.2715
===> Epoch[34](1000/2500): Loss: 0.2739
===> Epoch[34](1100/2500): Loss: 0.2790
===> Epoch[34](1200/2500): Loss: 0.2459
===> Epoch[34](1300/2500): Loss: 0.2822
===> Epoch[34](1400/2500): Loss: 0.2787
===> Epoch[34](1500/2500): Loss: 0.2836
===> Epoch[34](1600/2500): Loss: 0.2936
===> Epoch[34](1700/2500): Loss: 0.2658
===> Epoch[34](1800/2500): Loss: 0.2820
===> Epoch[34](1900/2500): Loss: 0.2703
===> Epoch[34](2000/2500): Loss: 0.2948
===> Epoch[34](2100/2500): Loss: 0.2753
===> Epoch[34](2200/2500): Loss: 0.3049
===> Epoch[34](2300/2500): Loss: 0.2978
===> Epoch[34](2400/2500): Loss: 0.2864
===> Epoch[34](2500/2500): Loss: 0.2864
===> Epoch 34 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:06:31]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2821
===> Epoch[34](200/2500): Loss: 0.2707
===> Epoch[34](300/2500): Loss: 0.2663
===> Epoch[34](400/2500): Loss: 0.3112
===> Epoch[34](500/2500): Loss: 0.3026
===> Epoch[34](600/2500): Loss: 0.2814
===> Epoch[34](700/2500): Loss: 0.2833
===> Epoch[34](800/2500): Loss: 0.2549
===> Epoch[34](900/2500): Loss: 0.2715
===> Epoch[34](1000/2500): Loss: 0.2739
===> Epoch[34](1100/2500): Loss: 0.2790
===> Epoch[34](1200/2500): Loss: 0.2459
===> Epoch[34](1300/2500): Loss: 0.2822
===> Epoch[34](1400/2500): Loss: 0.2787
===> Epoch[34](1500/2500): Loss: 0.2836
===> Epoch[34](1600/2500): Loss: 0.2936
===> Epoch[34](1700/2500): Loss: 0.2658
===> Epoch[34](1800/2500): Loss: 0.2820
===> Epoch[34](1900/2500): Loss: 0.2703
===> Epoch[34](2000/2500): Loss: 0.2948
===> Epoch[34](2100/2500): Loss: 0.2753
===> Epoch[34](2200/2500): Loss: 0.3049
===> Epoch[34](2300/2500): Loss: 0.2978
===> Epoch[34](2400/2500): Loss: 0.2864
===> Epoch[34](2500/2500): Loss: 0.2864
===> Epoch 34 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:06:31]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2821
===> Epoch[34](200/2500): Loss: 0.2707
===> Epoch[34](300/2500): Loss: 0.2663
===> Epoch[34](400/2500): Loss: 0.3112
===> Epoch[34](500/2500): Loss: 0.3026
===> Epoch[34](600/2500): Loss: 0.2814
===> Epoch[34](700/2500): Loss: 0.2833
===> Epoch[34](800/2500): Loss: 0.2549
===> Epoch[34](900/2500): Loss: 0.2715
===> Epoch[34](1000/2500): Loss: 0.2739
===> Epoch[34](1100/2500): Loss: 0.2790
===> Epoch[34](1200/2500): Loss: 0.2459
===> Epoch[34](1300/2500): Loss: 0.2822
===> Epoch[34](1400/2500): Loss: 0.2787
===> Epoch[34](1500/2500): Loss: 0.2836
===> Epoch[34](1600/2500): Loss: 0.2936
===> Epoch[34](1700/2500): Loss: 0.2658
===> Epoch[34](1800/2500): Loss: 0.2820
===> Epoch[34](1900/2500): Loss: 0.2703
===> Epoch[34](2000/2500): Loss: 0.2948
===> Epoch[34](2100/2500): Loss: 0.2753
===> Epoch[34](2200/2500): Loss: 0.3049
===> Epoch[34](2300/2500): Loss: 0.2978
===> Epoch[34](2400/2500): Loss: 0.2864
===> Epoch[34](2500/2500): Loss: 0.2864
===> Epoch 34 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:06:31]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2821
===> Epoch[34](200/2500): Loss: 0.2707
===> Epoch[34](300/2500): Loss: 0.2663
===> Epoch[34](400/2500): Loss: 0.3112
===> Epoch[34](500/2500): Loss: 0.3026
===> Epoch[34](600/2500): Loss: 0.2814
===> Epoch[34](700/2500): Loss: 0.2833
===> Epoch[34](800/2500): Loss: 0.2549
===> Epoch[34](900/2500): Loss: 0.2715
===> Epoch[34](1000/2500): Loss: 0.2739
===> Epoch[34](1100/2500): Loss: 0.2790
===> Epoch[34](1200/2500): Loss: 0.2459
===> Epoch[34](1300/2500): Loss: 0.2822
===> Epoch[34](1400/2500): Loss: 0.2787
===> Epoch[34](1500/2500): Loss: 0.2836
===> Epoch[34](1600/2500): Loss: 0.2936
===> Epoch[34](1700/2500): Loss: 0.2658
===> Epoch[34](1800/2500): Loss: 0.2820
===> Epoch[34](1900/2500): Loss: 0.2703
===> Epoch[34](2000/2500): Loss: 0.2948
===> Epoch[34](2100/2500): Loss: 0.2753
===> Epoch[34](2200/2500): Loss: 0.3049
===> Epoch[34](2300/2500): Loss: 0.2978
===> Epoch[34](2400/2500): Loss: 0.2864
===> Epoch[34](2500/2500): Loss: 0.2864
===> Epoch 34 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:06:31]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2821
===> Epoch[34](200/2500): Loss: 0.2707
===> Epoch[34](300/2500): Loss: 0.2663
===> Epoch[34](400/2500): Loss: 0.3112
===> Epoch[34](500/2500): Loss: 0.3026
===> Epoch[34](600/2500): Loss: 0.2814
===> Epoch[34](700/2500): Loss: 0.2833
===> Epoch[34](800/2500): Loss: 0.2549
===> Epoch[34](900/2500): Loss: 0.2715
===> Epoch[34](1000/2500): Loss: 0.2739
===> Epoch[34](1100/2500): Loss: 0.2790
===> Epoch[34](1200/2500): Loss: 0.2459
===> Epoch[34](1300/2500): Loss: 0.2822
===> Epoch[34](1400/2500): Loss: 0.2787
===> Epoch[34](1500/2500): Loss: 0.2836
===> Epoch[34](1600/2500): Loss: 0.2936
===> Epoch[34](1700/2500): Loss: 0.2658
===> Epoch[34](1800/2500): Loss: 0.2820
===> Epoch[34](1900/2500): Loss: 0.2703
===> Epoch[34](2000/2500): Loss: 0.2948
===> Epoch[34](2100/2500): Loss: 0.2753
===> Epoch[34](2200/2500): Loss: 0.3049
===> Epoch[34](2300/2500): Loss: 0.2978
===> Epoch[34](2400/2500): Loss: 0.2864
===> Epoch[34](2500/2500): Loss: 0.2864
===> Epoch 34 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:06:31]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2821
===> Epoch[34](200/2500): Loss: 0.2707
===> Epoch[34](300/2500): Loss: 0.2663
===> Epoch[34](400/2500): Loss: 0.3112
===> Epoch[34](500/2500): Loss: 0.3026
===> Epoch[34](600/2500): Loss: 0.2814
===> Epoch[34](700/2500): Loss: 0.2833
===> Epoch[34](800/2500): Loss: 0.2549
===> Epoch[34](900/2500): Loss: 0.2715
===> Epoch[34](1000/2500): Loss: 0.2739
===> Epoch[34](1100/2500): Loss: 0.2790
===> Epoch[34](1200/2500): Loss: 0.2459
===> Epoch[34](1300/2500): Loss: 0.2822
===> Epoch[34](1400/2500): Loss: 0.2787
===> Epoch[34](1500/2500): Loss: 0.2836
===> Epoch[34](1600/2500): Loss: 0.2936
===> Epoch[34](1700/2500): Loss: 0.2658
===> Epoch[34](1800/2500): Loss: 0.2820
===> Epoch[34](1900/2500): Loss: 0.2703
===> Epoch[34](2000/2500): Loss: 0.2948
===> Epoch[34](2100/2500): Loss: 0.2753
===> Epoch[34](2200/2500): Loss: 0.3049
===> Epoch[34](2300/2500): Loss: 0.2978
===> Epoch[34](2400/2500): Loss: 0.2864
===> Epoch[34](2500/2500): Loss: 0.2864
===> Epoch 34 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:06:31]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.2821
===> Epoch[34](200/2500): Loss: 0.2707
===> Epoch[34](300/2500): Loss: 0.2663
===> Epoch[34](400/2500): Loss: 0.3112
===> Epoch[34](500/2500): Loss: 0.3026
===> Epoch[34](600/2500): Loss: 0.2814
===> Epoch[34](700/2500): Loss: 0.2833
===> Epoch[34](800/2500): Loss: 0.2549
===> Epoch[34](900/2500): Loss: 0.2715
===> Epoch[34](1000/2500): Loss: 0.2739
===> Epoch[34](1100/2500): Loss: 0.2790
===> Epoch[34](1200/2500): Loss: 0.2459
===> Epoch[34](1300/2500): Loss: 0.2822
===> Epoch[34](1400/2500): Loss: 0.2787
===> Epoch[34](1500/2500): Loss: 0.2836
===> Epoch[34](1600/2500): Loss: 0.2936
===> Epoch[34](1700/2500): Loss: 0.2658
===> Epoch[34](1800/2500): Loss: 0.2820
===> Epoch[34](1900/2500): Loss: 0.2703
===> Epoch[34](2000/2500): Loss: 0.2948
===> Epoch[34](2100/2500): Loss: 0.2753
===> Epoch[34](2200/2500): Loss: 0.3049
===> Epoch[34](2300/2500): Loss: 0.2978
===> Epoch[34](2400/2500): Loss: 0.2864
===> Epoch[34](2500/2500): Loss: 0.2864
===> Epoch 34 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:06:31]
===> Loading train datasets
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.2744
===> Epoch[35](200/2500): Loss: 0.2818
===> Epoch[35](300/2500): Loss: 0.2863
===> Epoch[35](400/2500): Loss: 0.2985
===> Epoch[35](500/2500): Loss: 0.2697
===> Epoch[35](600/2500): Loss: 0.3102
===> Epoch[35](700/2500): Loss: 0.2698
===> Epoch[35](800/2500): Loss: 0.2935
===> Epoch[35](900/2500): Loss: 0.2905
===> Epoch[35](1000/2500): Loss: 0.2864
===> Epoch[35](1100/2500): Loss: 0.2861
===> Epoch[35](1200/2500): Loss: 0.2738
===> Epoch[35](1300/2500): Loss: 0.2617
===> Epoch[35](1400/2500): Loss: 0.2862
===> Epoch[35](1500/2500): Loss: 0.2710
===> Epoch[35](1600/2500): Loss: 0.2746
===> Epoch[35](1700/2500): Loss: 0.2657
===> Epoch[35](1800/2500): Loss: 0.2706
===> Epoch[35](1900/2500): Loss: 0.2863
===> Epoch[35](2000/2500): Loss: 0.2986
===> Epoch[35](2100/2500): Loss: 0.2745
===> Epoch[35](2200/2500): Loss: 0.2744
===> Epoch[35](2300/2500): Loss: 0.2866
===> Epoch[35](2400/2500): Loss: 0.2587
===> Epoch[35](2500/2500): Loss: 0.2861
===> Epoch 35 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:11:05]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.2789
===> Epoch[36](200/2500): Loss: 0.2938
===> Epoch[36](300/2500): Loss: 0.2697
===> Epoch[36](400/2500): Loss: 0.2937
===> Epoch[36](500/2500): Loss: 0.2864
===> Epoch[36](600/2500): Loss: 0.2785
===> Epoch[36](700/2500): Loss: 0.2579
===> Epoch[36](800/2500): Loss: 0.2783
===> Epoch[36](900/2500): Loss: 0.2984
===> Epoch[36](1000/2500): Loss: 0.2713
===> Epoch[36](1100/2500): Loss: 0.2909
===> Epoch[36](1200/2500): Loss: 0.3148
===> Epoch[36](1300/2500): Loss: 0.2911
===> Epoch[36](1400/2500): Loss: 0.2713
===> Epoch[36](1500/2500): Loss: 0.2952
===> Epoch[36](1600/2500): Loss: 0.2700
===> Epoch[36](1700/2500): Loss: 0.2580
===> Epoch[36](1800/2500): Loss: 0.2617
===> Epoch[36](1900/2500): Loss: 0.2864
===> Epoch[36](2000/2500): Loss: 0.2986
===> Epoch[36](2100/2500): Loss: 0.2866
===> Epoch[36](2200/2500): Loss: 0.2816
===> Epoch[36](2300/2500): Loss: 0.2649
===> Epoch[36](2400/2500): Loss: 0.2958
===> Epoch[36](2500/2500): Loss: 0.2672
===> Epoch 36 Complete: Avg. Loss: 0.2852
===> Timestamp: [2025-08-03 22:15:39]
===> Loading train datasets
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.2822
===> Epoch[37](200/2500): Loss: 0.2782
===> Epoch[37](300/2500): Loss: 0.2741
===> Epoch[37](400/2500): Loss: 0.2784
===> Epoch[37](500/2500): Loss: 0.2909
===> Epoch[37](600/2500): Loss: 0.2906
===> Epoch[37](700/2500): Loss: 0.2744
===> Epoch[37](800/2500): Loss: 0.2738
===> Epoch[37](900/2500): Loss: 0.3221
===> Epoch[37](1000/2500): Loss: 0.2761
===> Epoch[37](1100/2500): Loss: 0.2788
===> Epoch[37](1200/2500): Loss: 0.2911
===> Epoch[37](1300/2500): Loss: 0.2903
===> Epoch[37](1400/2500): Loss: 0.2983
===> Epoch[37](1500/2500): Loss: 0.2903
===> Epoch[37](1600/2500): Loss: 0.2774
===> Epoch[37](1700/2500): Loss: 0.2791
===> Epoch[37](1800/2500): Loss: 0.2909
===> Epoch[37](1900/2500): Loss: 0.3028
===> Epoch[37](2000/2500): Loss: 0.2937
===> Epoch[37](2100/2500): Loss: 0.2754
===> Epoch[37](2200/2500): Loss: 0.2655
===> Epoch[37](2300/2500): Loss: 0.2671
===> Epoch[37](2400/2500): Loss: 0.2784
===> Epoch[37](2500/2500): Loss: 0.2702
===> Epoch 37 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:20:17]
===> Loading train datasets
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.2741
===> Epoch[38](200/2500): Loss: 0.2816
===> Epoch[38](300/2500): Loss: 0.2780
===> Epoch[38](400/2500): Loss: 0.2862
===> Epoch[38](500/2500): Loss: 0.2640
===> Epoch[38](600/2500): Loss: 0.2741
===> Epoch[38](700/2500): Loss: 0.2693
===> Epoch[38](800/2500): Loss: 0.2801
===> Epoch[38](900/2500): Loss: 0.2858
===> Epoch[38](1000/2500): Loss: 0.2861
===> Epoch[38](1100/2500): Loss: 0.2984
===> Epoch[38](1200/2500): Loss: 0.2661
===> Epoch[38](1300/2500): Loss: 0.2940
===> Epoch[38](1400/2500): Loss: 0.2620
===> Epoch[38](1500/2500): Loss: 0.2906
===> Epoch[38](1600/2500): Loss: 0.2908
===> Epoch[38](1700/2500): Loss: 0.2831
===> Epoch[38](1800/2500): Loss: 0.2550
===> Epoch[38](1900/2500): Loss: 0.2790
===> Epoch[38](2000/2500): Loss: 0.3026
===> Epoch[38](2100/2500): Loss: 0.3135
===> Epoch[38](2200/2500): Loss: 0.2937
===> Epoch[38](2300/2500): Loss: 0.2669
===> Epoch[38](2400/2500): Loss: 0.2979
===> Epoch[38](2500/2500): Loss: 0.2991
===> Epoch 38 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:24:51]
===> Loading train datasets
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.2816
===> Epoch[39](200/2500): Loss: 0.2860
===> Epoch[39](300/2500): Loss: 0.3020
===> Epoch[39](400/2500): Loss: 0.2831
===> Epoch[39](500/2500): Loss: 0.2863
===> Epoch[39](600/2500): Loss: 0.2817
===> Epoch[39](700/2500): Loss: 0.2913
===> Epoch[39](800/2500): Loss: 0.2936
===> Epoch[39](900/2500): Loss: 0.2861
===> Epoch[39](1000/2500): Loss: 0.2627
===> Epoch[39](1100/2500): Loss: 0.3217
===> Epoch[39](1200/2500): Loss: 0.2759
===> Epoch[39](1300/2500): Loss: 0.2787
===> Epoch[39](1400/2500): Loss: 0.2868
===> Epoch[39](1500/2500): Loss: 0.2856
===> Epoch[39](1600/2500): Loss: 0.2794
===> Epoch[39](1700/2500): Loss: 0.2836
===> Epoch[39](1800/2500): Loss: 0.2836
===> Epoch[39](1900/2500): Loss: 0.2892
===> Epoch[39](2000/2500): Loss: 0.2661
===> Epoch[39](2100/2500): Loss: 0.3055
===> Epoch[39](2200/2500): Loss: 0.3030
===> Epoch[39](2300/2500): Loss: 0.2737
===> Epoch[39](2400/2500): Loss: 0.2937
===> Epoch[39](2500/2500): Loss: 0.2740
===> Epoch 39 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:29:25]
===> Loading train datasets
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.2865
===> Epoch[40](200/2500): Loss: 0.2925
===> Epoch[40](300/2500): Loss: 0.2987
===> Epoch[40](400/2500): Loss: 0.2861
===> Epoch[40](500/2500): Loss: 0.2904
===> Epoch[40](600/2500): Loss: 0.2860
===> Epoch[40](700/2500): Loss: 0.2934
===> Epoch[40](800/2500): Loss: 0.2581
===> Epoch[40](900/2500): Loss: 0.2820
===> Epoch[40](1000/2500): Loss: 0.2740
===> Epoch[40](1100/2500): Loss: 0.2716
===> Epoch[40](1200/2500): Loss: 0.2738
===> Epoch[40](1300/2500): Loss: 0.3070
===> Epoch[40](1400/2500): Loss: 0.2673
===> Epoch[40](1500/2500): Loss: 0.2903
===> Epoch[40](1600/2500): Loss: 0.3098
===> Epoch[40](1700/2500): Loss: 0.2619
===> Epoch[40](1800/2500): Loss: 0.2936
===> Epoch[40](1900/2500): Loss: 0.2706
===> Epoch[40](2000/2500): Loss: 0.2825
===> Epoch[40](2100/2500): Loss: 0.2875
===> Epoch[40](2200/2500): Loss: 0.2710
===> Epoch[40](2300/2500): Loss: 0.2979
===> Epoch[40](2400/2500): Loss: 0.2900
===> Epoch[40](2500/2500): Loss: 0.2832
===> Epoch 40 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:33:59]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.2981
===> Epoch[41](200/2500): Loss: 0.2623
===> Epoch[41](300/2500): Loss: 0.2671
===> Epoch[41](400/2500): Loss: 0.3024
===> Epoch[41](500/2500): Loss: 0.2793
===> Epoch[41](600/2500): Loss: 0.2860
===> Epoch[41](700/2500): Loss: 0.2948
===> Epoch[41](800/2500): Loss: 0.2820
===> Epoch[41](900/2500): Loss: 0.3025
===> Epoch[41](1000/2500): Loss: 0.2865
===> Epoch[41](1100/2500): Loss: 0.2861
===> Epoch[41](1200/2500): Loss: 0.2876
===> Epoch[41](1300/2500): Loss: 0.2715
===> Epoch[41](1400/2500): Loss: 0.2978
===> Epoch[41](1500/2500): Loss: 0.2823
===> Epoch[41](1600/2500): Loss: 0.3095
===> Epoch[41](1700/2500): Loss: 0.2897
===> Epoch[41](1800/2500): Loss: 0.2735
===> Epoch[41](1900/2500): Loss: 0.2945
===> Epoch[41](2000/2500): Loss: 0.3056
===> Epoch[41](2100/2500): Loss: 0.2754
===> Epoch[41](2200/2500): Loss: 0.2980
===> Epoch[41](2300/2500): Loss: 0.2982
===> Epoch[41](2400/2500): Loss: 0.2979
===> Epoch[41](2500/2500): Loss: 0.2741
===> Epoch 41 Complete: Avg. Loss: 0.2851
===> Timestamp: [2025-08-03 22:38:33]
===> Loading train datasets
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.3029
===> Epoch[42](200/2500): Loss: 0.3178
===> Epoch[42](300/2500): Loss: 0.2621
===> Epoch[42](400/2500): Loss: 0.3026
===> Epoch[42](500/2500): Loss: 0.2860
===> Epoch[42](600/2500): Loss: 0.2938
===> Epoch[42](700/2500): Loss: 0.2910
===> Epoch[42](800/2500): Loss: 0.2817
===> Epoch[42](900/2500): Loss: 0.2973
===> Epoch[42](1000/2500): Loss: 0.2977
===> Epoch[42](1100/2500): Loss: 0.2699
===> Epoch[42](1200/2500): Loss: 0.3053
===> Epoch[42](1300/2500): Loss: 0.2853
===> Epoch[42](1400/2500): Loss: 0.2779
===> Epoch[42](1500/2500): Loss: 0.2664
===> Epoch[42](1600/2500): Loss: 0.2709
===> Epoch[42](1700/2500): Loss: 0.3024
===> Epoch[42](1800/2500): Loss: 0.2859
===> Epoch[42](1900/2500): Loss: 0.2778
===> Epoch[42](2000/2500): Loss: 0.2711
===> Epoch[42](2100/2500): Loss: 0.2941
===> Epoch[42](2200/2500): Loss: 0.2733
===> Epoch[42](2300/2500): Loss: 0.2855
===> Epoch[42](2400/2500): Loss: 0.2970
===> Epoch[42](2500/2500): Loss: 0.3170
===> Epoch 42 Complete: Avg. Loss: 0.2847
===> Timestamp: [2025-08-03 22:43:07]
===> Loading train datasets
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.2980
===> Epoch[43](200/2500): Loss: 0.2858
===> Epoch[43](300/2500): Loss: 0.2693
===> Epoch[43](400/2500): Loss: 0.2859
===> Epoch[43](500/2500): Loss: 0.2855
===> Epoch[43](600/2500): Loss: 0.3091
===> Epoch[43](700/2500): Loss: 0.2745
===> Epoch[43](800/2500): Loss: 0.2824
===> Epoch[43](900/2500): Loss: 0.2661
===> Epoch[43](1000/2500): Loss: 0.2969
===> Epoch[43](1100/2500): Loss: 0.2807
===> Epoch[43](1200/2500): Loss: 0.3137
===> Epoch[43](1300/2500): Loss: 0.2739
===> Epoch[43](1400/2500): Loss: 0.2736
===> Epoch[43](1500/2500): Loss: 0.2821
===> Epoch[43](1600/2500): Loss: 0.2826
===> Epoch[43](1700/2500): Loss: 0.3057
===> Epoch[43](1800/2500): Loss: 0.2869
===> Epoch[43](1900/2500): Loss: 0.2900
===> Epoch[43](2000/2500): Loss: 0.2778
===> Epoch[43](2100/2500): Loss: 0.3095
===> Epoch[43](2200/2500): Loss: 0.2967
===> Epoch[43](2300/2500): Loss: 0.2609
===> Epoch[43](2400/2500): Loss: 0.2735
===> Epoch[43](2500/2500): Loss: 0.2944
===> Epoch 43 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:47:41]
===> Loading train datasets
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.2924
===> Epoch[44](200/2500): Loss: 0.2781
===> Epoch[44](300/2500): Loss: 0.2852
===> Epoch[44](400/2500): Loss: 0.2858
===> Epoch[44](500/2500): Loss: 0.3069
===> Epoch[44](600/2500): Loss: 0.2784
===> Epoch[44](700/2500): Loss: 0.2783
===> Epoch[44](800/2500): Loss: 0.2928
===> Epoch[44](900/2500): Loss: 0.2977
===> Epoch[44](1000/2500): Loss: 0.2815
===> Epoch[44](1100/2500): Loss: 0.2617
===> Epoch[44](1200/2500): Loss: 0.2783
===> Epoch[44](1300/2500): Loss: 0.2930
===> Epoch[44](1400/2500): Loss: 0.2776
===> Epoch[44](1500/2500): Loss: 0.2885
===> Epoch[44](1600/2500): Loss: 0.2850
===> Epoch[44](1700/2500): Loss: 0.2670
===> Epoch[44](1800/2500): Loss: 0.2653
===> Epoch[44](1900/2500): Loss: 0.2710
===> Epoch[44](2000/2500): Loss: 0.2774
===> Epoch[44](2100/2500): Loss: 0.2573
===> Epoch[44](2200/2500): Loss: 0.2930
===> Epoch[44](2300/2500): Loss: 0.2857
===> Epoch[44](2400/2500): Loss: 0.2689
===> Epoch[44](2500/2500): Loss: 0.2834
===> Epoch 44 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:52:14]
===> Loading train datasets
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.2867
===> Epoch[45](200/2500): Loss: 0.2775
===> Epoch[45](300/2500): Loss: 0.2824
===> Epoch[45](400/2500): Loss: 0.2660
===> Epoch[45](500/2500): Loss: 0.2587
===> Epoch[45](600/2500): Loss: 0.2784
===> Epoch[45](700/2500): Loss: 0.3060
===> Epoch[45](800/2500): Loss: 0.2774
===> Epoch[45](900/2500): Loss: 0.2856
===> Epoch[45](1000/2500): Loss: 0.3016
===> Epoch[45](1100/2500): Loss: 0.2951
===> Epoch[45](1200/2500): Loss: 0.2687
===> Epoch[45](1300/2500): Loss: 0.2570
===> Epoch[45](1400/2500): Loss: 0.2669
===> Epoch[45](1500/2500): Loss: 0.2925
===> Epoch[45](1600/2500): Loss: 0.2692
===> Epoch[45](1700/2500): Loss: 0.2737
===> Epoch[45](1800/2500): Loss: 0.2851
===> Epoch[45](1900/2500): Loss: 0.3091
===> Epoch[45](2000/2500): Loss: 0.2618
===> Epoch[45](2100/2500): Loss: 0.2825
===> Epoch[45](2200/2500): Loss: 0.2782
===> Epoch[45](2300/2500): Loss: 0.2972
===> Epoch[45](2400/2500): Loss: 0.2974
===> Epoch[45](2500/2500): Loss: 0.2811
===> Epoch 45 Complete: Avg. Loss: 0.2844
===> Timestamp: [2025-08-03 22:56:48]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.2867
===> Epoch[46](200/2500): Loss: 0.2989
===> Epoch[46](300/2500): Loss: 0.3005
===> Epoch[46](400/2500): Loss: 0.2660
===> Epoch[46](500/2500): Loss: 0.2583
===> Epoch[46](600/2500): Loss: 0.2821
===> Epoch[46](700/2500): Loss: 0.2698
===> Epoch[46](800/2500): Loss: 0.2899
===> Epoch[46](900/2500): Loss: 0.3089
===> Epoch[46](1000/2500): Loss: 0.2825
===> Epoch[46](1100/2500): Loss: 0.2659
===> Epoch[46](1200/2500): Loss: 0.2887
===> Epoch[46](1300/2500): Loss: 0.2808
===> Epoch[46](1400/2500): Loss: 0.2811
===> Epoch[46](1500/2500): Loss: 0.2612
===> Epoch[46](1600/2500): Loss: 0.2821
===> Epoch[46](1700/2500): Loss: 0.2737
===> Epoch[46](1800/2500): Loss: 0.2925
===> Epoch[46](1900/2500): Loss: 0.2540
===> Epoch[46](2000/2500): Loss: 0.2644
===> Epoch[46](2100/2500): Loss: 0.2776
===> Epoch[46](2200/2500): Loss: 0.2854
===> Epoch[46](2300/2500): Loss: 0.2975
===> Epoch[46](2400/2500): Loss: 0.2943
===> Epoch[46](2500/2500): Loss: 0.2727
===> Epoch 46 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:01:22]
===> Loading train datasets
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.2707
===> Epoch[47](200/2500): Loss: 0.2884
===> Epoch[47](300/2500): Loss: 0.3217
===> Epoch[47](400/2500): Loss: 0.3094
===> Epoch[47](500/2500): Loss: 0.2857
===> Epoch[47](600/2500): Loss: 0.2976
===> Epoch[47](700/2500): Loss: 0.2653
===> Epoch[47](800/2500): Loss: 0.2938
===> Epoch[47](900/2500): Loss: 0.2498
===> Epoch[47](1000/2500): Loss: 0.2816
===> Epoch[47](1100/2500): Loss: 0.2853
===> Epoch[47](1200/2500): Loss: 0.2764
===> Epoch[47](1300/2500): Loss: 0.2856
===> Epoch[47](1400/2500): Loss: 0.2780
===> Epoch[47](1500/2500): Loss: 0.2810
===> Epoch[47](1600/2500): Loss: 0.2852
===> Epoch[47](1700/2500): Loss: 0.2665
===> Epoch[47](1800/2500): Loss: 0.2665
===> Epoch[47](1900/2500): Loss: 0.3010
===> Epoch[47](2000/2500): Loss: 0.2855
===> Epoch[47](2100/2500): Loss: 0.2783
===> Epoch[47](2200/2500): Loss: 0.2567
===> Epoch[47](2300/2500): Loss: 0.2903
===> Epoch[47](2400/2500): Loss: 0.3084
===> Epoch[47](2500/2500): Loss: 0.3012
===> Epoch 47 Complete: Avg. Loss: 0.2843
===> Timestamp: [2025-08-03 23:05:56]
===> Loading train datasets
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.2897
===> Epoch[48](200/2500): Loss: 0.3162
===> Epoch[48](300/2500): Loss: 0.2973
===> Epoch[48](400/2500): Loss: 0.3000
===> Epoch[48](500/2500): Loss: 0.2976
===> Epoch[48](600/2500): Loss: 0.2899
===> Epoch[48](700/2500): Loss: 0.2902
===> Epoch[48](800/2500): Loss: 0.2773
===> Epoch[48](900/2500): Loss: 0.2681
===> Epoch[48](1000/2500): Loss: 0.2974
===> Epoch[48](1100/2500): Loss: 0.2890
===> Epoch[48](1200/2500): Loss: 0.2790
===> Epoch[48](1300/2500): Loss: 0.2961
===> Epoch[48](1400/2500): Loss: 0.2858
===> Epoch[48](1500/2500): Loss: 0.2718
===> Epoch[48](1600/2500): Loss: 0.2930
===> Epoch[48](1700/2500): Loss: 0.2931
===> Epoch[48](1800/2500): Loss: 0.2696
===> Epoch[48](1900/2500): Loss: 0.2676
===> Epoch[48](2000/2500): Loss: 0.2643
===> Epoch[48](2100/2500): Loss: 0.2676
===> Epoch[48](2200/2500): Loss: 0.2646
===> Epoch[48](2300/2500): Loss: 0.2887
===> Epoch[48](2400/2500): Loss: 0.2802
===> Epoch[48](2500/2500): Loss: 0.2681
===> Epoch 48 Complete: Avg. Loss: 0.2835
===> Timestamp: [2025-08-03 23:10:30]
===> Loading train datasets
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.2681
===> Epoch[49](200/2500): Loss: 0.2931
===> Epoch[49](300/2500): Loss: 0.2933
===> Epoch[49](400/2500): Loss: 0.2751
===> Epoch[49](500/2500): Loss: 0.2802
===> Epoch[49](600/2500): Loss: 0.2953
===> Epoch[49](700/2500): Loss: 0.2962
===> Epoch[49](800/2500): Loss: 0.2770
===> Epoch[49](900/2500): Loss: 0.2882
===> Epoch[49](1000/2500): Loss: 0.2691
===> Epoch[49](1100/2500): Loss: 0.2809
===> Epoch[49](1200/2500): Loss: 0.2717
===> Epoch[49](1300/2500): Loss: 0.2768
===> Epoch[49](1400/2500): Loss: 0.2676
===> Epoch[49](1500/2500): Loss: 0.2885
===> Epoch[49](1600/2500): Loss: 0.3036
===> Epoch[49](1700/2500): Loss: 0.2726
===> Epoch[49](1800/2500): Loss: 0.2876
===> Epoch[49](1900/2500): Loss: 0.2721
===> Epoch[49](2000/2500): Loss: 0.2959
===> Epoch[49](2100/2500): Loss: 0.2836
===> Epoch[49](2200/2500): Loss: 0.2955
===> Epoch[49](2300/2500): Loss: 0.3080
===> Epoch[49](2400/2500): Loss: 0.2975
===> Epoch[49](2500/2500): Loss: 0.2563
===> Epoch 49 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:15:04]
===> Loading train datasets
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.2848
===> Epoch[50](200/2500): Loss: 0.2885
===> Epoch[50](300/2500): Loss: 0.2717
===> Epoch[50](400/2500): Loss: 0.2884
===> Epoch[50](500/2500): Loss: 0.2790
===> Epoch[50](600/2500): Loss: 0.2696
===> Epoch[50](700/2500): Loss: 0.2690
===> Epoch[50](800/2500): Loss: 0.2765
===> Epoch[50](900/2500): Loss: 0.3074
===> Epoch[50](1000/2500): Loss: 0.2766
===> Epoch[50](1100/2500): Loss: 0.2961
===> Epoch[50](1200/2500): Loss: 0.2911
===> Epoch[50](1300/2500): Loss: 0.2721
===> Epoch[50](1400/2500): Loss: 0.2833
===> Epoch[50](1500/2500): Loss: 0.2676
===> Epoch[50](1600/2500): Loss: 0.2926
===> Epoch[50](1700/2500): Loss: 0.2725
===> Epoch[50](1800/2500): Loss: 0.2764
===> Epoch[50](1900/2500): Loss: 0.2846
===> Epoch[50](2000/2500): Loss: 0.2903
===> Epoch[50](2100/2500): Loss: 0.2927
===> Epoch[50](2200/2500): Loss: 0.2650
===> Epoch[50](2300/2500): Loss: 0.2811
===> Epoch[50](2400/2500): Loss: 0.2846
===> Epoch[50](2500/2500): Loss: 0.2800
===> Epoch 50 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:19:38]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.2964
===> Epoch[51](200/2500): Loss: 0.2766
===> Epoch[51](300/2500): Loss: 0.2967
===> Epoch[51](400/2500): Loss: 0.2910
===> Epoch[51](500/2500): Loss: 0.2658
===> Epoch[51](600/2500): Loss: 0.3078
===> Epoch[51](700/2500): Loss: 0.2880
===> Epoch[51](800/2500): Loss: 0.2727
===> Epoch[51](900/2500): Loss: 0.2841
===> Epoch[51](1000/2500): Loss: 0.2939
===> Epoch[51](1100/2500): Loss: 0.2773
===> Epoch[51](1200/2500): Loss: 0.2808
===> Epoch[51](1300/2500): Loss: 0.2762
===> Epoch[51](1400/2500): Loss: 0.2715
===> Epoch[51](1500/2500): Loss: 0.2693
===> Epoch[51](1600/2500): Loss: 0.2725
===> Epoch[51](1700/2500): Loss: 0.3039
===> Epoch[51](1800/2500): Loss: 0.3152
===> Epoch[51](1900/2500): Loss: 0.2891
===> Epoch[51](2000/2500): Loss: 0.2607
===> Epoch[51](2100/2500): Loss: 0.2798
===> Epoch[51](2200/2500): Loss: 0.2846
===> Epoch[51](2300/2500): Loss: 0.3035
===> Epoch[51](2400/2500): Loss: 0.2768
===> Epoch[51](2500/2500): Loss: 0.2638
===> Epoch 51 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:24:12]
===> Loading train datasets
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.2918
===> Epoch[52](200/2500): Loss: 0.2839
===> Epoch[52](300/2500): Loss: 0.2977
===> Epoch[52](400/2500): Loss: 0.2557
===> Epoch[52](500/2500): Loss: 0.2809
===> Epoch[52](600/2500): Loss: 0.2771
===> Epoch[52](700/2500): Loss: 0.2688
===> Epoch[52](800/2500): Loss: 0.2769
===> Epoch[52](900/2500): Loss: 0.2510
===> Epoch[52](1000/2500): Loss: 0.2629
===> Epoch[52](1100/2500): Loss: 0.2643
===> Epoch[52](1200/2500): Loss: 0.2860
===> Epoch[52](1300/2500): Loss: 0.2839
===> Epoch[52](1400/2500): Loss: 0.3278
===> Epoch[52](1500/2500): Loss: 0.2961
===> Epoch[52](1600/2500): Loss: 0.2936
===> Epoch[52](1700/2500): Loss: 0.3036
===> Epoch[52](1800/2500): Loss: 0.2892
===> Epoch[52](1900/2500): Loss: 0.2887
===> Epoch[52](2000/2500): Loss: 0.3086
===> Epoch[52](2100/2500): Loss: 0.2736
===> Epoch[52](2200/2500): Loss: 0.2919
===> Epoch[52](2300/2500): Loss: 0.2800
===> Epoch[52](2400/2500): Loss: 0.2844
===> Epoch[52](2500/2500): Loss: 0.2574
===> Epoch 52 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:28:46]
===> Loading train datasets
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.3201
===> Epoch[53](200/2500): Loss: 0.2842
===> Epoch[53](300/2500): Loss: 0.2782
===> Epoch[53](400/2500): Loss: 0.2650
===> Epoch[53](500/2500): Loss: 0.2844
===> Epoch[53](600/2500): Loss: 0.2839
===> Epoch[53](700/2500): Loss: 0.2733
===> Epoch[53](800/2500): Loss: 0.2885
===> Epoch[53](900/2500): Loss: 0.2621
===> Epoch[53](1000/2500): Loss: 0.2722
===> Epoch[53](1100/2500): Loss: 0.2959
===> Epoch[53](1200/2500): Loss: 0.2641
===> Epoch[53](1300/2500): Loss: 0.3074
===> Epoch[53](1400/2500): Loss: 0.2884
===> Epoch[53](1500/2500): Loss: 0.2723
===> Epoch[53](1600/2500): Loss: 0.2935
===> Epoch[53](1700/2500): Loss: 0.2844
===> Epoch[53](1800/2500): Loss: 0.2676
===> Epoch[53](1900/2500): Loss: 0.2558
===> Epoch[53](2000/2500): Loss: 0.2962
===> Epoch[53](2100/2500): Loss: 0.2964
===> Epoch[53](2200/2500): Loss: 0.2908
===> Epoch[53](2300/2500): Loss: 0.2604
===> Epoch[53](2400/2500): Loss: 0.3078
===> Epoch[53](2500/2500): Loss: 0.2839
===> Epoch 53 Complete: Avg. Loss: 0.2831
===> Timestamp: [2025-08-03 23:33:20]
===> Loading train datasets
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.2806
===> Epoch[54](200/2500): Loss: 0.2914
===> Epoch[54](300/2500): Loss: 0.2764
===> Epoch[54](400/2500): Loss: 0.2844
===> Epoch[54](500/2500): Loss: 0.2604
===> Epoch[54](600/2500): Loss: 0.2739
===> Epoch[54](700/2500): Loss: 0.2768
===> Epoch[54](800/2500): Loss: 0.2769
===> Epoch[54](900/2500): Loss: 0.2930
===> Epoch[54](1000/2500): Loss: 0.2599
===> Epoch[54](1100/2500): Loss: 0.2617
===> Epoch[54](1200/2500): Loss: 0.3034
===> Epoch[54](1300/2500): Loss: 0.2880
===> Epoch[54](1400/2500): Loss: 0.3003
===> Epoch[54](1500/2500): Loss: 0.2880
===> Epoch[54](1600/2500): Loss: 0.2855
===> Epoch[54](1700/2500): Loss: 0.2717
===> Epoch[54](1800/2500): Loss: 0.2916
===> Epoch[54](1900/2500): Loss: 0.2758
===> Epoch[54](2000/2500): Loss: 0.2953
===> Epoch[54](2100/2500): Loss: 0.2842
===> Epoch[54](2200/2500): Loss: 0.3194
===> Epoch[54](2300/2500): Loss: 0.2758
===> Epoch[54](2400/2500): Loss: 0.2957
===> Epoch[54](2500/2500): Loss: 0.2910
===> Epoch 54 Complete: Avg. Loss: 0.2830
===> Timestamp: [2025-08-03 23:37:54]
===> Loading train datasets
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.2913
===> Epoch[55](200/2500): Loss: 0.2872
===> Epoch[55](300/2500): Loss: 0.3029
===> Epoch[55](400/2500): Loss: 0.2928
===> Epoch[55](500/2500): Loss: 0.3118
===> Epoch[55](600/2500): Loss: 0.2887
===> Epoch[55](700/2500): Loss: 0.2923
===> Epoch[55](800/2500): Loss: 0.2721
===> Epoch[55](900/2500): Loss: 0.2845
===> Epoch[55](1000/2500): Loss: 0.2887
===> Epoch[55](1100/2500): Loss: 0.2961
===> Epoch[55](1200/2500): Loss: 0.2994
===> Epoch[55](1300/2500): Loss: 0.2885
===> Epoch[55](1400/2500): Loss: 0.2908
===> Epoch[55](1500/2500): Loss: 0.3004
===> Epoch[55](1600/2500): Loss: 0.2676
===> Epoch[55](1700/2500): Loss: 0.2963
===> Epoch[55](1800/2500): Loss: 0.2667
===> Epoch[55](1900/2500): Loss: 0.2716
===> Epoch[55](2000/2500): Loss: 0.2958
===> Epoch[55](2100/2500): Loss: 0.3005
===> Epoch[55](2200/2500): Loss: 0.2889
===> Epoch[55](2300/2500): Loss: 0.2734
===> Epoch[55](2400/2500): Loss: 0.2569
===> Epoch[55](2500/2500): Loss: 0.3024
===> Epoch 55 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:42:28]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.2737
===> Epoch[56](200/2500): Loss: 0.2835
===> Epoch[56](300/2500): Loss: 0.2962
===> Epoch[56](400/2500): Loss: 0.2529
===> Epoch[56](500/2500): Loss: 0.2800
===> Epoch[56](600/2500): Loss: 0.2909
===> Epoch[56](700/2500): Loss: 0.3002
===> Epoch[56](800/2500): Loss: 0.2813
===> Epoch[56](900/2500): Loss: 0.3120
===> Epoch[56](1000/2500): Loss: 0.2888
===> Epoch[56](1100/2500): Loss: 0.2719
===> Epoch[56](1200/2500): Loss: 0.2789
===> Epoch[56](1300/2500): Loss: 0.2646
===> Epoch[56](1400/2500): Loss: 0.2991
===> Epoch[56](1500/2500): Loss: 0.2807
===> Epoch[56](1600/2500): Loss: 0.2925
===> Epoch[56](1700/2500): Loss: 0.2919
===> Epoch[56](1800/2500): Loss: 0.2956
===> Epoch[56](1900/2500): Loss: 0.3071
===> Epoch[56](2000/2500): Loss: 0.2857
===> Epoch[56](2100/2500): Loss: 0.2780
===> Epoch[56](2200/2500): Loss: 0.2928
===> Epoch[56](2300/2500): Loss: 0.2951
===> Epoch[56](2400/2500): Loss: 0.2889
===> Epoch[56](2500/2500): Loss: 0.3004
===> Epoch 56 Complete: Avg. Loss: 0.2829
===> Timestamp: [2025-08-03 23:47:03]
===> Loading train datasets
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.3153
===> Epoch[57](200/2500): Loss: 0.2986
===> Epoch[57](300/2500): Loss: 0.2640
===> Epoch[57](400/2500): Loss: 0.2764
===> Epoch[57](500/2500): Loss: 0.2927
===> Epoch[57](600/2500): Loss: 0.2913
===> Epoch[57](700/2500): Loss: 0.2842
===> Epoch[57](800/2500): Loss: 0.2883
===> Epoch[57](900/2500): Loss: 0.2553
===> Epoch[57](1000/2500): Loss: 0.2930
===> Epoch[57](1100/2500): Loss: 0.3023
===> Epoch[57](1200/2500): Loss: 0.2880
===> Epoch[57](1300/2500): Loss: 0.2841
===> Epoch[57](1400/2500): Loss: 0.2741
===> Epoch[57](1500/2500): Loss: 0.2838
===> Epoch[57](1600/2500): Loss: 0.3045
===> Epoch[57](1700/2500): Loss: 0.2837
===> Epoch[57](1800/2500): Loss: 0.2859
===> Epoch[57](1900/2500): Loss: 0.2836
===> Epoch[57](2000/2500): Loss: 0.3003
===> Epoch[57](2100/2500): Loss: 0.2881
===> Epoch[57](2200/2500): Loss: 0.2598
===> Epoch[57](2300/2500): Loss: 0.2767
===> Epoch[57](2400/2500): Loss: 0.3038
===> Epoch[57](2500/2500): Loss: 0.2765
===> Epoch 57 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:51:37]
===> Loading train datasets
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.2559
===> Epoch[58](200/2500): Loss: 0.2758
===> Epoch[58](300/2500): Loss: 0.2793
===> Epoch[58](400/2500): Loss: 0.2916
===> Epoch[58](500/2500): Loss: 0.2721
===> Epoch[58](600/2500): Loss: 0.2880
===> Epoch[58](700/2500): Loss: 0.2765
===> Epoch[58](800/2500): Loss: 0.2887
===> Epoch[58](900/2500): Loss: 0.2764
===> Epoch[58](1000/2500): Loss: 0.3029
===> Epoch[58](1100/2500): Loss: 0.2570
===> Epoch[58](1200/2500): Loss: 0.2692
===> Epoch[58](1300/2500): Loss: 0.3025
===> Epoch[58](1400/2500): Loss: 0.2690
===> Epoch[58](1500/2500): Loss: 0.2840
===> Epoch[58](1600/2500): Loss: 0.3119
===> Epoch[58](1700/2500): Loss: 0.2760
===> Epoch[58](1800/2500): Loss: 0.2752
===> Epoch[58](1900/2500): Loss: 0.2678
===> Epoch[58](2000/2500): Loss: 0.2715
===> Epoch[58](2100/2500): Loss: 0.2563
===> Epoch[58](2200/2500): Loss: 0.2557
===> Epoch[58](2300/2500): Loss: 0.2838
===> Epoch[58](2400/2500): Loss: 0.2813
===> Epoch[58](2500/2500): Loss: 0.2886
===> Epoch 58 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-03 23:56:11]
===> Loading train datasets
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.2958
===> Epoch[59](200/2500): Loss: 0.2802
===> Epoch[59](300/2500): Loss: 0.2808
===> Epoch[59](400/2500): Loss: 0.2677
===> Epoch[59](500/2500): Loss: 0.2725
===> Epoch[59](600/2500): Loss: 0.2805
===> Epoch[59](700/2500): Loss: 0.2720
===> Epoch[59](800/2500): Loss: 0.2913
===> Epoch[59](900/2500): Loss: 0.2783
===> Epoch[59](1000/2500): Loss: 0.2833
===> Epoch[59](1100/2500): Loss: 0.2951
===> Epoch[59](1200/2500): Loss: 0.2708
===> Epoch[59](1300/2500): Loss: 0.2837
===> Epoch[59](1400/2500): Loss: 0.2846
===> Epoch[59](1500/2500): Loss: 0.2959
===> Epoch[59](1600/2500): Loss: 0.2827
===> Epoch[59](1700/2500): Loss: 0.2765
===> Epoch[59](1800/2500): Loss: 0.2915
===> Epoch[59](1900/2500): Loss: 0.2720
===> Epoch[59](2000/2500): Loss: 0.2916
===> Epoch[59](2100/2500): Loss: 0.3002
===> Epoch[59](2200/2500): Loss: 0.2600
===> Epoch[59](2300/2500): Loss: 0.2890
===> Epoch[59](2400/2500): Loss: 0.2674
===> Epoch[59](2500/2500): Loss: 0.2958
===> Epoch 59 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:00:46]
===> Loading train datasets
===> Loading train datasets
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.3082
===> Epoch[60](200/2500): Loss: 0.2838
===> Epoch[60](300/2500): Loss: 0.2806
===> Epoch[60](400/2500): Loss: 0.2752
===> Epoch[60](500/2500): Loss: 0.2761
===> Epoch[60](600/2500): Loss: 0.3077
===> Epoch[60](700/2500): Loss: 0.2729
===> Epoch[60](800/2500): Loss: 0.2880
===> Epoch[60](900/2500): Loss: 0.2724
===> Epoch[60](1000/2500): Loss: 0.2993
===> Epoch[60](1100/2500): Loss: 0.2845
===> Epoch[60](1200/2500): Loss: 0.2714
===> Epoch[60](1300/2500): Loss: 0.3045
===> Epoch[60](1400/2500): Loss: 0.3033
===> Epoch[60](1500/2500): Loss: 0.3074
===> Epoch[60](1600/2500): Loss: 0.2676
===> Epoch[60](1700/2500): Loss: 0.2691
===> Epoch[60](1800/2500): Loss: 0.2836
===> Epoch[60](1900/2500): Loss: 0.2885
===> Epoch[60](2000/2500): Loss: 0.3031
===> Epoch[60](2100/2500): Loss: 0.2918
===> Epoch[60](2200/2500): Loss: 0.2558
===> Epoch[60](2300/2500): Loss: 0.3050
===> Epoch[60](2400/2500): Loss: 0.2808
===> Epoch[60](2500/2500): Loss: 0.2951
===> Epoch 60 Complete: Avg. Loss: 0.2828
===> Timestamp: [2025-08-04 00:05:20]
Checkpoint saved to TrainedNet/_epoch_60.pth
