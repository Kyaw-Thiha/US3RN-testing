===> Loading train datasets
===> Epoch[31](100/2500): Loss: 0.1113
===> Epoch[31](200/2500): Loss: 0.1008
===> Epoch[31](300/2500): Loss: 0.0996
===> Epoch[31](400/2500): Loss: 0.0992
===> Epoch[31](500/2500): Loss: 0.0983
===> Epoch[31](600/2500): Loss: 0.0993
===> Epoch[31](700/2500): Loss: 0.0992
===> Epoch[31](800/2500): Loss: 0.0986
===> Epoch[31](900/2500): Loss: 0.0990
===> Epoch[31](1000/2500): Loss: 0.0989
===> Epoch[31](1100/2500): Loss: 0.0986
===> Epoch[31](1200/2500): Loss: 0.0988
===> Epoch[31](1300/2500): Loss: 0.0990
===> Epoch[31](1400/2500): Loss: 0.0992
===> Epoch[31](1500/2500): Loss: 0.0991
===> Epoch[31](1600/2500): Loss: 0.0985
===> Epoch[31](1700/2500): Loss: 0.0987
===> Epoch[31](1800/2500): Loss: 0.0993
===> Epoch[31](1900/2500): Loss: 0.0992
===> Epoch[31](2000/2500): Loss: 0.0985
===> Epoch[31](2100/2500): Loss: 0.0994
===> Epoch[31](2200/2500): Loss: 0.0992
===> Epoch[31](2300/2500): Loss: 0.0991
===> Epoch[31](2400/2500): Loss: 0.0989
===> Epoch[31](2500/2500): Loss: 0.0987
===> Epoch 31 Complete: Avg. Loss: 0.1004
===> Timestamp: [2025-07-29 17:51:26]
===> Loading train datasets
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.0985
===> Epoch[32](200/2500): Loss: 0.0991
===> Epoch[32](300/2500): Loss: 0.1546
===> Epoch[32](400/2500): Loss: 0.1084
===> Epoch[32](500/2500): Loss: 0.0998
===> Epoch[32](600/2500): Loss: 0.0989
===> Epoch[32](700/2500): Loss: 0.0990
===> Epoch[32](800/2500): Loss: 0.0984
===> Epoch[32](900/2500): Loss: 0.0979
===> Epoch[32](1000/2500): Loss: 0.0985
===> Epoch[32](1100/2500): Loss: 0.0979
===> Epoch[32](1200/2500): Loss: 0.0990
===> Epoch[32](1300/2500): Loss: 0.0984
===> Epoch[32](1400/2500): Loss: 0.0984
===> Epoch[32](1500/2500): Loss: 0.0979
===> Epoch[32](1600/2500): Loss: 0.0979
===> Epoch[32](1700/2500): Loss: 0.0984
===> Epoch[32](1800/2500): Loss: 0.0981
===> Epoch[32](1900/2500): Loss: 0.0973
===> Epoch[32](2000/2500): Loss: 0.0983
===> Epoch[32](2100/2500): Loss: 0.0980
===> Epoch[32](2200/2500): Loss: 0.0982
===> Epoch[32](2300/2500): Loss: 0.0979
===> Epoch[32](2400/2500): Loss: 0.0986
===> Epoch[32](2500/2500): Loss: 0.0983
===> Epoch 32 Complete: Avg. Loss: 0.1003
===> Timestamp: [2025-07-29 17:56:22]
===> Loading train datasets
===> Epoch[32](100/2500): Loss: 0.0985
===> Epoch[32](200/2500): Loss: 0.0991
===> Epoch[32](300/2500): Loss: 0.1546
===> Epoch[32](400/2500): Loss: 0.1084
===> Epoch[32](500/2500): Loss: 0.0998
===> Epoch[32](600/2500): Loss: 0.0989
===> Epoch[32](700/2500): Loss: 0.0990
===> Epoch[32](800/2500): Loss: 0.0984
===> Epoch[32](900/2500): Loss: 0.0979
===> Epoch[32](1000/2500): Loss: 0.0985
===> Epoch[32](1100/2500): Loss: 0.0979
===> Epoch[32](1200/2500): Loss: 0.0990
===> Epoch[32](1300/2500): Loss: 0.0984
===> Epoch[32](1400/2500): Loss: 0.0984
===> Epoch[32](1500/2500): Loss: 0.0979
===> Epoch[32](1600/2500): Loss: 0.0979
===> Epoch[32](1700/2500): Loss: 0.0984
===> Epoch[32](1800/2500): Loss: 0.0981
===> Epoch[32](1900/2500): Loss: 0.0973
===> Epoch[32](2000/2500): Loss: 0.0983
===> Epoch[32](2100/2500): Loss: 0.0980
===> Epoch[32](2200/2500): Loss: 0.0982
===> Epoch[32](2300/2500): Loss: 0.0979
===> Epoch[32](2400/2500): Loss: 0.0986
===> Epoch[32](2500/2500): Loss: 0.0983
===> Epoch 32 Complete: Avg. Loss: 0.1003
===> Timestamp: [2025-07-29 17:56:22]
===> Loading train datasets
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.0983
===> Epoch[33](200/2500): Loss: 0.0983
===> Epoch[33](300/2500): Loss: 0.0991
===> Epoch[33](400/2500): Loss: 0.0982
===> Epoch[33](500/2500): Loss: 0.0984
===> Epoch[33](600/2500): Loss: 0.0982
===> Epoch[33](700/2500): Loss: 0.0984
===> Epoch[33](800/2500): Loss: 0.1429
===> Epoch[33](900/2500): Loss: 0.1173
===> Epoch[33](1000/2500): Loss: 0.1012
===> Epoch[33](1100/2500): Loss: 0.0986
===> Epoch[33](1200/2500): Loss: 0.0986
===> Epoch[33](1300/2500): Loss: 0.0983
===> Epoch[33](1400/2500): Loss: 0.0985
===> Epoch[33](1500/2500): Loss: 0.0980
===> Epoch[33](1600/2500): Loss: 0.0983
===> Epoch[33](1700/2500): Loss: 0.0980
===> Epoch[33](1800/2500): Loss: 0.0984
===> Epoch[33](1900/2500): Loss: 0.0984
===> Epoch[33](2000/2500): Loss: 0.0978
===> Epoch[33](2100/2500): Loss: 0.0985
===> Epoch[33](2200/2500): Loss: 0.0979
===> Epoch[33](2300/2500): Loss: 0.0987
===> Epoch[33](2400/2500): Loss: 0.0977
===> Epoch[33](2500/2500): Loss: 0.0982
===> Epoch 33 Complete: Avg. Loss: 0.0998
===> Timestamp: [2025-07-29 18:01:20]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.0983
===> Epoch[33](200/2500): Loss: 0.0983
===> Epoch[33](300/2500): Loss: 0.0991
===> Epoch[33](400/2500): Loss: 0.0982
===> Epoch[33](500/2500): Loss: 0.0984
===> Epoch[33](600/2500): Loss: 0.0982
===> Epoch[33](700/2500): Loss: 0.0984
===> Epoch[33](800/2500): Loss: 0.1429
===> Epoch[33](900/2500): Loss: 0.1173
===> Epoch[33](1000/2500): Loss: 0.1012
===> Epoch[33](1100/2500): Loss: 0.0986
===> Epoch[33](1200/2500): Loss: 0.0986
===> Epoch[33](1300/2500): Loss: 0.0983
===> Epoch[33](1400/2500): Loss: 0.0985
===> Epoch[33](1500/2500): Loss: 0.0980
===> Epoch[33](1600/2500): Loss: 0.0983
===> Epoch[33](1700/2500): Loss: 0.0980
===> Epoch[33](1800/2500): Loss: 0.0984
===> Epoch[33](1900/2500): Loss: 0.0984
===> Epoch[33](2000/2500): Loss: 0.0978
===> Epoch[33](2100/2500): Loss: 0.0985
===> Epoch[33](2200/2500): Loss: 0.0979
===> Epoch[33](2300/2500): Loss: 0.0987
===> Epoch[33](2400/2500): Loss: 0.0977
===> Epoch[33](2500/2500): Loss: 0.0982
===> Epoch 33 Complete: Avg. Loss: 0.0998
===> Timestamp: [2025-07-29 18:01:20]
===> Loading train datasets
===> Epoch[33](100/2500): Loss: 0.0983
===> Epoch[33](200/2500): Loss: 0.0983
===> Epoch[33](300/2500): Loss: 0.0991
===> Epoch[33](400/2500): Loss: 0.0982
===> Epoch[33](500/2500): Loss: 0.0984
===> Epoch[33](600/2500): Loss: 0.0982
===> Epoch[33](700/2500): Loss: 0.0984
===> Epoch[33](800/2500): Loss: 0.1429
===> Epoch[33](900/2500): Loss: 0.1173
===> Epoch[33](1000/2500): Loss: 0.1012
===> Epoch[33](1100/2500): Loss: 0.0986
===> Epoch[33](1200/2500): Loss: 0.0986
===> Epoch[33](1300/2500): Loss: 0.0983
===> Epoch[33](1400/2500): Loss: 0.0985
===> Epoch[33](1500/2500): Loss: 0.0980
===> Epoch[33](1600/2500): Loss: 0.0983
===> Epoch[33](1700/2500): Loss: 0.0980
===> Epoch[33](1800/2500): Loss: 0.0984
===> Epoch[33](1900/2500): Loss: 0.0984
===> Epoch[33](2000/2500): Loss: 0.0978
===> Epoch[33](2100/2500): Loss: 0.0985
===> Epoch[33](2200/2500): Loss: 0.0979
===> Epoch[33](2300/2500): Loss: 0.0987
===> Epoch[33](2400/2500): Loss: 0.0977
===> Epoch[33](2500/2500): Loss: 0.0982
===> Epoch 33 Complete: Avg. Loss: 0.0998
===> Timestamp: [2025-07-29 18:01:20]
===> Loading train datasets
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.0978
===> Epoch[34](200/2500): Loss: 0.0980
===> Epoch[34](300/2500): Loss: 0.0984
===> Epoch[34](400/2500): Loss: 0.0979
===> Epoch[34](500/2500): Loss: 0.0978
===> Epoch[34](600/2500): Loss: 0.0980
===> Epoch[34](700/2500): Loss: 0.0974
===> Epoch[34](800/2500): Loss: 0.0986
===> Epoch[34](900/2500): Loss: 0.0979
===> Epoch[34](1000/2500): Loss: 0.0980
===> Epoch[34](1100/2500): Loss: 0.1321
===> Epoch[34](1200/2500): Loss: 0.1095
===> Epoch[34](1300/2500): Loss: 0.0997
===> Epoch[34](1400/2500): Loss: 0.0987
===> Epoch[34](1500/2500): Loss: 0.0983
===> Epoch[34](1600/2500): Loss: 0.0971
===> Epoch[34](1700/2500): Loss: 0.0977
===> Epoch[34](1800/2500): Loss: 0.0973
===> Epoch[34](1900/2500): Loss: 0.0973
===> Epoch[34](2000/2500): Loss: 0.0976
===> Epoch[34](2100/2500): Loss: 0.0979
===> Epoch[34](2200/2500): Loss: 0.0977
===> Epoch[34](2300/2500): Loss: 0.0977
===> Epoch[34](2400/2500): Loss: 0.0978
===> Epoch[34](2500/2500): Loss: 0.0973
===> Epoch 34 Complete: Avg. Loss: 0.0998
===> Timestamp: [2025-07-29 18:06:18]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.0978
===> Epoch[34](200/2500): Loss: 0.0980
===> Epoch[34](300/2500): Loss: 0.0984
===> Epoch[34](400/2500): Loss: 0.0979
===> Epoch[34](500/2500): Loss: 0.0978
===> Epoch[34](600/2500): Loss: 0.0980
===> Epoch[34](700/2500): Loss: 0.0974
===> Epoch[34](800/2500): Loss: 0.0986
===> Epoch[34](900/2500): Loss: 0.0979
===> Epoch[34](1000/2500): Loss: 0.0980
===> Epoch[34](1100/2500): Loss: 0.1321
===> Epoch[34](1200/2500): Loss: 0.1095
===> Epoch[34](1300/2500): Loss: 0.0997
===> Epoch[34](1400/2500): Loss: 0.0987
===> Epoch[34](1500/2500): Loss: 0.0983
===> Epoch[34](1600/2500): Loss: 0.0971
===> Epoch[34](1700/2500): Loss: 0.0977
===> Epoch[34](1800/2500): Loss: 0.0973
===> Epoch[34](1900/2500): Loss: 0.0973
===> Epoch[34](2000/2500): Loss: 0.0976
===> Epoch[34](2100/2500): Loss: 0.0979
===> Epoch[34](2200/2500): Loss: 0.0977
===> Epoch[34](2300/2500): Loss: 0.0977
===> Epoch[34](2400/2500): Loss: 0.0978
===> Epoch[34](2500/2500): Loss: 0.0973
===> Epoch 34 Complete: Avg. Loss: 0.0998
===> Timestamp: [2025-07-29 18:06:18]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.0978
===> Epoch[34](200/2500): Loss: 0.0980
===> Epoch[34](300/2500): Loss: 0.0984
===> Epoch[34](400/2500): Loss: 0.0979
===> Epoch[34](500/2500): Loss: 0.0978
===> Epoch[34](600/2500): Loss: 0.0980
===> Epoch[34](700/2500): Loss: 0.0974
===> Epoch[34](800/2500): Loss: 0.0986
===> Epoch[34](900/2500): Loss: 0.0979
===> Epoch[34](1000/2500): Loss: 0.0980
===> Epoch[34](1100/2500): Loss: 0.1321
===> Epoch[34](1200/2500): Loss: 0.1095
===> Epoch[34](1300/2500): Loss: 0.0997
===> Epoch[34](1400/2500): Loss: 0.0987
===> Epoch[34](1500/2500): Loss: 0.0983
===> Epoch[34](1600/2500): Loss: 0.0971
===> Epoch[34](1700/2500): Loss: 0.0977
===> Epoch[34](1800/2500): Loss: 0.0973
===> Epoch[34](1900/2500): Loss: 0.0973
===> Epoch[34](2000/2500): Loss: 0.0976
===> Epoch[34](2100/2500): Loss: 0.0979
===> Epoch[34](2200/2500): Loss: 0.0977
===> Epoch[34](2300/2500): Loss: 0.0977
===> Epoch[34](2400/2500): Loss: 0.0978
===> Epoch[34](2500/2500): Loss: 0.0973
===> Epoch 34 Complete: Avg. Loss: 0.0998
===> Timestamp: [2025-07-29 18:06:18]
===> Loading train datasets
===> Epoch[34](100/2500): Loss: 0.0978
===> Epoch[34](200/2500): Loss: 0.0980
===> Epoch[34](300/2500): Loss: 0.0984
===> Epoch[34](400/2500): Loss: 0.0979
===> Epoch[34](500/2500): Loss: 0.0978
===> Epoch[34](600/2500): Loss: 0.0980
===> Epoch[34](700/2500): Loss: 0.0974
===> Epoch[34](800/2500): Loss: 0.0986
===> Epoch[34](900/2500): Loss: 0.0979
===> Epoch[34](1000/2500): Loss: 0.0980
===> Epoch[34](1100/2500): Loss: 0.1321
===> Epoch[34](1200/2500): Loss: 0.1095
===> Epoch[34](1300/2500): Loss: 0.0997
===> Epoch[34](1400/2500): Loss: 0.0987
===> Epoch[34](1500/2500): Loss: 0.0983
===> Epoch[34](1600/2500): Loss: 0.0971
===> Epoch[34](1700/2500): Loss: 0.0977
===> Epoch[34](1800/2500): Loss: 0.0973
===> Epoch[34](1900/2500): Loss: 0.0973
===> Epoch[34](2000/2500): Loss: 0.0976
===> Epoch[34](2100/2500): Loss: 0.0979
===> Epoch[34](2200/2500): Loss: 0.0977
===> Epoch[34](2300/2500): Loss: 0.0977
===> Epoch[34](2400/2500): Loss: 0.0978
===> Epoch[34](2500/2500): Loss: 0.0973
===> Epoch 34 Complete: Avg. Loss: 0.0998
===> Timestamp: [2025-07-29 18:06:18]
===> Loading train datasets
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.0973
===> Epoch[35](200/2500): Loss: 0.0978
===> Epoch[35](300/2500): Loss: 0.0977
===> Epoch[35](400/2500): Loss: 0.0973
===> Epoch[35](500/2500): Loss: 0.0975
===> Epoch[35](600/2500): Loss: 0.0971
===> Epoch[35](700/2500): Loss: 0.0971
===> Epoch[35](800/2500): Loss: 0.0970
===> Epoch[35](900/2500): Loss: 0.0967
===> Epoch[35](1000/2500): Loss: 0.0974
===> Epoch[35](1100/2500): Loss: 0.0979
===> Epoch[35](1200/2500): Loss: 0.0974
===> Epoch[35](1300/2500): Loss: 0.0971
===> Epoch[35](1400/2500): Loss: 0.0978
===> Epoch[35](1500/2500): Loss: 0.0976
===> Epoch[35](1600/2500): Loss: 0.1179
===> Epoch[35](1700/2500): Loss: 0.1008
===> Epoch[35](1800/2500): Loss: 0.0978
===> Epoch[35](1900/2500): Loss: 0.0979
===> Epoch[35](2000/2500): Loss: 0.0975
===> Epoch[35](2100/2500): Loss: 0.0976
===> Epoch[35](2200/2500): Loss: 0.0976
===> Epoch[35](2300/2500): Loss: 0.0973
===> Epoch[35](2400/2500): Loss: 0.0973
===> Epoch[35](2500/2500): Loss: 0.0972
===> Epoch 35 Complete: Avg. Loss: 0.0990
===> Timestamp: [2025-07-29 18:11:18]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.0973
===> Epoch[35](200/2500): Loss: 0.0978
===> Epoch[35](300/2500): Loss: 0.0977
===> Epoch[35](400/2500): Loss: 0.0973
===> Epoch[35](500/2500): Loss: 0.0975
===> Epoch[35](600/2500): Loss: 0.0971
===> Epoch[35](700/2500): Loss: 0.0971
===> Epoch[35](800/2500): Loss: 0.0970
===> Epoch[35](900/2500): Loss: 0.0967
===> Epoch[35](1000/2500): Loss: 0.0974
===> Epoch[35](1100/2500): Loss: 0.0979
===> Epoch[35](1200/2500): Loss: 0.0974
===> Epoch[35](1300/2500): Loss: 0.0971
===> Epoch[35](1400/2500): Loss: 0.0978
===> Epoch[35](1500/2500): Loss: 0.0976
===> Epoch[35](1600/2500): Loss: 0.1179
===> Epoch[35](1700/2500): Loss: 0.1008
===> Epoch[35](1800/2500): Loss: 0.0978
===> Epoch[35](1900/2500): Loss: 0.0979
===> Epoch[35](2000/2500): Loss: 0.0975
===> Epoch[35](2100/2500): Loss: 0.0976
===> Epoch[35](2200/2500): Loss: 0.0976
===> Epoch[35](2300/2500): Loss: 0.0973
===> Epoch[35](2400/2500): Loss: 0.0973
===> Epoch[35](2500/2500): Loss: 0.0972
===> Epoch 35 Complete: Avg. Loss: 0.0990
===> Timestamp: [2025-07-29 18:11:18]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.0973
===> Epoch[35](200/2500): Loss: 0.0978
===> Epoch[35](300/2500): Loss: 0.0977
===> Epoch[35](400/2500): Loss: 0.0973
===> Epoch[35](500/2500): Loss: 0.0975
===> Epoch[35](600/2500): Loss: 0.0971
===> Epoch[35](700/2500): Loss: 0.0971
===> Epoch[35](800/2500): Loss: 0.0970
===> Epoch[35](900/2500): Loss: 0.0967
===> Epoch[35](1000/2500): Loss: 0.0974
===> Epoch[35](1100/2500): Loss: 0.0979
===> Epoch[35](1200/2500): Loss: 0.0974
===> Epoch[35](1300/2500): Loss: 0.0971
===> Epoch[35](1400/2500): Loss: 0.0978
===> Epoch[35](1500/2500): Loss: 0.0976
===> Epoch[35](1600/2500): Loss: 0.1179
===> Epoch[35](1700/2500): Loss: 0.1008
===> Epoch[35](1800/2500): Loss: 0.0978
===> Epoch[35](1900/2500): Loss: 0.0979
===> Epoch[35](2000/2500): Loss: 0.0975
===> Epoch[35](2100/2500): Loss: 0.0976
===> Epoch[35](2200/2500): Loss: 0.0976
===> Epoch[35](2300/2500): Loss: 0.0973
===> Epoch[35](2400/2500): Loss: 0.0973
===> Epoch[35](2500/2500): Loss: 0.0972
===> Epoch 35 Complete: Avg. Loss: 0.0990
===> Timestamp: [2025-07-29 18:11:18]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.0973
===> Epoch[35](200/2500): Loss: 0.0978
===> Epoch[35](300/2500): Loss: 0.0977
===> Epoch[35](400/2500): Loss: 0.0973
===> Epoch[35](500/2500): Loss: 0.0975
===> Epoch[35](600/2500): Loss: 0.0971
===> Epoch[35](700/2500): Loss: 0.0971
===> Epoch[35](800/2500): Loss: 0.0970
===> Epoch[35](900/2500): Loss: 0.0967
===> Epoch[35](1000/2500): Loss: 0.0974
===> Epoch[35](1100/2500): Loss: 0.0979
===> Epoch[35](1200/2500): Loss: 0.0974
===> Epoch[35](1300/2500): Loss: 0.0971
===> Epoch[35](1400/2500): Loss: 0.0978
===> Epoch[35](1500/2500): Loss: 0.0976
===> Epoch[35](1600/2500): Loss: 0.1179
===> Epoch[35](1700/2500): Loss: 0.1008
===> Epoch[35](1800/2500): Loss: 0.0978
===> Epoch[35](1900/2500): Loss: 0.0979
===> Epoch[35](2000/2500): Loss: 0.0975
===> Epoch[35](2100/2500): Loss: 0.0976
===> Epoch[35](2200/2500): Loss: 0.0976
===> Epoch[35](2300/2500): Loss: 0.0973
===> Epoch[35](2400/2500): Loss: 0.0973
===> Epoch[35](2500/2500): Loss: 0.0972
===> Epoch 35 Complete: Avg. Loss: 0.0990
===> Timestamp: [2025-07-29 18:11:18]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Epoch[35](100/2500): Loss: 0.0973
===> Epoch[35](200/2500): Loss: 0.0978
===> Epoch[35](300/2500): Loss: 0.0977
===> Epoch[35](400/2500): Loss: 0.0973
===> Epoch[35](500/2500): Loss: 0.0975
===> Epoch[35](600/2500): Loss: 0.0971
===> Epoch[35](700/2500): Loss: 0.0971
===> Epoch[35](800/2500): Loss: 0.0970
===> Epoch[35](900/2500): Loss: 0.0967
===> Epoch[35](1000/2500): Loss: 0.0974
===> Epoch[35](1100/2500): Loss: 0.0979
===> Epoch[35](1200/2500): Loss: 0.0974
===> Epoch[35](1300/2500): Loss: 0.0971
===> Epoch[35](1400/2500): Loss: 0.0978
===> Epoch[35](1500/2500): Loss: 0.0976
===> Epoch[35](1600/2500): Loss: 0.1179
===> Epoch[35](1700/2500): Loss: 0.1008
===> Epoch[35](1800/2500): Loss: 0.0978
===> Epoch[35](1900/2500): Loss: 0.0979
===> Epoch[35](2000/2500): Loss: 0.0975
===> Epoch[35](2100/2500): Loss: 0.0976
===> Epoch[35](2200/2500): Loss: 0.0976
===> Epoch[35](2300/2500): Loss: 0.0973
===> Epoch[35](2400/2500): Loss: 0.0973
===> Epoch[35](2500/2500): Loss: 0.0972
===> Epoch 35 Complete: Avg. Loss: 0.0990
===> Timestamp: [2025-07-29 18:11:18]
Checkpoint saved to TrainedNet/_epoch_35.pth
===> Loading train datasets
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.0971
===> Epoch[36](200/2500): Loss: 0.0972
===> Epoch[36](300/2500): Loss: 0.0975
===> Epoch[36](400/2500): Loss: 0.0976
===> Epoch[36](500/2500): Loss: 0.0978
===> Epoch[36](600/2500): Loss: 0.0975
===> Epoch[36](700/2500): Loss: 0.0969
===> Epoch[36](800/2500): Loss: 0.0973
===> Epoch[36](900/2500): Loss: 0.0971
===> Epoch[36](1000/2500): Loss: 0.0978
===> Epoch[36](1100/2500): Loss: 0.0972
===> Epoch[36](1200/2500): Loss: 0.0975
===> Epoch[36](1300/2500): Loss: 0.0975
===> Epoch[36](1400/2500): Loss: 0.0974
===> Epoch[36](1500/2500): Loss: 0.0973
===> Epoch[36](1600/2500): Loss: 0.0975
===> Epoch[36](1700/2500): Loss: 0.0978
===> Epoch[36](1800/2500): Loss: 0.1303
===> Epoch[36](1900/2500): Loss: 0.1050
===> Epoch[36](2000/2500): Loss: 0.0992
===> Epoch[36](2100/2500): Loss: 0.0980
===> Epoch[36](2200/2500): Loss: 0.0972
===> Epoch[36](2300/2500): Loss: 0.0973
===> Epoch[36](2400/2500): Loss: 0.0972
===> Epoch[36](2500/2500): Loss: 0.0975
===> Epoch 36 Complete: Avg. Loss: 0.0993
===> Timestamp: [2025-07-29 18:16:16]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.0971
===> Epoch[36](200/2500): Loss: 0.0972
===> Epoch[36](300/2500): Loss: 0.0975
===> Epoch[36](400/2500): Loss: 0.0976
===> Epoch[36](500/2500): Loss: 0.0978
===> Epoch[36](600/2500): Loss: 0.0975
===> Epoch[36](700/2500): Loss: 0.0969
===> Epoch[36](800/2500): Loss: 0.0973
===> Epoch[36](900/2500): Loss: 0.0971
===> Epoch[36](1000/2500): Loss: 0.0978
===> Epoch[36](1100/2500): Loss: 0.0972
===> Epoch[36](1200/2500): Loss: 0.0975
===> Epoch[36](1300/2500): Loss: 0.0975
===> Epoch[36](1400/2500): Loss: 0.0974
===> Epoch[36](1500/2500): Loss: 0.0973
===> Epoch[36](1600/2500): Loss: 0.0975
===> Epoch[36](1700/2500): Loss: 0.0978
===> Epoch[36](1800/2500): Loss: 0.1303
===> Epoch[36](1900/2500): Loss: 0.1050
===> Epoch[36](2000/2500): Loss: 0.0992
===> Epoch[36](2100/2500): Loss: 0.0980
===> Epoch[36](2200/2500): Loss: 0.0972
===> Epoch[36](2300/2500): Loss: 0.0973
===> Epoch[36](2400/2500): Loss: 0.0972
===> Epoch[36](2500/2500): Loss: 0.0975
===> Epoch 36 Complete: Avg. Loss: 0.0993
===> Timestamp: [2025-07-29 18:16:16]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.0971
===> Epoch[36](200/2500): Loss: 0.0972
===> Epoch[36](300/2500): Loss: 0.0975
===> Epoch[36](400/2500): Loss: 0.0976
===> Epoch[36](500/2500): Loss: 0.0978
===> Epoch[36](600/2500): Loss: 0.0975
===> Epoch[36](700/2500): Loss: 0.0969
===> Epoch[36](800/2500): Loss: 0.0973
===> Epoch[36](900/2500): Loss: 0.0971
===> Epoch[36](1000/2500): Loss: 0.0978
===> Epoch[36](1100/2500): Loss: 0.0972
===> Epoch[36](1200/2500): Loss: 0.0975
===> Epoch[36](1300/2500): Loss: 0.0975
===> Epoch[36](1400/2500): Loss: 0.0974
===> Epoch[36](1500/2500): Loss: 0.0973
===> Epoch[36](1600/2500): Loss: 0.0975
===> Epoch[36](1700/2500): Loss: 0.0978
===> Epoch[36](1800/2500): Loss: 0.1303
===> Epoch[36](1900/2500): Loss: 0.1050
===> Epoch[36](2000/2500): Loss: 0.0992
===> Epoch[36](2100/2500): Loss: 0.0980
===> Epoch[36](2200/2500): Loss: 0.0972
===> Epoch[36](2300/2500): Loss: 0.0973
===> Epoch[36](2400/2500): Loss: 0.0972
===> Epoch[36](2500/2500): Loss: 0.0975
===> Epoch 36 Complete: Avg. Loss: 0.0993
===> Timestamp: [2025-07-29 18:16:16]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.0971
===> Epoch[36](200/2500): Loss: 0.0972
===> Epoch[36](300/2500): Loss: 0.0975
===> Epoch[36](400/2500): Loss: 0.0976
===> Epoch[36](500/2500): Loss: 0.0978
===> Epoch[36](600/2500): Loss: 0.0975
===> Epoch[36](700/2500): Loss: 0.0969
===> Epoch[36](800/2500): Loss: 0.0973
===> Epoch[36](900/2500): Loss: 0.0971
===> Epoch[36](1000/2500): Loss: 0.0978
===> Epoch[36](1100/2500): Loss: 0.0972
===> Epoch[36](1200/2500): Loss: 0.0975
===> Epoch[36](1300/2500): Loss: 0.0975
===> Epoch[36](1400/2500): Loss: 0.0974
===> Epoch[36](1500/2500): Loss: 0.0973
===> Epoch[36](1600/2500): Loss: 0.0975
===> Epoch[36](1700/2500): Loss: 0.0978
===> Epoch[36](1800/2500): Loss: 0.1303
===> Epoch[36](1900/2500): Loss: 0.1050
===> Epoch[36](2000/2500): Loss: 0.0992
===> Epoch[36](2100/2500): Loss: 0.0980
===> Epoch[36](2200/2500): Loss: 0.0972
===> Epoch[36](2300/2500): Loss: 0.0973
===> Epoch[36](2400/2500): Loss: 0.0972
===> Epoch[36](2500/2500): Loss: 0.0975
===> Epoch 36 Complete: Avg. Loss: 0.0993
===> Timestamp: [2025-07-29 18:16:16]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.0971
===> Epoch[36](200/2500): Loss: 0.0972
===> Epoch[36](300/2500): Loss: 0.0975
===> Epoch[36](400/2500): Loss: 0.0976
===> Epoch[36](500/2500): Loss: 0.0978
===> Epoch[36](600/2500): Loss: 0.0975
===> Epoch[36](700/2500): Loss: 0.0969
===> Epoch[36](800/2500): Loss: 0.0973
===> Epoch[36](900/2500): Loss: 0.0971
===> Epoch[36](1000/2500): Loss: 0.0978
===> Epoch[36](1100/2500): Loss: 0.0972
===> Epoch[36](1200/2500): Loss: 0.0975
===> Epoch[36](1300/2500): Loss: 0.0975
===> Epoch[36](1400/2500): Loss: 0.0974
===> Epoch[36](1500/2500): Loss: 0.0973
===> Epoch[36](1600/2500): Loss: 0.0975
===> Epoch[36](1700/2500): Loss: 0.0978
===> Epoch[36](1800/2500): Loss: 0.1303
===> Epoch[36](1900/2500): Loss: 0.1050
===> Epoch[36](2000/2500): Loss: 0.0992
===> Epoch[36](2100/2500): Loss: 0.0980
===> Epoch[36](2200/2500): Loss: 0.0972
===> Epoch[36](2300/2500): Loss: 0.0973
===> Epoch[36](2400/2500): Loss: 0.0972
===> Epoch[36](2500/2500): Loss: 0.0975
===> Epoch 36 Complete: Avg. Loss: 0.0993
===> Timestamp: [2025-07-29 18:16:16]
===> Loading train datasets
===> Epoch[36](100/2500): Loss: 0.0971
===> Epoch[36](200/2500): Loss: 0.0972
===> Epoch[36](300/2500): Loss: 0.0975
===> Epoch[36](400/2500): Loss: 0.0976
===> Epoch[36](500/2500): Loss: 0.0978
===> Epoch[36](600/2500): Loss: 0.0975
===> Epoch[36](700/2500): Loss: 0.0969
===> Epoch[36](800/2500): Loss: 0.0973
===> Epoch[36](900/2500): Loss: 0.0971
===> Epoch[36](1000/2500): Loss: 0.0978
===> Epoch[36](1100/2500): Loss: 0.0972
===> Epoch[36](1200/2500): Loss: 0.0975
===> Epoch[36](1300/2500): Loss: 0.0975
===> Epoch[36](1400/2500): Loss: 0.0974
===> Epoch[36](1500/2500): Loss: 0.0973
===> Epoch[36](1600/2500): Loss: 0.0975
===> Epoch[36](1700/2500): Loss: 0.0978
===> Epoch[36](1800/2500): Loss: 0.1303
===> Epoch[36](1900/2500): Loss: 0.1050
===> Epoch[36](2000/2500): Loss: 0.0992
===> Epoch[36](2100/2500): Loss: 0.0980
===> Epoch[36](2200/2500): Loss: 0.0972
===> Epoch[36](2300/2500): Loss: 0.0973
===> Epoch[36](2400/2500): Loss: 0.0972
===> Epoch[36](2500/2500): Loss: 0.0975
===> Epoch 36 Complete: Avg. Loss: 0.0993
===> Timestamp: [2025-07-29 18:16:16]
===> Loading train datasets
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.0968
===> Epoch[37](200/2500): Loss: 0.0968
===> Epoch[37](300/2500): Loss: 0.0972
===> Epoch[37](400/2500): Loss: 0.0969
===> Epoch[37](500/2500): Loss: 0.0977
===> Epoch[37](600/2500): Loss: 0.0972
===> Epoch[37](700/2500): Loss: 0.0979
===> Epoch[37](800/2500): Loss: 0.0978
===> Epoch[37](900/2500): Loss: 0.0969
===> Epoch[37](1000/2500): Loss: 0.0973
===> Epoch[37](1100/2500): Loss: 0.0973
===> Epoch[37](1200/2500): Loss: 0.0970
===> Epoch[37](1300/2500): Loss: 0.0975
===> Epoch[37](1400/2500): Loss: 0.0978
===> Epoch[37](1500/2500): Loss: 0.0973
===> Epoch[37](1600/2500): Loss: 0.0973
===> Epoch[37](1700/2500): Loss: 0.0980
===> Epoch[37](1800/2500): Loss: 0.0976
===> Epoch[37](1900/2500): Loss: 0.0972
===> Epoch[37](2000/2500): Loss: 0.0968
===> Epoch[37](2100/2500): Loss: 0.1556
===> Epoch[37](2200/2500): Loss: 0.1109
===> Epoch[37](2300/2500): Loss: 0.1000
===> Epoch[37](2400/2500): Loss: 0.0979
===> Epoch[37](2500/2500): Loss: 0.0976
===> Epoch 37 Complete: Avg. Loss: 0.0994
===> Timestamp: [2025-07-29 18:21:14]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.0968
===> Epoch[37](200/2500): Loss: 0.0968
===> Epoch[37](300/2500): Loss: 0.0972
===> Epoch[37](400/2500): Loss: 0.0969
===> Epoch[37](500/2500): Loss: 0.0977
===> Epoch[37](600/2500): Loss: 0.0972
===> Epoch[37](700/2500): Loss: 0.0979
===> Epoch[37](800/2500): Loss: 0.0978
===> Epoch[37](900/2500): Loss: 0.0969
===> Epoch[37](1000/2500): Loss: 0.0973
===> Epoch[37](1100/2500): Loss: 0.0973
===> Epoch[37](1200/2500): Loss: 0.0970
===> Epoch[37](1300/2500): Loss: 0.0975
===> Epoch[37](1400/2500): Loss: 0.0978
===> Epoch[37](1500/2500): Loss: 0.0973
===> Epoch[37](1600/2500): Loss: 0.0973
===> Epoch[37](1700/2500): Loss: 0.0980
===> Epoch[37](1800/2500): Loss: 0.0976
===> Epoch[37](1900/2500): Loss: 0.0972
===> Epoch[37](2000/2500): Loss: 0.0968
===> Epoch[37](2100/2500): Loss: 0.1556
===> Epoch[37](2200/2500): Loss: 0.1109
===> Epoch[37](2300/2500): Loss: 0.1000
===> Epoch[37](2400/2500): Loss: 0.0979
===> Epoch[37](2500/2500): Loss: 0.0976
===> Epoch 37 Complete: Avg. Loss: 0.0994
===> Timestamp: [2025-07-29 18:21:14]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.0968
===> Epoch[37](200/2500): Loss: 0.0968
===> Epoch[37](300/2500): Loss: 0.0972
===> Epoch[37](400/2500): Loss: 0.0969
===> Epoch[37](500/2500): Loss: 0.0977
===> Epoch[37](600/2500): Loss: 0.0972
===> Epoch[37](700/2500): Loss: 0.0979
===> Epoch[37](800/2500): Loss: 0.0978
===> Epoch[37](900/2500): Loss: 0.0969
===> Epoch[37](1000/2500): Loss: 0.0973
===> Epoch[37](1100/2500): Loss: 0.0973
===> Epoch[37](1200/2500): Loss: 0.0970
===> Epoch[37](1300/2500): Loss: 0.0975
===> Epoch[37](1400/2500): Loss: 0.0978
===> Epoch[37](1500/2500): Loss: 0.0973
===> Epoch[37](1600/2500): Loss: 0.0973
===> Epoch[37](1700/2500): Loss: 0.0980
===> Epoch[37](1800/2500): Loss: 0.0976
===> Epoch[37](1900/2500): Loss: 0.0972
===> Epoch[37](2000/2500): Loss: 0.0968
===> Epoch[37](2100/2500): Loss: 0.1556
===> Epoch[37](2200/2500): Loss: 0.1109
===> Epoch[37](2300/2500): Loss: 0.1000
===> Epoch[37](2400/2500): Loss: 0.0979
===> Epoch[37](2500/2500): Loss: 0.0976
===> Epoch 37 Complete: Avg. Loss: 0.0994
===> Timestamp: [2025-07-29 18:21:14]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.0968
===> Epoch[37](200/2500): Loss: 0.0968
===> Epoch[37](300/2500): Loss: 0.0972
===> Epoch[37](400/2500): Loss: 0.0969
===> Epoch[37](500/2500): Loss: 0.0977
===> Epoch[37](600/2500): Loss: 0.0972
===> Epoch[37](700/2500): Loss: 0.0979
===> Epoch[37](800/2500): Loss: 0.0978
===> Epoch[37](900/2500): Loss: 0.0969
===> Epoch[37](1000/2500): Loss: 0.0973
===> Epoch[37](1100/2500): Loss: 0.0973
===> Epoch[37](1200/2500): Loss: 0.0970
===> Epoch[37](1300/2500): Loss: 0.0975
===> Epoch[37](1400/2500): Loss: 0.0978
===> Epoch[37](1500/2500): Loss: 0.0973
===> Epoch[37](1600/2500): Loss: 0.0973
===> Epoch[37](1700/2500): Loss: 0.0980
===> Epoch[37](1800/2500): Loss: 0.0976
===> Epoch[37](1900/2500): Loss: 0.0972
===> Epoch[37](2000/2500): Loss: 0.0968
===> Epoch[37](2100/2500): Loss: 0.1556
===> Epoch[37](2200/2500): Loss: 0.1109
===> Epoch[37](2300/2500): Loss: 0.1000
===> Epoch[37](2400/2500): Loss: 0.0979
===> Epoch[37](2500/2500): Loss: 0.0976
===> Epoch 37 Complete: Avg. Loss: 0.0994
===> Timestamp: [2025-07-29 18:21:14]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.0968
===> Epoch[37](200/2500): Loss: 0.0968
===> Epoch[37](300/2500): Loss: 0.0972
===> Epoch[37](400/2500): Loss: 0.0969
===> Epoch[37](500/2500): Loss: 0.0977
===> Epoch[37](600/2500): Loss: 0.0972
===> Epoch[37](700/2500): Loss: 0.0979
===> Epoch[37](800/2500): Loss: 0.0978
===> Epoch[37](900/2500): Loss: 0.0969
===> Epoch[37](1000/2500): Loss: 0.0973
===> Epoch[37](1100/2500): Loss: 0.0973
===> Epoch[37](1200/2500): Loss: 0.0970
===> Epoch[37](1300/2500): Loss: 0.0975
===> Epoch[37](1400/2500): Loss: 0.0978
===> Epoch[37](1500/2500): Loss: 0.0973
===> Epoch[37](1600/2500): Loss: 0.0973
===> Epoch[37](1700/2500): Loss: 0.0980
===> Epoch[37](1800/2500): Loss: 0.0976
===> Epoch[37](1900/2500): Loss: 0.0972
===> Epoch[37](2000/2500): Loss: 0.0968
===> Epoch[37](2100/2500): Loss: 0.1556
===> Epoch[37](2200/2500): Loss: 0.1109
===> Epoch[37](2300/2500): Loss: 0.1000
===> Epoch[37](2400/2500): Loss: 0.0979
===> Epoch[37](2500/2500): Loss: 0.0976
===> Epoch 37 Complete: Avg. Loss: 0.0994
===> Timestamp: [2025-07-29 18:21:14]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.0968
===> Epoch[37](200/2500): Loss: 0.0968
===> Epoch[37](300/2500): Loss: 0.0972
===> Epoch[37](400/2500): Loss: 0.0969
===> Epoch[37](500/2500): Loss: 0.0977
===> Epoch[37](600/2500): Loss: 0.0972
===> Epoch[37](700/2500): Loss: 0.0979
===> Epoch[37](800/2500): Loss: 0.0978
===> Epoch[37](900/2500): Loss: 0.0969
===> Epoch[37](1000/2500): Loss: 0.0973
===> Epoch[37](1100/2500): Loss: 0.0973
===> Epoch[37](1200/2500): Loss: 0.0970
===> Epoch[37](1300/2500): Loss: 0.0975
===> Epoch[37](1400/2500): Loss: 0.0978
===> Epoch[37](1500/2500): Loss: 0.0973
===> Epoch[37](1600/2500): Loss: 0.0973
===> Epoch[37](1700/2500): Loss: 0.0980
===> Epoch[37](1800/2500): Loss: 0.0976
===> Epoch[37](1900/2500): Loss: 0.0972
===> Epoch[37](2000/2500): Loss: 0.0968
===> Epoch[37](2100/2500): Loss: 0.1556
===> Epoch[37](2200/2500): Loss: 0.1109
===> Epoch[37](2300/2500): Loss: 0.1000
===> Epoch[37](2400/2500): Loss: 0.0979
===> Epoch[37](2500/2500): Loss: 0.0976
===> Epoch 37 Complete: Avg. Loss: 0.0994
===> Timestamp: [2025-07-29 18:21:14]
===> Loading train datasets
===> Epoch[37](100/2500): Loss: 0.0968
===> Epoch[37](200/2500): Loss: 0.0968
===> Epoch[37](300/2500): Loss: 0.0972
===> Epoch[37](400/2500): Loss: 0.0969
===> Epoch[37](500/2500): Loss: 0.0977
===> Epoch[37](600/2500): Loss: 0.0972
===> Epoch[37](700/2500): Loss: 0.0979
===> Epoch[37](800/2500): Loss: 0.0978
===> Epoch[37](900/2500): Loss: 0.0969
===> Epoch[37](1000/2500): Loss: 0.0973
===> Epoch[37](1100/2500): Loss: 0.0973
===> Epoch[37](1200/2500): Loss: 0.0970
===> Epoch[37](1300/2500): Loss: 0.0975
===> Epoch[37](1400/2500): Loss: 0.0978
===> Epoch[37](1500/2500): Loss: 0.0973
===> Epoch[37](1600/2500): Loss: 0.0973
===> Epoch[37](1700/2500): Loss: 0.0980
===> Epoch[37](1800/2500): Loss: 0.0976
===> Epoch[37](1900/2500): Loss: 0.0972
===> Epoch[37](2000/2500): Loss: 0.0968
===> Epoch[37](2100/2500): Loss: 0.1556
===> Epoch[37](2200/2500): Loss: 0.1109
===> Epoch[37](2300/2500): Loss: 0.1000
===> Epoch[37](2400/2500): Loss: 0.0979
===> Epoch[37](2500/2500): Loss: 0.0976
===> Epoch 37 Complete: Avg. Loss: 0.0994
===> Timestamp: [2025-07-29 18:21:14]
===> Loading train datasets
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.0973
===> Epoch[38](200/2500): Loss: 0.0972
===> Epoch[38](300/2500): Loss: 0.0977
===> Epoch[38](400/2500): Loss: 0.0976
===> Epoch[38](500/2500): Loss: 0.0976
===> Epoch[38](600/2500): Loss: 0.0974
===> Epoch[38](700/2500): Loss: 0.0972
===> Epoch[38](800/2500): Loss: 0.0972
===> Epoch[38](900/2500): Loss: 0.0976
===> Epoch[38](1000/2500): Loss: 0.0974
===> Epoch[38](1100/2500): Loss: 0.0978
===> Epoch[38](1200/2500): Loss: 0.0974
===> Epoch[38](1300/2500): Loss: 0.0974
===> Epoch[38](1400/2500): Loss: 0.0976
===> Epoch[38](1500/2500): Loss: 0.0969
===> Epoch[38](1600/2500): Loss: 0.0971
===> Epoch[38](1700/2500): Loss: 0.0974
===> Epoch[38](1800/2500): Loss: 0.0967
===> Epoch[38](1900/2500): Loss: 0.0974
===> Epoch[38](2000/2500): Loss: 0.0976
===> Epoch[38](2100/2500): Loss: 0.0967
===> Epoch[38](2200/2500): Loss: 0.0970
===> Epoch[38](2300/2500): Loss: 0.0981
===> Epoch[38](2400/2500): Loss: 0.1103
===> Epoch[38](2500/2500): Loss: 0.1205
===> Epoch 38 Complete: Avg. Loss: 0.0987
===> Timestamp: [2025-07-29 18:26:14]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.0973
===> Epoch[38](200/2500): Loss: 0.0972
===> Epoch[38](300/2500): Loss: 0.0977
===> Epoch[38](400/2500): Loss: 0.0976
===> Epoch[38](500/2500): Loss: 0.0976
===> Epoch[38](600/2500): Loss: 0.0974
===> Epoch[38](700/2500): Loss: 0.0972
===> Epoch[38](800/2500): Loss: 0.0972
===> Epoch[38](900/2500): Loss: 0.0976
===> Epoch[38](1000/2500): Loss: 0.0974
===> Epoch[38](1100/2500): Loss: 0.0978
===> Epoch[38](1200/2500): Loss: 0.0974
===> Epoch[38](1300/2500): Loss: 0.0974
===> Epoch[38](1400/2500): Loss: 0.0976
===> Epoch[38](1500/2500): Loss: 0.0969
===> Epoch[38](1600/2500): Loss: 0.0971
===> Epoch[38](1700/2500): Loss: 0.0974
===> Epoch[38](1800/2500): Loss: 0.0967
===> Epoch[38](1900/2500): Loss: 0.0974
===> Epoch[38](2000/2500): Loss: 0.0976
===> Epoch[38](2100/2500): Loss: 0.0967
===> Epoch[38](2200/2500): Loss: 0.0970
===> Epoch[38](2300/2500): Loss: 0.0981
===> Epoch[38](2400/2500): Loss: 0.1103
===> Epoch[38](2500/2500): Loss: 0.1205
===> Epoch 38 Complete: Avg. Loss: 0.0987
===> Timestamp: [2025-07-29 18:26:14]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.0973
===> Epoch[38](200/2500): Loss: 0.0972
===> Epoch[38](300/2500): Loss: 0.0977
===> Epoch[38](400/2500): Loss: 0.0976
===> Epoch[38](500/2500): Loss: 0.0976
===> Epoch[38](600/2500): Loss: 0.0974
===> Epoch[38](700/2500): Loss: 0.0972
===> Epoch[38](800/2500): Loss: 0.0972
===> Epoch[38](900/2500): Loss: 0.0976
===> Epoch[38](1000/2500): Loss: 0.0974
===> Epoch[38](1100/2500): Loss: 0.0978
===> Epoch[38](1200/2500): Loss: 0.0974
===> Epoch[38](1300/2500): Loss: 0.0974
===> Epoch[38](1400/2500): Loss: 0.0976
===> Epoch[38](1500/2500): Loss: 0.0969
===> Epoch[38](1600/2500): Loss: 0.0971
===> Epoch[38](1700/2500): Loss: 0.0974
===> Epoch[38](1800/2500): Loss: 0.0967
===> Epoch[38](1900/2500): Loss: 0.0974
===> Epoch[38](2000/2500): Loss: 0.0976
===> Epoch[38](2100/2500): Loss: 0.0967
===> Epoch[38](2200/2500): Loss: 0.0970
===> Epoch[38](2300/2500): Loss: 0.0981
===> Epoch[38](2400/2500): Loss: 0.1103
===> Epoch[38](2500/2500): Loss: 0.1205
===> Epoch 38 Complete: Avg. Loss: 0.0987
===> Timestamp: [2025-07-29 18:26:14]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.0973
===> Epoch[38](200/2500): Loss: 0.0972
===> Epoch[38](300/2500): Loss: 0.0977
===> Epoch[38](400/2500): Loss: 0.0976
===> Epoch[38](500/2500): Loss: 0.0976
===> Epoch[38](600/2500): Loss: 0.0974
===> Epoch[38](700/2500): Loss: 0.0972
===> Epoch[38](800/2500): Loss: 0.0972
===> Epoch[38](900/2500): Loss: 0.0976
===> Epoch[38](1000/2500): Loss: 0.0974
===> Epoch[38](1100/2500): Loss: 0.0978
===> Epoch[38](1200/2500): Loss: 0.0974
===> Epoch[38](1300/2500): Loss: 0.0974
===> Epoch[38](1400/2500): Loss: 0.0976
===> Epoch[38](1500/2500): Loss: 0.0969
===> Epoch[38](1600/2500): Loss: 0.0971
===> Epoch[38](1700/2500): Loss: 0.0974
===> Epoch[38](1800/2500): Loss: 0.0967
===> Epoch[38](1900/2500): Loss: 0.0974
===> Epoch[38](2000/2500): Loss: 0.0976
===> Epoch[38](2100/2500): Loss: 0.0967
===> Epoch[38](2200/2500): Loss: 0.0970
===> Epoch[38](2300/2500): Loss: 0.0981
===> Epoch[38](2400/2500): Loss: 0.1103
===> Epoch[38](2500/2500): Loss: 0.1205
===> Epoch 38 Complete: Avg. Loss: 0.0987
===> Timestamp: [2025-07-29 18:26:14]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.0973
===> Epoch[38](200/2500): Loss: 0.0972
===> Epoch[38](300/2500): Loss: 0.0977
===> Epoch[38](400/2500): Loss: 0.0976
===> Epoch[38](500/2500): Loss: 0.0976
===> Epoch[38](600/2500): Loss: 0.0974
===> Epoch[38](700/2500): Loss: 0.0972
===> Epoch[38](800/2500): Loss: 0.0972
===> Epoch[38](900/2500): Loss: 0.0976
===> Epoch[38](1000/2500): Loss: 0.0974
===> Epoch[38](1100/2500): Loss: 0.0978
===> Epoch[38](1200/2500): Loss: 0.0974
===> Epoch[38](1300/2500): Loss: 0.0974
===> Epoch[38](1400/2500): Loss: 0.0976
===> Epoch[38](1500/2500): Loss: 0.0969
===> Epoch[38](1600/2500): Loss: 0.0971
===> Epoch[38](1700/2500): Loss: 0.0974
===> Epoch[38](1800/2500): Loss: 0.0967
===> Epoch[38](1900/2500): Loss: 0.0974
===> Epoch[38](2000/2500): Loss: 0.0976
===> Epoch[38](2100/2500): Loss: 0.0967
===> Epoch[38](2200/2500): Loss: 0.0970
===> Epoch[38](2300/2500): Loss: 0.0981
===> Epoch[38](2400/2500): Loss: 0.1103
===> Epoch[38](2500/2500): Loss: 0.1205
===> Epoch 38 Complete: Avg. Loss: 0.0987
===> Timestamp: [2025-07-29 18:26:14]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.0973
===> Epoch[38](200/2500): Loss: 0.0972
===> Epoch[38](300/2500): Loss: 0.0977
===> Epoch[38](400/2500): Loss: 0.0976
===> Epoch[38](500/2500): Loss: 0.0976
===> Epoch[38](600/2500): Loss: 0.0974
===> Epoch[38](700/2500): Loss: 0.0972
===> Epoch[38](800/2500): Loss: 0.0972
===> Epoch[38](900/2500): Loss: 0.0976
===> Epoch[38](1000/2500): Loss: 0.0974
===> Epoch[38](1100/2500): Loss: 0.0978
===> Epoch[38](1200/2500): Loss: 0.0974
===> Epoch[38](1300/2500): Loss: 0.0974
===> Epoch[38](1400/2500): Loss: 0.0976
===> Epoch[38](1500/2500): Loss: 0.0969
===> Epoch[38](1600/2500): Loss: 0.0971
===> Epoch[38](1700/2500): Loss: 0.0974
===> Epoch[38](1800/2500): Loss: 0.0967
===> Epoch[38](1900/2500): Loss: 0.0974
===> Epoch[38](2000/2500): Loss: 0.0976
===> Epoch[38](2100/2500): Loss: 0.0967
===> Epoch[38](2200/2500): Loss: 0.0970
===> Epoch[38](2300/2500): Loss: 0.0981
===> Epoch[38](2400/2500): Loss: 0.1103
===> Epoch[38](2500/2500): Loss: 0.1205
===> Epoch 38 Complete: Avg. Loss: 0.0987
===> Timestamp: [2025-07-29 18:26:14]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.0973
===> Epoch[38](200/2500): Loss: 0.0972
===> Epoch[38](300/2500): Loss: 0.0977
===> Epoch[38](400/2500): Loss: 0.0976
===> Epoch[38](500/2500): Loss: 0.0976
===> Epoch[38](600/2500): Loss: 0.0974
===> Epoch[38](700/2500): Loss: 0.0972
===> Epoch[38](800/2500): Loss: 0.0972
===> Epoch[38](900/2500): Loss: 0.0976
===> Epoch[38](1000/2500): Loss: 0.0974
===> Epoch[38](1100/2500): Loss: 0.0978
===> Epoch[38](1200/2500): Loss: 0.0974
===> Epoch[38](1300/2500): Loss: 0.0974
===> Epoch[38](1400/2500): Loss: 0.0976
===> Epoch[38](1500/2500): Loss: 0.0969
===> Epoch[38](1600/2500): Loss: 0.0971
===> Epoch[38](1700/2500): Loss: 0.0974
===> Epoch[38](1800/2500): Loss: 0.0967
===> Epoch[38](1900/2500): Loss: 0.0974
===> Epoch[38](2000/2500): Loss: 0.0976
===> Epoch[38](2100/2500): Loss: 0.0967
===> Epoch[38](2200/2500): Loss: 0.0970
===> Epoch[38](2300/2500): Loss: 0.0981
===> Epoch[38](2400/2500): Loss: 0.1103
===> Epoch[38](2500/2500): Loss: 0.1205
===> Epoch 38 Complete: Avg. Loss: 0.0987
===> Timestamp: [2025-07-29 18:26:14]
===> Loading train datasets
===> Epoch[38](100/2500): Loss: 0.0973
===> Epoch[38](200/2500): Loss: 0.0972
===> Epoch[38](300/2500): Loss: 0.0977
===> Epoch[38](400/2500): Loss: 0.0976
===> Epoch[38](500/2500): Loss: 0.0976
===> Epoch[38](600/2500): Loss: 0.0974
===> Epoch[38](700/2500): Loss: 0.0972
===> Epoch[38](800/2500): Loss: 0.0972
===> Epoch[38](900/2500): Loss: 0.0976
===> Epoch[38](1000/2500): Loss: 0.0974
===> Epoch[38](1100/2500): Loss: 0.0978
===> Epoch[38](1200/2500): Loss: 0.0974
===> Epoch[38](1300/2500): Loss: 0.0974
===> Epoch[38](1400/2500): Loss: 0.0976
===> Epoch[38](1500/2500): Loss: 0.0969
===> Epoch[38](1600/2500): Loss: 0.0971
===> Epoch[38](1700/2500): Loss: 0.0974
===> Epoch[38](1800/2500): Loss: 0.0967
===> Epoch[38](1900/2500): Loss: 0.0974
===> Epoch[38](2000/2500): Loss: 0.0976
===> Epoch[38](2100/2500): Loss: 0.0967
===> Epoch[38](2200/2500): Loss: 0.0970
===> Epoch[38](2300/2500): Loss: 0.0981
===> Epoch[38](2400/2500): Loss: 0.1103
===> Epoch[38](2500/2500): Loss: 0.1205
===> Epoch 38 Complete: Avg. Loss: 0.0987
===> Timestamp: [2025-07-29 18:26:14]
===> Loading train datasets
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.1026
===> Epoch[39](200/2500): Loss: 0.0984
===> Epoch[39](300/2500): Loss: 0.0976
===> Epoch[39](400/2500): Loss: 0.0974
===> Epoch[39](500/2500): Loss: 0.0977
===> Epoch[39](600/2500): Loss: 0.0971
===> Epoch[39](700/2500): Loss: 0.0975
===> Epoch[39](800/2500): Loss: 0.0977
===> Epoch[39](900/2500): Loss: 0.0971
===> Epoch[39](1000/2500): Loss: 0.0971
===> Epoch[39](1100/2500): Loss: 0.0970
===> Epoch[39](1200/2500): Loss: 0.0977
===> Epoch[39](1300/2500): Loss: 0.0976
===> Epoch[39](1400/2500): Loss: 0.0975
===> Epoch[39](1500/2500): Loss: 0.0969
===> Epoch[39](1600/2500): Loss: 0.0970
===> Epoch[39](1700/2500): Loss: 0.0975
===> Epoch[39](1800/2500): Loss: 0.0972
===> Epoch[39](1900/2500): Loss: 0.0970
===> Epoch[39](2000/2500): Loss: 0.0969
===> Epoch[39](2100/2500): Loss: 0.0966
===> Epoch[39](2200/2500): Loss: 0.0973
===> Epoch[39](2300/2500): Loss: 0.0975
===> Epoch[39](2400/2500): Loss: 0.0971
===> Epoch[39](2500/2500): Loss: 0.0967
===> Epoch 39 Complete: Avg. Loss: 0.0979
===> Timestamp: [2025-07-29 18:31:12]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.1026
===> Epoch[39](200/2500): Loss: 0.0984
===> Epoch[39](300/2500): Loss: 0.0976
===> Epoch[39](400/2500): Loss: 0.0974
===> Epoch[39](500/2500): Loss: 0.0977
===> Epoch[39](600/2500): Loss: 0.0971
===> Epoch[39](700/2500): Loss: 0.0975
===> Epoch[39](800/2500): Loss: 0.0977
===> Epoch[39](900/2500): Loss: 0.0971
===> Epoch[39](1000/2500): Loss: 0.0971
===> Epoch[39](1100/2500): Loss: 0.0970
===> Epoch[39](1200/2500): Loss: 0.0977
===> Epoch[39](1300/2500): Loss: 0.0976
===> Epoch[39](1400/2500): Loss: 0.0975
===> Epoch[39](1500/2500): Loss: 0.0969
===> Epoch[39](1600/2500): Loss: 0.0970
===> Epoch[39](1700/2500): Loss: 0.0975
===> Epoch[39](1800/2500): Loss: 0.0972
===> Epoch[39](1900/2500): Loss: 0.0970
===> Epoch[39](2000/2500): Loss: 0.0969
===> Epoch[39](2100/2500): Loss: 0.0966
===> Epoch[39](2200/2500): Loss: 0.0973
===> Epoch[39](2300/2500): Loss: 0.0975
===> Epoch[39](2400/2500): Loss: 0.0971
===> Epoch[39](2500/2500): Loss: 0.0967
===> Epoch 39 Complete: Avg. Loss: 0.0979
===> Timestamp: [2025-07-29 18:31:12]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.1026
===> Epoch[39](200/2500): Loss: 0.0984
===> Epoch[39](300/2500): Loss: 0.0976
===> Epoch[39](400/2500): Loss: 0.0974
===> Epoch[39](500/2500): Loss: 0.0977
===> Epoch[39](600/2500): Loss: 0.0971
===> Epoch[39](700/2500): Loss: 0.0975
===> Epoch[39](800/2500): Loss: 0.0977
===> Epoch[39](900/2500): Loss: 0.0971
===> Epoch[39](1000/2500): Loss: 0.0971
===> Epoch[39](1100/2500): Loss: 0.0970
===> Epoch[39](1200/2500): Loss: 0.0977
===> Epoch[39](1300/2500): Loss: 0.0976
===> Epoch[39](1400/2500): Loss: 0.0975
===> Epoch[39](1500/2500): Loss: 0.0969
===> Epoch[39](1600/2500): Loss: 0.0970
===> Epoch[39](1700/2500): Loss: 0.0975
===> Epoch[39](1800/2500): Loss: 0.0972
===> Epoch[39](1900/2500): Loss: 0.0970
===> Epoch[39](2000/2500): Loss: 0.0969
===> Epoch[39](2100/2500): Loss: 0.0966
===> Epoch[39](2200/2500): Loss: 0.0973
===> Epoch[39](2300/2500): Loss: 0.0975
===> Epoch[39](2400/2500): Loss: 0.0971
===> Epoch[39](2500/2500): Loss: 0.0967
===> Epoch 39 Complete: Avg. Loss: 0.0979
===> Timestamp: [2025-07-29 18:31:12]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.1026
===> Epoch[39](200/2500): Loss: 0.0984
===> Epoch[39](300/2500): Loss: 0.0976
===> Epoch[39](400/2500): Loss: 0.0974
===> Epoch[39](500/2500): Loss: 0.0977
===> Epoch[39](600/2500): Loss: 0.0971
===> Epoch[39](700/2500): Loss: 0.0975
===> Epoch[39](800/2500): Loss: 0.0977
===> Epoch[39](900/2500): Loss: 0.0971
===> Epoch[39](1000/2500): Loss: 0.0971
===> Epoch[39](1100/2500): Loss: 0.0970
===> Epoch[39](1200/2500): Loss: 0.0977
===> Epoch[39](1300/2500): Loss: 0.0976
===> Epoch[39](1400/2500): Loss: 0.0975
===> Epoch[39](1500/2500): Loss: 0.0969
===> Epoch[39](1600/2500): Loss: 0.0970
===> Epoch[39](1700/2500): Loss: 0.0975
===> Epoch[39](1800/2500): Loss: 0.0972
===> Epoch[39](1900/2500): Loss: 0.0970
===> Epoch[39](2000/2500): Loss: 0.0969
===> Epoch[39](2100/2500): Loss: 0.0966
===> Epoch[39](2200/2500): Loss: 0.0973
===> Epoch[39](2300/2500): Loss: 0.0975
===> Epoch[39](2400/2500): Loss: 0.0971
===> Epoch[39](2500/2500): Loss: 0.0967
===> Epoch 39 Complete: Avg. Loss: 0.0979
===> Timestamp: [2025-07-29 18:31:12]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.1026
===> Epoch[39](200/2500): Loss: 0.0984
===> Epoch[39](300/2500): Loss: 0.0976
===> Epoch[39](400/2500): Loss: 0.0974
===> Epoch[39](500/2500): Loss: 0.0977
===> Epoch[39](600/2500): Loss: 0.0971
===> Epoch[39](700/2500): Loss: 0.0975
===> Epoch[39](800/2500): Loss: 0.0977
===> Epoch[39](900/2500): Loss: 0.0971
===> Epoch[39](1000/2500): Loss: 0.0971
===> Epoch[39](1100/2500): Loss: 0.0970
===> Epoch[39](1200/2500): Loss: 0.0977
===> Epoch[39](1300/2500): Loss: 0.0976
===> Epoch[39](1400/2500): Loss: 0.0975
===> Epoch[39](1500/2500): Loss: 0.0969
===> Epoch[39](1600/2500): Loss: 0.0970
===> Epoch[39](1700/2500): Loss: 0.0975
===> Epoch[39](1800/2500): Loss: 0.0972
===> Epoch[39](1900/2500): Loss: 0.0970
===> Epoch[39](2000/2500): Loss: 0.0969
===> Epoch[39](2100/2500): Loss: 0.0966
===> Epoch[39](2200/2500): Loss: 0.0973
===> Epoch[39](2300/2500): Loss: 0.0975
===> Epoch[39](2400/2500): Loss: 0.0971
===> Epoch[39](2500/2500): Loss: 0.0967
===> Epoch 39 Complete: Avg. Loss: 0.0979
===> Timestamp: [2025-07-29 18:31:12]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.1026
===> Epoch[39](200/2500): Loss: 0.0984
===> Epoch[39](300/2500): Loss: 0.0976
===> Epoch[39](400/2500): Loss: 0.0974
===> Epoch[39](500/2500): Loss: 0.0977
===> Epoch[39](600/2500): Loss: 0.0971
===> Epoch[39](700/2500): Loss: 0.0975
===> Epoch[39](800/2500): Loss: 0.0977
===> Epoch[39](900/2500): Loss: 0.0971
===> Epoch[39](1000/2500): Loss: 0.0971
===> Epoch[39](1100/2500): Loss: 0.0970
===> Epoch[39](1200/2500): Loss: 0.0977
===> Epoch[39](1300/2500): Loss: 0.0976
===> Epoch[39](1400/2500): Loss: 0.0975
===> Epoch[39](1500/2500): Loss: 0.0969
===> Epoch[39](1600/2500): Loss: 0.0970
===> Epoch[39](1700/2500): Loss: 0.0975
===> Epoch[39](1800/2500): Loss: 0.0972
===> Epoch[39](1900/2500): Loss: 0.0970
===> Epoch[39](2000/2500): Loss: 0.0969
===> Epoch[39](2100/2500): Loss: 0.0966
===> Epoch[39](2200/2500): Loss: 0.0973
===> Epoch[39](2300/2500): Loss: 0.0975
===> Epoch[39](2400/2500): Loss: 0.0971
===> Epoch[39](2500/2500): Loss: 0.0967
===> Epoch 39 Complete: Avg. Loss: 0.0979
===> Timestamp: [2025-07-29 18:31:12]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.1026
===> Epoch[39](200/2500): Loss: 0.0984
===> Epoch[39](300/2500): Loss: 0.0976
===> Epoch[39](400/2500): Loss: 0.0974
===> Epoch[39](500/2500): Loss: 0.0977
===> Epoch[39](600/2500): Loss: 0.0971
===> Epoch[39](700/2500): Loss: 0.0975
===> Epoch[39](800/2500): Loss: 0.0977
===> Epoch[39](900/2500): Loss: 0.0971
===> Epoch[39](1000/2500): Loss: 0.0971
===> Epoch[39](1100/2500): Loss: 0.0970
===> Epoch[39](1200/2500): Loss: 0.0977
===> Epoch[39](1300/2500): Loss: 0.0976
===> Epoch[39](1400/2500): Loss: 0.0975
===> Epoch[39](1500/2500): Loss: 0.0969
===> Epoch[39](1600/2500): Loss: 0.0970
===> Epoch[39](1700/2500): Loss: 0.0975
===> Epoch[39](1800/2500): Loss: 0.0972
===> Epoch[39](1900/2500): Loss: 0.0970
===> Epoch[39](2000/2500): Loss: 0.0969
===> Epoch[39](2100/2500): Loss: 0.0966
===> Epoch[39](2200/2500): Loss: 0.0973
===> Epoch[39](2300/2500): Loss: 0.0975
===> Epoch[39](2400/2500): Loss: 0.0971
===> Epoch[39](2500/2500): Loss: 0.0967
===> Epoch 39 Complete: Avg. Loss: 0.0979
===> Timestamp: [2025-07-29 18:31:12]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.1026
===> Epoch[39](200/2500): Loss: 0.0984
===> Epoch[39](300/2500): Loss: 0.0976
===> Epoch[39](400/2500): Loss: 0.0974
===> Epoch[39](500/2500): Loss: 0.0977
===> Epoch[39](600/2500): Loss: 0.0971
===> Epoch[39](700/2500): Loss: 0.0975
===> Epoch[39](800/2500): Loss: 0.0977
===> Epoch[39](900/2500): Loss: 0.0971
===> Epoch[39](1000/2500): Loss: 0.0971
===> Epoch[39](1100/2500): Loss: 0.0970
===> Epoch[39](1200/2500): Loss: 0.0977
===> Epoch[39](1300/2500): Loss: 0.0976
===> Epoch[39](1400/2500): Loss: 0.0975
===> Epoch[39](1500/2500): Loss: 0.0969
===> Epoch[39](1600/2500): Loss: 0.0970
===> Epoch[39](1700/2500): Loss: 0.0975
===> Epoch[39](1800/2500): Loss: 0.0972
===> Epoch[39](1900/2500): Loss: 0.0970
===> Epoch[39](2000/2500): Loss: 0.0969
===> Epoch[39](2100/2500): Loss: 0.0966
===> Epoch[39](2200/2500): Loss: 0.0973
===> Epoch[39](2300/2500): Loss: 0.0975
===> Epoch[39](2400/2500): Loss: 0.0971
===> Epoch[39](2500/2500): Loss: 0.0967
===> Epoch 39 Complete: Avg. Loss: 0.0979
===> Timestamp: [2025-07-29 18:31:12]
===> Loading train datasets
===> Epoch[39](100/2500): Loss: 0.1026
===> Epoch[39](200/2500): Loss: 0.0984
===> Epoch[39](300/2500): Loss: 0.0976
===> Epoch[39](400/2500): Loss: 0.0974
===> Epoch[39](500/2500): Loss: 0.0977
===> Epoch[39](600/2500): Loss: 0.0971
===> Epoch[39](700/2500): Loss: 0.0975
===> Epoch[39](800/2500): Loss: 0.0977
===> Epoch[39](900/2500): Loss: 0.0971
===> Epoch[39](1000/2500): Loss: 0.0971
===> Epoch[39](1100/2500): Loss: 0.0970
===> Epoch[39](1200/2500): Loss: 0.0977
===> Epoch[39](1300/2500): Loss: 0.0976
===> Epoch[39](1400/2500): Loss: 0.0975
===> Epoch[39](1500/2500): Loss: 0.0969
===> Epoch[39](1600/2500): Loss: 0.0970
===> Epoch[39](1700/2500): Loss: 0.0975
===> Epoch[39](1800/2500): Loss: 0.0972
===> Epoch[39](1900/2500): Loss: 0.0970
===> Epoch[39](2000/2500): Loss: 0.0969
===> Epoch[39](2100/2500): Loss: 0.0966
===> Epoch[39](2200/2500): Loss: 0.0973
===> Epoch[39](2300/2500): Loss: 0.0975
===> Epoch[39](2400/2500): Loss: 0.0971
===> Epoch[39](2500/2500): Loss: 0.0967
===> Epoch 39 Complete: Avg. Loss: 0.0979
===> Timestamp: [2025-07-29 18:31:12]
===> Loading train datasets
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.0974
===> Epoch[40](200/2500): Loss: 0.0976
===> Epoch[40](300/2500): Loss: 0.1215
===> Epoch[40](400/2500): Loss: 0.1022
===> Epoch[40](500/2500): Loss: 0.0977
===> Epoch[40](600/2500): Loss: 0.0970
===> Epoch[40](700/2500): Loss: 0.0977
===> Epoch[40](800/2500): Loss: 0.0977
===> Epoch[40](900/2500): Loss: 0.0974
===> Epoch[40](1000/2500): Loss: 0.0975
===> Epoch[40](1100/2500): Loss: 0.0972
===> Epoch[40](1200/2500): Loss: 0.0974
===> Epoch[40](1300/2500): Loss: 0.0975
===> Epoch[40](1400/2500): Loss: 0.0972
===> Epoch[40](1500/2500): Loss: 0.0979
===> Epoch[40](1600/2500): Loss: 0.0974
===> Epoch[40](1700/2500): Loss: 0.0971
===> Epoch[40](1800/2500): Loss: 0.0980
===> Epoch[40](1900/2500): Loss: 0.0977
===> Epoch[40](2000/2500): Loss: 0.0973
===> Epoch[40](2100/2500): Loss: 0.0975
===> Epoch[40](2200/2500): Loss: 0.0966
===> Epoch[40](2300/2500): Loss: 0.0970
===> Epoch[40](2400/2500): Loss: 0.0978
===> Epoch[40](2500/2500): Loss: 0.0973
===> Epoch 40 Complete: Avg. Loss: 0.0989
===> Timestamp: [2025-07-29 18:36:11]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.0974
===> Epoch[40](200/2500): Loss: 0.0976
===> Epoch[40](300/2500): Loss: 0.1215
===> Epoch[40](400/2500): Loss: 0.1022
===> Epoch[40](500/2500): Loss: 0.0977
===> Epoch[40](600/2500): Loss: 0.0970
===> Epoch[40](700/2500): Loss: 0.0977
===> Epoch[40](800/2500): Loss: 0.0977
===> Epoch[40](900/2500): Loss: 0.0974
===> Epoch[40](1000/2500): Loss: 0.0975
===> Epoch[40](1100/2500): Loss: 0.0972
===> Epoch[40](1200/2500): Loss: 0.0974
===> Epoch[40](1300/2500): Loss: 0.0975
===> Epoch[40](1400/2500): Loss: 0.0972
===> Epoch[40](1500/2500): Loss: 0.0979
===> Epoch[40](1600/2500): Loss: 0.0974
===> Epoch[40](1700/2500): Loss: 0.0971
===> Epoch[40](1800/2500): Loss: 0.0980
===> Epoch[40](1900/2500): Loss: 0.0977
===> Epoch[40](2000/2500): Loss: 0.0973
===> Epoch[40](2100/2500): Loss: 0.0975
===> Epoch[40](2200/2500): Loss: 0.0966
===> Epoch[40](2300/2500): Loss: 0.0970
===> Epoch[40](2400/2500): Loss: 0.0978
===> Epoch[40](2500/2500): Loss: 0.0973
===> Epoch 40 Complete: Avg. Loss: 0.0989
===> Timestamp: [2025-07-29 18:36:11]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.0974
===> Epoch[40](200/2500): Loss: 0.0976
===> Epoch[40](300/2500): Loss: 0.1215
===> Epoch[40](400/2500): Loss: 0.1022
===> Epoch[40](500/2500): Loss: 0.0977
===> Epoch[40](600/2500): Loss: 0.0970
===> Epoch[40](700/2500): Loss: 0.0977
===> Epoch[40](800/2500): Loss: 0.0977
===> Epoch[40](900/2500): Loss: 0.0974
===> Epoch[40](1000/2500): Loss: 0.0975
===> Epoch[40](1100/2500): Loss: 0.0972
===> Epoch[40](1200/2500): Loss: 0.0974
===> Epoch[40](1300/2500): Loss: 0.0975
===> Epoch[40](1400/2500): Loss: 0.0972
===> Epoch[40](1500/2500): Loss: 0.0979
===> Epoch[40](1600/2500): Loss: 0.0974
===> Epoch[40](1700/2500): Loss: 0.0971
===> Epoch[40](1800/2500): Loss: 0.0980
===> Epoch[40](1900/2500): Loss: 0.0977
===> Epoch[40](2000/2500): Loss: 0.0973
===> Epoch[40](2100/2500): Loss: 0.0975
===> Epoch[40](2200/2500): Loss: 0.0966
===> Epoch[40](2300/2500): Loss: 0.0970
===> Epoch[40](2400/2500): Loss: 0.0978
===> Epoch[40](2500/2500): Loss: 0.0973
===> Epoch 40 Complete: Avg. Loss: 0.0989
===> Timestamp: [2025-07-29 18:36:11]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.0974
===> Epoch[40](200/2500): Loss: 0.0976
===> Epoch[40](300/2500): Loss: 0.1215
===> Epoch[40](400/2500): Loss: 0.1022
===> Epoch[40](500/2500): Loss: 0.0977
===> Epoch[40](600/2500): Loss: 0.0970
===> Epoch[40](700/2500): Loss: 0.0977
===> Epoch[40](800/2500): Loss: 0.0977
===> Epoch[40](900/2500): Loss: 0.0974
===> Epoch[40](1000/2500): Loss: 0.0975
===> Epoch[40](1100/2500): Loss: 0.0972
===> Epoch[40](1200/2500): Loss: 0.0974
===> Epoch[40](1300/2500): Loss: 0.0975
===> Epoch[40](1400/2500): Loss: 0.0972
===> Epoch[40](1500/2500): Loss: 0.0979
===> Epoch[40](1600/2500): Loss: 0.0974
===> Epoch[40](1700/2500): Loss: 0.0971
===> Epoch[40](1800/2500): Loss: 0.0980
===> Epoch[40](1900/2500): Loss: 0.0977
===> Epoch[40](2000/2500): Loss: 0.0973
===> Epoch[40](2100/2500): Loss: 0.0975
===> Epoch[40](2200/2500): Loss: 0.0966
===> Epoch[40](2300/2500): Loss: 0.0970
===> Epoch[40](2400/2500): Loss: 0.0978
===> Epoch[40](2500/2500): Loss: 0.0973
===> Epoch 40 Complete: Avg. Loss: 0.0989
===> Timestamp: [2025-07-29 18:36:11]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.0974
===> Epoch[40](200/2500): Loss: 0.0976
===> Epoch[40](300/2500): Loss: 0.1215
===> Epoch[40](400/2500): Loss: 0.1022
===> Epoch[40](500/2500): Loss: 0.0977
===> Epoch[40](600/2500): Loss: 0.0970
===> Epoch[40](700/2500): Loss: 0.0977
===> Epoch[40](800/2500): Loss: 0.0977
===> Epoch[40](900/2500): Loss: 0.0974
===> Epoch[40](1000/2500): Loss: 0.0975
===> Epoch[40](1100/2500): Loss: 0.0972
===> Epoch[40](1200/2500): Loss: 0.0974
===> Epoch[40](1300/2500): Loss: 0.0975
===> Epoch[40](1400/2500): Loss: 0.0972
===> Epoch[40](1500/2500): Loss: 0.0979
===> Epoch[40](1600/2500): Loss: 0.0974
===> Epoch[40](1700/2500): Loss: 0.0971
===> Epoch[40](1800/2500): Loss: 0.0980
===> Epoch[40](1900/2500): Loss: 0.0977
===> Epoch[40](2000/2500): Loss: 0.0973
===> Epoch[40](2100/2500): Loss: 0.0975
===> Epoch[40](2200/2500): Loss: 0.0966
===> Epoch[40](2300/2500): Loss: 0.0970
===> Epoch[40](2400/2500): Loss: 0.0978
===> Epoch[40](2500/2500): Loss: 0.0973
===> Epoch 40 Complete: Avg. Loss: 0.0989
===> Timestamp: [2025-07-29 18:36:11]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.0974
===> Epoch[40](200/2500): Loss: 0.0976
===> Epoch[40](300/2500): Loss: 0.1215
===> Epoch[40](400/2500): Loss: 0.1022
===> Epoch[40](500/2500): Loss: 0.0977
===> Epoch[40](600/2500): Loss: 0.0970
===> Epoch[40](700/2500): Loss: 0.0977
===> Epoch[40](800/2500): Loss: 0.0977
===> Epoch[40](900/2500): Loss: 0.0974
===> Epoch[40](1000/2500): Loss: 0.0975
===> Epoch[40](1100/2500): Loss: 0.0972
===> Epoch[40](1200/2500): Loss: 0.0974
===> Epoch[40](1300/2500): Loss: 0.0975
===> Epoch[40](1400/2500): Loss: 0.0972
===> Epoch[40](1500/2500): Loss: 0.0979
===> Epoch[40](1600/2500): Loss: 0.0974
===> Epoch[40](1700/2500): Loss: 0.0971
===> Epoch[40](1800/2500): Loss: 0.0980
===> Epoch[40](1900/2500): Loss: 0.0977
===> Epoch[40](2000/2500): Loss: 0.0973
===> Epoch[40](2100/2500): Loss: 0.0975
===> Epoch[40](2200/2500): Loss: 0.0966
===> Epoch[40](2300/2500): Loss: 0.0970
===> Epoch[40](2400/2500): Loss: 0.0978
===> Epoch[40](2500/2500): Loss: 0.0973
===> Epoch 40 Complete: Avg. Loss: 0.0989
===> Timestamp: [2025-07-29 18:36:11]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.0974
===> Epoch[40](200/2500): Loss: 0.0976
===> Epoch[40](300/2500): Loss: 0.1215
===> Epoch[40](400/2500): Loss: 0.1022
===> Epoch[40](500/2500): Loss: 0.0977
===> Epoch[40](600/2500): Loss: 0.0970
===> Epoch[40](700/2500): Loss: 0.0977
===> Epoch[40](800/2500): Loss: 0.0977
===> Epoch[40](900/2500): Loss: 0.0974
===> Epoch[40](1000/2500): Loss: 0.0975
===> Epoch[40](1100/2500): Loss: 0.0972
===> Epoch[40](1200/2500): Loss: 0.0974
===> Epoch[40](1300/2500): Loss: 0.0975
===> Epoch[40](1400/2500): Loss: 0.0972
===> Epoch[40](1500/2500): Loss: 0.0979
===> Epoch[40](1600/2500): Loss: 0.0974
===> Epoch[40](1700/2500): Loss: 0.0971
===> Epoch[40](1800/2500): Loss: 0.0980
===> Epoch[40](1900/2500): Loss: 0.0977
===> Epoch[40](2000/2500): Loss: 0.0973
===> Epoch[40](2100/2500): Loss: 0.0975
===> Epoch[40](2200/2500): Loss: 0.0966
===> Epoch[40](2300/2500): Loss: 0.0970
===> Epoch[40](2400/2500): Loss: 0.0978
===> Epoch[40](2500/2500): Loss: 0.0973
===> Epoch 40 Complete: Avg. Loss: 0.0989
===> Timestamp: [2025-07-29 18:36:11]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.0974
===> Epoch[40](200/2500): Loss: 0.0976
===> Epoch[40](300/2500): Loss: 0.1215
===> Epoch[40](400/2500): Loss: 0.1022
===> Epoch[40](500/2500): Loss: 0.0977
===> Epoch[40](600/2500): Loss: 0.0970
===> Epoch[40](700/2500): Loss: 0.0977
===> Epoch[40](800/2500): Loss: 0.0977
===> Epoch[40](900/2500): Loss: 0.0974
===> Epoch[40](1000/2500): Loss: 0.0975
===> Epoch[40](1100/2500): Loss: 0.0972
===> Epoch[40](1200/2500): Loss: 0.0974
===> Epoch[40](1300/2500): Loss: 0.0975
===> Epoch[40](1400/2500): Loss: 0.0972
===> Epoch[40](1500/2500): Loss: 0.0979
===> Epoch[40](1600/2500): Loss: 0.0974
===> Epoch[40](1700/2500): Loss: 0.0971
===> Epoch[40](1800/2500): Loss: 0.0980
===> Epoch[40](1900/2500): Loss: 0.0977
===> Epoch[40](2000/2500): Loss: 0.0973
===> Epoch[40](2100/2500): Loss: 0.0975
===> Epoch[40](2200/2500): Loss: 0.0966
===> Epoch[40](2300/2500): Loss: 0.0970
===> Epoch[40](2400/2500): Loss: 0.0978
===> Epoch[40](2500/2500): Loss: 0.0973
===> Epoch 40 Complete: Avg. Loss: 0.0989
===> Timestamp: [2025-07-29 18:36:11]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.0974
===> Epoch[40](200/2500): Loss: 0.0976
===> Epoch[40](300/2500): Loss: 0.1215
===> Epoch[40](400/2500): Loss: 0.1022
===> Epoch[40](500/2500): Loss: 0.0977
===> Epoch[40](600/2500): Loss: 0.0970
===> Epoch[40](700/2500): Loss: 0.0977
===> Epoch[40](800/2500): Loss: 0.0977
===> Epoch[40](900/2500): Loss: 0.0974
===> Epoch[40](1000/2500): Loss: 0.0975
===> Epoch[40](1100/2500): Loss: 0.0972
===> Epoch[40](1200/2500): Loss: 0.0974
===> Epoch[40](1300/2500): Loss: 0.0975
===> Epoch[40](1400/2500): Loss: 0.0972
===> Epoch[40](1500/2500): Loss: 0.0979
===> Epoch[40](1600/2500): Loss: 0.0974
===> Epoch[40](1700/2500): Loss: 0.0971
===> Epoch[40](1800/2500): Loss: 0.0980
===> Epoch[40](1900/2500): Loss: 0.0977
===> Epoch[40](2000/2500): Loss: 0.0973
===> Epoch[40](2100/2500): Loss: 0.0975
===> Epoch[40](2200/2500): Loss: 0.0966
===> Epoch[40](2300/2500): Loss: 0.0970
===> Epoch[40](2400/2500): Loss: 0.0978
===> Epoch[40](2500/2500): Loss: 0.0973
===> Epoch 40 Complete: Avg. Loss: 0.0989
===> Timestamp: [2025-07-29 18:36:11]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Epoch[40](100/2500): Loss: 0.0974
===> Epoch[40](200/2500): Loss: 0.0976
===> Epoch[40](300/2500): Loss: 0.1215
===> Epoch[40](400/2500): Loss: 0.1022
===> Epoch[40](500/2500): Loss: 0.0977
===> Epoch[40](600/2500): Loss: 0.0970
===> Epoch[40](700/2500): Loss: 0.0977
===> Epoch[40](800/2500): Loss: 0.0977
===> Epoch[40](900/2500): Loss: 0.0974
===> Epoch[40](1000/2500): Loss: 0.0975
===> Epoch[40](1100/2500): Loss: 0.0972
===> Epoch[40](1200/2500): Loss: 0.0974
===> Epoch[40](1300/2500): Loss: 0.0975
===> Epoch[40](1400/2500): Loss: 0.0972
===> Epoch[40](1500/2500): Loss: 0.0979
===> Epoch[40](1600/2500): Loss: 0.0974
===> Epoch[40](1700/2500): Loss: 0.0971
===> Epoch[40](1800/2500): Loss: 0.0980
===> Epoch[40](1900/2500): Loss: 0.0977
===> Epoch[40](2000/2500): Loss: 0.0973
===> Epoch[40](2100/2500): Loss: 0.0975
===> Epoch[40](2200/2500): Loss: 0.0966
===> Epoch[40](2300/2500): Loss: 0.0970
===> Epoch[40](2400/2500): Loss: 0.0978
===> Epoch[40](2500/2500): Loss: 0.0973
===> Epoch 40 Complete: Avg. Loss: 0.0989
===> Timestamp: [2025-07-29 18:36:11]
Checkpoint saved to TrainedNet/_epoch_40.pth
===> Loading train datasets
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.0970
===> Epoch[41](200/2500): Loss: 0.0974
===> Epoch[41](300/2500): Loss: 0.0975
===> Epoch[41](400/2500): Loss: 0.0974
===> Epoch[41](500/2500): Loss: 0.0967
===> Epoch[41](600/2500): Loss: 0.0970
===> Epoch[41](700/2500): Loss: 0.0968
===> Epoch[41](800/2500): Loss: 0.0971
===> Epoch[41](900/2500): Loss: 0.0965
===> Epoch[41](1000/2500): Loss: 0.0968
===> Epoch[41](1100/2500): Loss: 0.0970
===> Epoch[41](1200/2500): Loss: 0.0972
===> Epoch[41](1300/2500): Loss: 0.0971
===> Epoch[41](1400/2500): Loss: 0.0967
===> Epoch[41](1500/2500): Loss: 0.0972
===> Epoch[41](1600/2500): Loss: 0.0967
===> Epoch[41](1700/2500): Loss: 0.0971
===> Epoch[41](1800/2500): Loss: 0.0972
===> Epoch[41](1900/2500): Loss: 0.0970
===> Epoch[41](2000/2500): Loss: 0.0974
===> Epoch[41](2100/2500): Loss: 0.0977
===> Epoch[41](2200/2500): Loss: 0.0974
===> Epoch[41](2300/2500): Loss: 0.0977
===> Epoch[41](2400/2500): Loss: 0.1036
===> Epoch[41](2500/2500): Loss: 0.0975
===> Epoch 41 Complete: Avg. Loss: 0.0971
===> Timestamp: [2025-07-29 18:41:09]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.0970
===> Epoch[41](200/2500): Loss: 0.0974
===> Epoch[41](300/2500): Loss: 0.0975
===> Epoch[41](400/2500): Loss: 0.0974
===> Epoch[41](500/2500): Loss: 0.0967
===> Epoch[41](600/2500): Loss: 0.0970
===> Epoch[41](700/2500): Loss: 0.0968
===> Epoch[41](800/2500): Loss: 0.0971
===> Epoch[41](900/2500): Loss: 0.0965
===> Epoch[41](1000/2500): Loss: 0.0968
===> Epoch[41](1100/2500): Loss: 0.0970
===> Epoch[41](1200/2500): Loss: 0.0972
===> Epoch[41](1300/2500): Loss: 0.0971
===> Epoch[41](1400/2500): Loss: 0.0967
===> Epoch[41](1500/2500): Loss: 0.0972
===> Epoch[41](1600/2500): Loss: 0.0967
===> Epoch[41](1700/2500): Loss: 0.0971
===> Epoch[41](1800/2500): Loss: 0.0972
===> Epoch[41](1900/2500): Loss: 0.0970
===> Epoch[41](2000/2500): Loss: 0.0974
===> Epoch[41](2100/2500): Loss: 0.0977
===> Epoch[41](2200/2500): Loss: 0.0974
===> Epoch[41](2300/2500): Loss: 0.0977
===> Epoch[41](2400/2500): Loss: 0.1036
===> Epoch[41](2500/2500): Loss: 0.0975
===> Epoch 41 Complete: Avg. Loss: 0.0971
===> Timestamp: [2025-07-29 18:41:09]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.0970
===> Epoch[41](200/2500): Loss: 0.0974
===> Epoch[41](300/2500): Loss: 0.0975
===> Epoch[41](400/2500): Loss: 0.0974
===> Epoch[41](500/2500): Loss: 0.0967
===> Epoch[41](600/2500): Loss: 0.0970
===> Epoch[41](700/2500): Loss: 0.0968
===> Epoch[41](800/2500): Loss: 0.0971
===> Epoch[41](900/2500): Loss: 0.0965
===> Epoch[41](1000/2500): Loss: 0.0968
===> Epoch[41](1100/2500): Loss: 0.0970
===> Epoch[41](1200/2500): Loss: 0.0972
===> Epoch[41](1300/2500): Loss: 0.0971
===> Epoch[41](1400/2500): Loss: 0.0967
===> Epoch[41](1500/2500): Loss: 0.0972
===> Epoch[41](1600/2500): Loss: 0.0967
===> Epoch[41](1700/2500): Loss: 0.0971
===> Epoch[41](1800/2500): Loss: 0.0972
===> Epoch[41](1900/2500): Loss: 0.0970
===> Epoch[41](2000/2500): Loss: 0.0974
===> Epoch[41](2100/2500): Loss: 0.0977
===> Epoch[41](2200/2500): Loss: 0.0974
===> Epoch[41](2300/2500): Loss: 0.0977
===> Epoch[41](2400/2500): Loss: 0.1036
===> Epoch[41](2500/2500): Loss: 0.0975
===> Epoch 41 Complete: Avg. Loss: 0.0971
===> Timestamp: [2025-07-29 18:41:09]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.0970
===> Epoch[41](200/2500): Loss: 0.0974
===> Epoch[41](300/2500): Loss: 0.0975
===> Epoch[41](400/2500): Loss: 0.0974
===> Epoch[41](500/2500): Loss: 0.0967
===> Epoch[41](600/2500): Loss: 0.0970
===> Epoch[41](700/2500): Loss: 0.0968
===> Epoch[41](800/2500): Loss: 0.0971
===> Epoch[41](900/2500): Loss: 0.0965
===> Epoch[41](1000/2500): Loss: 0.0968
===> Epoch[41](1100/2500): Loss: 0.0970
===> Epoch[41](1200/2500): Loss: 0.0972
===> Epoch[41](1300/2500): Loss: 0.0971
===> Epoch[41](1400/2500): Loss: 0.0967
===> Epoch[41](1500/2500): Loss: 0.0972
===> Epoch[41](1600/2500): Loss: 0.0967
===> Epoch[41](1700/2500): Loss: 0.0971
===> Epoch[41](1800/2500): Loss: 0.0972
===> Epoch[41](1900/2500): Loss: 0.0970
===> Epoch[41](2000/2500): Loss: 0.0974
===> Epoch[41](2100/2500): Loss: 0.0977
===> Epoch[41](2200/2500): Loss: 0.0974
===> Epoch[41](2300/2500): Loss: 0.0977
===> Epoch[41](2400/2500): Loss: 0.1036
===> Epoch[41](2500/2500): Loss: 0.0975
===> Epoch 41 Complete: Avg. Loss: 0.0971
===> Timestamp: [2025-07-29 18:41:09]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.0970
===> Epoch[41](200/2500): Loss: 0.0974
===> Epoch[41](300/2500): Loss: 0.0975
===> Epoch[41](400/2500): Loss: 0.0974
===> Epoch[41](500/2500): Loss: 0.0967
===> Epoch[41](600/2500): Loss: 0.0970
===> Epoch[41](700/2500): Loss: 0.0968
===> Epoch[41](800/2500): Loss: 0.0971
===> Epoch[41](900/2500): Loss: 0.0965
===> Epoch[41](1000/2500): Loss: 0.0968
===> Epoch[41](1100/2500): Loss: 0.0970
===> Epoch[41](1200/2500): Loss: 0.0972
===> Epoch[41](1300/2500): Loss: 0.0971
===> Epoch[41](1400/2500): Loss: 0.0967
===> Epoch[41](1500/2500): Loss: 0.0972
===> Epoch[41](1600/2500): Loss: 0.0967
===> Epoch[41](1700/2500): Loss: 0.0971
===> Epoch[41](1800/2500): Loss: 0.0972
===> Epoch[41](1900/2500): Loss: 0.0970
===> Epoch[41](2000/2500): Loss: 0.0974
===> Epoch[41](2100/2500): Loss: 0.0977
===> Epoch[41](2200/2500): Loss: 0.0974
===> Epoch[41](2300/2500): Loss: 0.0977
===> Epoch[41](2400/2500): Loss: 0.1036
===> Epoch[41](2500/2500): Loss: 0.0975
===> Epoch 41 Complete: Avg. Loss: 0.0971
===> Timestamp: [2025-07-29 18:41:09]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.0970
===> Epoch[41](200/2500): Loss: 0.0974
===> Epoch[41](300/2500): Loss: 0.0975
===> Epoch[41](400/2500): Loss: 0.0974
===> Epoch[41](500/2500): Loss: 0.0967
===> Epoch[41](600/2500): Loss: 0.0970
===> Epoch[41](700/2500): Loss: 0.0968
===> Epoch[41](800/2500): Loss: 0.0971
===> Epoch[41](900/2500): Loss: 0.0965
===> Epoch[41](1000/2500): Loss: 0.0968
===> Epoch[41](1100/2500): Loss: 0.0970
===> Epoch[41](1200/2500): Loss: 0.0972
===> Epoch[41](1300/2500): Loss: 0.0971
===> Epoch[41](1400/2500): Loss: 0.0967
===> Epoch[41](1500/2500): Loss: 0.0972
===> Epoch[41](1600/2500): Loss: 0.0967
===> Epoch[41](1700/2500): Loss: 0.0971
===> Epoch[41](1800/2500): Loss: 0.0972
===> Epoch[41](1900/2500): Loss: 0.0970
===> Epoch[41](2000/2500): Loss: 0.0974
===> Epoch[41](2100/2500): Loss: 0.0977
===> Epoch[41](2200/2500): Loss: 0.0974
===> Epoch[41](2300/2500): Loss: 0.0977
===> Epoch[41](2400/2500): Loss: 0.1036
===> Epoch[41](2500/2500): Loss: 0.0975
===> Epoch 41 Complete: Avg. Loss: 0.0971
===> Timestamp: [2025-07-29 18:41:09]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.0970
===> Epoch[41](200/2500): Loss: 0.0974
===> Epoch[41](300/2500): Loss: 0.0975
===> Epoch[41](400/2500): Loss: 0.0974
===> Epoch[41](500/2500): Loss: 0.0967
===> Epoch[41](600/2500): Loss: 0.0970
===> Epoch[41](700/2500): Loss: 0.0968
===> Epoch[41](800/2500): Loss: 0.0971
===> Epoch[41](900/2500): Loss: 0.0965
===> Epoch[41](1000/2500): Loss: 0.0968
===> Epoch[41](1100/2500): Loss: 0.0970
===> Epoch[41](1200/2500): Loss: 0.0972
===> Epoch[41](1300/2500): Loss: 0.0971
===> Epoch[41](1400/2500): Loss: 0.0967
===> Epoch[41](1500/2500): Loss: 0.0972
===> Epoch[41](1600/2500): Loss: 0.0967
===> Epoch[41](1700/2500): Loss: 0.0971
===> Epoch[41](1800/2500): Loss: 0.0972
===> Epoch[41](1900/2500): Loss: 0.0970
===> Epoch[41](2000/2500): Loss: 0.0974
===> Epoch[41](2100/2500): Loss: 0.0977
===> Epoch[41](2200/2500): Loss: 0.0974
===> Epoch[41](2300/2500): Loss: 0.0977
===> Epoch[41](2400/2500): Loss: 0.1036
===> Epoch[41](2500/2500): Loss: 0.0975
===> Epoch 41 Complete: Avg. Loss: 0.0971
===> Timestamp: [2025-07-29 18:41:09]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.0970
===> Epoch[41](200/2500): Loss: 0.0974
===> Epoch[41](300/2500): Loss: 0.0975
===> Epoch[41](400/2500): Loss: 0.0974
===> Epoch[41](500/2500): Loss: 0.0967
===> Epoch[41](600/2500): Loss: 0.0970
===> Epoch[41](700/2500): Loss: 0.0968
===> Epoch[41](800/2500): Loss: 0.0971
===> Epoch[41](900/2500): Loss: 0.0965
===> Epoch[41](1000/2500): Loss: 0.0968
===> Epoch[41](1100/2500): Loss: 0.0970
===> Epoch[41](1200/2500): Loss: 0.0972
===> Epoch[41](1300/2500): Loss: 0.0971
===> Epoch[41](1400/2500): Loss: 0.0967
===> Epoch[41](1500/2500): Loss: 0.0972
===> Epoch[41](1600/2500): Loss: 0.0967
===> Epoch[41](1700/2500): Loss: 0.0971
===> Epoch[41](1800/2500): Loss: 0.0972
===> Epoch[41](1900/2500): Loss: 0.0970
===> Epoch[41](2000/2500): Loss: 0.0974
===> Epoch[41](2100/2500): Loss: 0.0977
===> Epoch[41](2200/2500): Loss: 0.0974
===> Epoch[41](2300/2500): Loss: 0.0977
===> Epoch[41](2400/2500): Loss: 0.1036
===> Epoch[41](2500/2500): Loss: 0.0975
===> Epoch 41 Complete: Avg. Loss: 0.0971
===> Timestamp: [2025-07-29 18:41:09]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.0970
===> Epoch[41](200/2500): Loss: 0.0974
===> Epoch[41](300/2500): Loss: 0.0975
===> Epoch[41](400/2500): Loss: 0.0974
===> Epoch[41](500/2500): Loss: 0.0967
===> Epoch[41](600/2500): Loss: 0.0970
===> Epoch[41](700/2500): Loss: 0.0968
===> Epoch[41](800/2500): Loss: 0.0971
===> Epoch[41](900/2500): Loss: 0.0965
===> Epoch[41](1000/2500): Loss: 0.0968
===> Epoch[41](1100/2500): Loss: 0.0970
===> Epoch[41](1200/2500): Loss: 0.0972
===> Epoch[41](1300/2500): Loss: 0.0971
===> Epoch[41](1400/2500): Loss: 0.0967
===> Epoch[41](1500/2500): Loss: 0.0972
===> Epoch[41](1600/2500): Loss: 0.0967
===> Epoch[41](1700/2500): Loss: 0.0971
===> Epoch[41](1800/2500): Loss: 0.0972
===> Epoch[41](1900/2500): Loss: 0.0970
===> Epoch[41](2000/2500): Loss: 0.0974
===> Epoch[41](2100/2500): Loss: 0.0977
===> Epoch[41](2200/2500): Loss: 0.0974
===> Epoch[41](2300/2500): Loss: 0.0977
===> Epoch[41](2400/2500): Loss: 0.1036
===> Epoch[41](2500/2500): Loss: 0.0975
===> Epoch 41 Complete: Avg. Loss: 0.0971
===> Timestamp: [2025-07-29 18:41:09]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.0970
===> Epoch[41](200/2500): Loss: 0.0974
===> Epoch[41](300/2500): Loss: 0.0975
===> Epoch[41](400/2500): Loss: 0.0974
===> Epoch[41](500/2500): Loss: 0.0967
===> Epoch[41](600/2500): Loss: 0.0970
===> Epoch[41](700/2500): Loss: 0.0968
===> Epoch[41](800/2500): Loss: 0.0971
===> Epoch[41](900/2500): Loss: 0.0965
===> Epoch[41](1000/2500): Loss: 0.0968
===> Epoch[41](1100/2500): Loss: 0.0970
===> Epoch[41](1200/2500): Loss: 0.0972
===> Epoch[41](1300/2500): Loss: 0.0971
===> Epoch[41](1400/2500): Loss: 0.0967
===> Epoch[41](1500/2500): Loss: 0.0972
===> Epoch[41](1600/2500): Loss: 0.0967
===> Epoch[41](1700/2500): Loss: 0.0971
===> Epoch[41](1800/2500): Loss: 0.0972
===> Epoch[41](1900/2500): Loss: 0.0970
===> Epoch[41](2000/2500): Loss: 0.0974
===> Epoch[41](2100/2500): Loss: 0.0977
===> Epoch[41](2200/2500): Loss: 0.0974
===> Epoch[41](2300/2500): Loss: 0.0977
===> Epoch[41](2400/2500): Loss: 0.1036
===> Epoch[41](2500/2500): Loss: 0.0975
===> Epoch 41 Complete: Avg. Loss: 0.0971
===> Timestamp: [2025-07-29 18:41:09]
===> Loading train datasets
===> Epoch[41](100/2500): Loss: 0.0970
===> Epoch[41](200/2500): Loss: 0.0974
===> Epoch[41](300/2500): Loss: 0.0975
===> Epoch[41](400/2500): Loss: 0.0974
===> Epoch[41](500/2500): Loss: 0.0967
===> Epoch[41](600/2500): Loss: 0.0970
===> Epoch[41](700/2500): Loss: 0.0968
===> Epoch[41](800/2500): Loss: 0.0971
===> Epoch[41](900/2500): Loss: 0.0965
===> Epoch[41](1000/2500): Loss: 0.0968
===> Epoch[41](1100/2500): Loss: 0.0970
===> Epoch[41](1200/2500): Loss: 0.0972
===> Epoch[41](1300/2500): Loss: 0.0971
===> Epoch[41](1400/2500): Loss: 0.0967
===> Epoch[41](1500/2500): Loss: 0.0972
===> Epoch[41](1600/2500): Loss: 0.0967
===> Epoch[41](1700/2500): Loss: 0.0971
===> Epoch[41](1800/2500): Loss: 0.0972
===> Epoch[41](1900/2500): Loss: 0.0970
===> Epoch[41](2000/2500): Loss: 0.0974
===> Epoch[41](2100/2500): Loss: 0.0977
===> Epoch[41](2200/2500): Loss: 0.0974
===> Epoch[41](2300/2500): Loss: 0.0977
===> Epoch[41](2400/2500): Loss: 0.1036
===> Epoch[41](2500/2500): Loss: 0.0975
===> Epoch 41 Complete: Avg. Loss: 0.0971
===> Timestamp: [2025-07-29 18:41:09]
===> Loading train datasets
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.0967
===> Epoch[42](200/2500): Loss: 0.0972
===> Epoch[42](300/2500): Loss: 0.0964
===> Epoch[42](400/2500): Loss: 0.0959
===> Epoch[42](500/2500): Loss: 0.0960
===> Epoch[42](600/2500): Loss: 0.0958
===> Epoch[42](700/2500): Loss: 0.0964
===> Epoch[42](800/2500): Loss: 0.0959
===> Epoch[42](900/2500): Loss: 0.0965
===> Epoch[42](1000/2500): Loss: 0.0963
===> Epoch[42](1100/2500): Loss: 0.0960
===> Epoch[42](1200/2500): Loss: 0.0955
===> Epoch[42](1300/2500): Loss: 0.0962
===> Epoch[42](1400/2500): Loss: 0.0960
===> Epoch[42](1500/2500): Loss: 0.0957
===> Epoch[42](1600/2500): Loss: 0.0958
===> Epoch[42](1700/2500): Loss: 0.0971
===> Epoch[42](1800/2500): Loss: 0.0965
===> Epoch[42](1900/2500): Loss: 0.0959
===> Epoch[42](2000/2500): Loss: 0.0965
===> Epoch[42](2100/2500): Loss: 0.0968
===> Epoch[42](2200/2500): Loss: 0.0967
===> Epoch[42](2300/2500): Loss: 0.0959
===> Epoch[42](2400/2500): Loss: 0.0971
===> Epoch[42](2500/2500): Loss: 0.0966
===> Epoch 42 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 18:46:09]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.0967
===> Epoch[42](200/2500): Loss: 0.0972
===> Epoch[42](300/2500): Loss: 0.0964
===> Epoch[42](400/2500): Loss: 0.0959
===> Epoch[42](500/2500): Loss: 0.0960
===> Epoch[42](600/2500): Loss: 0.0958
===> Epoch[42](700/2500): Loss: 0.0964
===> Epoch[42](800/2500): Loss: 0.0959
===> Epoch[42](900/2500): Loss: 0.0965
===> Epoch[42](1000/2500): Loss: 0.0963
===> Epoch[42](1100/2500): Loss: 0.0960
===> Epoch[42](1200/2500): Loss: 0.0955
===> Epoch[42](1300/2500): Loss: 0.0962
===> Epoch[42](1400/2500): Loss: 0.0960
===> Epoch[42](1500/2500): Loss: 0.0957
===> Epoch[42](1600/2500): Loss: 0.0958
===> Epoch[42](1700/2500): Loss: 0.0971
===> Epoch[42](1800/2500): Loss: 0.0965
===> Epoch[42](1900/2500): Loss: 0.0959
===> Epoch[42](2000/2500): Loss: 0.0965
===> Epoch[42](2100/2500): Loss: 0.0968
===> Epoch[42](2200/2500): Loss: 0.0967
===> Epoch[42](2300/2500): Loss: 0.0959
===> Epoch[42](2400/2500): Loss: 0.0971
===> Epoch[42](2500/2500): Loss: 0.0966
===> Epoch 42 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 18:46:09]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.0967
===> Epoch[42](200/2500): Loss: 0.0972
===> Epoch[42](300/2500): Loss: 0.0964
===> Epoch[42](400/2500): Loss: 0.0959
===> Epoch[42](500/2500): Loss: 0.0960
===> Epoch[42](600/2500): Loss: 0.0958
===> Epoch[42](700/2500): Loss: 0.0964
===> Epoch[42](800/2500): Loss: 0.0959
===> Epoch[42](900/2500): Loss: 0.0965
===> Epoch[42](1000/2500): Loss: 0.0963
===> Epoch[42](1100/2500): Loss: 0.0960
===> Epoch[42](1200/2500): Loss: 0.0955
===> Epoch[42](1300/2500): Loss: 0.0962
===> Epoch[42](1400/2500): Loss: 0.0960
===> Epoch[42](1500/2500): Loss: 0.0957
===> Epoch[42](1600/2500): Loss: 0.0958
===> Epoch[42](1700/2500): Loss: 0.0971
===> Epoch[42](1800/2500): Loss: 0.0965
===> Epoch[42](1900/2500): Loss: 0.0959
===> Epoch[42](2000/2500): Loss: 0.0965
===> Epoch[42](2100/2500): Loss: 0.0968
===> Epoch[42](2200/2500): Loss: 0.0967
===> Epoch[42](2300/2500): Loss: 0.0959
===> Epoch[42](2400/2500): Loss: 0.0971
===> Epoch[42](2500/2500): Loss: 0.0966
===> Epoch 42 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 18:46:09]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.0967
===> Epoch[42](200/2500): Loss: 0.0972
===> Epoch[42](300/2500): Loss: 0.0964
===> Epoch[42](400/2500): Loss: 0.0959
===> Epoch[42](500/2500): Loss: 0.0960
===> Epoch[42](600/2500): Loss: 0.0958
===> Epoch[42](700/2500): Loss: 0.0964
===> Epoch[42](800/2500): Loss: 0.0959
===> Epoch[42](900/2500): Loss: 0.0965
===> Epoch[42](1000/2500): Loss: 0.0963
===> Epoch[42](1100/2500): Loss: 0.0960
===> Epoch[42](1200/2500): Loss: 0.0955
===> Epoch[42](1300/2500): Loss: 0.0962
===> Epoch[42](1400/2500): Loss: 0.0960
===> Epoch[42](1500/2500): Loss: 0.0957
===> Epoch[42](1600/2500): Loss: 0.0958
===> Epoch[42](1700/2500): Loss: 0.0971
===> Epoch[42](1800/2500): Loss: 0.0965
===> Epoch[42](1900/2500): Loss: 0.0959
===> Epoch[42](2000/2500): Loss: 0.0965
===> Epoch[42](2100/2500): Loss: 0.0968
===> Epoch[42](2200/2500): Loss: 0.0967
===> Epoch[42](2300/2500): Loss: 0.0959
===> Epoch[42](2400/2500): Loss: 0.0971
===> Epoch[42](2500/2500): Loss: 0.0966
===> Epoch 42 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 18:46:09]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.0967
===> Epoch[42](200/2500): Loss: 0.0972
===> Epoch[42](300/2500): Loss: 0.0964
===> Epoch[42](400/2500): Loss: 0.0959
===> Epoch[42](500/2500): Loss: 0.0960
===> Epoch[42](600/2500): Loss: 0.0958
===> Epoch[42](700/2500): Loss: 0.0964
===> Epoch[42](800/2500): Loss: 0.0959
===> Epoch[42](900/2500): Loss: 0.0965
===> Epoch[42](1000/2500): Loss: 0.0963
===> Epoch[42](1100/2500): Loss: 0.0960
===> Epoch[42](1200/2500): Loss: 0.0955
===> Epoch[42](1300/2500): Loss: 0.0962
===> Epoch[42](1400/2500): Loss: 0.0960
===> Epoch[42](1500/2500): Loss: 0.0957
===> Epoch[42](1600/2500): Loss: 0.0958
===> Epoch[42](1700/2500): Loss: 0.0971
===> Epoch[42](1800/2500): Loss: 0.0965
===> Epoch[42](1900/2500): Loss: 0.0959
===> Epoch[42](2000/2500): Loss: 0.0965
===> Epoch[42](2100/2500): Loss: 0.0968
===> Epoch[42](2200/2500): Loss: 0.0967
===> Epoch[42](2300/2500): Loss: 0.0959
===> Epoch[42](2400/2500): Loss: 0.0971
===> Epoch[42](2500/2500): Loss: 0.0966
===> Epoch 42 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 18:46:09]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.0967
===> Epoch[42](200/2500): Loss: 0.0972
===> Epoch[42](300/2500): Loss: 0.0964
===> Epoch[42](400/2500): Loss: 0.0959
===> Epoch[42](500/2500): Loss: 0.0960
===> Epoch[42](600/2500): Loss: 0.0958
===> Epoch[42](700/2500): Loss: 0.0964
===> Epoch[42](800/2500): Loss: 0.0959
===> Epoch[42](900/2500): Loss: 0.0965
===> Epoch[42](1000/2500): Loss: 0.0963
===> Epoch[42](1100/2500): Loss: 0.0960
===> Epoch[42](1200/2500): Loss: 0.0955
===> Epoch[42](1300/2500): Loss: 0.0962
===> Epoch[42](1400/2500): Loss: 0.0960
===> Epoch[42](1500/2500): Loss: 0.0957
===> Epoch[42](1600/2500): Loss: 0.0958
===> Epoch[42](1700/2500): Loss: 0.0971
===> Epoch[42](1800/2500): Loss: 0.0965
===> Epoch[42](1900/2500): Loss: 0.0959
===> Epoch[42](2000/2500): Loss: 0.0965
===> Epoch[42](2100/2500): Loss: 0.0968
===> Epoch[42](2200/2500): Loss: 0.0967
===> Epoch[42](2300/2500): Loss: 0.0959
===> Epoch[42](2400/2500): Loss: 0.0971
===> Epoch[42](2500/2500): Loss: 0.0966
===> Epoch 42 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 18:46:09]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.0967
===> Epoch[42](200/2500): Loss: 0.0972
===> Epoch[42](300/2500): Loss: 0.0964
===> Epoch[42](400/2500): Loss: 0.0959
===> Epoch[42](500/2500): Loss: 0.0960
===> Epoch[42](600/2500): Loss: 0.0958
===> Epoch[42](700/2500): Loss: 0.0964
===> Epoch[42](800/2500): Loss: 0.0959
===> Epoch[42](900/2500): Loss: 0.0965
===> Epoch[42](1000/2500): Loss: 0.0963
===> Epoch[42](1100/2500): Loss: 0.0960
===> Epoch[42](1200/2500): Loss: 0.0955
===> Epoch[42](1300/2500): Loss: 0.0962
===> Epoch[42](1400/2500): Loss: 0.0960
===> Epoch[42](1500/2500): Loss: 0.0957
===> Epoch[42](1600/2500): Loss: 0.0958
===> Epoch[42](1700/2500): Loss: 0.0971
===> Epoch[42](1800/2500): Loss: 0.0965
===> Epoch[42](1900/2500): Loss: 0.0959
===> Epoch[42](2000/2500): Loss: 0.0965
===> Epoch[42](2100/2500): Loss: 0.0968
===> Epoch[42](2200/2500): Loss: 0.0967
===> Epoch[42](2300/2500): Loss: 0.0959
===> Epoch[42](2400/2500): Loss: 0.0971
===> Epoch[42](2500/2500): Loss: 0.0966
===> Epoch 42 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 18:46:09]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.0967
===> Epoch[42](200/2500): Loss: 0.0972
===> Epoch[42](300/2500): Loss: 0.0964
===> Epoch[42](400/2500): Loss: 0.0959
===> Epoch[42](500/2500): Loss: 0.0960
===> Epoch[42](600/2500): Loss: 0.0958
===> Epoch[42](700/2500): Loss: 0.0964
===> Epoch[42](800/2500): Loss: 0.0959
===> Epoch[42](900/2500): Loss: 0.0965
===> Epoch[42](1000/2500): Loss: 0.0963
===> Epoch[42](1100/2500): Loss: 0.0960
===> Epoch[42](1200/2500): Loss: 0.0955
===> Epoch[42](1300/2500): Loss: 0.0962
===> Epoch[42](1400/2500): Loss: 0.0960
===> Epoch[42](1500/2500): Loss: 0.0957
===> Epoch[42](1600/2500): Loss: 0.0958
===> Epoch[42](1700/2500): Loss: 0.0971
===> Epoch[42](1800/2500): Loss: 0.0965
===> Epoch[42](1900/2500): Loss: 0.0959
===> Epoch[42](2000/2500): Loss: 0.0965
===> Epoch[42](2100/2500): Loss: 0.0968
===> Epoch[42](2200/2500): Loss: 0.0967
===> Epoch[42](2300/2500): Loss: 0.0959
===> Epoch[42](2400/2500): Loss: 0.0971
===> Epoch[42](2500/2500): Loss: 0.0966
===> Epoch 42 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 18:46:09]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.0967
===> Epoch[42](200/2500): Loss: 0.0972
===> Epoch[42](300/2500): Loss: 0.0964
===> Epoch[42](400/2500): Loss: 0.0959
===> Epoch[42](500/2500): Loss: 0.0960
===> Epoch[42](600/2500): Loss: 0.0958
===> Epoch[42](700/2500): Loss: 0.0964
===> Epoch[42](800/2500): Loss: 0.0959
===> Epoch[42](900/2500): Loss: 0.0965
===> Epoch[42](1000/2500): Loss: 0.0963
===> Epoch[42](1100/2500): Loss: 0.0960
===> Epoch[42](1200/2500): Loss: 0.0955
===> Epoch[42](1300/2500): Loss: 0.0962
===> Epoch[42](1400/2500): Loss: 0.0960
===> Epoch[42](1500/2500): Loss: 0.0957
===> Epoch[42](1600/2500): Loss: 0.0958
===> Epoch[42](1700/2500): Loss: 0.0971
===> Epoch[42](1800/2500): Loss: 0.0965
===> Epoch[42](1900/2500): Loss: 0.0959
===> Epoch[42](2000/2500): Loss: 0.0965
===> Epoch[42](2100/2500): Loss: 0.0968
===> Epoch[42](2200/2500): Loss: 0.0967
===> Epoch[42](2300/2500): Loss: 0.0959
===> Epoch[42](2400/2500): Loss: 0.0971
===> Epoch[42](2500/2500): Loss: 0.0966
===> Epoch 42 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 18:46:09]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.0967
===> Epoch[42](200/2500): Loss: 0.0972
===> Epoch[42](300/2500): Loss: 0.0964
===> Epoch[42](400/2500): Loss: 0.0959
===> Epoch[42](500/2500): Loss: 0.0960
===> Epoch[42](600/2500): Loss: 0.0958
===> Epoch[42](700/2500): Loss: 0.0964
===> Epoch[42](800/2500): Loss: 0.0959
===> Epoch[42](900/2500): Loss: 0.0965
===> Epoch[42](1000/2500): Loss: 0.0963
===> Epoch[42](1100/2500): Loss: 0.0960
===> Epoch[42](1200/2500): Loss: 0.0955
===> Epoch[42](1300/2500): Loss: 0.0962
===> Epoch[42](1400/2500): Loss: 0.0960
===> Epoch[42](1500/2500): Loss: 0.0957
===> Epoch[42](1600/2500): Loss: 0.0958
===> Epoch[42](1700/2500): Loss: 0.0971
===> Epoch[42](1800/2500): Loss: 0.0965
===> Epoch[42](1900/2500): Loss: 0.0959
===> Epoch[42](2000/2500): Loss: 0.0965
===> Epoch[42](2100/2500): Loss: 0.0968
===> Epoch[42](2200/2500): Loss: 0.0967
===> Epoch[42](2300/2500): Loss: 0.0959
===> Epoch[42](2400/2500): Loss: 0.0971
===> Epoch[42](2500/2500): Loss: 0.0966
===> Epoch 42 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 18:46:09]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.0967
===> Epoch[42](200/2500): Loss: 0.0972
===> Epoch[42](300/2500): Loss: 0.0964
===> Epoch[42](400/2500): Loss: 0.0959
===> Epoch[42](500/2500): Loss: 0.0960
===> Epoch[42](600/2500): Loss: 0.0958
===> Epoch[42](700/2500): Loss: 0.0964
===> Epoch[42](800/2500): Loss: 0.0959
===> Epoch[42](900/2500): Loss: 0.0965
===> Epoch[42](1000/2500): Loss: 0.0963
===> Epoch[42](1100/2500): Loss: 0.0960
===> Epoch[42](1200/2500): Loss: 0.0955
===> Epoch[42](1300/2500): Loss: 0.0962
===> Epoch[42](1400/2500): Loss: 0.0960
===> Epoch[42](1500/2500): Loss: 0.0957
===> Epoch[42](1600/2500): Loss: 0.0958
===> Epoch[42](1700/2500): Loss: 0.0971
===> Epoch[42](1800/2500): Loss: 0.0965
===> Epoch[42](1900/2500): Loss: 0.0959
===> Epoch[42](2000/2500): Loss: 0.0965
===> Epoch[42](2100/2500): Loss: 0.0968
===> Epoch[42](2200/2500): Loss: 0.0967
===> Epoch[42](2300/2500): Loss: 0.0959
===> Epoch[42](2400/2500): Loss: 0.0971
===> Epoch[42](2500/2500): Loss: 0.0966
===> Epoch 42 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 18:46:09]
===> Loading train datasets
===> Epoch[42](100/2500): Loss: 0.0967
===> Epoch[42](200/2500): Loss: 0.0972
===> Epoch[42](300/2500): Loss: 0.0964
===> Epoch[42](400/2500): Loss: 0.0959
===> Epoch[42](500/2500): Loss: 0.0960
===> Epoch[42](600/2500): Loss: 0.0958
===> Epoch[42](700/2500): Loss: 0.0964
===> Epoch[42](800/2500): Loss: 0.0959
===> Epoch[42](900/2500): Loss: 0.0965
===> Epoch[42](1000/2500): Loss: 0.0963
===> Epoch[42](1100/2500): Loss: 0.0960
===> Epoch[42](1200/2500): Loss: 0.0955
===> Epoch[42](1300/2500): Loss: 0.0962
===> Epoch[42](1400/2500): Loss: 0.0960
===> Epoch[42](1500/2500): Loss: 0.0957
===> Epoch[42](1600/2500): Loss: 0.0958
===> Epoch[42](1700/2500): Loss: 0.0971
===> Epoch[42](1800/2500): Loss: 0.0965
===> Epoch[42](1900/2500): Loss: 0.0959
===> Epoch[42](2000/2500): Loss: 0.0965
===> Epoch[42](2100/2500): Loss: 0.0968
===> Epoch[42](2200/2500): Loss: 0.0967
===> Epoch[42](2300/2500): Loss: 0.0959
===> Epoch[42](2400/2500): Loss: 0.0971
===> Epoch[42](2500/2500): Loss: 0.0966
===> Epoch 42 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 18:46:09]
===> Loading train datasets
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.0967
===> Epoch[43](200/2500): Loss: 0.0959
===> Epoch[43](300/2500): Loss: 0.0966
===> Epoch[43](400/2500): Loss: 0.1032
===> Epoch[43](500/2500): Loss: 0.0966
===> Epoch[43](600/2500): Loss: 0.0963
===> Epoch[43](700/2500): Loss: 0.0963
===> Epoch[43](800/2500): Loss: 0.0968
===> Epoch[43](900/2500): Loss: 0.0960
===> Epoch[43](1000/2500): Loss: 0.0965
===> Epoch[43](1100/2500): Loss: 0.0964
===> Epoch[43](1200/2500): Loss: 0.0963
===> Epoch[43](1300/2500): Loss: 0.0964
===> Epoch[43](1400/2500): Loss: 0.0965
===> Epoch[43](1500/2500): Loss: 0.0959
===> Epoch[43](1600/2500): Loss: 0.0965
===> Epoch[43](1700/2500): Loss: 0.0965
===> Epoch[43](1800/2500): Loss: 0.0964
===> Epoch[43](1900/2500): Loss: 0.0960
===> Epoch[43](2000/2500): Loss: 0.0964
===> Epoch[43](2100/2500): Loss: 0.0961
===> Epoch[43](2200/2500): Loss: 0.0967
===> Epoch[43](2300/2500): Loss: 0.0956
===> Epoch[43](2400/2500): Loss: 0.0963
===> Epoch[43](2500/2500): Loss: 0.0962
===> Epoch 43 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 18:51:08]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.0967
===> Epoch[43](200/2500): Loss: 0.0959
===> Epoch[43](300/2500): Loss: 0.0966
===> Epoch[43](400/2500): Loss: 0.1032
===> Epoch[43](500/2500): Loss: 0.0966
===> Epoch[43](600/2500): Loss: 0.0963
===> Epoch[43](700/2500): Loss: 0.0963
===> Epoch[43](800/2500): Loss: 0.0968
===> Epoch[43](900/2500): Loss: 0.0960
===> Epoch[43](1000/2500): Loss: 0.0965
===> Epoch[43](1100/2500): Loss: 0.0964
===> Epoch[43](1200/2500): Loss: 0.0963
===> Epoch[43](1300/2500): Loss: 0.0964
===> Epoch[43](1400/2500): Loss: 0.0965
===> Epoch[43](1500/2500): Loss: 0.0959
===> Epoch[43](1600/2500): Loss: 0.0965
===> Epoch[43](1700/2500): Loss: 0.0965
===> Epoch[43](1800/2500): Loss: 0.0964
===> Epoch[43](1900/2500): Loss: 0.0960
===> Epoch[43](2000/2500): Loss: 0.0964
===> Epoch[43](2100/2500): Loss: 0.0961
===> Epoch[43](2200/2500): Loss: 0.0967
===> Epoch[43](2300/2500): Loss: 0.0956
===> Epoch[43](2400/2500): Loss: 0.0963
===> Epoch[43](2500/2500): Loss: 0.0962
===> Epoch 43 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 18:51:08]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.0967
===> Epoch[43](200/2500): Loss: 0.0959
===> Epoch[43](300/2500): Loss: 0.0966
===> Epoch[43](400/2500): Loss: 0.1032
===> Epoch[43](500/2500): Loss: 0.0966
===> Epoch[43](600/2500): Loss: 0.0963
===> Epoch[43](700/2500): Loss: 0.0963
===> Epoch[43](800/2500): Loss: 0.0968
===> Epoch[43](900/2500): Loss: 0.0960
===> Epoch[43](1000/2500): Loss: 0.0965
===> Epoch[43](1100/2500): Loss: 0.0964
===> Epoch[43](1200/2500): Loss: 0.0963
===> Epoch[43](1300/2500): Loss: 0.0964
===> Epoch[43](1400/2500): Loss: 0.0965
===> Epoch[43](1500/2500): Loss: 0.0959
===> Epoch[43](1600/2500): Loss: 0.0965
===> Epoch[43](1700/2500): Loss: 0.0965
===> Epoch[43](1800/2500): Loss: 0.0964
===> Epoch[43](1900/2500): Loss: 0.0960
===> Epoch[43](2000/2500): Loss: 0.0964
===> Epoch[43](2100/2500): Loss: 0.0961
===> Epoch[43](2200/2500): Loss: 0.0967
===> Epoch[43](2300/2500): Loss: 0.0956
===> Epoch[43](2400/2500): Loss: 0.0963
===> Epoch[43](2500/2500): Loss: 0.0962
===> Epoch 43 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 18:51:08]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.0967
===> Epoch[43](200/2500): Loss: 0.0959
===> Epoch[43](300/2500): Loss: 0.0966
===> Epoch[43](400/2500): Loss: 0.1032
===> Epoch[43](500/2500): Loss: 0.0966
===> Epoch[43](600/2500): Loss: 0.0963
===> Epoch[43](700/2500): Loss: 0.0963
===> Epoch[43](800/2500): Loss: 0.0968
===> Epoch[43](900/2500): Loss: 0.0960
===> Epoch[43](1000/2500): Loss: 0.0965
===> Epoch[43](1100/2500): Loss: 0.0964
===> Epoch[43](1200/2500): Loss: 0.0963
===> Epoch[43](1300/2500): Loss: 0.0964
===> Epoch[43](1400/2500): Loss: 0.0965
===> Epoch[43](1500/2500): Loss: 0.0959
===> Epoch[43](1600/2500): Loss: 0.0965
===> Epoch[43](1700/2500): Loss: 0.0965
===> Epoch[43](1800/2500): Loss: 0.0964
===> Epoch[43](1900/2500): Loss: 0.0960
===> Epoch[43](2000/2500): Loss: 0.0964
===> Epoch[43](2100/2500): Loss: 0.0961
===> Epoch[43](2200/2500): Loss: 0.0967
===> Epoch[43](2300/2500): Loss: 0.0956
===> Epoch[43](2400/2500): Loss: 0.0963
===> Epoch[43](2500/2500): Loss: 0.0962
===> Epoch 43 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 18:51:08]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.0967
===> Epoch[43](200/2500): Loss: 0.0959
===> Epoch[43](300/2500): Loss: 0.0966
===> Epoch[43](400/2500): Loss: 0.1032
===> Epoch[43](500/2500): Loss: 0.0966
===> Epoch[43](600/2500): Loss: 0.0963
===> Epoch[43](700/2500): Loss: 0.0963
===> Epoch[43](800/2500): Loss: 0.0968
===> Epoch[43](900/2500): Loss: 0.0960
===> Epoch[43](1000/2500): Loss: 0.0965
===> Epoch[43](1100/2500): Loss: 0.0964
===> Epoch[43](1200/2500): Loss: 0.0963
===> Epoch[43](1300/2500): Loss: 0.0964
===> Epoch[43](1400/2500): Loss: 0.0965
===> Epoch[43](1500/2500): Loss: 0.0959
===> Epoch[43](1600/2500): Loss: 0.0965
===> Epoch[43](1700/2500): Loss: 0.0965
===> Epoch[43](1800/2500): Loss: 0.0964
===> Epoch[43](1900/2500): Loss: 0.0960
===> Epoch[43](2000/2500): Loss: 0.0964
===> Epoch[43](2100/2500): Loss: 0.0961
===> Epoch[43](2200/2500): Loss: 0.0967
===> Epoch[43](2300/2500): Loss: 0.0956
===> Epoch[43](2400/2500): Loss: 0.0963
===> Epoch[43](2500/2500): Loss: 0.0962
===> Epoch 43 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 18:51:08]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.0967
===> Epoch[43](200/2500): Loss: 0.0959
===> Epoch[43](300/2500): Loss: 0.0966
===> Epoch[43](400/2500): Loss: 0.1032
===> Epoch[43](500/2500): Loss: 0.0966
===> Epoch[43](600/2500): Loss: 0.0963
===> Epoch[43](700/2500): Loss: 0.0963
===> Epoch[43](800/2500): Loss: 0.0968
===> Epoch[43](900/2500): Loss: 0.0960
===> Epoch[43](1000/2500): Loss: 0.0965
===> Epoch[43](1100/2500): Loss: 0.0964
===> Epoch[43](1200/2500): Loss: 0.0963
===> Epoch[43](1300/2500): Loss: 0.0964
===> Epoch[43](1400/2500): Loss: 0.0965
===> Epoch[43](1500/2500): Loss: 0.0959
===> Epoch[43](1600/2500): Loss: 0.0965
===> Epoch[43](1700/2500): Loss: 0.0965
===> Epoch[43](1800/2500): Loss: 0.0964
===> Epoch[43](1900/2500): Loss: 0.0960
===> Epoch[43](2000/2500): Loss: 0.0964
===> Epoch[43](2100/2500): Loss: 0.0961
===> Epoch[43](2200/2500): Loss: 0.0967
===> Epoch[43](2300/2500): Loss: 0.0956
===> Epoch[43](2400/2500): Loss: 0.0963
===> Epoch[43](2500/2500): Loss: 0.0962
===> Epoch 43 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 18:51:08]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.0967
===> Epoch[43](200/2500): Loss: 0.0959
===> Epoch[43](300/2500): Loss: 0.0966
===> Epoch[43](400/2500): Loss: 0.1032
===> Epoch[43](500/2500): Loss: 0.0966
===> Epoch[43](600/2500): Loss: 0.0963
===> Epoch[43](700/2500): Loss: 0.0963
===> Epoch[43](800/2500): Loss: 0.0968
===> Epoch[43](900/2500): Loss: 0.0960
===> Epoch[43](1000/2500): Loss: 0.0965
===> Epoch[43](1100/2500): Loss: 0.0964
===> Epoch[43](1200/2500): Loss: 0.0963
===> Epoch[43](1300/2500): Loss: 0.0964
===> Epoch[43](1400/2500): Loss: 0.0965
===> Epoch[43](1500/2500): Loss: 0.0959
===> Epoch[43](1600/2500): Loss: 0.0965
===> Epoch[43](1700/2500): Loss: 0.0965
===> Epoch[43](1800/2500): Loss: 0.0964
===> Epoch[43](1900/2500): Loss: 0.0960
===> Epoch[43](2000/2500): Loss: 0.0964
===> Epoch[43](2100/2500): Loss: 0.0961
===> Epoch[43](2200/2500): Loss: 0.0967
===> Epoch[43](2300/2500): Loss: 0.0956
===> Epoch[43](2400/2500): Loss: 0.0963
===> Epoch[43](2500/2500): Loss: 0.0962
===> Epoch 43 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 18:51:08]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.0967
===> Epoch[43](200/2500): Loss: 0.0959
===> Epoch[43](300/2500): Loss: 0.0966
===> Epoch[43](400/2500): Loss: 0.1032
===> Epoch[43](500/2500): Loss: 0.0966
===> Epoch[43](600/2500): Loss: 0.0963
===> Epoch[43](700/2500): Loss: 0.0963
===> Epoch[43](800/2500): Loss: 0.0968
===> Epoch[43](900/2500): Loss: 0.0960
===> Epoch[43](1000/2500): Loss: 0.0965
===> Epoch[43](1100/2500): Loss: 0.0964
===> Epoch[43](1200/2500): Loss: 0.0963
===> Epoch[43](1300/2500): Loss: 0.0964
===> Epoch[43](1400/2500): Loss: 0.0965
===> Epoch[43](1500/2500): Loss: 0.0959
===> Epoch[43](1600/2500): Loss: 0.0965
===> Epoch[43](1700/2500): Loss: 0.0965
===> Epoch[43](1800/2500): Loss: 0.0964
===> Epoch[43](1900/2500): Loss: 0.0960
===> Epoch[43](2000/2500): Loss: 0.0964
===> Epoch[43](2100/2500): Loss: 0.0961
===> Epoch[43](2200/2500): Loss: 0.0967
===> Epoch[43](2300/2500): Loss: 0.0956
===> Epoch[43](2400/2500): Loss: 0.0963
===> Epoch[43](2500/2500): Loss: 0.0962
===> Epoch 43 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 18:51:08]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.0967
===> Epoch[43](200/2500): Loss: 0.0959
===> Epoch[43](300/2500): Loss: 0.0966
===> Epoch[43](400/2500): Loss: 0.1032
===> Epoch[43](500/2500): Loss: 0.0966
===> Epoch[43](600/2500): Loss: 0.0963
===> Epoch[43](700/2500): Loss: 0.0963
===> Epoch[43](800/2500): Loss: 0.0968
===> Epoch[43](900/2500): Loss: 0.0960
===> Epoch[43](1000/2500): Loss: 0.0965
===> Epoch[43](1100/2500): Loss: 0.0964
===> Epoch[43](1200/2500): Loss: 0.0963
===> Epoch[43](1300/2500): Loss: 0.0964
===> Epoch[43](1400/2500): Loss: 0.0965
===> Epoch[43](1500/2500): Loss: 0.0959
===> Epoch[43](1600/2500): Loss: 0.0965
===> Epoch[43](1700/2500): Loss: 0.0965
===> Epoch[43](1800/2500): Loss: 0.0964
===> Epoch[43](1900/2500): Loss: 0.0960
===> Epoch[43](2000/2500): Loss: 0.0964
===> Epoch[43](2100/2500): Loss: 0.0961
===> Epoch[43](2200/2500): Loss: 0.0967
===> Epoch[43](2300/2500): Loss: 0.0956
===> Epoch[43](2400/2500): Loss: 0.0963
===> Epoch[43](2500/2500): Loss: 0.0962
===> Epoch 43 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 18:51:08]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.0967
===> Epoch[43](200/2500): Loss: 0.0959
===> Epoch[43](300/2500): Loss: 0.0966
===> Epoch[43](400/2500): Loss: 0.1032
===> Epoch[43](500/2500): Loss: 0.0966
===> Epoch[43](600/2500): Loss: 0.0963
===> Epoch[43](700/2500): Loss: 0.0963
===> Epoch[43](800/2500): Loss: 0.0968
===> Epoch[43](900/2500): Loss: 0.0960
===> Epoch[43](1000/2500): Loss: 0.0965
===> Epoch[43](1100/2500): Loss: 0.0964
===> Epoch[43](1200/2500): Loss: 0.0963
===> Epoch[43](1300/2500): Loss: 0.0964
===> Epoch[43](1400/2500): Loss: 0.0965
===> Epoch[43](1500/2500): Loss: 0.0959
===> Epoch[43](1600/2500): Loss: 0.0965
===> Epoch[43](1700/2500): Loss: 0.0965
===> Epoch[43](1800/2500): Loss: 0.0964
===> Epoch[43](1900/2500): Loss: 0.0960
===> Epoch[43](2000/2500): Loss: 0.0964
===> Epoch[43](2100/2500): Loss: 0.0961
===> Epoch[43](2200/2500): Loss: 0.0967
===> Epoch[43](2300/2500): Loss: 0.0956
===> Epoch[43](2400/2500): Loss: 0.0963
===> Epoch[43](2500/2500): Loss: 0.0962
===> Epoch 43 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 18:51:08]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.0967
===> Epoch[43](200/2500): Loss: 0.0959
===> Epoch[43](300/2500): Loss: 0.0966
===> Epoch[43](400/2500): Loss: 0.1032
===> Epoch[43](500/2500): Loss: 0.0966
===> Epoch[43](600/2500): Loss: 0.0963
===> Epoch[43](700/2500): Loss: 0.0963
===> Epoch[43](800/2500): Loss: 0.0968
===> Epoch[43](900/2500): Loss: 0.0960
===> Epoch[43](1000/2500): Loss: 0.0965
===> Epoch[43](1100/2500): Loss: 0.0964
===> Epoch[43](1200/2500): Loss: 0.0963
===> Epoch[43](1300/2500): Loss: 0.0964
===> Epoch[43](1400/2500): Loss: 0.0965
===> Epoch[43](1500/2500): Loss: 0.0959
===> Epoch[43](1600/2500): Loss: 0.0965
===> Epoch[43](1700/2500): Loss: 0.0965
===> Epoch[43](1800/2500): Loss: 0.0964
===> Epoch[43](1900/2500): Loss: 0.0960
===> Epoch[43](2000/2500): Loss: 0.0964
===> Epoch[43](2100/2500): Loss: 0.0961
===> Epoch[43](2200/2500): Loss: 0.0967
===> Epoch[43](2300/2500): Loss: 0.0956
===> Epoch[43](2400/2500): Loss: 0.0963
===> Epoch[43](2500/2500): Loss: 0.0962
===> Epoch 43 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 18:51:08]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.0967
===> Epoch[43](200/2500): Loss: 0.0959
===> Epoch[43](300/2500): Loss: 0.0966
===> Epoch[43](400/2500): Loss: 0.1032
===> Epoch[43](500/2500): Loss: 0.0966
===> Epoch[43](600/2500): Loss: 0.0963
===> Epoch[43](700/2500): Loss: 0.0963
===> Epoch[43](800/2500): Loss: 0.0968
===> Epoch[43](900/2500): Loss: 0.0960
===> Epoch[43](1000/2500): Loss: 0.0965
===> Epoch[43](1100/2500): Loss: 0.0964
===> Epoch[43](1200/2500): Loss: 0.0963
===> Epoch[43](1300/2500): Loss: 0.0964
===> Epoch[43](1400/2500): Loss: 0.0965
===> Epoch[43](1500/2500): Loss: 0.0959
===> Epoch[43](1600/2500): Loss: 0.0965
===> Epoch[43](1700/2500): Loss: 0.0965
===> Epoch[43](1800/2500): Loss: 0.0964
===> Epoch[43](1900/2500): Loss: 0.0960
===> Epoch[43](2000/2500): Loss: 0.0964
===> Epoch[43](2100/2500): Loss: 0.0961
===> Epoch[43](2200/2500): Loss: 0.0967
===> Epoch[43](2300/2500): Loss: 0.0956
===> Epoch[43](2400/2500): Loss: 0.0963
===> Epoch[43](2500/2500): Loss: 0.0962
===> Epoch 43 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 18:51:08]
===> Loading train datasets
===> Epoch[43](100/2500): Loss: 0.0967
===> Epoch[43](200/2500): Loss: 0.0959
===> Epoch[43](300/2500): Loss: 0.0966
===> Epoch[43](400/2500): Loss: 0.1032
===> Epoch[43](500/2500): Loss: 0.0966
===> Epoch[43](600/2500): Loss: 0.0963
===> Epoch[43](700/2500): Loss: 0.0963
===> Epoch[43](800/2500): Loss: 0.0968
===> Epoch[43](900/2500): Loss: 0.0960
===> Epoch[43](1000/2500): Loss: 0.0965
===> Epoch[43](1100/2500): Loss: 0.0964
===> Epoch[43](1200/2500): Loss: 0.0963
===> Epoch[43](1300/2500): Loss: 0.0964
===> Epoch[43](1400/2500): Loss: 0.0965
===> Epoch[43](1500/2500): Loss: 0.0959
===> Epoch[43](1600/2500): Loss: 0.0965
===> Epoch[43](1700/2500): Loss: 0.0965
===> Epoch[43](1800/2500): Loss: 0.0964
===> Epoch[43](1900/2500): Loss: 0.0960
===> Epoch[43](2000/2500): Loss: 0.0964
===> Epoch[43](2100/2500): Loss: 0.0961
===> Epoch[43](2200/2500): Loss: 0.0967
===> Epoch[43](2300/2500): Loss: 0.0956
===> Epoch[43](2400/2500): Loss: 0.0963
===> Epoch[43](2500/2500): Loss: 0.0962
===> Epoch 43 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 18:51:08]
===> Loading train datasets
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.0962
===> Epoch[44](200/2500): Loss: 0.0965
===> Epoch[44](300/2500): Loss: 0.0958
===> Epoch[44](400/2500): Loss: 0.0965
===> Epoch[44](500/2500): Loss: 0.0961
===> Epoch[44](600/2500): Loss: 0.0959
===> Epoch[44](700/2500): Loss: 0.0955
===> Epoch[44](800/2500): Loss: 0.0959
===> Epoch[44](900/2500): Loss: 0.0960
===> Epoch[44](1000/2500): Loss: 0.0963
===> Epoch[44](1100/2500): Loss: 0.0994
===> Epoch[44](1200/2500): Loss: 0.0965
===> Epoch[44](1300/2500): Loss: 0.0964
===> Epoch[44](1400/2500): Loss: 0.0960
===> Epoch[44](1500/2500): Loss: 0.0960
===> Epoch[44](1600/2500): Loss: 0.0963
===> Epoch[44](1700/2500): Loss: 0.0962
===> Epoch[44](1800/2500): Loss: 0.0959
===> Epoch[44](1900/2500): Loss: 0.0964
===> Epoch[44](2000/2500): Loss: 0.0958
===> Epoch[44](2100/2500): Loss: 0.0968
===> Epoch[44](2200/2500): Loss: 0.0958
===> Epoch[44](2300/2500): Loss: 0.0968
===> Epoch[44](2400/2500): Loss: 0.0961
===> Epoch[44](2500/2500): Loss: 0.0960
===> Epoch 44 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 18:56:07]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.0962
===> Epoch[44](200/2500): Loss: 0.0965
===> Epoch[44](300/2500): Loss: 0.0958
===> Epoch[44](400/2500): Loss: 0.0965
===> Epoch[44](500/2500): Loss: 0.0961
===> Epoch[44](600/2500): Loss: 0.0959
===> Epoch[44](700/2500): Loss: 0.0955
===> Epoch[44](800/2500): Loss: 0.0959
===> Epoch[44](900/2500): Loss: 0.0960
===> Epoch[44](1000/2500): Loss: 0.0963
===> Epoch[44](1100/2500): Loss: 0.0994
===> Epoch[44](1200/2500): Loss: 0.0965
===> Epoch[44](1300/2500): Loss: 0.0964
===> Epoch[44](1400/2500): Loss: 0.0960
===> Epoch[44](1500/2500): Loss: 0.0960
===> Epoch[44](1600/2500): Loss: 0.0963
===> Epoch[44](1700/2500): Loss: 0.0962
===> Epoch[44](1800/2500): Loss: 0.0959
===> Epoch[44](1900/2500): Loss: 0.0964
===> Epoch[44](2000/2500): Loss: 0.0958
===> Epoch[44](2100/2500): Loss: 0.0968
===> Epoch[44](2200/2500): Loss: 0.0958
===> Epoch[44](2300/2500): Loss: 0.0968
===> Epoch[44](2400/2500): Loss: 0.0961
===> Epoch[44](2500/2500): Loss: 0.0960
===> Epoch 44 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 18:56:07]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.0962
===> Epoch[44](200/2500): Loss: 0.0965
===> Epoch[44](300/2500): Loss: 0.0958
===> Epoch[44](400/2500): Loss: 0.0965
===> Epoch[44](500/2500): Loss: 0.0961
===> Epoch[44](600/2500): Loss: 0.0959
===> Epoch[44](700/2500): Loss: 0.0955
===> Epoch[44](800/2500): Loss: 0.0959
===> Epoch[44](900/2500): Loss: 0.0960
===> Epoch[44](1000/2500): Loss: 0.0963
===> Epoch[44](1100/2500): Loss: 0.0994
===> Epoch[44](1200/2500): Loss: 0.0965
===> Epoch[44](1300/2500): Loss: 0.0964
===> Epoch[44](1400/2500): Loss: 0.0960
===> Epoch[44](1500/2500): Loss: 0.0960
===> Epoch[44](1600/2500): Loss: 0.0963
===> Epoch[44](1700/2500): Loss: 0.0962
===> Epoch[44](1800/2500): Loss: 0.0959
===> Epoch[44](1900/2500): Loss: 0.0964
===> Epoch[44](2000/2500): Loss: 0.0958
===> Epoch[44](2100/2500): Loss: 0.0968
===> Epoch[44](2200/2500): Loss: 0.0958
===> Epoch[44](2300/2500): Loss: 0.0968
===> Epoch[44](2400/2500): Loss: 0.0961
===> Epoch[44](2500/2500): Loss: 0.0960
===> Epoch 44 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 18:56:07]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.0962
===> Epoch[44](200/2500): Loss: 0.0965
===> Epoch[44](300/2500): Loss: 0.0958
===> Epoch[44](400/2500): Loss: 0.0965
===> Epoch[44](500/2500): Loss: 0.0961
===> Epoch[44](600/2500): Loss: 0.0959
===> Epoch[44](700/2500): Loss: 0.0955
===> Epoch[44](800/2500): Loss: 0.0959
===> Epoch[44](900/2500): Loss: 0.0960
===> Epoch[44](1000/2500): Loss: 0.0963
===> Epoch[44](1100/2500): Loss: 0.0994
===> Epoch[44](1200/2500): Loss: 0.0965
===> Epoch[44](1300/2500): Loss: 0.0964
===> Epoch[44](1400/2500): Loss: 0.0960
===> Epoch[44](1500/2500): Loss: 0.0960
===> Epoch[44](1600/2500): Loss: 0.0963
===> Epoch[44](1700/2500): Loss: 0.0962
===> Epoch[44](1800/2500): Loss: 0.0959
===> Epoch[44](1900/2500): Loss: 0.0964
===> Epoch[44](2000/2500): Loss: 0.0958
===> Epoch[44](2100/2500): Loss: 0.0968
===> Epoch[44](2200/2500): Loss: 0.0958
===> Epoch[44](2300/2500): Loss: 0.0968
===> Epoch[44](2400/2500): Loss: 0.0961
===> Epoch[44](2500/2500): Loss: 0.0960
===> Epoch 44 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 18:56:07]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.0962
===> Epoch[44](200/2500): Loss: 0.0965
===> Epoch[44](300/2500): Loss: 0.0958
===> Epoch[44](400/2500): Loss: 0.0965
===> Epoch[44](500/2500): Loss: 0.0961
===> Epoch[44](600/2500): Loss: 0.0959
===> Epoch[44](700/2500): Loss: 0.0955
===> Epoch[44](800/2500): Loss: 0.0959
===> Epoch[44](900/2500): Loss: 0.0960
===> Epoch[44](1000/2500): Loss: 0.0963
===> Epoch[44](1100/2500): Loss: 0.0994
===> Epoch[44](1200/2500): Loss: 0.0965
===> Epoch[44](1300/2500): Loss: 0.0964
===> Epoch[44](1400/2500): Loss: 0.0960
===> Epoch[44](1500/2500): Loss: 0.0960
===> Epoch[44](1600/2500): Loss: 0.0963
===> Epoch[44](1700/2500): Loss: 0.0962
===> Epoch[44](1800/2500): Loss: 0.0959
===> Epoch[44](1900/2500): Loss: 0.0964
===> Epoch[44](2000/2500): Loss: 0.0958
===> Epoch[44](2100/2500): Loss: 0.0968
===> Epoch[44](2200/2500): Loss: 0.0958
===> Epoch[44](2300/2500): Loss: 0.0968
===> Epoch[44](2400/2500): Loss: 0.0961
===> Epoch[44](2500/2500): Loss: 0.0960
===> Epoch 44 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 18:56:07]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.0962
===> Epoch[44](200/2500): Loss: 0.0965
===> Epoch[44](300/2500): Loss: 0.0958
===> Epoch[44](400/2500): Loss: 0.0965
===> Epoch[44](500/2500): Loss: 0.0961
===> Epoch[44](600/2500): Loss: 0.0959
===> Epoch[44](700/2500): Loss: 0.0955
===> Epoch[44](800/2500): Loss: 0.0959
===> Epoch[44](900/2500): Loss: 0.0960
===> Epoch[44](1000/2500): Loss: 0.0963
===> Epoch[44](1100/2500): Loss: 0.0994
===> Epoch[44](1200/2500): Loss: 0.0965
===> Epoch[44](1300/2500): Loss: 0.0964
===> Epoch[44](1400/2500): Loss: 0.0960
===> Epoch[44](1500/2500): Loss: 0.0960
===> Epoch[44](1600/2500): Loss: 0.0963
===> Epoch[44](1700/2500): Loss: 0.0962
===> Epoch[44](1800/2500): Loss: 0.0959
===> Epoch[44](1900/2500): Loss: 0.0964
===> Epoch[44](2000/2500): Loss: 0.0958
===> Epoch[44](2100/2500): Loss: 0.0968
===> Epoch[44](2200/2500): Loss: 0.0958
===> Epoch[44](2300/2500): Loss: 0.0968
===> Epoch[44](2400/2500): Loss: 0.0961
===> Epoch[44](2500/2500): Loss: 0.0960
===> Epoch 44 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 18:56:07]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.0962
===> Epoch[44](200/2500): Loss: 0.0965
===> Epoch[44](300/2500): Loss: 0.0958
===> Epoch[44](400/2500): Loss: 0.0965
===> Epoch[44](500/2500): Loss: 0.0961
===> Epoch[44](600/2500): Loss: 0.0959
===> Epoch[44](700/2500): Loss: 0.0955
===> Epoch[44](800/2500): Loss: 0.0959
===> Epoch[44](900/2500): Loss: 0.0960
===> Epoch[44](1000/2500): Loss: 0.0963
===> Epoch[44](1100/2500): Loss: 0.0994
===> Epoch[44](1200/2500): Loss: 0.0965
===> Epoch[44](1300/2500): Loss: 0.0964
===> Epoch[44](1400/2500): Loss: 0.0960
===> Epoch[44](1500/2500): Loss: 0.0960
===> Epoch[44](1600/2500): Loss: 0.0963
===> Epoch[44](1700/2500): Loss: 0.0962
===> Epoch[44](1800/2500): Loss: 0.0959
===> Epoch[44](1900/2500): Loss: 0.0964
===> Epoch[44](2000/2500): Loss: 0.0958
===> Epoch[44](2100/2500): Loss: 0.0968
===> Epoch[44](2200/2500): Loss: 0.0958
===> Epoch[44](2300/2500): Loss: 0.0968
===> Epoch[44](2400/2500): Loss: 0.0961
===> Epoch[44](2500/2500): Loss: 0.0960
===> Epoch 44 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 18:56:07]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.0962
===> Epoch[44](200/2500): Loss: 0.0965
===> Epoch[44](300/2500): Loss: 0.0958
===> Epoch[44](400/2500): Loss: 0.0965
===> Epoch[44](500/2500): Loss: 0.0961
===> Epoch[44](600/2500): Loss: 0.0959
===> Epoch[44](700/2500): Loss: 0.0955
===> Epoch[44](800/2500): Loss: 0.0959
===> Epoch[44](900/2500): Loss: 0.0960
===> Epoch[44](1000/2500): Loss: 0.0963
===> Epoch[44](1100/2500): Loss: 0.0994
===> Epoch[44](1200/2500): Loss: 0.0965
===> Epoch[44](1300/2500): Loss: 0.0964
===> Epoch[44](1400/2500): Loss: 0.0960
===> Epoch[44](1500/2500): Loss: 0.0960
===> Epoch[44](1600/2500): Loss: 0.0963
===> Epoch[44](1700/2500): Loss: 0.0962
===> Epoch[44](1800/2500): Loss: 0.0959
===> Epoch[44](1900/2500): Loss: 0.0964
===> Epoch[44](2000/2500): Loss: 0.0958
===> Epoch[44](2100/2500): Loss: 0.0968
===> Epoch[44](2200/2500): Loss: 0.0958
===> Epoch[44](2300/2500): Loss: 0.0968
===> Epoch[44](2400/2500): Loss: 0.0961
===> Epoch[44](2500/2500): Loss: 0.0960
===> Epoch 44 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 18:56:07]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.0962
===> Epoch[44](200/2500): Loss: 0.0965
===> Epoch[44](300/2500): Loss: 0.0958
===> Epoch[44](400/2500): Loss: 0.0965
===> Epoch[44](500/2500): Loss: 0.0961
===> Epoch[44](600/2500): Loss: 0.0959
===> Epoch[44](700/2500): Loss: 0.0955
===> Epoch[44](800/2500): Loss: 0.0959
===> Epoch[44](900/2500): Loss: 0.0960
===> Epoch[44](1000/2500): Loss: 0.0963
===> Epoch[44](1100/2500): Loss: 0.0994
===> Epoch[44](1200/2500): Loss: 0.0965
===> Epoch[44](1300/2500): Loss: 0.0964
===> Epoch[44](1400/2500): Loss: 0.0960
===> Epoch[44](1500/2500): Loss: 0.0960
===> Epoch[44](1600/2500): Loss: 0.0963
===> Epoch[44](1700/2500): Loss: 0.0962
===> Epoch[44](1800/2500): Loss: 0.0959
===> Epoch[44](1900/2500): Loss: 0.0964
===> Epoch[44](2000/2500): Loss: 0.0958
===> Epoch[44](2100/2500): Loss: 0.0968
===> Epoch[44](2200/2500): Loss: 0.0958
===> Epoch[44](2300/2500): Loss: 0.0968
===> Epoch[44](2400/2500): Loss: 0.0961
===> Epoch[44](2500/2500): Loss: 0.0960
===> Epoch 44 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 18:56:07]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.0962
===> Epoch[44](200/2500): Loss: 0.0965
===> Epoch[44](300/2500): Loss: 0.0958
===> Epoch[44](400/2500): Loss: 0.0965
===> Epoch[44](500/2500): Loss: 0.0961
===> Epoch[44](600/2500): Loss: 0.0959
===> Epoch[44](700/2500): Loss: 0.0955
===> Epoch[44](800/2500): Loss: 0.0959
===> Epoch[44](900/2500): Loss: 0.0960
===> Epoch[44](1000/2500): Loss: 0.0963
===> Epoch[44](1100/2500): Loss: 0.0994
===> Epoch[44](1200/2500): Loss: 0.0965
===> Epoch[44](1300/2500): Loss: 0.0964
===> Epoch[44](1400/2500): Loss: 0.0960
===> Epoch[44](1500/2500): Loss: 0.0960
===> Epoch[44](1600/2500): Loss: 0.0963
===> Epoch[44](1700/2500): Loss: 0.0962
===> Epoch[44](1800/2500): Loss: 0.0959
===> Epoch[44](1900/2500): Loss: 0.0964
===> Epoch[44](2000/2500): Loss: 0.0958
===> Epoch[44](2100/2500): Loss: 0.0968
===> Epoch[44](2200/2500): Loss: 0.0958
===> Epoch[44](2300/2500): Loss: 0.0968
===> Epoch[44](2400/2500): Loss: 0.0961
===> Epoch[44](2500/2500): Loss: 0.0960
===> Epoch 44 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 18:56:07]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.0962
===> Epoch[44](200/2500): Loss: 0.0965
===> Epoch[44](300/2500): Loss: 0.0958
===> Epoch[44](400/2500): Loss: 0.0965
===> Epoch[44](500/2500): Loss: 0.0961
===> Epoch[44](600/2500): Loss: 0.0959
===> Epoch[44](700/2500): Loss: 0.0955
===> Epoch[44](800/2500): Loss: 0.0959
===> Epoch[44](900/2500): Loss: 0.0960
===> Epoch[44](1000/2500): Loss: 0.0963
===> Epoch[44](1100/2500): Loss: 0.0994
===> Epoch[44](1200/2500): Loss: 0.0965
===> Epoch[44](1300/2500): Loss: 0.0964
===> Epoch[44](1400/2500): Loss: 0.0960
===> Epoch[44](1500/2500): Loss: 0.0960
===> Epoch[44](1600/2500): Loss: 0.0963
===> Epoch[44](1700/2500): Loss: 0.0962
===> Epoch[44](1800/2500): Loss: 0.0959
===> Epoch[44](1900/2500): Loss: 0.0964
===> Epoch[44](2000/2500): Loss: 0.0958
===> Epoch[44](2100/2500): Loss: 0.0968
===> Epoch[44](2200/2500): Loss: 0.0958
===> Epoch[44](2300/2500): Loss: 0.0968
===> Epoch[44](2400/2500): Loss: 0.0961
===> Epoch[44](2500/2500): Loss: 0.0960
===> Epoch 44 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 18:56:07]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.0962
===> Epoch[44](200/2500): Loss: 0.0965
===> Epoch[44](300/2500): Loss: 0.0958
===> Epoch[44](400/2500): Loss: 0.0965
===> Epoch[44](500/2500): Loss: 0.0961
===> Epoch[44](600/2500): Loss: 0.0959
===> Epoch[44](700/2500): Loss: 0.0955
===> Epoch[44](800/2500): Loss: 0.0959
===> Epoch[44](900/2500): Loss: 0.0960
===> Epoch[44](1000/2500): Loss: 0.0963
===> Epoch[44](1100/2500): Loss: 0.0994
===> Epoch[44](1200/2500): Loss: 0.0965
===> Epoch[44](1300/2500): Loss: 0.0964
===> Epoch[44](1400/2500): Loss: 0.0960
===> Epoch[44](1500/2500): Loss: 0.0960
===> Epoch[44](1600/2500): Loss: 0.0963
===> Epoch[44](1700/2500): Loss: 0.0962
===> Epoch[44](1800/2500): Loss: 0.0959
===> Epoch[44](1900/2500): Loss: 0.0964
===> Epoch[44](2000/2500): Loss: 0.0958
===> Epoch[44](2100/2500): Loss: 0.0968
===> Epoch[44](2200/2500): Loss: 0.0958
===> Epoch[44](2300/2500): Loss: 0.0968
===> Epoch[44](2400/2500): Loss: 0.0961
===> Epoch[44](2500/2500): Loss: 0.0960
===> Epoch 44 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 18:56:07]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.0962
===> Epoch[44](200/2500): Loss: 0.0965
===> Epoch[44](300/2500): Loss: 0.0958
===> Epoch[44](400/2500): Loss: 0.0965
===> Epoch[44](500/2500): Loss: 0.0961
===> Epoch[44](600/2500): Loss: 0.0959
===> Epoch[44](700/2500): Loss: 0.0955
===> Epoch[44](800/2500): Loss: 0.0959
===> Epoch[44](900/2500): Loss: 0.0960
===> Epoch[44](1000/2500): Loss: 0.0963
===> Epoch[44](1100/2500): Loss: 0.0994
===> Epoch[44](1200/2500): Loss: 0.0965
===> Epoch[44](1300/2500): Loss: 0.0964
===> Epoch[44](1400/2500): Loss: 0.0960
===> Epoch[44](1500/2500): Loss: 0.0960
===> Epoch[44](1600/2500): Loss: 0.0963
===> Epoch[44](1700/2500): Loss: 0.0962
===> Epoch[44](1800/2500): Loss: 0.0959
===> Epoch[44](1900/2500): Loss: 0.0964
===> Epoch[44](2000/2500): Loss: 0.0958
===> Epoch[44](2100/2500): Loss: 0.0968
===> Epoch[44](2200/2500): Loss: 0.0958
===> Epoch[44](2300/2500): Loss: 0.0968
===> Epoch[44](2400/2500): Loss: 0.0961
===> Epoch[44](2500/2500): Loss: 0.0960
===> Epoch 44 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 18:56:07]
===> Loading train datasets
===> Epoch[44](100/2500): Loss: 0.0962
===> Epoch[44](200/2500): Loss: 0.0965
===> Epoch[44](300/2500): Loss: 0.0958
===> Epoch[44](400/2500): Loss: 0.0965
===> Epoch[44](500/2500): Loss: 0.0961
===> Epoch[44](600/2500): Loss: 0.0959
===> Epoch[44](700/2500): Loss: 0.0955
===> Epoch[44](800/2500): Loss: 0.0959
===> Epoch[44](900/2500): Loss: 0.0960
===> Epoch[44](1000/2500): Loss: 0.0963
===> Epoch[44](1100/2500): Loss: 0.0994
===> Epoch[44](1200/2500): Loss: 0.0965
===> Epoch[44](1300/2500): Loss: 0.0964
===> Epoch[44](1400/2500): Loss: 0.0960
===> Epoch[44](1500/2500): Loss: 0.0960
===> Epoch[44](1600/2500): Loss: 0.0963
===> Epoch[44](1700/2500): Loss: 0.0962
===> Epoch[44](1800/2500): Loss: 0.0959
===> Epoch[44](1900/2500): Loss: 0.0964
===> Epoch[44](2000/2500): Loss: 0.0958
===> Epoch[44](2100/2500): Loss: 0.0968
===> Epoch[44](2200/2500): Loss: 0.0958
===> Epoch[44](2300/2500): Loss: 0.0968
===> Epoch[44](2400/2500): Loss: 0.0961
===> Epoch[44](2500/2500): Loss: 0.0960
===> Epoch 44 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 18:56:07]
===> Loading train datasets
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.0962
===> Epoch[45](200/2500): Loss: 0.0963
===> Epoch[45](300/2500): Loss: 0.0962
===> Epoch[45](400/2500): Loss: 0.0961
===> Epoch[45](500/2500): Loss: 0.0965
===> Epoch[45](600/2500): Loss: 0.0958
===> Epoch[45](700/2500): Loss: 0.0960
===> Epoch[45](800/2500): Loss: 0.0962
===> Epoch[45](900/2500): Loss: 0.0962
===> Epoch[45](1000/2500): Loss: 0.0963
===> Epoch[45](1100/2500): Loss: 0.0967
===> Epoch[45](1200/2500): Loss: 0.0962
===> Epoch[45](1300/2500): Loss: 0.0953
===> Epoch[45](1400/2500): Loss: 0.1088
===> Epoch[45](1500/2500): Loss: 0.0979
===> Epoch[45](1600/2500): Loss: 0.0957
===> Epoch[45](1700/2500): Loss: 0.0969
===> Epoch[45](1800/2500): Loss: 0.0960
===> Epoch[45](1900/2500): Loss: 0.0963
===> Epoch[45](2000/2500): Loss: 0.0962
===> Epoch[45](2100/2500): Loss: 0.0957
===> Epoch[45](2200/2500): Loss: 0.0958
===> Epoch[45](2300/2500): Loss: 0.0959
===> Epoch[45](2400/2500): Loss: 0.0964
===> Epoch[45](2500/2500): Loss: 0.0963
===> Epoch 45 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:01:07]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.0962
===> Epoch[45](200/2500): Loss: 0.0963
===> Epoch[45](300/2500): Loss: 0.0962
===> Epoch[45](400/2500): Loss: 0.0961
===> Epoch[45](500/2500): Loss: 0.0965
===> Epoch[45](600/2500): Loss: 0.0958
===> Epoch[45](700/2500): Loss: 0.0960
===> Epoch[45](800/2500): Loss: 0.0962
===> Epoch[45](900/2500): Loss: 0.0962
===> Epoch[45](1000/2500): Loss: 0.0963
===> Epoch[45](1100/2500): Loss: 0.0967
===> Epoch[45](1200/2500): Loss: 0.0962
===> Epoch[45](1300/2500): Loss: 0.0953
===> Epoch[45](1400/2500): Loss: 0.1088
===> Epoch[45](1500/2500): Loss: 0.0979
===> Epoch[45](1600/2500): Loss: 0.0957
===> Epoch[45](1700/2500): Loss: 0.0969
===> Epoch[45](1800/2500): Loss: 0.0960
===> Epoch[45](1900/2500): Loss: 0.0963
===> Epoch[45](2000/2500): Loss: 0.0962
===> Epoch[45](2100/2500): Loss: 0.0957
===> Epoch[45](2200/2500): Loss: 0.0958
===> Epoch[45](2300/2500): Loss: 0.0959
===> Epoch[45](2400/2500): Loss: 0.0964
===> Epoch[45](2500/2500): Loss: 0.0963
===> Epoch 45 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:01:07]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.0962
===> Epoch[45](200/2500): Loss: 0.0963
===> Epoch[45](300/2500): Loss: 0.0962
===> Epoch[45](400/2500): Loss: 0.0961
===> Epoch[45](500/2500): Loss: 0.0965
===> Epoch[45](600/2500): Loss: 0.0958
===> Epoch[45](700/2500): Loss: 0.0960
===> Epoch[45](800/2500): Loss: 0.0962
===> Epoch[45](900/2500): Loss: 0.0962
===> Epoch[45](1000/2500): Loss: 0.0963
===> Epoch[45](1100/2500): Loss: 0.0967
===> Epoch[45](1200/2500): Loss: 0.0962
===> Epoch[45](1300/2500): Loss: 0.0953
===> Epoch[45](1400/2500): Loss: 0.1088
===> Epoch[45](1500/2500): Loss: 0.0979
===> Epoch[45](1600/2500): Loss: 0.0957
===> Epoch[45](1700/2500): Loss: 0.0969
===> Epoch[45](1800/2500): Loss: 0.0960
===> Epoch[45](1900/2500): Loss: 0.0963
===> Epoch[45](2000/2500): Loss: 0.0962
===> Epoch[45](2100/2500): Loss: 0.0957
===> Epoch[45](2200/2500): Loss: 0.0958
===> Epoch[45](2300/2500): Loss: 0.0959
===> Epoch[45](2400/2500): Loss: 0.0964
===> Epoch[45](2500/2500): Loss: 0.0963
===> Epoch 45 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:01:07]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.0962
===> Epoch[45](200/2500): Loss: 0.0963
===> Epoch[45](300/2500): Loss: 0.0962
===> Epoch[45](400/2500): Loss: 0.0961
===> Epoch[45](500/2500): Loss: 0.0965
===> Epoch[45](600/2500): Loss: 0.0958
===> Epoch[45](700/2500): Loss: 0.0960
===> Epoch[45](800/2500): Loss: 0.0962
===> Epoch[45](900/2500): Loss: 0.0962
===> Epoch[45](1000/2500): Loss: 0.0963
===> Epoch[45](1100/2500): Loss: 0.0967
===> Epoch[45](1200/2500): Loss: 0.0962
===> Epoch[45](1300/2500): Loss: 0.0953
===> Epoch[45](1400/2500): Loss: 0.1088
===> Epoch[45](1500/2500): Loss: 0.0979
===> Epoch[45](1600/2500): Loss: 0.0957
===> Epoch[45](1700/2500): Loss: 0.0969
===> Epoch[45](1800/2500): Loss: 0.0960
===> Epoch[45](1900/2500): Loss: 0.0963
===> Epoch[45](2000/2500): Loss: 0.0962
===> Epoch[45](2100/2500): Loss: 0.0957
===> Epoch[45](2200/2500): Loss: 0.0958
===> Epoch[45](2300/2500): Loss: 0.0959
===> Epoch[45](2400/2500): Loss: 0.0964
===> Epoch[45](2500/2500): Loss: 0.0963
===> Epoch 45 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:01:07]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.0962
===> Epoch[45](200/2500): Loss: 0.0963
===> Epoch[45](300/2500): Loss: 0.0962
===> Epoch[45](400/2500): Loss: 0.0961
===> Epoch[45](500/2500): Loss: 0.0965
===> Epoch[45](600/2500): Loss: 0.0958
===> Epoch[45](700/2500): Loss: 0.0960
===> Epoch[45](800/2500): Loss: 0.0962
===> Epoch[45](900/2500): Loss: 0.0962
===> Epoch[45](1000/2500): Loss: 0.0963
===> Epoch[45](1100/2500): Loss: 0.0967
===> Epoch[45](1200/2500): Loss: 0.0962
===> Epoch[45](1300/2500): Loss: 0.0953
===> Epoch[45](1400/2500): Loss: 0.1088
===> Epoch[45](1500/2500): Loss: 0.0979
===> Epoch[45](1600/2500): Loss: 0.0957
===> Epoch[45](1700/2500): Loss: 0.0969
===> Epoch[45](1800/2500): Loss: 0.0960
===> Epoch[45](1900/2500): Loss: 0.0963
===> Epoch[45](2000/2500): Loss: 0.0962
===> Epoch[45](2100/2500): Loss: 0.0957
===> Epoch[45](2200/2500): Loss: 0.0958
===> Epoch[45](2300/2500): Loss: 0.0959
===> Epoch[45](2400/2500): Loss: 0.0964
===> Epoch[45](2500/2500): Loss: 0.0963
===> Epoch 45 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:01:07]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.0962
===> Epoch[45](200/2500): Loss: 0.0963
===> Epoch[45](300/2500): Loss: 0.0962
===> Epoch[45](400/2500): Loss: 0.0961
===> Epoch[45](500/2500): Loss: 0.0965
===> Epoch[45](600/2500): Loss: 0.0958
===> Epoch[45](700/2500): Loss: 0.0960
===> Epoch[45](800/2500): Loss: 0.0962
===> Epoch[45](900/2500): Loss: 0.0962
===> Epoch[45](1000/2500): Loss: 0.0963
===> Epoch[45](1100/2500): Loss: 0.0967
===> Epoch[45](1200/2500): Loss: 0.0962
===> Epoch[45](1300/2500): Loss: 0.0953
===> Epoch[45](1400/2500): Loss: 0.1088
===> Epoch[45](1500/2500): Loss: 0.0979
===> Epoch[45](1600/2500): Loss: 0.0957
===> Epoch[45](1700/2500): Loss: 0.0969
===> Epoch[45](1800/2500): Loss: 0.0960
===> Epoch[45](1900/2500): Loss: 0.0963
===> Epoch[45](2000/2500): Loss: 0.0962
===> Epoch[45](2100/2500): Loss: 0.0957
===> Epoch[45](2200/2500): Loss: 0.0958
===> Epoch[45](2300/2500): Loss: 0.0959
===> Epoch[45](2400/2500): Loss: 0.0964
===> Epoch[45](2500/2500): Loss: 0.0963
===> Epoch 45 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:01:07]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.0962
===> Epoch[45](200/2500): Loss: 0.0963
===> Epoch[45](300/2500): Loss: 0.0962
===> Epoch[45](400/2500): Loss: 0.0961
===> Epoch[45](500/2500): Loss: 0.0965
===> Epoch[45](600/2500): Loss: 0.0958
===> Epoch[45](700/2500): Loss: 0.0960
===> Epoch[45](800/2500): Loss: 0.0962
===> Epoch[45](900/2500): Loss: 0.0962
===> Epoch[45](1000/2500): Loss: 0.0963
===> Epoch[45](1100/2500): Loss: 0.0967
===> Epoch[45](1200/2500): Loss: 0.0962
===> Epoch[45](1300/2500): Loss: 0.0953
===> Epoch[45](1400/2500): Loss: 0.1088
===> Epoch[45](1500/2500): Loss: 0.0979
===> Epoch[45](1600/2500): Loss: 0.0957
===> Epoch[45](1700/2500): Loss: 0.0969
===> Epoch[45](1800/2500): Loss: 0.0960
===> Epoch[45](1900/2500): Loss: 0.0963
===> Epoch[45](2000/2500): Loss: 0.0962
===> Epoch[45](2100/2500): Loss: 0.0957
===> Epoch[45](2200/2500): Loss: 0.0958
===> Epoch[45](2300/2500): Loss: 0.0959
===> Epoch[45](2400/2500): Loss: 0.0964
===> Epoch[45](2500/2500): Loss: 0.0963
===> Epoch 45 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:01:07]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.0962
===> Epoch[45](200/2500): Loss: 0.0963
===> Epoch[45](300/2500): Loss: 0.0962
===> Epoch[45](400/2500): Loss: 0.0961
===> Epoch[45](500/2500): Loss: 0.0965
===> Epoch[45](600/2500): Loss: 0.0958
===> Epoch[45](700/2500): Loss: 0.0960
===> Epoch[45](800/2500): Loss: 0.0962
===> Epoch[45](900/2500): Loss: 0.0962
===> Epoch[45](1000/2500): Loss: 0.0963
===> Epoch[45](1100/2500): Loss: 0.0967
===> Epoch[45](1200/2500): Loss: 0.0962
===> Epoch[45](1300/2500): Loss: 0.0953
===> Epoch[45](1400/2500): Loss: 0.1088
===> Epoch[45](1500/2500): Loss: 0.0979
===> Epoch[45](1600/2500): Loss: 0.0957
===> Epoch[45](1700/2500): Loss: 0.0969
===> Epoch[45](1800/2500): Loss: 0.0960
===> Epoch[45](1900/2500): Loss: 0.0963
===> Epoch[45](2000/2500): Loss: 0.0962
===> Epoch[45](2100/2500): Loss: 0.0957
===> Epoch[45](2200/2500): Loss: 0.0958
===> Epoch[45](2300/2500): Loss: 0.0959
===> Epoch[45](2400/2500): Loss: 0.0964
===> Epoch[45](2500/2500): Loss: 0.0963
===> Epoch 45 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:01:07]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.0962
===> Epoch[45](200/2500): Loss: 0.0963
===> Epoch[45](300/2500): Loss: 0.0962
===> Epoch[45](400/2500): Loss: 0.0961
===> Epoch[45](500/2500): Loss: 0.0965
===> Epoch[45](600/2500): Loss: 0.0958
===> Epoch[45](700/2500): Loss: 0.0960
===> Epoch[45](800/2500): Loss: 0.0962
===> Epoch[45](900/2500): Loss: 0.0962
===> Epoch[45](1000/2500): Loss: 0.0963
===> Epoch[45](1100/2500): Loss: 0.0967
===> Epoch[45](1200/2500): Loss: 0.0962
===> Epoch[45](1300/2500): Loss: 0.0953
===> Epoch[45](1400/2500): Loss: 0.1088
===> Epoch[45](1500/2500): Loss: 0.0979
===> Epoch[45](1600/2500): Loss: 0.0957
===> Epoch[45](1700/2500): Loss: 0.0969
===> Epoch[45](1800/2500): Loss: 0.0960
===> Epoch[45](1900/2500): Loss: 0.0963
===> Epoch[45](2000/2500): Loss: 0.0962
===> Epoch[45](2100/2500): Loss: 0.0957
===> Epoch[45](2200/2500): Loss: 0.0958
===> Epoch[45](2300/2500): Loss: 0.0959
===> Epoch[45](2400/2500): Loss: 0.0964
===> Epoch[45](2500/2500): Loss: 0.0963
===> Epoch 45 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:01:07]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.0962
===> Epoch[45](200/2500): Loss: 0.0963
===> Epoch[45](300/2500): Loss: 0.0962
===> Epoch[45](400/2500): Loss: 0.0961
===> Epoch[45](500/2500): Loss: 0.0965
===> Epoch[45](600/2500): Loss: 0.0958
===> Epoch[45](700/2500): Loss: 0.0960
===> Epoch[45](800/2500): Loss: 0.0962
===> Epoch[45](900/2500): Loss: 0.0962
===> Epoch[45](1000/2500): Loss: 0.0963
===> Epoch[45](1100/2500): Loss: 0.0967
===> Epoch[45](1200/2500): Loss: 0.0962
===> Epoch[45](1300/2500): Loss: 0.0953
===> Epoch[45](1400/2500): Loss: 0.1088
===> Epoch[45](1500/2500): Loss: 0.0979
===> Epoch[45](1600/2500): Loss: 0.0957
===> Epoch[45](1700/2500): Loss: 0.0969
===> Epoch[45](1800/2500): Loss: 0.0960
===> Epoch[45](1900/2500): Loss: 0.0963
===> Epoch[45](2000/2500): Loss: 0.0962
===> Epoch[45](2100/2500): Loss: 0.0957
===> Epoch[45](2200/2500): Loss: 0.0958
===> Epoch[45](2300/2500): Loss: 0.0959
===> Epoch[45](2400/2500): Loss: 0.0964
===> Epoch[45](2500/2500): Loss: 0.0963
===> Epoch 45 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:01:07]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.0962
===> Epoch[45](200/2500): Loss: 0.0963
===> Epoch[45](300/2500): Loss: 0.0962
===> Epoch[45](400/2500): Loss: 0.0961
===> Epoch[45](500/2500): Loss: 0.0965
===> Epoch[45](600/2500): Loss: 0.0958
===> Epoch[45](700/2500): Loss: 0.0960
===> Epoch[45](800/2500): Loss: 0.0962
===> Epoch[45](900/2500): Loss: 0.0962
===> Epoch[45](1000/2500): Loss: 0.0963
===> Epoch[45](1100/2500): Loss: 0.0967
===> Epoch[45](1200/2500): Loss: 0.0962
===> Epoch[45](1300/2500): Loss: 0.0953
===> Epoch[45](1400/2500): Loss: 0.1088
===> Epoch[45](1500/2500): Loss: 0.0979
===> Epoch[45](1600/2500): Loss: 0.0957
===> Epoch[45](1700/2500): Loss: 0.0969
===> Epoch[45](1800/2500): Loss: 0.0960
===> Epoch[45](1900/2500): Loss: 0.0963
===> Epoch[45](2000/2500): Loss: 0.0962
===> Epoch[45](2100/2500): Loss: 0.0957
===> Epoch[45](2200/2500): Loss: 0.0958
===> Epoch[45](2300/2500): Loss: 0.0959
===> Epoch[45](2400/2500): Loss: 0.0964
===> Epoch[45](2500/2500): Loss: 0.0963
===> Epoch 45 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:01:07]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.0962
===> Epoch[45](200/2500): Loss: 0.0963
===> Epoch[45](300/2500): Loss: 0.0962
===> Epoch[45](400/2500): Loss: 0.0961
===> Epoch[45](500/2500): Loss: 0.0965
===> Epoch[45](600/2500): Loss: 0.0958
===> Epoch[45](700/2500): Loss: 0.0960
===> Epoch[45](800/2500): Loss: 0.0962
===> Epoch[45](900/2500): Loss: 0.0962
===> Epoch[45](1000/2500): Loss: 0.0963
===> Epoch[45](1100/2500): Loss: 0.0967
===> Epoch[45](1200/2500): Loss: 0.0962
===> Epoch[45](1300/2500): Loss: 0.0953
===> Epoch[45](1400/2500): Loss: 0.1088
===> Epoch[45](1500/2500): Loss: 0.0979
===> Epoch[45](1600/2500): Loss: 0.0957
===> Epoch[45](1700/2500): Loss: 0.0969
===> Epoch[45](1800/2500): Loss: 0.0960
===> Epoch[45](1900/2500): Loss: 0.0963
===> Epoch[45](2000/2500): Loss: 0.0962
===> Epoch[45](2100/2500): Loss: 0.0957
===> Epoch[45](2200/2500): Loss: 0.0958
===> Epoch[45](2300/2500): Loss: 0.0959
===> Epoch[45](2400/2500): Loss: 0.0964
===> Epoch[45](2500/2500): Loss: 0.0963
===> Epoch 45 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:01:07]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.0962
===> Epoch[45](200/2500): Loss: 0.0963
===> Epoch[45](300/2500): Loss: 0.0962
===> Epoch[45](400/2500): Loss: 0.0961
===> Epoch[45](500/2500): Loss: 0.0965
===> Epoch[45](600/2500): Loss: 0.0958
===> Epoch[45](700/2500): Loss: 0.0960
===> Epoch[45](800/2500): Loss: 0.0962
===> Epoch[45](900/2500): Loss: 0.0962
===> Epoch[45](1000/2500): Loss: 0.0963
===> Epoch[45](1100/2500): Loss: 0.0967
===> Epoch[45](1200/2500): Loss: 0.0962
===> Epoch[45](1300/2500): Loss: 0.0953
===> Epoch[45](1400/2500): Loss: 0.1088
===> Epoch[45](1500/2500): Loss: 0.0979
===> Epoch[45](1600/2500): Loss: 0.0957
===> Epoch[45](1700/2500): Loss: 0.0969
===> Epoch[45](1800/2500): Loss: 0.0960
===> Epoch[45](1900/2500): Loss: 0.0963
===> Epoch[45](2000/2500): Loss: 0.0962
===> Epoch[45](2100/2500): Loss: 0.0957
===> Epoch[45](2200/2500): Loss: 0.0958
===> Epoch[45](2300/2500): Loss: 0.0959
===> Epoch[45](2400/2500): Loss: 0.0964
===> Epoch[45](2500/2500): Loss: 0.0963
===> Epoch 45 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:01:07]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.0962
===> Epoch[45](200/2500): Loss: 0.0963
===> Epoch[45](300/2500): Loss: 0.0962
===> Epoch[45](400/2500): Loss: 0.0961
===> Epoch[45](500/2500): Loss: 0.0965
===> Epoch[45](600/2500): Loss: 0.0958
===> Epoch[45](700/2500): Loss: 0.0960
===> Epoch[45](800/2500): Loss: 0.0962
===> Epoch[45](900/2500): Loss: 0.0962
===> Epoch[45](1000/2500): Loss: 0.0963
===> Epoch[45](1100/2500): Loss: 0.0967
===> Epoch[45](1200/2500): Loss: 0.0962
===> Epoch[45](1300/2500): Loss: 0.0953
===> Epoch[45](1400/2500): Loss: 0.1088
===> Epoch[45](1500/2500): Loss: 0.0979
===> Epoch[45](1600/2500): Loss: 0.0957
===> Epoch[45](1700/2500): Loss: 0.0969
===> Epoch[45](1800/2500): Loss: 0.0960
===> Epoch[45](1900/2500): Loss: 0.0963
===> Epoch[45](2000/2500): Loss: 0.0962
===> Epoch[45](2100/2500): Loss: 0.0957
===> Epoch[45](2200/2500): Loss: 0.0958
===> Epoch[45](2300/2500): Loss: 0.0959
===> Epoch[45](2400/2500): Loss: 0.0964
===> Epoch[45](2500/2500): Loss: 0.0963
===> Epoch 45 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:01:07]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Epoch[45](100/2500): Loss: 0.0962
===> Epoch[45](200/2500): Loss: 0.0963
===> Epoch[45](300/2500): Loss: 0.0962
===> Epoch[45](400/2500): Loss: 0.0961
===> Epoch[45](500/2500): Loss: 0.0965
===> Epoch[45](600/2500): Loss: 0.0958
===> Epoch[45](700/2500): Loss: 0.0960
===> Epoch[45](800/2500): Loss: 0.0962
===> Epoch[45](900/2500): Loss: 0.0962
===> Epoch[45](1000/2500): Loss: 0.0963
===> Epoch[45](1100/2500): Loss: 0.0967
===> Epoch[45](1200/2500): Loss: 0.0962
===> Epoch[45](1300/2500): Loss: 0.0953
===> Epoch[45](1400/2500): Loss: 0.1088
===> Epoch[45](1500/2500): Loss: 0.0979
===> Epoch[45](1600/2500): Loss: 0.0957
===> Epoch[45](1700/2500): Loss: 0.0969
===> Epoch[45](1800/2500): Loss: 0.0960
===> Epoch[45](1900/2500): Loss: 0.0963
===> Epoch[45](2000/2500): Loss: 0.0962
===> Epoch[45](2100/2500): Loss: 0.0957
===> Epoch[45](2200/2500): Loss: 0.0958
===> Epoch[45](2300/2500): Loss: 0.0959
===> Epoch[45](2400/2500): Loss: 0.0964
===> Epoch[45](2500/2500): Loss: 0.0963
===> Epoch 45 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:01:07]
Checkpoint saved to TrainedNet/_epoch_45.pth
===> Loading train datasets
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.0959
===> Epoch[46](200/2500): Loss: 0.0958
===> Epoch[46](300/2500): Loss: 0.0963
===> Epoch[46](400/2500): Loss: 0.0961
===> Epoch[46](500/2500): Loss: 0.0963
===> Epoch[46](600/2500): Loss: 0.0969
===> Epoch[46](700/2500): Loss: 0.0961
===> Epoch[46](800/2500): Loss: 0.0959
===> Epoch[46](900/2500): Loss: 0.0966
===> Epoch[46](1000/2500): Loss: 0.0965
===> Epoch[46](1100/2500): Loss: 0.0964
===> Epoch[46](1200/2500): Loss: 0.0959
===> Epoch[46](1300/2500): Loss: 0.0963
===> Epoch[46](1400/2500): Loss: 0.0963
===> Epoch[46](1500/2500): Loss: 0.0960
===> Epoch[46](1600/2500): Loss: 0.0962
===> Epoch[46](1700/2500): Loss: 0.0963
===> Epoch[46](1800/2500): Loss: 0.0953
===> Epoch[46](1900/2500): Loss: 0.0963
===> Epoch[46](2000/2500): Loss: 0.1027
===> Epoch[46](2100/2500): Loss: 0.0976
===> Epoch[46](2200/2500): Loss: 0.0960
===> Epoch[46](2300/2500): Loss: 0.0959
===> Epoch[46](2400/2500): Loss: 0.0963
===> Epoch[46](2500/2500): Loss: 0.0963
===> Epoch 46 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:06:06]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.0959
===> Epoch[46](200/2500): Loss: 0.0958
===> Epoch[46](300/2500): Loss: 0.0963
===> Epoch[46](400/2500): Loss: 0.0961
===> Epoch[46](500/2500): Loss: 0.0963
===> Epoch[46](600/2500): Loss: 0.0969
===> Epoch[46](700/2500): Loss: 0.0961
===> Epoch[46](800/2500): Loss: 0.0959
===> Epoch[46](900/2500): Loss: 0.0966
===> Epoch[46](1000/2500): Loss: 0.0965
===> Epoch[46](1100/2500): Loss: 0.0964
===> Epoch[46](1200/2500): Loss: 0.0959
===> Epoch[46](1300/2500): Loss: 0.0963
===> Epoch[46](1400/2500): Loss: 0.0963
===> Epoch[46](1500/2500): Loss: 0.0960
===> Epoch[46](1600/2500): Loss: 0.0962
===> Epoch[46](1700/2500): Loss: 0.0963
===> Epoch[46](1800/2500): Loss: 0.0953
===> Epoch[46](1900/2500): Loss: 0.0963
===> Epoch[46](2000/2500): Loss: 0.1027
===> Epoch[46](2100/2500): Loss: 0.0976
===> Epoch[46](2200/2500): Loss: 0.0960
===> Epoch[46](2300/2500): Loss: 0.0959
===> Epoch[46](2400/2500): Loss: 0.0963
===> Epoch[46](2500/2500): Loss: 0.0963
===> Epoch 46 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:06:06]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.0959
===> Epoch[46](200/2500): Loss: 0.0958
===> Epoch[46](300/2500): Loss: 0.0963
===> Epoch[46](400/2500): Loss: 0.0961
===> Epoch[46](500/2500): Loss: 0.0963
===> Epoch[46](600/2500): Loss: 0.0969
===> Epoch[46](700/2500): Loss: 0.0961
===> Epoch[46](800/2500): Loss: 0.0959
===> Epoch[46](900/2500): Loss: 0.0966
===> Epoch[46](1000/2500): Loss: 0.0965
===> Epoch[46](1100/2500): Loss: 0.0964
===> Epoch[46](1200/2500): Loss: 0.0959
===> Epoch[46](1300/2500): Loss: 0.0963
===> Epoch[46](1400/2500): Loss: 0.0963
===> Epoch[46](1500/2500): Loss: 0.0960
===> Epoch[46](1600/2500): Loss: 0.0962
===> Epoch[46](1700/2500): Loss: 0.0963
===> Epoch[46](1800/2500): Loss: 0.0953
===> Epoch[46](1900/2500): Loss: 0.0963
===> Epoch[46](2000/2500): Loss: 0.1027
===> Epoch[46](2100/2500): Loss: 0.0976
===> Epoch[46](2200/2500): Loss: 0.0960
===> Epoch[46](2300/2500): Loss: 0.0959
===> Epoch[46](2400/2500): Loss: 0.0963
===> Epoch[46](2500/2500): Loss: 0.0963
===> Epoch 46 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:06:06]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.0959
===> Epoch[46](200/2500): Loss: 0.0958
===> Epoch[46](300/2500): Loss: 0.0963
===> Epoch[46](400/2500): Loss: 0.0961
===> Epoch[46](500/2500): Loss: 0.0963
===> Epoch[46](600/2500): Loss: 0.0969
===> Epoch[46](700/2500): Loss: 0.0961
===> Epoch[46](800/2500): Loss: 0.0959
===> Epoch[46](900/2500): Loss: 0.0966
===> Epoch[46](1000/2500): Loss: 0.0965
===> Epoch[46](1100/2500): Loss: 0.0964
===> Epoch[46](1200/2500): Loss: 0.0959
===> Epoch[46](1300/2500): Loss: 0.0963
===> Epoch[46](1400/2500): Loss: 0.0963
===> Epoch[46](1500/2500): Loss: 0.0960
===> Epoch[46](1600/2500): Loss: 0.0962
===> Epoch[46](1700/2500): Loss: 0.0963
===> Epoch[46](1800/2500): Loss: 0.0953
===> Epoch[46](1900/2500): Loss: 0.0963
===> Epoch[46](2000/2500): Loss: 0.1027
===> Epoch[46](2100/2500): Loss: 0.0976
===> Epoch[46](2200/2500): Loss: 0.0960
===> Epoch[46](2300/2500): Loss: 0.0959
===> Epoch[46](2400/2500): Loss: 0.0963
===> Epoch[46](2500/2500): Loss: 0.0963
===> Epoch 46 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:06:06]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.0959
===> Epoch[46](200/2500): Loss: 0.0958
===> Epoch[46](300/2500): Loss: 0.0963
===> Epoch[46](400/2500): Loss: 0.0961
===> Epoch[46](500/2500): Loss: 0.0963
===> Epoch[46](600/2500): Loss: 0.0969
===> Epoch[46](700/2500): Loss: 0.0961
===> Epoch[46](800/2500): Loss: 0.0959
===> Epoch[46](900/2500): Loss: 0.0966
===> Epoch[46](1000/2500): Loss: 0.0965
===> Epoch[46](1100/2500): Loss: 0.0964
===> Epoch[46](1200/2500): Loss: 0.0959
===> Epoch[46](1300/2500): Loss: 0.0963
===> Epoch[46](1400/2500): Loss: 0.0963
===> Epoch[46](1500/2500): Loss: 0.0960
===> Epoch[46](1600/2500): Loss: 0.0962
===> Epoch[46](1700/2500): Loss: 0.0963
===> Epoch[46](1800/2500): Loss: 0.0953
===> Epoch[46](1900/2500): Loss: 0.0963
===> Epoch[46](2000/2500): Loss: 0.1027
===> Epoch[46](2100/2500): Loss: 0.0976
===> Epoch[46](2200/2500): Loss: 0.0960
===> Epoch[46](2300/2500): Loss: 0.0959
===> Epoch[46](2400/2500): Loss: 0.0963
===> Epoch[46](2500/2500): Loss: 0.0963
===> Epoch 46 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:06:06]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.0959
===> Epoch[46](200/2500): Loss: 0.0958
===> Epoch[46](300/2500): Loss: 0.0963
===> Epoch[46](400/2500): Loss: 0.0961
===> Epoch[46](500/2500): Loss: 0.0963
===> Epoch[46](600/2500): Loss: 0.0969
===> Epoch[46](700/2500): Loss: 0.0961
===> Epoch[46](800/2500): Loss: 0.0959
===> Epoch[46](900/2500): Loss: 0.0966
===> Epoch[46](1000/2500): Loss: 0.0965
===> Epoch[46](1100/2500): Loss: 0.0964
===> Epoch[46](1200/2500): Loss: 0.0959
===> Epoch[46](1300/2500): Loss: 0.0963
===> Epoch[46](1400/2500): Loss: 0.0963
===> Epoch[46](1500/2500): Loss: 0.0960
===> Epoch[46](1600/2500): Loss: 0.0962
===> Epoch[46](1700/2500): Loss: 0.0963
===> Epoch[46](1800/2500): Loss: 0.0953
===> Epoch[46](1900/2500): Loss: 0.0963
===> Epoch[46](2000/2500): Loss: 0.1027
===> Epoch[46](2100/2500): Loss: 0.0976
===> Epoch[46](2200/2500): Loss: 0.0960
===> Epoch[46](2300/2500): Loss: 0.0959
===> Epoch[46](2400/2500): Loss: 0.0963
===> Epoch[46](2500/2500): Loss: 0.0963
===> Epoch 46 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:06:06]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.0959
===> Epoch[46](200/2500): Loss: 0.0958
===> Epoch[46](300/2500): Loss: 0.0963
===> Epoch[46](400/2500): Loss: 0.0961
===> Epoch[46](500/2500): Loss: 0.0963
===> Epoch[46](600/2500): Loss: 0.0969
===> Epoch[46](700/2500): Loss: 0.0961
===> Epoch[46](800/2500): Loss: 0.0959
===> Epoch[46](900/2500): Loss: 0.0966
===> Epoch[46](1000/2500): Loss: 0.0965
===> Epoch[46](1100/2500): Loss: 0.0964
===> Epoch[46](1200/2500): Loss: 0.0959
===> Epoch[46](1300/2500): Loss: 0.0963
===> Epoch[46](1400/2500): Loss: 0.0963
===> Epoch[46](1500/2500): Loss: 0.0960
===> Epoch[46](1600/2500): Loss: 0.0962
===> Epoch[46](1700/2500): Loss: 0.0963
===> Epoch[46](1800/2500): Loss: 0.0953
===> Epoch[46](1900/2500): Loss: 0.0963
===> Epoch[46](2000/2500): Loss: 0.1027
===> Epoch[46](2100/2500): Loss: 0.0976
===> Epoch[46](2200/2500): Loss: 0.0960
===> Epoch[46](2300/2500): Loss: 0.0959
===> Epoch[46](2400/2500): Loss: 0.0963
===> Epoch[46](2500/2500): Loss: 0.0963
===> Epoch 46 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:06:06]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.0959
===> Epoch[46](200/2500): Loss: 0.0958
===> Epoch[46](300/2500): Loss: 0.0963
===> Epoch[46](400/2500): Loss: 0.0961
===> Epoch[46](500/2500): Loss: 0.0963
===> Epoch[46](600/2500): Loss: 0.0969
===> Epoch[46](700/2500): Loss: 0.0961
===> Epoch[46](800/2500): Loss: 0.0959
===> Epoch[46](900/2500): Loss: 0.0966
===> Epoch[46](1000/2500): Loss: 0.0965
===> Epoch[46](1100/2500): Loss: 0.0964
===> Epoch[46](1200/2500): Loss: 0.0959
===> Epoch[46](1300/2500): Loss: 0.0963
===> Epoch[46](1400/2500): Loss: 0.0963
===> Epoch[46](1500/2500): Loss: 0.0960
===> Epoch[46](1600/2500): Loss: 0.0962
===> Epoch[46](1700/2500): Loss: 0.0963
===> Epoch[46](1800/2500): Loss: 0.0953
===> Epoch[46](1900/2500): Loss: 0.0963
===> Epoch[46](2000/2500): Loss: 0.1027
===> Epoch[46](2100/2500): Loss: 0.0976
===> Epoch[46](2200/2500): Loss: 0.0960
===> Epoch[46](2300/2500): Loss: 0.0959
===> Epoch[46](2400/2500): Loss: 0.0963
===> Epoch[46](2500/2500): Loss: 0.0963
===> Epoch 46 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:06:06]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.0959
===> Epoch[46](200/2500): Loss: 0.0958
===> Epoch[46](300/2500): Loss: 0.0963
===> Epoch[46](400/2500): Loss: 0.0961
===> Epoch[46](500/2500): Loss: 0.0963
===> Epoch[46](600/2500): Loss: 0.0969
===> Epoch[46](700/2500): Loss: 0.0961
===> Epoch[46](800/2500): Loss: 0.0959
===> Epoch[46](900/2500): Loss: 0.0966
===> Epoch[46](1000/2500): Loss: 0.0965
===> Epoch[46](1100/2500): Loss: 0.0964
===> Epoch[46](1200/2500): Loss: 0.0959
===> Epoch[46](1300/2500): Loss: 0.0963
===> Epoch[46](1400/2500): Loss: 0.0963
===> Epoch[46](1500/2500): Loss: 0.0960
===> Epoch[46](1600/2500): Loss: 0.0962
===> Epoch[46](1700/2500): Loss: 0.0963
===> Epoch[46](1800/2500): Loss: 0.0953
===> Epoch[46](1900/2500): Loss: 0.0963
===> Epoch[46](2000/2500): Loss: 0.1027
===> Epoch[46](2100/2500): Loss: 0.0976
===> Epoch[46](2200/2500): Loss: 0.0960
===> Epoch[46](2300/2500): Loss: 0.0959
===> Epoch[46](2400/2500): Loss: 0.0963
===> Epoch[46](2500/2500): Loss: 0.0963
===> Epoch 46 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:06:06]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.0959
===> Epoch[46](200/2500): Loss: 0.0958
===> Epoch[46](300/2500): Loss: 0.0963
===> Epoch[46](400/2500): Loss: 0.0961
===> Epoch[46](500/2500): Loss: 0.0963
===> Epoch[46](600/2500): Loss: 0.0969
===> Epoch[46](700/2500): Loss: 0.0961
===> Epoch[46](800/2500): Loss: 0.0959
===> Epoch[46](900/2500): Loss: 0.0966
===> Epoch[46](1000/2500): Loss: 0.0965
===> Epoch[46](1100/2500): Loss: 0.0964
===> Epoch[46](1200/2500): Loss: 0.0959
===> Epoch[46](1300/2500): Loss: 0.0963
===> Epoch[46](1400/2500): Loss: 0.0963
===> Epoch[46](1500/2500): Loss: 0.0960
===> Epoch[46](1600/2500): Loss: 0.0962
===> Epoch[46](1700/2500): Loss: 0.0963
===> Epoch[46](1800/2500): Loss: 0.0953
===> Epoch[46](1900/2500): Loss: 0.0963
===> Epoch[46](2000/2500): Loss: 0.1027
===> Epoch[46](2100/2500): Loss: 0.0976
===> Epoch[46](2200/2500): Loss: 0.0960
===> Epoch[46](2300/2500): Loss: 0.0959
===> Epoch[46](2400/2500): Loss: 0.0963
===> Epoch[46](2500/2500): Loss: 0.0963
===> Epoch 46 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:06:06]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.0959
===> Epoch[46](200/2500): Loss: 0.0958
===> Epoch[46](300/2500): Loss: 0.0963
===> Epoch[46](400/2500): Loss: 0.0961
===> Epoch[46](500/2500): Loss: 0.0963
===> Epoch[46](600/2500): Loss: 0.0969
===> Epoch[46](700/2500): Loss: 0.0961
===> Epoch[46](800/2500): Loss: 0.0959
===> Epoch[46](900/2500): Loss: 0.0966
===> Epoch[46](1000/2500): Loss: 0.0965
===> Epoch[46](1100/2500): Loss: 0.0964
===> Epoch[46](1200/2500): Loss: 0.0959
===> Epoch[46](1300/2500): Loss: 0.0963
===> Epoch[46](1400/2500): Loss: 0.0963
===> Epoch[46](1500/2500): Loss: 0.0960
===> Epoch[46](1600/2500): Loss: 0.0962
===> Epoch[46](1700/2500): Loss: 0.0963
===> Epoch[46](1800/2500): Loss: 0.0953
===> Epoch[46](1900/2500): Loss: 0.0963
===> Epoch[46](2000/2500): Loss: 0.1027
===> Epoch[46](2100/2500): Loss: 0.0976
===> Epoch[46](2200/2500): Loss: 0.0960
===> Epoch[46](2300/2500): Loss: 0.0959
===> Epoch[46](2400/2500): Loss: 0.0963
===> Epoch[46](2500/2500): Loss: 0.0963
===> Epoch 46 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:06:06]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.0959
===> Epoch[46](200/2500): Loss: 0.0958
===> Epoch[46](300/2500): Loss: 0.0963
===> Epoch[46](400/2500): Loss: 0.0961
===> Epoch[46](500/2500): Loss: 0.0963
===> Epoch[46](600/2500): Loss: 0.0969
===> Epoch[46](700/2500): Loss: 0.0961
===> Epoch[46](800/2500): Loss: 0.0959
===> Epoch[46](900/2500): Loss: 0.0966
===> Epoch[46](1000/2500): Loss: 0.0965
===> Epoch[46](1100/2500): Loss: 0.0964
===> Epoch[46](1200/2500): Loss: 0.0959
===> Epoch[46](1300/2500): Loss: 0.0963
===> Epoch[46](1400/2500): Loss: 0.0963
===> Epoch[46](1500/2500): Loss: 0.0960
===> Epoch[46](1600/2500): Loss: 0.0962
===> Epoch[46](1700/2500): Loss: 0.0963
===> Epoch[46](1800/2500): Loss: 0.0953
===> Epoch[46](1900/2500): Loss: 0.0963
===> Epoch[46](2000/2500): Loss: 0.1027
===> Epoch[46](2100/2500): Loss: 0.0976
===> Epoch[46](2200/2500): Loss: 0.0960
===> Epoch[46](2300/2500): Loss: 0.0959
===> Epoch[46](2400/2500): Loss: 0.0963
===> Epoch[46](2500/2500): Loss: 0.0963
===> Epoch 46 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:06:06]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.0959
===> Epoch[46](200/2500): Loss: 0.0958
===> Epoch[46](300/2500): Loss: 0.0963
===> Epoch[46](400/2500): Loss: 0.0961
===> Epoch[46](500/2500): Loss: 0.0963
===> Epoch[46](600/2500): Loss: 0.0969
===> Epoch[46](700/2500): Loss: 0.0961
===> Epoch[46](800/2500): Loss: 0.0959
===> Epoch[46](900/2500): Loss: 0.0966
===> Epoch[46](1000/2500): Loss: 0.0965
===> Epoch[46](1100/2500): Loss: 0.0964
===> Epoch[46](1200/2500): Loss: 0.0959
===> Epoch[46](1300/2500): Loss: 0.0963
===> Epoch[46](1400/2500): Loss: 0.0963
===> Epoch[46](1500/2500): Loss: 0.0960
===> Epoch[46](1600/2500): Loss: 0.0962
===> Epoch[46](1700/2500): Loss: 0.0963
===> Epoch[46](1800/2500): Loss: 0.0953
===> Epoch[46](1900/2500): Loss: 0.0963
===> Epoch[46](2000/2500): Loss: 0.1027
===> Epoch[46](2100/2500): Loss: 0.0976
===> Epoch[46](2200/2500): Loss: 0.0960
===> Epoch[46](2300/2500): Loss: 0.0959
===> Epoch[46](2400/2500): Loss: 0.0963
===> Epoch[46](2500/2500): Loss: 0.0963
===> Epoch 46 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:06:06]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.0959
===> Epoch[46](200/2500): Loss: 0.0958
===> Epoch[46](300/2500): Loss: 0.0963
===> Epoch[46](400/2500): Loss: 0.0961
===> Epoch[46](500/2500): Loss: 0.0963
===> Epoch[46](600/2500): Loss: 0.0969
===> Epoch[46](700/2500): Loss: 0.0961
===> Epoch[46](800/2500): Loss: 0.0959
===> Epoch[46](900/2500): Loss: 0.0966
===> Epoch[46](1000/2500): Loss: 0.0965
===> Epoch[46](1100/2500): Loss: 0.0964
===> Epoch[46](1200/2500): Loss: 0.0959
===> Epoch[46](1300/2500): Loss: 0.0963
===> Epoch[46](1400/2500): Loss: 0.0963
===> Epoch[46](1500/2500): Loss: 0.0960
===> Epoch[46](1600/2500): Loss: 0.0962
===> Epoch[46](1700/2500): Loss: 0.0963
===> Epoch[46](1800/2500): Loss: 0.0953
===> Epoch[46](1900/2500): Loss: 0.0963
===> Epoch[46](2000/2500): Loss: 0.1027
===> Epoch[46](2100/2500): Loss: 0.0976
===> Epoch[46](2200/2500): Loss: 0.0960
===> Epoch[46](2300/2500): Loss: 0.0959
===> Epoch[46](2400/2500): Loss: 0.0963
===> Epoch[46](2500/2500): Loss: 0.0963
===> Epoch 46 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:06:06]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.0959
===> Epoch[46](200/2500): Loss: 0.0958
===> Epoch[46](300/2500): Loss: 0.0963
===> Epoch[46](400/2500): Loss: 0.0961
===> Epoch[46](500/2500): Loss: 0.0963
===> Epoch[46](600/2500): Loss: 0.0969
===> Epoch[46](700/2500): Loss: 0.0961
===> Epoch[46](800/2500): Loss: 0.0959
===> Epoch[46](900/2500): Loss: 0.0966
===> Epoch[46](1000/2500): Loss: 0.0965
===> Epoch[46](1100/2500): Loss: 0.0964
===> Epoch[46](1200/2500): Loss: 0.0959
===> Epoch[46](1300/2500): Loss: 0.0963
===> Epoch[46](1400/2500): Loss: 0.0963
===> Epoch[46](1500/2500): Loss: 0.0960
===> Epoch[46](1600/2500): Loss: 0.0962
===> Epoch[46](1700/2500): Loss: 0.0963
===> Epoch[46](1800/2500): Loss: 0.0953
===> Epoch[46](1900/2500): Loss: 0.0963
===> Epoch[46](2000/2500): Loss: 0.1027
===> Epoch[46](2100/2500): Loss: 0.0976
===> Epoch[46](2200/2500): Loss: 0.0960
===> Epoch[46](2300/2500): Loss: 0.0959
===> Epoch[46](2400/2500): Loss: 0.0963
===> Epoch[46](2500/2500): Loss: 0.0963
===> Epoch 46 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:06:06]
===> Loading train datasets
===> Epoch[46](100/2500): Loss: 0.0959
===> Epoch[46](200/2500): Loss: 0.0958
===> Epoch[46](300/2500): Loss: 0.0963
===> Epoch[46](400/2500): Loss: 0.0961
===> Epoch[46](500/2500): Loss: 0.0963
===> Epoch[46](600/2500): Loss: 0.0969
===> Epoch[46](700/2500): Loss: 0.0961
===> Epoch[46](800/2500): Loss: 0.0959
===> Epoch[46](900/2500): Loss: 0.0966
===> Epoch[46](1000/2500): Loss: 0.0965
===> Epoch[46](1100/2500): Loss: 0.0964
===> Epoch[46](1200/2500): Loss: 0.0959
===> Epoch[46](1300/2500): Loss: 0.0963
===> Epoch[46](1400/2500): Loss: 0.0963
===> Epoch[46](1500/2500): Loss: 0.0960
===> Epoch[46](1600/2500): Loss: 0.0962
===> Epoch[46](1700/2500): Loss: 0.0963
===> Epoch[46](1800/2500): Loss: 0.0953
===> Epoch[46](1900/2500): Loss: 0.0963
===> Epoch[46](2000/2500): Loss: 0.1027
===> Epoch[46](2100/2500): Loss: 0.0976
===> Epoch[46](2200/2500): Loss: 0.0960
===> Epoch[46](2300/2500): Loss: 0.0959
===> Epoch[46](2400/2500): Loss: 0.0963
===> Epoch[46](2500/2500): Loss: 0.0963
===> Epoch 46 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:06:06]
===> Loading train datasets
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.0958
===> Epoch[47](200/2500): Loss: 0.0959
===> Epoch[47](300/2500): Loss: 0.0967
===> Epoch[47](400/2500): Loss: 0.0960
===> Epoch[47](500/2500): Loss: 0.0963
===> Epoch[47](600/2500): Loss: 0.0956
===> Epoch[47](700/2500): Loss: 0.0961
===> Epoch[47](800/2500): Loss: 0.0958
===> Epoch[47](900/2500): Loss: 0.0962
===> Epoch[47](1000/2500): Loss: 0.0960
===> Epoch[47](1100/2500): Loss: 0.0962
===> Epoch[47](1200/2500): Loss: 0.0956
===> Epoch[47](1300/2500): Loss: 0.0963
===> Epoch[47](1400/2500): Loss: 0.0959
===> Epoch[47](1500/2500): Loss: 0.0963
===> Epoch[47](1600/2500): Loss: 0.0967
===> Epoch[47](1700/2500): Loss: 0.0958
===> Epoch[47](1800/2500): Loss: 0.0964
===> Epoch[47](1900/2500): Loss: 0.0964
===> Epoch[47](2000/2500): Loss: 0.0960
===> Epoch[47](2100/2500): Loss: 0.0959
===> Epoch[47](2200/2500): Loss: 0.0962
===> Epoch[47](2300/2500): Loss: 0.0958
===> Epoch[47](2400/2500): Loss: 0.0965
===> Epoch[47](2500/2500): Loss: 0.0960
===> Epoch 47 Complete: Avg. Loss: 0.0962
===> Timestamp: [2025-07-29 19:11:06]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.0958
===> Epoch[47](200/2500): Loss: 0.0959
===> Epoch[47](300/2500): Loss: 0.0967
===> Epoch[47](400/2500): Loss: 0.0960
===> Epoch[47](500/2500): Loss: 0.0963
===> Epoch[47](600/2500): Loss: 0.0956
===> Epoch[47](700/2500): Loss: 0.0961
===> Epoch[47](800/2500): Loss: 0.0958
===> Epoch[47](900/2500): Loss: 0.0962
===> Epoch[47](1000/2500): Loss: 0.0960
===> Epoch[47](1100/2500): Loss: 0.0962
===> Epoch[47](1200/2500): Loss: 0.0956
===> Epoch[47](1300/2500): Loss: 0.0963
===> Epoch[47](1400/2500): Loss: 0.0959
===> Epoch[47](1500/2500): Loss: 0.0963
===> Epoch[47](1600/2500): Loss: 0.0967
===> Epoch[47](1700/2500): Loss: 0.0958
===> Epoch[47](1800/2500): Loss: 0.0964
===> Epoch[47](1900/2500): Loss: 0.0964
===> Epoch[47](2000/2500): Loss: 0.0960
===> Epoch[47](2100/2500): Loss: 0.0959
===> Epoch[47](2200/2500): Loss: 0.0962
===> Epoch[47](2300/2500): Loss: 0.0958
===> Epoch[47](2400/2500): Loss: 0.0965
===> Epoch[47](2500/2500): Loss: 0.0960
===> Epoch 47 Complete: Avg. Loss: 0.0962
===> Timestamp: [2025-07-29 19:11:06]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.0958
===> Epoch[47](200/2500): Loss: 0.0959
===> Epoch[47](300/2500): Loss: 0.0967
===> Epoch[47](400/2500): Loss: 0.0960
===> Epoch[47](500/2500): Loss: 0.0963
===> Epoch[47](600/2500): Loss: 0.0956
===> Epoch[47](700/2500): Loss: 0.0961
===> Epoch[47](800/2500): Loss: 0.0958
===> Epoch[47](900/2500): Loss: 0.0962
===> Epoch[47](1000/2500): Loss: 0.0960
===> Epoch[47](1100/2500): Loss: 0.0962
===> Epoch[47](1200/2500): Loss: 0.0956
===> Epoch[47](1300/2500): Loss: 0.0963
===> Epoch[47](1400/2500): Loss: 0.0959
===> Epoch[47](1500/2500): Loss: 0.0963
===> Epoch[47](1600/2500): Loss: 0.0967
===> Epoch[47](1700/2500): Loss: 0.0958
===> Epoch[47](1800/2500): Loss: 0.0964
===> Epoch[47](1900/2500): Loss: 0.0964
===> Epoch[47](2000/2500): Loss: 0.0960
===> Epoch[47](2100/2500): Loss: 0.0959
===> Epoch[47](2200/2500): Loss: 0.0962
===> Epoch[47](2300/2500): Loss: 0.0958
===> Epoch[47](2400/2500): Loss: 0.0965
===> Epoch[47](2500/2500): Loss: 0.0960
===> Epoch 47 Complete: Avg. Loss: 0.0962
===> Timestamp: [2025-07-29 19:11:06]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.0958
===> Epoch[47](200/2500): Loss: 0.0959
===> Epoch[47](300/2500): Loss: 0.0967
===> Epoch[47](400/2500): Loss: 0.0960
===> Epoch[47](500/2500): Loss: 0.0963
===> Epoch[47](600/2500): Loss: 0.0956
===> Epoch[47](700/2500): Loss: 0.0961
===> Epoch[47](800/2500): Loss: 0.0958
===> Epoch[47](900/2500): Loss: 0.0962
===> Epoch[47](1000/2500): Loss: 0.0960
===> Epoch[47](1100/2500): Loss: 0.0962
===> Epoch[47](1200/2500): Loss: 0.0956
===> Epoch[47](1300/2500): Loss: 0.0963
===> Epoch[47](1400/2500): Loss: 0.0959
===> Epoch[47](1500/2500): Loss: 0.0963
===> Epoch[47](1600/2500): Loss: 0.0967
===> Epoch[47](1700/2500): Loss: 0.0958
===> Epoch[47](1800/2500): Loss: 0.0964
===> Epoch[47](1900/2500): Loss: 0.0964
===> Epoch[47](2000/2500): Loss: 0.0960
===> Epoch[47](2100/2500): Loss: 0.0959
===> Epoch[47](2200/2500): Loss: 0.0962
===> Epoch[47](2300/2500): Loss: 0.0958
===> Epoch[47](2400/2500): Loss: 0.0965
===> Epoch[47](2500/2500): Loss: 0.0960
===> Epoch 47 Complete: Avg. Loss: 0.0962
===> Timestamp: [2025-07-29 19:11:06]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.0958
===> Epoch[47](200/2500): Loss: 0.0959
===> Epoch[47](300/2500): Loss: 0.0967
===> Epoch[47](400/2500): Loss: 0.0960
===> Epoch[47](500/2500): Loss: 0.0963
===> Epoch[47](600/2500): Loss: 0.0956
===> Epoch[47](700/2500): Loss: 0.0961
===> Epoch[47](800/2500): Loss: 0.0958
===> Epoch[47](900/2500): Loss: 0.0962
===> Epoch[47](1000/2500): Loss: 0.0960
===> Epoch[47](1100/2500): Loss: 0.0962
===> Epoch[47](1200/2500): Loss: 0.0956
===> Epoch[47](1300/2500): Loss: 0.0963
===> Epoch[47](1400/2500): Loss: 0.0959
===> Epoch[47](1500/2500): Loss: 0.0963
===> Epoch[47](1600/2500): Loss: 0.0967
===> Epoch[47](1700/2500): Loss: 0.0958
===> Epoch[47](1800/2500): Loss: 0.0964
===> Epoch[47](1900/2500): Loss: 0.0964
===> Epoch[47](2000/2500): Loss: 0.0960
===> Epoch[47](2100/2500): Loss: 0.0959
===> Epoch[47](2200/2500): Loss: 0.0962
===> Epoch[47](2300/2500): Loss: 0.0958
===> Epoch[47](2400/2500): Loss: 0.0965
===> Epoch[47](2500/2500): Loss: 0.0960
===> Epoch 47 Complete: Avg. Loss: 0.0962
===> Timestamp: [2025-07-29 19:11:06]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.0958
===> Epoch[47](200/2500): Loss: 0.0959
===> Epoch[47](300/2500): Loss: 0.0967
===> Epoch[47](400/2500): Loss: 0.0960
===> Epoch[47](500/2500): Loss: 0.0963
===> Epoch[47](600/2500): Loss: 0.0956
===> Epoch[47](700/2500): Loss: 0.0961
===> Epoch[47](800/2500): Loss: 0.0958
===> Epoch[47](900/2500): Loss: 0.0962
===> Epoch[47](1000/2500): Loss: 0.0960
===> Epoch[47](1100/2500): Loss: 0.0962
===> Epoch[47](1200/2500): Loss: 0.0956
===> Epoch[47](1300/2500): Loss: 0.0963
===> Epoch[47](1400/2500): Loss: 0.0959
===> Epoch[47](1500/2500): Loss: 0.0963
===> Epoch[47](1600/2500): Loss: 0.0967
===> Epoch[47](1700/2500): Loss: 0.0958
===> Epoch[47](1800/2500): Loss: 0.0964
===> Epoch[47](1900/2500): Loss: 0.0964
===> Epoch[47](2000/2500): Loss: 0.0960
===> Epoch[47](2100/2500): Loss: 0.0959
===> Epoch[47](2200/2500): Loss: 0.0962
===> Epoch[47](2300/2500): Loss: 0.0958
===> Epoch[47](2400/2500): Loss: 0.0965
===> Epoch[47](2500/2500): Loss: 0.0960
===> Epoch 47 Complete: Avg. Loss: 0.0962
===> Timestamp: [2025-07-29 19:11:06]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.0958
===> Epoch[47](200/2500): Loss: 0.0959
===> Epoch[47](300/2500): Loss: 0.0967
===> Epoch[47](400/2500): Loss: 0.0960
===> Epoch[47](500/2500): Loss: 0.0963
===> Epoch[47](600/2500): Loss: 0.0956
===> Epoch[47](700/2500): Loss: 0.0961
===> Epoch[47](800/2500): Loss: 0.0958
===> Epoch[47](900/2500): Loss: 0.0962
===> Epoch[47](1000/2500): Loss: 0.0960
===> Epoch[47](1100/2500): Loss: 0.0962
===> Epoch[47](1200/2500): Loss: 0.0956
===> Epoch[47](1300/2500): Loss: 0.0963
===> Epoch[47](1400/2500): Loss: 0.0959
===> Epoch[47](1500/2500): Loss: 0.0963
===> Epoch[47](1600/2500): Loss: 0.0967
===> Epoch[47](1700/2500): Loss: 0.0958
===> Epoch[47](1800/2500): Loss: 0.0964
===> Epoch[47](1900/2500): Loss: 0.0964
===> Epoch[47](2000/2500): Loss: 0.0960
===> Epoch[47](2100/2500): Loss: 0.0959
===> Epoch[47](2200/2500): Loss: 0.0962
===> Epoch[47](2300/2500): Loss: 0.0958
===> Epoch[47](2400/2500): Loss: 0.0965
===> Epoch[47](2500/2500): Loss: 0.0960
===> Epoch 47 Complete: Avg. Loss: 0.0962
===> Timestamp: [2025-07-29 19:11:06]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.0958
===> Epoch[47](200/2500): Loss: 0.0959
===> Epoch[47](300/2500): Loss: 0.0967
===> Epoch[47](400/2500): Loss: 0.0960
===> Epoch[47](500/2500): Loss: 0.0963
===> Epoch[47](600/2500): Loss: 0.0956
===> Epoch[47](700/2500): Loss: 0.0961
===> Epoch[47](800/2500): Loss: 0.0958
===> Epoch[47](900/2500): Loss: 0.0962
===> Epoch[47](1000/2500): Loss: 0.0960
===> Epoch[47](1100/2500): Loss: 0.0962
===> Epoch[47](1200/2500): Loss: 0.0956
===> Epoch[47](1300/2500): Loss: 0.0963
===> Epoch[47](1400/2500): Loss: 0.0959
===> Epoch[47](1500/2500): Loss: 0.0963
===> Epoch[47](1600/2500): Loss: 0.0967
===> Epoch[47](1700/2500): Loss: 0.0958
===> Epoch[47](1800/2500): Loss: 0.0964
===> Epoch[47](1900/2500): Loss: 0.0964
===> Epoch[47](2000/2500): Loss: 0.0960
===> Epoch[47](2100/2500): Loss: 0.0959
===> Epoch[47](2200/2500): Loss: 0.0962
===> Epoch[47](2300/2500): Loss: 0.0958
===> Epoch[47](2400/2500): Loss: 0.0965
===> Epoch[47](2500/2500): Loss: 0.0960
===> Epoch 47 Complete: Avg. Loss: 0.0962
===> Timestamp: [2025-07-29 19:11:06]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.0958
===> Epoch[47](200/2500): Loss: 0.0959
===> Epoch[47](300/2500): Loss: 0.0967
===> Epoch[47](400/2500): Loss: 0.0960
===> Epoch[47](500/2500): Loss: 0.0963
===> Epoch[47](600/2500): Loss: 0.0956
===> Epoch[47](700/2500): Loss: 0.0961
===> Epoch[47](800/2500): Loss: 0.0958
===> Epoch[47](900/2500): Loss: 0.0962
===> Epoch[47](1000/2500): Loss: 0.0960
===> Epoch[47](1100/2500): Loss: 0.0962
===> Epoch[47](1200/2500): Loss: 0.0956
===> Epoch[47](1300/2500): Loss: 0.0963
===> Epoch[47](1400/2500): Loss: 0.0959
===> Epoch[47](1500/2500): Loss: 0.0963
===> Epoch[47](1600/2500): Loss: 0.0967
===> Epoch[47](1700/2500): Loss: 0.0958
===> Epoch[47](1800/2500): Loss: 0.0964
===> Epoch[47](1900/2500): Loss: 0.0964
===> Epoch[47](2000/2500): Loss: 0.0960
===> Epoch[47](2100/2500): Loss: 0.0959
===> Epoch[47](2200/2500): Loss: 0.0962
===> Epoch[47](2300/2500): Loss: 0.0958
===> Epoch[47](2400/2500): Loss: 0.0965
===> Epoch[47](2500/2500): Loss: 0.0960
===> Epoch 47 Complete: Avg. Loss: 0.0962
===> Timestamp: [2025-07-29 19:11:06]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.0958
===> Epoch[47](200/2500): Loss: 0.0959
===> Epoch[47](300/2500): Loss: 0.0967
===> Epoch[47](400/2500): Loss: 0.0960
===> Epoch[47](500/2500): Loss: 0.0963
===> Epoch[47](600/2500): Loss: 0.0956
===> Epoch[47](700/2500): Loss: 0.0961
===> Epoch[47](800/2500): Loss: 0.0958
===> Epoch[47](900/2500): Loss: 0.0962
===> Epoch[47](1000/2500): Loss: 0.0960
===> Epoch[47](1100/2500): Loss: 0.0962
===> Epoch[47](1200/2500): Loss: 0.0956
===> Epoch[47](1300/2500): Loss: 0.0963
===> Epoch[47](1400/2500): Loss: 0.0959
===> Epoch[47](1500/2500): Loss: 0.0963
===> Epoch[47](1600/2500): Loss: 0.0967
===> Epoch[47](1700/2500): Loss: 0.0958
===> Epoch[47](1800/2500): Loss: 0.0964
===> Epoch[47](1900/2500): Loss: 0.0964
===> Epoch[47](2000/2500): Loss: 0.0960
===> Epoch[47](2100/2500): Loss: 0.0959
===> Epoch[47](2200/2500): Loss: 0.0962
===> Epoch[47](2300/2500): Loss: 0.0958
===> Epoch[47](2400/2500): Loss: 0.0965
===> Epoch[47](2500/2500): Loss: 0.0960
===> Epoch 47 Complete: Avg. Loss: 0.0962
===> Timestamp: [2025-07-29 19:11:06]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.0958
===> Epoch[47](200/2500): Loss: 0.0959
===> Epoch[47](300/2500): Loss: 0.0967
===> Epoch[47](400/2500): Loss: 0.0960
===> Epoch[47](500/2500): Loss: 0.0963
===> Epoch[47](600/2500): Loss: 0.0956
===> Epoch[47](700/2500): Loss: 0.0961
===> Epoch[47](800/2500): Loss: 0.0958
===> Epoch[47](900/2500): Loss: 0.0962
===> Epoch[47](1000/2500): Loss: 0.0960
===> Epoch[47](1100/2500): Loss: 0.0962
===> Epoch[47](1200/2500): Loss: 0.0956
===> Epoch[47](1300/2500): Loss: 0.0963
===> Epoch[47](1400/2500): Loss: 0.0959
===> Epoch[47](1500/2500): Loss: 0.0963
===> Epoch[47](1600/2500): Loss: 0.0967
===> Epoch[47](1700/2500): Loss: 0.0958
===> Epoch[47](1800/2500): Loss: 0.0964
===> Epoch[47](1900/2500): Loss: 0.0964
===> Epoch[47](2000/2500): Loss: 0.0960
===> Epoch[47](2100/2500): Loss: 0.0959
===> Epoch[47](2200/2500): Loss: 0.0962
===> Epoch[47](2300/2500): Loss: 0.0958
===> Epoch[47](2400/2500): Loss: 0.0965
===> Epoch[47](2500/2500): Loss: 0.0960
===> Epoch 47 Complete: Avg. Loss: 0.0962
===> Timestamp: [2025-07-29 19:11:06]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.0958
===> Epoch[47](200/2500): Loss: 0.0959
===> Epoch[47](300/2500): Loss: 0.0967
===> Epoch[47](400/2500): Loss: 0.0960
===> Epoch[47](500/2500): Loss: 0.0963
===> Epoch[47](600/2500): Loss: 0.0956
===> Epoch[47](700/2500): Loss: 0.0961
===> Epoch[47](800/2500): Loss: 0.0958
===> Epoch[47](900/2500): Loss: 0.0962
===> Epoch[47](1000/2500): Loss: 0.0960
===> Epoch[47](1100/2500): Loss: 0.0962
===> Epoch[47](1200/2500): Loss: 0.0956
===> Epoch[47](1300/2500): Loss: 0.0963
===> Epoch[47](1400/2500): Loss: 0.0959
===> Epoch[47](1500/2500): Loss: 0.0963
===> Epoch[47](1600/2500): Loss: 0.0967
===> Epoch[47](1700/2500): Loss: 0.0958
===> Epoch[47](1800/2500): Loss: 0.0964
===> Epoch[47](1900/2500): Loss: 0.0964
===> Epoch[47](2000/2500): Loss: 0.0960
===> Epoch[47](2100/2500): Loss: 0.0959
===> Epoch[47](2200/2500): Loss: 0.0962
===> Epoch[47](2300/2500): Loss: 0.0958
===> Epoch[47](2400/2500): Loss: 0.0965
===> Epoch[47](2500/2500): Loss: 0.0960
===> Epoch 47 Complete: Avg. Loss: 0.0962
===> Timestamp: [2025-07-29 19:11:06]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.0958
===> Epoch[47](200/2500): Loss: 0.0959
===> Epoch[47](300/2500): Loss: 0.0967
===> Epoch[47](400/2500): Loss: 0.0960
===> Epoch[47](500/2500): Loss: 0.0963
===> Epoch[47](600/2500): Loss: 0.0956
===> Epoch[47](700/2500): Loss: 0.0961
===> Epoch[47](800/2500): Loss: 0.0958
===> Epoch[47](900/2500): Loss: 0.0962
===> Epoch[47](1000/2500): Loss: 0.0960
===> Epoch[47](1100/2500): Loss: 0.0962
===> Epoch[47](1200/2500): Loss: 0.0956
===> Epoch[47](1300/2500): Loss: 0.0963
===> Epoch[47](1400/2500): Loss: 0.0959
===> Epoch[47](1500/2500): Loss: 0.0963
===> Epoch[47](1600/2500): Loss: 0.0967
===> Epoch[47](1700/2500): Loss: 0.0958
===> Epoch[47](1800/2500): Loss: 0.0964
===> Epoch[47](1900/2500): Loss: 0.0964
===> Epoch[47](2000/2500): Loss: 0.0960
===> Epoch[47](2100/2500): Loss: 0.0959
===> Epoch[47](2200/2500): Loss: 0.0962
===> Epoch[47](2300/2500): Loss: 0.0958
===> Epoch[47](2400/2500): Loss: 0.0965
===> Epoch[47](2500/2500): Loss: 0.0960
===> Epoch 47 Complete: Avg. Loss: 0.0962
===> Timestamp: [2025-07-29 19:11:06]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.0958
===> Epoch[47](200/2500): Loss: 0.0959
===> Epoch[47](300/2500): Loss: 0.0967
===> Epoch[47](400/2500): Loss: 0.0960
===> Epoch[47](500/2500): Loss: 0.0963
===> Epoch[47](600/2500): Loss: 0.0956
===> Epoch[47](700/2500): Loss: 0.0961
===> Epoch[47](800/2500): Loss: 0.0958
===> Epoch[47](900/2500): Loss: 0.0962
===> Epoch[47](1000/2500): Loss: 0.0960
===> Epoch[47](1100/2500): Loss: 0.0962
===> Epoch[47](1200/2500): Loss: 0.0956
===> Epoch[47](1300/2500): Loss: 0.0963
===> Epoch[47](1400/2500): Loss: 0.0959
===> Epoch[47](1500/2500): Loss: 0.0963
===> Epoch[47](1600/2500): Loss: 0.0967
===> Epoch[47](1700/2500): Loss: 0.0958
===> Epoch[47](1800/2500): Loss: 0.0964
===> Epoch[47](1900/2500): Loss: 0.0964
===> Epoch[47](2000/2500): Loss: 0.0960
===> Epoch[47](2100/2500): Loss: 0.0959
===> Epoch[47](2200/2500): Loss: 0.0962
===> Epoch[47](2300/2500): Loss: 0.0958
===> Epoch[47](2400/2500): Loss: 0.0965
===> Epoch[47](2500/2500): Loss: 0.0960
===> Epoch 47 Complete: Avg. Loss: 0.0962
===> Timestamp: [2025-07-29 19:11:06]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.0958
===> Epoch[47](200/2500): Loss: 0.0959
===> Epoch[47](300/2500): Loss: 0.0967
===> Epoch[47](400/2500): Loss: 0.0960
===> Epoch[47](500/2500): Loss: 0.0963
===> Epoch[47](600/2500): Loss: 0.0956
===> Epoch[47](700/2500): Loss: 0.0961
===> Epoch[47](800/2500): Loss: 0.0958
===> Epoch[47](900/2500): Loss: 0.0962
===> Epoch[47](1000/2500): Loss: 0.0960
===> Epoch[47](1100/2500): Loss: 0.0962
===> Epoch[47](1200/2500): Loss: 0.0956
===> Epoch[47](1300/2500): Loss: 0.0963
===> Epoch[47](1400/2500): Loss: 0.0959
===> Epoch[47](1500/2500): Loss: 0.0963
===> Epoch[47](1600/2500): Loss: 0.0967
===> Epoch[47](1700/2500): Loss: 0.0958
===> Epoch[47](1800/2500): Loss: 0.0964
===> Epoch[47](1900/2500): Loss: 0.0964
===> Epoch[47](2000/2500): Loss: 0.0960
===> Epoch[47](2100/2500): Loss: 0.0959
===> Epoch[47](2200/2500): Loss: 0.0962
===> Epoch[47](2300/2500): Loss: 0.0958
===> Epoch[47](2400/2500): Loss: 0.0965
===> Epoch[47](2500/2500): Loss: 0.0960
===> Epoch 47 Complete: Avg. Loss: 0.0962
===> Timestamp: [2025-07-29 19:11:06]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.0958
===> Epoch[47](200/2500): Loss: 0.0959
===> Epoch[47](300/2500): Loss: 0.0967
===> Epoch[47](400/2500): Loss: 0.0960
===> Epoch[47](500/2500): Loss: 0.0963
===> Epoch[47](600/2500): Loss: 0.0956
===> Epoch[47](700/2500): Loss: 0.0961
===> Epoch[47](800/2500): Loss: 0.0958
===> Epoch[47](900/2500): Loss: 0.0962
===> Epoch[47](1000/2500): Loss: 0.0960
===> Epoch[47](1100/2500): Loss: 0.0962
===> Epoch[47](1200/2500): Loss: 0.0956
===> Epoch[47](1300/2500): Loss: 0.0963
===> Epoch[47](1400/2500): Loss: 0.0959
===> Epoch[47](1500/2500): Loss: 0.0963
===> Epoch[47](1600/2500): Loss: 0.0967
===> Epoch[47](1700/2500): Loss: 0.0958
===> Epoch[47](1800/2500): Loss: 0.0964
===> Epoch[47](1900/2500): Loss: 0.0964
===> Epoch[47](2000/2500): Loss: 0.0960
===> Epoch[47](2100/2500): Loss: 0.0959
===> Epoch[47](2200/2500): Loss: 0.0962
===> Epoch[47](2300/2500): Loss: 0.0958
===> Epoch[47](2400/2500): Loss: 0.0965
===> Epoch[47](2500/2500): Loss: 0.0960
===> Epoch 47 Complete: Avg. Loss: 0.0962
===> Timestamp: [2025-07-29 19:11:06]
===> Loading train datasets
===> Epoch[47](100/2500): Loss: 0.0958
===> Epoch[47](200/2500): Loss: 0.0959
===> Epoch[47](300/2500): Loss: 0.0967
===> Epoch[47](400/2500): Loss: 0.0960
===> Epoch[47](500/2500): Loss: 0.0963
===> Epoch[47](600/2500): Loss: 0.0956
===> Epoch[47](700/2500): Loss: 0.0961
===> Epoch[47](800/2500): Loss: 0.0958
===> Epoch[47](900/2500): Loss: 0.0962
===> Epoch[47](1000/2500): Loss: 0.0960
===> Epoch[47](1100/2500): Loss: 0.0962
===> Epoch[47](1200/2500): Loss: 0.0956
===> Epoch[47](1300/2500): Loss: 0.0963
===> Epoch[47](1400/2500): Loss: 0.0959
===> Epoch[47](1500/2500): Loss: 0.0963
===> Epoch[47](1600/2500): Loss: 0.0967
===> Epoch[47](1700/2500): Loss: 0.0958
===> Epoch[47](1800/2500): Loss: 0.0964
===> Epoch[47](1900/2500): Loss: 0.0964
===> Epoch[47](2000/2500): Loss: 0.0960
===> Epoch[47](2100/2500): Loss: 0.0959
===> Epoch[47](2200/2500): Loss: 0.0962
===> Epoch[47](2300/2500): Loss: 0.0958
===> Epoch[47](2400/2500): Loss: 0.0965
===> Epoch[47](2500/2500): Loss: 0.0960
===> Epoch 47 Complete: Avg. Loss: 0.0962
===> Timestamp: [2025-07-29 19:11:06]
===> Loading train datasets
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.1020
===> Epoch[48](200/2500): Loss: 0.0967
===> Epoch[48](300/2500): Loss: 0.0965
===> Epoch[48](400/2500): Loss: 0.0963
===> Epoch[48](500/2500): Loss: 0.0965
===> Epoch[48](600/2500): Loss: 0.0964
===> Epoch[48](700/2500): Loss: 0.0962
===> Epoch[48](800/2500): Loss: 0.0960
===> Epoch[48](900/2500): Loss: 0.0959
===> Epoch[48](1000/2500): Loss: 0.0964
===> Epoch[48](1100/2500): Loss: 0.0962
===> Epoch[48](1200/2500): Loss: 0.0962
===> Epoch[48](1300/2500): Loss: 0.0960
===> Epoch[48](1400/2500): Loss: 0.0962
===> Epoch[48](1500/2500): Loss: 0.0964
===> Epoch[48](1600/2500): Loss: 0.0965
===> Epoch[48](1700/2500): Loss: 0.0961
===> Epoch[48](1800/2500): Loss: 0.0958
===> Epoch[48](1900/2500): Loss: 0.0967
===> Epoch[48](2000/2500): Loss: 0.0966
===> Epoch[48](2100/2500): Loss: 0.0965
===> Epoch[48](2200/2500): Loss: 0.0965
===> Epoch[48](2300/2500): Loss: 0.0962
===> Epoch[48](2400/2500): Loss: 0.0962
===> Epoch[48](2500/2500): Loss: 0.0967
===> Epoch 48 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:16:05]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.1020
===> Epoch[48](200/2500): Loss: 0.0967
===> Epoch[48](300/2500): Loss: 0.0965
===> Epoch[48](400/2500): Loss: 0.0963
===> Epoch[48](500/2500): Loss: 0.0965
===> Epoch[48](600/2500): Loss: 0.0964
===> Epoch[48](700/2500): Loss: 0.0962
===> Epoch[48](800/2500): Loss: 0.0960
===> Epoch[48](900/2500): Loss: 0.0959
===> Epoch[48](1000/2500): Loss: 0.0964
===> Epoch[48](1100/2500): Loss: 0.0962
===> Epoch[48](1200/2500): Loss: 0.0962
===> Epoch[48](1300/2500): Loss: 0.0960
===> Epoch[48](1400/2500): Loss: 0.0962
===> Epoch[48](1500/2500): Loss: 0.0964
===> Epoch[48](1600/2500): Loss: 0.0965
===> Epoch[48](1700/2500): Loss: 0.0961
===> Epoch[48](1800/2500): Loss: 0.0958
===> Epoch[48](1900/2500): Loss: 0.0967
===> Epoch[48](2000/2500): Loss: 0.0966
===> Epoch[48](2100/2500): Loss: 0.0965
===> Epoch[48](2200/2500): Loss: 0.0965
===> Epoch[48](2300/2500): Loss: 0.0962
===> Epoch[48](2400/2500): Loss: 0.0962
===> Epoch[48](2500/2500): Loss: 0.0967
===> Epoch 48 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:16:05]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.1020
===> Epoch[48](200/2500): Loss: 0.0967
===> Epoch[48](300/2500): Loss: 0.0965
===> Epoch[48](400/2500): Loss: 0.0963
===> Epoch[48](500/2500): Loss: 0.0965
===> Epoch[48](600/2500): Loss: 0.0964
===> Epoch[48](700/2500): Loss: 0.0962
===> Epoch[48](800/2500): Loss: 0.0960
===> Epoch[48](900/2500): Loss: 0.0959
===> Epoch[48](1000/2500): Loss: 0.0964
===> Epoch[48](1100/2500): Loss: 0.0962
===> Epoch[48](1200/2500): Loss: 0.0962
===> Epoch[48](1300/2500): Loss: 0.0960
===> Epoch[48](1400/2500): Loss: 0.0962
===> Epoch[48](1500/2500): Loss: 0.0964
===> Epoch[48](1600/2500): Loss: 0.0965
===> Epoch[48](1700/2500): Loss: 0.0961
===> Epoch[48](1800/2500): Loss: 0.0958
===> Epoch[48](1900/2500): Loss: 0.0967
===> Epoch[48](2000/2500): Loss: 0.0966
===> Epoch[48](2100/2500): Loss: 0.0965
===> Epoch[48](2200/2500): Loss: 0.0965
===> Epoch[48](2300/2500): Loss: 0.0962
===> Epoch[48](2400/2500): Loss: 0.0962
===> Epoch[48](2500/2500): Loss: 0.0967
===> Epoch 48 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:16:05]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.1020
===> Epoch[48](200/2500): Loss: 0.0967
===> Epoch[48](300/2500): Loss: 0.0965
===> Epoch[48](400/2500): Loss: 0.0963
===> Epoch[48](500/2500): Loss: 0.0965
===> Epoch[48](600/2500): Loss: 0.0964
===> Epoch[48](700/2500): Loss: 0.0962
===> Epoch[48](800/2500): Loss: 0.0960
===> Epoch[48](900/2500): Loss: 0.0959
===> Epoch[48](1000/2500): Loss: 0.0964
===> Epoch[48](1100/2500): Loss: 0.0962
===> Epoch[48](1200/2500): Loss: 0.0962
===> Epoch[48](1300/2500): Loss: 0.0960
===> Epoch[48](1400/2500): Loss: 0.0962
===> Epoch[48](1500/2500): Loss: 0.0964
===> Epoch[48](1600/2500): Loss: 0.0965
===> Epoch[48](1700/2500): Loss: 0.0961
===> Epoch[48](1800/2500): Loss: 0.0958
===> Epoch[48](1900/2500): Loss: 0.0967
===> Epoch[48](2000/2500): Loss: 0.0966
===> Epoch[48](2100/2500): Loss: 0.0965
===> Epoch[48](2200/2500): Loss: 0.0965
===> Epoch[48](2300/2500): Loss: 0.0962
===> Epoch[48](2400/2500): Loss: 0.0962
===> Epoch[48](2500/2500): Loss: 0.0967
===> Epoch 48 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:16:05]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.1020
===> Epoch[48](200/2500): Loss: 0.0967
===> Epoch[48](300/2500): Loss: 0.0965
===> Epoch[48](400/2500): Loss: 0.0963
===> Epoch[48](500/2500): Loss: 0.0965
===> Epoch[48](600/2500): Loss: 0.0964
===> Epoch[48](700/2500): Loss: 0.0962
===> Epoch[48](800/2500): Loss: 0.0960
===> Epoch[48](900/2500): Loss: 0.0959
===> Epoch[48](1000/2500): Loss: 0.0964
===> Epoch[48](1100/2500): Loss: 0.0962
===> Epoch[48](1200/2500): Loss: 0.0962
===> Epoch[48](1300/2500): Loss: 0.0960
===> Epoch[48](1400/2500): Loss: 0.0962
===> Epoch[48](1500/2500): Loss: 0.0964
===> Epoch[48](1600/2500): Loss: 0.0965
===> Epoch[48](1700/2500): Loss: 0.0961
===> Epoch[48](1800/2500): Loss: 0.0958
===> Epoch[48](1900/2500): Loss: 0.0967
===> Epoch[48](2000/2500): Loss: 0.0966
===> Epoch[48](2100/2500): Loss: 0.0965
===> Epoch[48](2200/2500): Loss: 0.0965
===> Epoch[48](2300/2500): Loss: 0.0962
===> Epoch[48](2400/2500): Loss: 0.0962
===> Epoch[48](2500/2500): Loss: 0.0967
===> Epoch 48 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:16:05]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.1020
===> Epoch[48](200/2500): Loss: 0.0967
===> Epoch[48](300/2500): Loss: 0.0965
===> Epoch[48](400/2500): Loss: 0.0963
===> Epoch[48](500/2500): Loss: 0.0965
===> Epoch[48](600/2500): Loss: 0.0964
===> Epoch[48](700/2500): Loss: 0.0962
===> Epoch[48](800/2500): Loss: 0.0960
===> Epoch[48](900/2500): Loss: 0.0959
===> Epoch[48](1000/2500): Loss: 0.0964
===> Epoch[48](1100/2500): Loss: 0.0962
===> Epoch[48](1200/2500): Loss: 0.0962
===> Epoch[48](1300/2500): Loss: 0.0960
===> Epoch[48](1400/2500): Loss: 0.0962
===> Epoch[48](1500/2500): Loss: 0.0964
===> Epoch[48](1600/2500): Loss: 0.0965
===> Epoch[48](1700/2500): Loss: 0.0961
===> Epoch[48](1800/2500): Loss: 0.0958
===> Epoch[48](1900/2500): Loss: 0.0967
===> Epoch[48](2000/2500): Loss: 0.0966
===> Epoch[48](2100/2500): Loss: 0.0965
===> Epoch[48](2200/2500): Loss: 0.0965
===> Epoch[48](2300/2500): Loss: 0.0962
===> Epoch[48](2400/2500): Loss: 0.0962
===> Epoch[48](2500/2500): Loss: 0.0967
===> Epoch 48 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:16:05]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.1020
===> Epoch[48](200/2500): Loss: 0.0967
===> Epoch[48](300/2500): Loss: 0.0965
===> Epoch[48](400/2500): Loss: 0.0963
===> Epoch[48](500/2500): Loss: 0.0965
===> Epoch[48](600/2500): Loss: 0.0964
===> Epoch[48](700/2500): Loss: 0.0962
===> Epoch[48](800/2500): Loss: 0.0960
===> Epoch[48](900/2500): Loss: 0.0959
===> Epoch[48](1000/2500): Loss: 0.0964
===> Epoch[48](1100/2500): Loss: 0.0962
===> Epoch[48](1200/2500): Loss: 0.0962
===> Epoch[48](1300/2500): Loss: 0.0960
===> Epoch[48](1400/2500): Loss: 0.0962
===> Epoch[48](1500/2500): Loss: 0.0964
===> Epoch[48](1600/2500): Loss: 0.0965
===> Epoch[48](1700/2500): Loss: 0.0961
===> Epoch[48](1800/2500): Loss: 0.0958
===> Epoch[48](1900/2500): Loss: 0.0967
===> Epoch[48](2000/2500): Loss: 0.0966
===> Epoch[48](2100/2500): Loss: 0.0965
===> Epoch[48](2200/2500): Loss: 0.0965
===> Epoch[48](2300/2500): Loss: 0.0962
===> Epoch[48](2400/2500): Loss: 0.0962
===> Epoch[48](2500/2500): Loss: 0.0967
===> Epoch 48 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:16:05]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.1020
===> Epoch[48](200/2500): Loss: 0.0967
===> Epoch[48](300/2500): Loss: 0.0965
===> Epoch[48](400/2500): Loss: 0.0963
===> Epoch[48](500/2500): Loss: 0.0965
===> Epoch[48](600/2500): Loss: 0.0964
===> Epoch[48](700/2500): Loss: 0.0962
===> Epoch[48](800/2500): Loss: 0.0960
===> Epoch[48](900/2500): Loss: 0.0959
===> Epoch[48](1000/2500): Loss: 0.0964
===> Epoch[48](1100/2500): Loss: 0.0962
===> Epoch[48](1200/2500): Loss: 0.0962
===> Epoch[48](1300/2500): Loss: 0.0960
===> Epoch[48](1400/2500): Loss: 0.0962
===> Epoch[48](1500/2500): Loss: 0.0964
===> Epoch[48](1600/2500): Loss: 0.0965
===> Epoch[48](1700/2500): Loss: 0.0961
===> Epoch[48](1800/2500): Loss: 0.0958
===> Epoch[48](1900/2500): Loss: 0.0967
===> Epoch[48](2000/2500): Loss: 0.0966
===> Epoch[48](2100/2500): Loss: 0.0965
===> Epoch[48](2200/2500): Loss: 0.0965
===> Epoch[48](2300/2500): Loss: 0.0962
===> Epoch[48](2400/2500): Loss: 0.0962
===> Epoch[48](2500/2500): Loss: 0.0967
===> Epoch 48 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:16:05]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.1020
===> Epoch[48](200/2500): Loss: 0.0967
===> Epoch[48](300/2500): Loss: 0.0965
===> Epoch[48](400/2500): Loss: 0.0963
===> Epoch[48](500/2500): Loss: 0.0965
===> Epoch[48](600/2500): Loss: 0.0964
===> Epoch[48](700/2500): Loss: 0.0962
===> Epoch[48](800/2500): Loss: 0.0960
===> Epoch[48](900/2500): Loss: 0.0959
===> Epoch[48](1000/2500): Loss: 0.0964
===> Epoch[48](1100/2500): Loss: 0.0962
===> Epoch[48](1200/2500): Loss: 0.0962
===> Epoch[48](1300/2500): Loss: 0.0960
===> Epoch[48](1400/2500): Loss: 0.0962
===> Epoch[48](1500/2500): Loss: 0.0964
===> Epoch[48](1600/2500): Loss: 0.0965
===> Epoch[48](1700/2500): Loss: 0.0961
===> Epoch[48](1800/2500): Loss: 0.0958
===> Epoch[48](1900/2500): Loss: 0.0967
===> Epoch[48](2000/2500): Loss: 0.0966
===> Epoch[48](2100/2500): Loss: 0.0965
===> Epoch[48](2200/2500): Loss: 0.0965
===> Epoch[48](2300/2500): Loss: 0.0962
===> Epoch[48](2400/2500): Loss: 0.0962
===> Epoch[48](2500/2500): Loss: 0.0967
===> Epoch 48 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:16:05]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.1020
===> Epoch[48](200/2500): Loss: 0.0967
===> Epoch[48](300/2500): Loss: 0.0965
===> Epoch[48](400/2500): Loss: 0.0963
===> Epoch[48](500/2500): Loss: 0.0965
===> Epoch[48](600/2500): Loss: 0.0964
===> Epoch[48](700/2500): Loss: 0.0962
===> Epoch[48](800/2500): Loss: 0.0960
===> Epoch[48](900/2500): Loss: 0.0959
===> Epoch[48](1000/2500): Loss: 0.0964
===> Epoch[48](1100/2500): Loss: 0.0962
===> Epoch[48](1200/2500): Loss: 0.0962
===> Epoch[48](1300/2500): Loss: 0.0960
===> Epoch[48](1400/2500): Loss: 0.0962
===> Epoch[48](1500/2500): Loss: 0.0964
===> Epoch[48](1600/2500): Loss: 0.0965
===> Epoch[48](1700/2500): Loss: 0.0961
===> Epoch[48](1800/2500): Loss: 0.0958
===> Epoch[48](1900/2500): Loss: 0.0967
===> Epoch[48](2000/2500): Loss: 0.0966
===> Epoch[48](2100/2500): Loss: 0.0965
===> Epoch[48](2200/2500): Loss: 0.0965
===> Epoch[48](2300/2500): Loss: 0.0962
===> Epoch[48](2400/2500): Loss: 0.0962
===> Epoch[48](2500/2500): Loss: 0.0967
===> Epoch 48 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:16:05]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.1020
===> Epoch[48](200/2500): Loss: 0.0967
===> Epoch[48](300/2500): Loss: 0.0965
===> Epoch[48](400/2500): Loss: 0.0963
===> Epoch[48](500/2500): Loss: 0.0965
===> Epoch[48](600/2500): Loss: 0.0964
===> Epoch[48](700/2500): Loss: 0.0962
===> Epoch[48](800/2500): Loss: 0.0960
===> Epoch[48](900/2500): Loss: 0.0959
===> Epoch[48](1000/2500): Loss: 0.0964
===> Epoch[48](1100/2500): Loss: 0.0962
===> Epoch[48](1200/2500): Loss: 0.0962
===> Epoch[48](1300/2500): Loss: 0.0960
===> Epoch[48](1400/2500): Loss: 0.0962
===> Epoch[48](1500/2500): Loss: 0.0964
===> Epoch[48](1600/2500): Loss: 0.0965
===> Epoch[48](1700/2500): Loss: 0.0961
===> Epoch[48](1800/2500): Loss: 0.0958
===> Epoch[48](1900/2500): Loss: 0.0967
===> Epoch[48](2000/2500): Loss: 0.0966
===> Epoch[48](2100/2500): Loss: 0.0965
===> Epoch[48](2200/2500): Loss: 0.0965
===> Epoch[48](2300/2500): Loss: 0.0962
===> Epoch[48](2400/2500): Loss: 0.0962
===> Epoch[48](2500/2500): Loss: 0.0967
===> Epoch 48 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:16:05]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.1020
===> Epoch[48](200/2500): Loss: 0.0967
===> Epoch[48](300/2500): Loss: 0.0965
===> Epoch[48](400/2500): Loss: 0.0963
===> Epoch[48](500/2500): Loss: 0.0965
===> Epoch[48](600/2500): Loss: 0.0964
===> Epoch[48](700/2500): Loss: 0.0962
===> Epoch[48](800/2500): Loss: 0.0960
===> Epoch[48](900/2500): Loss: 0.0959
===> Epoch[48](1000/2500): Loss: 0.0964
===> Epoch[48](1100/2500): Loss: 0.0962
===> Epoch[48](1200/2500): Loss: 0.0962
===> Epoch[48](1300/2500): Loss: 0.0960
===> Epoch[48](1400/2500): Loss: 0.0962
===> Epoch[48](1500/2500): Loss: 0.0964
===> Epoch[48](1600/2500): Loss: 0.0965
===> Epoch[48](1700/2500): Loss: 0.0961
===> Epoch[48](1800/2500): Loss: 0.0958
===> Epoch[48](1900/2500): Loss: 0.0967
===> Epoch[48](2000/2500): Loss: 0.0966
===> Epoch[48](2100/2500): Loss: 0.0965
===> Epoch[48](2200/2500): Loss: 0.0965
===> Epoch[48](2300/2500): Loss: 0.0962
===> Epoch[48](2400/2500): Loss: 0.0962
===> Epoch[48](2500/2500): Loss: 0.0967
===> Epoch 48 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:16:05]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.1020
===> Epoch[48](200/2500): Loss: 0.0967
===> Epoch[48](300/2500): Loss: 0.0965
===> Epoch[48](400/2500): Loss: 0.0963
===> Epoch[48](500/2500): Loss: 0.0965
===> Epoch[48](600/2500): Loss: 0.0964
===> Epoch[48](700/2500): Loss: 0.0962
===> Epoch[48](800/2500): Loss: 0.0960
===> Epoch[48](900/2500): Loss: 0.0959
===> Epoch[48](1000/2500): Loss: 0.0964
===> Epoch[48](1100/2500): Loss: 0.0962
===> Epoch[48](1200/2500): Loss: 0.0962
===> Epoch[48](1300/2500): Loss: 0.0960
===> Epoch[48](1400/2500): Loss: 0.0962
===> Epoch[48](1500/2500): Loss: 0.0964
===> Epoch[48](1600/2500): Loss: 0.0965
===> Epoch[48](1700/2500): Loss: 0.0961
===> Epoch[48](1800/2500): Loss: 0.0958
===> Epoch[48](1900/2500): Loss: 0.0967
===> Epoch[48](2000/2500): Loss: 0.0966
===> Epoch[48](2100/2500): Loss: 0.0965
===> Epoch[48](2200/2500): Loss: 0.0965
===> Epoch[48](2300/2500): Loss: 0.0962
===> Epoch[48](2400/2500): Loss: 0.0962
===> Epoch[48](2500/2500): Loss: 0.0967
===> Epoch 48 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:16:05]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.1020
===> Epoch[48](200/2500): Loss: 0.0967
===> Epoch[48](300/2500): Loss: 0.0965
===> Epoch[48](400/2500): Loss: 0.0963
===> Epoch[48](500/2500): Loss: 0.0965
===> Epoch[48](600/2500): Loss: 0.0964
===> Epoch[48](700/2500): Loss: 0.0962
===> Epoch[48](800/2500): Loss: 0.0960
===> Epoch[48](900/2500): Loss: 0.0959
===> Epoch[48](1000/2500): Loss: 0.0964
===> Epoch[48](1100/2500): Loss: 0.0962
===> Epoch[48](1200/2500): Loss: 0.0962
===> Epoch[48](1300/2500): Loss: 0.0960
===> Epoch[48](1400/2500): Loss: 0.0962
===> Epoch[48](1500/2500): Loss: 0.0964
===> Epoch[48](1600/2500): Loss: 0.0965
===> Epoch[48](1700/2500): Loss: 0.0961
===> Epoch[48](1800/2500): Loss: 0.0958
===> Epoch[48](1900/2500): Loss: 0.0967
===> Epoch[48](2000/2500): Loss: 0.0966
===> Epoch[48](2100/2500): Loss: 0.0965
===> Epoch[48](2200/2500): Loss: 0.0965
===> Epoch[48](2300/2500): Loss: 0.0962
===> Epoch[48](2400/2500): Loss: 0.0962
===> Epoch[48](2500/2500): Loss: 0.0967
===> Epoch 48 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:16:05]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.1020
===> Epoch[48](200/2500): Loss: 0.0967
===> Epoch[48](300/2500): Loss: 0.0965
===> Epoch[48](400/2500): Loss: 0.0963
===> Epoch[48](500/2500): Loss: 0.0965
===> Epoch[48](600/2500): Loss: 0.0964
===> Epoch[48](700/2500): Loss: 0.0962
===> Epoch[48](800/2500): Loss: 0.0960
===> Epoch[48](900/2500): Loss: 0.0959
===> Epoch[48](1000/2500): Loss: 0.0964
===> Epoch[48](1100/2500): Loss: 0.0962
===> Epoch[48](1200/2500): Loss: 0.0962
===> Epoch[48](1300/2500): Loss: 0.0960
===> Epoch[48](1400/2500): Loss: 0.0962
===> Epoch[48](1500/2500): Loss: 0.0964
===> Epoch[48](1600/2500): Loss: 0.0965
===> Epoch[48](1700/2500): Loss: 0.0961
===> Epoch[48](1800/2500): Loss: 0.0958
===> Epoch[48](1900/2500): Loss: 0.0967
===> Epoch[48](2000/2500): Loss: 0.0966
===> Epoch[48](2100/2500): Loss: 0.0965
===> Epoch[48](2200/2500): Loss: 0.0965
===> Epoch[48](2300/2500): Loss: 0.0962
===> Epoch[48](2400/2500): Loss: 0.0962
===> Epoch[48](2500/2500): Loss: 0.0967
===> Epoch 48 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:16:05]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.1020
===> Epoch[48](200/2500): Loss: 0.0967
===> Epoch[48](300/2500): Loss: 0.0965
===> Epoch[48](400/2500): Loss: 0.0963
===> Epoch[48](500/2500): Loss: 0.0965
===> Epoch[48](600/2500): Loss: 0.0964
===> Epoch[48](700/2500): Loss: 0.0962
===> Epoch[48](800/2500): Loss: 0.0960
===> Epoch[48](900/2500): Loss: 0.0959
===> Epoch[48](1000/2500): Loss: 0.0964
===> Epoch[48](1100/2500): Loss: 0.0962
===> Epoch[48](1200/2500): Loss: 0.0962
===> Epoch[48](1300/2500): Loss: 0.0960
===> Epoch[48](1400/2500): Loss: 0.0962
===> Epoch[48](1500/2500): Loss: 0.0964
===> Epoch[48](1600/2500): Loss: 0.0965
===> Epoch[48](1700/2500): Loss: 0.0961
===> Epoch[48](1800/2500): Loss: 0.0958
===> Epoch[48](1900/2500): Loss: 0.0967
===> Epoch[48](2000/2500): Loss: 0.0966
===> Epoch[48](2100/2500): Loss: 0.0965
===> Epoch[48](2200/2500): Loss: 0.0965
===> Epoch[48](2300/2500): Loss: 0.0962
===> Epoch[48](2400/2500): Loss: 0.0962
===> Epoch[48](2500/2500): Loss: 0.0967
===> Epoch 48 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:16:05]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.1020
===> Epoch[48](200/2500): Loss: 0.0967
===> Epoch[48](300/2500): Loss: 0.0965
===> Epoch[48](400/2500): Loss: 0.0963
===> Epoch[48](500/2500): Loss: 0.0965
===> Epoch[48](600/2500): Loss: 0.0964
===> Epoch[48](700/2500): Loss: 0.0962
===> Epoch[48](800/2500): Loss: 0.0960
===> Epoch[48](900/2500): Loss: 0.0959
===> Epoch[48](1000/2500): Loss: 0.0964
===> Epoch[48](1100/2500): Loss: 0.0962
===> Epoch[48](1200/2500): Loss: 0.0962
===> Epoch[48](1300/2500): Loss: 0.0960
===> Epoch[48](1400/2500): Loss: 0.0962
===> Epoch[48](1500/2500): Loss: 0.0964
===> Epoch[48](1600/2500): Loss: 0.0965
===> Epoch[48](1700/2500): Loss: 0.0961
===> Epoch[48](1800/2500): Loss: 0.0958
===> Epoch[48](1900/2500): Loss: 0.0967
===> Epoch[48](2000/2500): Loss: 0.0966
===> Epoch[48](2100/2500): Loss: 0.0965
===> Epoch[48](2200/2500): Loss: 0.0965
===> Epoch[48](2300/2500): Loss: 0.0962
===> Epoch[48](2400/2500): Loss: 0.0962
===> Epoch[48](2500/2500): Loss: 0.0967
===> Epoch 48 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:16:05]
===> Loading train datasets
===> Epoch[48](100/2500): Loss: 0.1020
===> Epoch[48](200/2500): Loss: 0.0967
===> Epoch[48](300/2500): Loss: 0.0965
===> Epoch[48](400/2500): Loss: 0.0963
===> Epoch[48](500/2500): Loss: 0.0965
===> Epoch[48](600/2500): Loss: 0.0964
===> Epoch[48](700/2500): Loss: 0.0962
===> Epoch[48](800/2500): Loss: 0.0960
===> Epoch[48](900/2500): Loss: 0.0959
===> Epoch[48](1000/2500): Loss: 0.0964
===> Epoch[48](1100/2500): Loss: 0.0962
===> Epoch[48](1200/2500): Loss: 0.0962
===> Epoch[48](1300/2500): Loss: 0.0960
===> Epoch[48](1400/2500): Loss: 0.0962
===> Epoch[48](1500/2500): Loss: 0.0964
===> Epoch[48](1600/2500): Loss: 0.0965
===> Epoch[48](1700/2500): Loss: 0.0961
===> Epoch[48](1800/2500): Loss: 0.0958
===> Epoch[48](1900/2500): Loss: 0.0967
===> Epoch[48](2000/2500): Loss: 0.0966
===> Epoch[48](2100/2500): Loss: 0.0965
===> Epoch[48](2200/2500): Loss: 0.0965
===> Epoch[48](2300/2500): Loss: 0.0962
===> Epoch[48](2400/2500): Loss: 0.0962
===> Epoch[48](2500/2500): Loss: 0.0967
===> Epoch 48 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:16:05]
===> Loading train datasets
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.0963
===> Epoch[49](200/2500): Loss: 0.0967
===> Epoch[49](300/2500): Loss: 0.1003
===> Epoch[49](400/2500): Loss: 0.0960
===> Epoch[49](500/2500): Loss: 0.0961
===> Epoch[49](600/2500): Loss: 0.0957
===> Epoch[49](700/2500): Loss: 0.0967
===> Epoch[49](800/2500): Loss: 0.0966
===> Epoch[49](900/2500): Loss: 0.0957
===> Epoch[49](1000/2500): Loss: 0.0962
===> Epoch[49](1100/2500): Loss: 0.0965
===> Epoch[49](1200/2500): Loss: 0.0964
===> Epoch[49](1300/2500): Loss: 0.0968
===> Epoch[49](1400/2500): Loss: 0.0959
===> Epoch[49](1500/2500): Loss: 0.0958
===> Epoch[49](1600/2500): Loss: 0.0962
===> Epoch[49](1700/2500): Loss: 0.0958
===> Epoch[49](1800/2500): Loss: 0.0958
===> Epoch[49](1900/2500): Loss: 0.0961
===> Epoch[49](2000/2500): Loss: 0.0961
===> Epoch[49](2100/2500): Loss: 0.0964
===> Epoch[49](2200/2500): Loss: 0.0961
===> Epoch[49](2300/2500): Loss: 0.0958
===> Epoch[49](2400/2500): Loss: 0.0966
===> Epoch[49](2500/2500): Loss: 0.0958
===> Epoch 49 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:21:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.0963
===> Epoch[49](200/2500): Loss: 0.0967
===> Epoch[49](300/2500): Loss: 0.1003
===> Epoch[49](400/2500): Loss: 0.0960
===> Epoch[49](500/2500): Loss: 0.0961
===> Epoch[49](600/2500): Loss: 0.0957
===> Epoch[49](700/2500): Loss: 0.0967
===> Epoch[49](800/2500): Loss: 0.0966
===> Epoch[49](900/2500): Loss: 0.0957
===> Epoch[49](1000/2500): Loss: 0.0962
===> Epoch[49](1100/2500): Loss: 0.0965
===> Epoch[49](1200/2500): Loss: 0.0964
===> Epoch[49](1300/2500): Loss: 0.0968
===> Epoch[49](1400/2500): Loss: 0.0959
===> Epoch[49](1500/2500): Loss: 0.0958
===> Epoch[49](1600/2500): Loss: 0.0962
===> Epoch[49](1700/2500): Loss: 0.0958
===> Epoch[49](1800/2500): Loss: 0.0958
===> Epoch[49](1900/2500): Loss: 0.0961
===> Epoch[49](2000/2500): Loss: 0.0961
===> Epoch[49](2100/2500): Loss: 0.0964
===> Epoch[49](2200/2500): Loss: 0.0961
===> Epoch[49](2300/2500): Loss: 0.0958
===> Epoch[49](2400/2500): Loss: 0.0966
===> Epoch[49](2500/2500): Loss: 0.0958
===> Epoch 49 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:21:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.0963
===> Epoch[49](200/2500): Loss: 0.0967
===> Epoch[49](300/2500): Loss: 0.1003
===> Epoch[49](400/2500): Loss: 0.0960
===> Epoch[49](500/2500): Loss: 0.0961
===> Epoch[49](600/2500): Loss: 0.0957
===> Epoch[49](700/2500): Loss: 0.0967
===> Epoch[49](800/2500): Loss: 0.0966
===> Epoch[49](900/2500): Loss: 0.0957
===> Epoch[49](1000/2500): Loss: 0.0962
===> Epoch[49](1100/2500): Loss: 0.0965
===> Epoch[49](1200/2500): Loss: 0.0964
===> Epoch[49](1300/2500): Loss: 0.0968
===> Epoch[49](1400/2500): Loss: 0.0959
===> Epoch[49](1500/2500): Loss: 0.0958
===> Epoch[49](1600/2500): Loss: 0.0962
===> Epoch[49](1700/2500): Loss: 0.0958
===> Epoch[49](1800/2500): Loss: 0.0958
===> Epoch[49](1900/2500): Loss: 0.0961
===> Epoch[49](2000/2500): Loss: 0.0961
===> Epoch[49](2100/2500): Loss: 0.0964
===> Epoch[49](2200/2500): Loss: 0.0961
===> Epoch[49](2300/2500): Loss: 0.0958
===> Epoch[49](2400/2500): Loss: 0.0966
===> Epoch[49](2500/2500): Loss: 0.0958
===> Epoch 49 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:21:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.0963
===> Epoch[49](200/2500): Loss: 0.0967
===> Epoch[49](300/2500): Loss: 0.1003
===> Epoch[49](400/2500): Loss: 0.0960
===> Epoch[49](500/2500): Loss: 0.0961
===> Epoch[49](600/2500): Loss: 0.0957
===> Epoch[49](700/2500): Loss: 0.0967
===> Epoch[49](800/2500): Loss: 0.0966
===> Epoch[49](900/2500): Loss: 0.0957
===> Epoch[49](1000/2500): Loss: 0.0962
===> Epoch[49](1100/2500): Loss: 0.0965
===> Epoch[49](1200/2500): Loss: 0.0964
===> Epoch[49](1300/2500): Loss: 0.0968
===> Epoch[49](1400/2500): Loss: 0.0959
===> Epoch[49](1500/2500): Loss: 0.0958
===> Epoch[49](1600/2500): Loss: 0.0962
===> Epoch[49](1700/2500): Loss: 0.0958
===> Epoch[49](1800/2500): Loss: 0.0958
===> Epoch[49](1900/2500): Loss: 0.0961
===> Epoch[49](2000/2500): Loss: 0.0961
===> Epoch[49](2100/2500): Loss: 0.0964
===> Epoch[49](2200/2500): Loss: 0.0961
===> Epoch[49](2300/2500): Loss: 0.0958
===> Epoch[49](2400/2500): Loss: 0.0966
===> Epoch[49](2500/2500): Loss: 0.0958
===> Epoch 49 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:21:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.0963
===> Epoch[49](200/2500): Loss: 0.0967
===> Epoch[49](300/2500): Loss: 0.1003
===> Epoch[49](400/2500): Loss: 0.0960
===> Epoch[49](500/2500): Loss: 0.0961
===> Epoch[49](600/2500): Loss: 0.0957
===> Epoch[49](700/2500): Loss: 0.0967
===> Epoch[49](800/2500): Loss: 0.0966
===> Epoch[49](900/2500): Loss: 0.0957
===> Epoch[49](1000/2500): Loss: 0.0962
===> Epoch[49](1100/2500): Loss: 0.0965
===> Epoch[49](1200/2500): Loss: 0.0964
===> Epoch[49](1300/2500): Loss: 0.0968
===> Epoch[49](1400/2500): Loss: 0.0959
===> Epoch[49](1500/2500): Loss: 0.0958
===> Epoch[49](1600/2500): Loss: 0.0962
===> Epoch[49](1700/2500): Loss: 0.0958
===> Epoch[49](1800/2500): Loss: 0.0958
===> Epoch[49](1900/2500): Loss: 0.0961
===> Epoch[49](2000/2500): Loss: 0.0961
===> Epoch[49](2100/2500): Loss: 0.0964
===> Epoch[49](2200/2500): Loss: 0.0961
===> Epoch[49](2300/2500): Loss: 0.0958
===> Epoch[49](2400/2500): Loss: 0.0966
===> Epoch[49](2500/2500): Loss: 0.0958
===> Epoch 49 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:21:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.0963
===> Epoch[49](200/2500): Loss: 0.0967
===> Epoch[49](300/2500): Loss: 0.1003
===> Epoch[49](400/2500): Loss: 0.0960
===> Epoch[49](500/2500): Loss: 0.0961
===> Epoch[49](600/2500): Loss: 0.0957
===> Epoch[49](700/2500): Loss: 0.0967
===> Epoch[49](800/2500): Loss: 0.0966
===> Epoch[49](900/2500): Loss: 0.0957
===> Epoch[49](1000/2500): Loss: 0.0962
===> Epoch[49](1100/2500): Loss: 0.0965
===> Epoch[49](1200/2500): Loss: 0.0964
===> Epoch[49](1300/2500): Loss: 0.0968
===> Epoch[49](1400/2500): Loss: 0.0959
===> Epoch[49](1500/2500): Loss: 0.0958
===> Epoch[49](1600/2500): Loss: 0.0962
===> Epoch[49](1700/2500): Loss: 0.0958
===> Epoch[49](1800/2500): Loss: 0.0958
===> Epoch[49](1900/2500): Loss: 0.0961
===> Epoch[49](2000/2500): Loss: 0.0961
===> Epoch[49](2100/2500): Loss: 0.0964
===> Epoch[49](2200/2500): Loss: 0.0961
===> Epoch[49](2300/2500): Loss: 0.0958
===> Epoch[49](2400/2500): Loss: 0.0966
===> Epoch[49](2500/2500): Loss: 0.0958
===> Epoch 49 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:21:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.0963
===> Epoch[49](200/2500): Loss: 0.0967
===> Epoch[49](300/2500): Loss: 0.1003
===> Epoch[49](400/2500): Loss: 0.0960
===> Epoch[49](500/2500): Loss: 0.0961
===> Epoch[49](600/2500): Loss: 0.0957
===> Epoch[49](700/2500): Loss: 0.0967
===> Epoch[49](800/2500): Loss: 0.0966
===> Epoch[49](900/2500): Loss: 0.0957
===> Epoch[49](1000/2500): Loss: 0.0962
===> Epoch[49](1100/2500): Loss: 0.0965
===> Epoch[49](1200/2500): Loss: 0.0964
===> Epoch[49](1300/2500): Loss: 0.0968
===> Epoch[49](1400/2500): Loss: 0.0959
===> Epoch[49](1500/2500): Loss: 0.0958
===> Epoch[49](1600/2500): Loss: 0.0962
===> Epoch[49](1700/2500): Loss: 0.0958
===> Epoch[49](1800/2500): Loss: 0.0958
===> Epoch[49](1900/2500): Loss: 0.0961
===> Epoch[49](2000/2500): Loss: 0.0961
===> Epoch[49](2100/2500): Loss: 0.0964
===> Epoch[49](2200/2500): Loss: 0.0961
===> Epoch[49](2300/2500): Loss: 0.0958
===> Epoch[49](2400/2500): Loss: 0.0966
===> Epoch[49](2500/2500): Loss: 0.0958
===> Epoch 49 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:21:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.0963
===> Epoch[49](200/2500): Loss: 0.0967
===> Epoch[49](300/2500): Loss: 0.1003
===> Epoch[49](400/2500): Loss: 0.0960
===> Epoch[49](500/2500): Loss: 0.0961
===> Epoch[49](600/2500): Loss: 0.0957
===> Epoch[49](700/2500): Loss: 0.0967
===> Epoch[49](800/2500): Loss: 0.0966
===> Epoch[49](900/2500): Loss: 0.0957
===> Epoch[49](1000/2500): Loss: 0.0962
===> Epoch[49](1100/2500): Loss: 0.0965
===> Epoch[49](1200/2500): Loss: 0.0964
===> Epoch[49](1300/2500): Loss: 0.0968
===> Epoch[49](1400/2500): Loss: 0.0959
===> Epoch[49](1500/2500): Loss: 0.0958
===> Epoch[49](1600/2500): Loss: 0.0962
===> Epoch[49](1700/2500): Loss: 0.0958
===> Epoch[49](1800/2500): Loss: 0.0958
===> Epoch[49](1900/2500): Loss: 0.0961
===> Epoch[49](2000/2500): Loss: 0.0961
===> Epoch[49](2100/2500): Loss: 0.0964
===> Epoch[49](2200/2500): Loss: 0.0961
===> Epoch[49](2300/2500): Loss: 0.0958
===> Epoch[49](2400/2500): Loss: 0.0966
===> Epoch[49](2500/2500): Loss: 0.0958
===> Epoch 49 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:21:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.0963
===> Epoch[49](200/2500): Loss: 0.0967
===> Epoch[49](300/2500): Loss: 0.1003
===> Epoch[49](400/2500): Loss: 0.0960
===> Epoch[49](500/2500): Loss: 0.0961
===> Epoch[49](600/2500): Loss: 0.0957
===> Epoch[49](700/2500): Loss: 0.0967
===> Epoch[49](800/2500): Loss: 0.0966
===> Epoch[49](900/2500): Loss: 0.0957
===> Epoch[49](1000/2500): Loss: 0.0962
===> Epoch[49](1100/2500): Loss: 0.0965
===> Epoch[49](1200/2500): Loss: 0.0964
===> Epoch[49](1300/2500): Loss: 0.0968
===> Epoch[49](1400/2500): Loss: 0.0959
===> Epoch[49](1500/2500): Loss: 0.0958
===> Epoch[49](1600/2500): Loss: 0.0962
===> Epoch[49](1700/2500): Loss: 0.0958
===> Epoch[49](1800/2500): Loss: 0.0958
===> Epoch[49](1900/2500): Loss: 0.0961
===> Epoch[49](2000/2500): Loss: 0.0961
===> Epoch[49](2100/2500): Loss: 0.0964
===> Epoch[49](2200/2500): Loss: 0.0961
===> Epoch[49](2300/2500): Loss: 0.0958
===> Epoch[49](2400/2500): Loss: 0.0966
===> Epoch[49](2500/2500): Loss: 0.0958
===> Epoch 49 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:21:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.0963
===> Epoch[49](200/2500): Loss: 0.0967
===> Epoch[49](300/2500): Loss: 0.1003
===> Epoch[49](400/2500): Loss: 0.0960
===> Epoch[49](500/2500): Loss: 0.0961
===> Epoch[49](600/2500): Loss: 0.0957
===> Epoch[49](700/2500): Loss: 0.0967
===> Epoch[49](800/2500): Loss: 0.0966
===> Epoch[49](900/2500): Loss: 0.0957
===> Epoch[49](1000/2500): Loss: 0.0962
===> Epoch[49](1100/2500): Loss: 0.0965
===> Epoch[49](1200/2500): Loss: 0.0964
===> Epoch[49](1300/2500): Loss: 0.0968
===> Epoch[49](1400/2500): Loss: 0.0959
===> Epoch[49](1500/2500): Loss: 0.0958
===> Epoch[49](1600/2500): Loss: 0.0962
===> Epoch[49](1700/2500): Loss: 0.0958
===> Epoch[49](1800/2500): Loss: 0.0958
===> Epoch[49](1900/2500): Loss: 0.0961
===> Epoch[49](2000/2500): Loss: 0.0961
===> Epoch[49](2100/2500): Loss: 0.0964
===> Epoch[49](2200/2500): Loss: 0.0961
===> Epoch[49](2300/2500): Loss: 0.0958
===> Epoch[49](2400/2500): Loss: 0.0966
===> Epoch[49](2500/2500): Loss: 0.0958
===> Epoch 49 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:21:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.0963
===> Epoch[49](200/2500): Loss: 0.0967
===> Epoch[49](300/2500): Loss: 0.1003
===> Epoch[49](400/2500): Loss: 0.0960
===> Epoch[49](500/2500): Loss: 0.0961
===> Epoch[49](600/2500): Loss: 0.0957
===> Epoch[49](700/2500): Loss: 0.0967
===> Epoch[49](800/2500): Loss: 0.0966
===> Epoch[49](900/2500): Loss: 0.0957
===> Epoch[49](1000/2500): Loss: 0.0962
===> Epoch[49](1100/2500): Loss: 0.0965
===> Epoch[49](1200/2500): Loss: 0.0964
===> Epoch[49](1300/2500): Loss: 0.0968
===> Epoch[49](1400/2500): Loss: 0.0959
===> Epoch[49](1500/2500): Loss: 0.0958
===> Epoch[49](1600/2500): Loss: 0.0962
===> Epoch[49](1700/2500): Loss: 0.0958
===> Epoch[49](1800/2500): Loss: 0.0958
===> Epoch[49](1900/2500): Loss: 0.0961
===> Epoch[49](2000/2500): Loss: 0.0961
===> Epoch[49](2100/2500): Loss: 0.0964
===> Epoch[49](2200/2500): Loss: 0.0961
===> Epoch[49](2300/2500): Loss: 0.0958
===> Epoch[49](2400/2500): Loss: 0.0966
===> Epoch[49](2500/2500): Loss: 0.0958
===> Epoch 49 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:21:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.0963
===> Epoch[49](200/2500): Loss: 0.0967
===> Epoch[49](300/2500): Loss: 0.1003
===> Epoch[49](400/2500): Loss: 0.0960
===> Epoch[49](500/2500): Loss: 0.0961
===> Epoch[49](600/2500): Loss: 0.0957
===> Epoch[49](700/2500): Loss: 0.0967
===> Epoch[49](800/2500): Loss: 0.0966
===> Epoch[49](900/2500): Loss: 0.0957
===> Epoch[49](1000/2500): Loss: 0.0962
===> Epoch[49](1100/2500): Loss: 0.0965
===> Epoch[49](1200/2500): Loss: 0.0964
===> Epoch[49](1300/2500): Loss: 0.0968
===> Epoch[49](1400/2500): Loss: 0.0959
===> Epoch[49](1500/2500): Loss: 0.0958
===> Epoch[49](1600/2500): Loss: 0.0962
===> Epoch[49](1700/2500): Loss: 0.0958
===> Epoch[49](1800/2500): Loss: 0.0958
===> Epoch[49](1900/2500): Loss: 0.0961
===> Epoch[49](2000/2500): Loss: 0.0961
===> Epoch[49](2100/2500): Loss: 0.0964
===> Epoch[49](2200/2500): Loss: 0.0961
===> Epoch[49](2300/2500): Loss: 0.0958
===> Epoch[49](2400/2500): Loss: 0.0966
===> Epoch[49](2500/2500): Loss: 0.0958
===> Epoch 49 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:21:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.0963
===> Epoch[49](200/2500): Loss: 0.0967
===> Epoch[49](300/2500): Loss: 0.1003
===> Epoch[49](400/2500): Loss: 0.0960
===> Epoch[49](500/2500): Loss: 0.0961
===> Epoch[49](600/2500): Loss: 0.0957
===> Epoch[49](700/2500): Loss: 0.0967
===> Epoch[49](800/2500): Loss: 0.0966
===> Epoch[49](900/2500): Loss: 0.0957
===> Epoch[49](1000/2500): Loss: 0.0962
===> Epoch[49](1100/2500): Loss: 0.0965
===> Epoch[49](1200/2500): Loss: 0.0964
===> Epoch[49](1300/2500): Loss: 0.0968
===> Epoch[49](1400/2500): Loss: 0.0959
===> Epoch[49](1500/2500): Loss: 0.0958
===> Epoch[49](1600/2500): Loss: 0.0962
===> Epoch[49](1700/2500): Loss: 0.0958
===> Epoch[49](1800/2500): Loss: 0.0958
===> Epoch[49](1900/2500): Loss: 0.0961
===> Epoch[49](2000/2500): Loss: 0.0961
===> Epoch[49](2100/2500): Loss: 0.0964
===> Epoch[49](2200/2500): Loss: 0.0961
===> Epoch[49](2300/2500): Loss: 0.0958
===> Epoch[49](2400/2500): Loss: 0.0966
===> Epoch[49](2500/2500): Loss: 0.0958
===> Epoch 49 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:21:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.0963
===> Epoch[49](200/2500): Loss: 0.0967
===> Epoch[49](300/2500): Loss: 0.1003
===> Epoch[49](400/2500): Loss: 0.0960
===> Epoch[49](500/2500): Loss: 0.0961
===> Epoch[49](600/2500): Loss: 0.0957
===> Epoch[49](700/2500): Loss: 0.0967
===> Epoch[49](800/2500): Loss: 0.0966
===> Epoch[49](900/2500): Loss: 0.0957
===> Epoch[49](1000/2500): Loss: 0.0962
===> Epoch[49](1100/2500): Loss: 0.0965
===> Epoch[49](1200/2500): Loss: 0.0964
===> Epoch[49](1300/2500): Loss: 0.0968
===> Epoch[49](1400/2500): Loss: 0.0959
===> Epoch[49](1500/2500): Loss: 0.0958
===> Epoch[49](1600/2500): Loss: 0.0962
===> Epoch[49](1700/2500): Loss: 0.0958
===> Epoch[49](1800/2500): Loss: 0.0958
===> Epoch[49](1900/2500): Loss: 0.0961
===> Epoch[49](2000/2500): Loss: 0.0961
===> Epoch[49](2100/2500): Loss: 0.0964
===> Epoch[49](2200/2500): Loss: 0.0961
===> Epoch[49](2300/2500): Loss: 0.0958
===> Epoch[49](2400/2500): Loss: 0.0966
===> Epoch[49](2500/2500): Loss: 0.0958
===> Epoch 49 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:21:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.0963
===> Epoch[49](200/2500): Loss: 0.0967
===> Epoch[49](300/2500): Loss: 0.1003
===> Epoch[49](400/2500): Loss: 0.0960
===> Epoch[49](500/2500): Loss: 0.0961
===> Epoch[49](600/2500): Loss: 0.0957
===> Epoch[49](700/2500): Loss: 0.0967
===> Epoch[49](800/2500): Loss: 0.0966
===> Epoch[49](900/2500): Loss: 0.0957
===> Epoch[49](1000/2500): Loss: 0.0962
===> Epoch[49](1100/2500): Loss: 0.0965
===> Epoch[49](1200/2500): Loss: 0.0964
===> Epoch[49](1300/2500): Loss: 0.0968
===> Epoch[49](1400/2500): Loss: 0.0959
===> Epoch[49](1500/2500): Loss: 0.0958
===> Epoch[49](1600/2500): Loss: 0.0962
===> Epoch[49](1700/2500): Loss: 0.0958
===> Epoch[49](1800/2500): Loss: 0.0958
===> Epoch[49](1900/2500): Loss: 0.0961
===> Epoch[49](2000/2500): Loss: 0.0961
===> Epoch[49](2100/2500): Loss: 0.0964
===> Epoch[49](2200/2500): Loss: 0.0961
===> Epoch[49](2300/2500): Loss: 0.0958
===> Epoch[49](2400/2500): Loss: 0.0966
===> Epoch[49](2500/2500): Loss: 0.0958
===> Epoch 49 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:21:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.0963
===> Epoch[49](200/2500): Loss: 0.0967
===> Epoch[49](300/2500): Loss: 0.1003
===> Epoch[49](400/2500): Loss: 0.0960
===> Epoch[49](500/2500): Loss: 0.0961
===> Epoch[49](600/2500): Loss: 0.0957
===> Epoch[49](700/2500): Loss: 0.0967
===> Epoch[49](800/2500): Loss: 0.0966
===> Epoch[49](900/2500): Loss: 0.0957
===> Epoch[49](1000/2500): Loss: 0.0962
===> Epoch[49](1100/2500): Loss: 0.0965
===> Epoch[49](1200/2500): Loss: 0.0964
===> Epoch[49](1300/2500): Loss: 0.0968
===> Epoch[49](1400/2500): Loss: 0.0959
===> Epoch[49](1500/2500): Loss: 0.0958
===> Epoch[49](1600/2500): Loss: 0.0962
===> Epoch[49](1700/2500): Loss: 0.0958
===> Epoch[49](1800/2500): Loss: 0.0958
===> Epoch[49](1900/2500): Loss: 0.0961
===> Epoch[49](2000/2500): Loss: 0.0961
===> Epoch[49](2100/2500): Loss: 0.0964
===> Epoch[49](2200/2500): Loss: 0.0961
===> Epoch[49](2300/2500): Loss: 0.0958
===> Epoch[49](2400/2500): Loss: 0.0966
===> Epoch[49](2500/2500): Loss: 0.0958
===> Epoch 49 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:21:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.0963
===> Epoch[49](200/2500): Loss: 0.0967
===> Epoch[49](300/2500): Loss: 0.1003
===> Epoch[49](400/2500): Loss: 0.0960
===> Epoch[49](500/2500): Loss: 0.0961
===> Epoch[49](600/2500): Loss: 0.0957
===> Epoch[49](700/2500): Loss: 0.0967
===> Epoch[49](800/2500): Loss: 0.0966
===> Epoch[49](900/2500): Loss: 0.0957
===> Epoch[49](1000/2500): Loss: 0.0962
===> Epoch[49](1100/2500): Loss: 0.0965
===> Epoch[49](1200/2500): Loss: 0.0964
===> Epoch[49](1300/2500): Loss: 0.0968
===> Epoch[49](1400/2500): Loss: 0.0959
===> Epoch[49](1500/2500): Loss: 0.0958
===> Epoch[49](1600/2500): Loss: 0.0962
===> Epoch[49](1700/2500): Loss: 0.0958
===> Epoch[49](1800/2500): Loss: 0.0958
===> Epoch[49](1900/2500): Loss: 0.0961
===> Epoch[49](2000/2500): Loss: 0.0961
===> Epoch[49](2100/2500): Loss: 0.0964
===> Epoch[49](2200/2500): Loss: 0.0961
===> Epoch[49](2300/2500): Loss: 0.0958
===> Epoch[49](2400/2500): Loss: 0.0966
===> Epoch[49](2500/2500): Loss: 0.0958
===> Epoch 49 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:21:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.0963
===> Epoch[49](200/2500): Loss: 0.0967
===> Epoch[49](300/2500): Loss: 0.1003
===> Epoch[49](400/2500): Loss: 0.0960
===> Epoch[49](500/2500): Loss: 0.0961
===> Epoch[49](600/2500): Loss: 0.0957
===> Epoch[49](700/2500): Loss: 0.0967
===> Epoch[49](800/2500): Loss: 0.0966
===> Epoch[49](900/2500): Loss: 0.0957
===> Epoch[49](1000/2500): Loss: 0.0962
===> Epoch[49](1100/2500): Loss: 0.0965
===> Epoch[49](1200/2500): Loss: 0.0964
===> Epoch[49](1300/2500): Loss: 0.0968
===> Epoch[49](1400/2500): Loss: 0.0959
===> Epoch[49](1500/2500): Loss: 0.0958
===> Epoch[49](1600/2500): Loss: 0.0962
===> Epoch[49](1700/2500): Loss: 0.0958
===> Epoch[49](1800/2500): Loss: 0.0958
===> Epoch[49](1900/2500): Loss: 0.0961
===> Epoch[49](2000/2500): Loss: 0.0961
===> Epoch[49](2100/2500): Loss: 0.0964
===> Epoch[49](2200/2500): Loss: 0.0961
===> Epoch[49](2300/2500): Loss: 0.0958
===> Epoch[49](2400/2500): Loss: 0.0966
===> Epoch[49](2500/2500): Loss: 0.0958
===> Epoch 49 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:21:04]
===> Loading train datasets
===> Epoch[49](100/2500): Loss: 0.0963
===> Epoch[49](200/2500): Loss: 0.0967
===> Epoch[49](300/2500): Loss: 0.1003
===> Epoch[49](400/2500): Loss: 0.0960
===> Epoch[49](500/2500): Loss: 0.0961
===> Epoch[49](600/2500): Loss: 0.0957
===> Epoch[49](700/2500): Loss: 0.0967
===> Epoch[49](800/2500): Loss: 0.0966
===> Epoch[49](900/2500): Loss: 0.0957
===> Epoch[49](1000/2500): Loss: 0.0962
===> Epoch[49](1100/2500): Loss: 0.0965
===> Epoch[49](1200/2500): Loss: 0.0964
===> Epoch[49](1300/2500): Loss: 0.0968
===> Epoch[49](1400/2500): Loss: 0.0959
===> Epoch[49](1500/2500): Loss: 0.0958
===> Epoch[49](1600/2500): Loss: 0.0962
===> Epoch[49](1700/2500): Loss: 0.0958
===> Epoch[49](1800/2500): Loss: 0.0958
===> Epoch[49](1900/2500): Loss: 0.0961
===> Epoch[49](2000/2500): Loss: 0.0961
===> Epoch[49](2100/2500): Loss: 0.0964
===> Epoch[49](2200/2500): Loss: 0.0961
===> Epoch[49](2300/2500): Loss: 0.0958
===> Epoch[49](2400/2500): Loss: 0.0966
===> Epoch[49](2500/2500): Loss: 0.0958
===> Epoch 49 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:21:04]
===> Loading train datasets
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.0969
===> Epoch[50](200/2500): Loss: 0.0963
===> Epoch[50](300/2500): Loss: 0.0962
===> Epoch[50](400/2500): Loss: 0.0963
===> Epoch[50](500/2500): Loss: 0.0961
===> Epoch[50](600/2500): Loss: 0.0962
===> Epoch[50](700/2500): Loss: 0.0965
===> Epoch[50](800/2500): Loss: 0.0971
===> Epoch[50](900/2500): Loss: 0.1062
===> Epoch[50](1000/2500): Loss: 0.0976
===> Epoch[50](1100/2500): Loss: 0.0960
===> Epoch[50](1200/2500): Loss: 0.0958
===> Epoch[50](1300/2500): Loss: 0.0954
===> Epoch[50](1400/2500): Loss: 0.0959
===> Epoch[50](1500/2500): Loss: 0.0960
===> Epoch[50](1600/2500): Loss: 0.0964
===> Epoch[50](1700/2500): Loss: 0.0966
===> Epoch[50](1800/2500): Loss: 0.0965
===> Epoch[50](1900/2500): Loss: 0.0962
===> Epoch[50](2000/2500): Loss: 0.0965
===> Epoch[50](2100/2500): Loss: 0.0964
===> Epoch[50](2200/2500): Loss: 0.0961
===> Epoch[50](2300/2500): Loss: 0.0959
===> Epoch[50](2400/2500): Loss: 0.0958
===> Epoch[50](2500/2500): Loss: 0.0966
===> Epoch 50 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:26:06]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.0969
===> Epoch[50](200/2500): Loss: 0.0963
===> Epoch[50](300/2500): Loss: 0.0962
===> Epoch[50](400/2500): Loss: 0.0963
===> Epoch[50](500/2500): Loss: 0.0961
===> Epoch[50](600/2500): Loss: 0.0962
===> Epoch[50](700/2500): Loss: 0.0965
===> Epoch[50](800/2500): Loss: 0.0971
===> Epoch[50](900/2500): Loss: 0.1062
===> Epoch[50](1000/2500): Loss: 0.0976
===> Epoch[50](1100/2500): Loss: 0.0960
===> Epoch[50](1200/2500): Loss: 0.0958
===> Epoch[50](1300/2500): Loss: 0.0954
===> Epoch[50](1400/2500): Loss: 0.0959
===> Epoch[50](1500/2500): Loss: 0.0960
===> Epoch[50](1600/2500): Loss: 0.0964
===> Epoch[50](1700/2500): Loss: 0.0966
===> Epoch[50](1800/2500): Loss: 0.0965
===> Epoch[50](1900/2500): Loss: 0.0962
===> Epoch[50](2000/2500): Loss: 0.0965
===> Epoch[50](2100/2500): Loss: 0.0964
===> Epoch[50](2200/2500): Loss: 0.0961
===> Epoch[50](2300/2500): Loss: 0.0959
===> Epoch[50](2400/2500): Loss: 0.0958
===> Epoch[50](2500/2500): Loss: 0.0966
===> Epoch 50 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:26:06]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.0969
===> Epoch[50](200/2500): Loss: 0.0963
===> Epoch[50](300/2500): Loss: 0.0962
===> Epoch[50](400/2500): Loss: 0.0963
===> Epoch[50](500/2500): Loss: 0.0961
===> Epoch[50](600/2500): Loss: 0.0962
===> Epoch[50](700/2500): Loss: 0.0965
===> Epoch[50](800/2500): Loss: 0.0971
===> Epoch[50](900/2500): Loss: 0.1062
===> Epoch[50](1000/2500): Loss: 0.0976
===> Epoch[50](1100/2500): Loss: 0.0960
===> Epoch[50](1200/2500): Loss: 0.0958
===> Epoch[50](1300/2500): Loss: 0.0954
===> Epoch[50](1400/2500): Loss: 0.0959
===> Epoch[50](1500/2500): Loss: 0.0960
===> Epoch[50](1600/2500): Loss: 0.0964
===> Epoch[50](1700/2500): Loss: 0.0966
===> Epoch[50](1800/2500): Loss: 0.0965
===> Epoch[50](1900/2500): Loss: 0.0962
===> Epoch[50](2000/2500): Loss: 0.0965
===> Epoch[50](2100/2500): Loss: 0.0964
===> Epoch[50](2200/2500): Loss: 0.0961
===> Epoch[50](2300/2500): Loss: 0.0959
===> Epoch[50](2400/2500): Loss: 0.0958
===> Epoch[50](2500/2500): Loss: 0.0966
===> Epoch 50 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:26:06]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.0969
===> Epoch[50](200/2500): Loss: 0.0963
===> Epoch[50](300/2500): Loss: 0.0962
===> Epoch[50](400/2500): Loss: 0.0963
===> Epoch[50](500/2500): Loss: 0.0961
===> Epoch[50](600/2500): Loss: 0.0962
===> Epoch[50](700/2500): Loss: 0.0965
===> Epoch[50](800/2500): Loss: 0.0971
===> Epoch[50](900/2500): Loss: 0.1062
===> Epoch[50](1000/2500): Loss: 0.0976
===> Epoch[50](1100/2500): Loss: 0.0960
===> Epoch[50](1200/2500): Loss: 0.0958
===> Epoch[50](1300/2500): Loss: 0.0954
===> Epoch[50](1400/2500): Loss: 0.0959
===> Epoch[50](1500/2500): Loss: 0.0960
===> Epoch[50](1600/2500): Loss: 0.0964
===> Epoch[50](1700/2500): Loss: 0.0966
===> Epoch[50](1800/2500): Loss: 0.0965
===> Epoch[50](1900/2500): Loss: 0.0962
===> Epoch[50](2000/2500): Loss: 0.0965
===> Epoch[50](2100/2500): Loss: 0.0964
===> Epoch[50](2200/2500): Loss: 0.0961
===> Epoch[50](2300/2500): Loss: 0.0959
===> Epoch[50](2400/2500): Loss: 0.0958
===> Epoch[50](2500/2500): Loss: 0.0966
===> Epoch 50 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:26:06]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.0969
===> Epoch[50](200/2500): Loss: 0.0963
===> Epoch[50](300/2500): Loss: 0.0962
===> Epoch[50](400/2500): Loss: 0.0963
===> Epoch[50](500/2500): Loss: 0.0961
===> Epoch[50](600/2500): Loss: 0.0962
===> Epoch[50](700/2500): Loss: 0.0965
===> Epoch[50](800/2500): Loss: 0.0971
===> Epoch[50](900/2500): Loss: 0.1062
===> Epoch[50](1000/2500): Loss: 0.0976
===> Epoch[50](1100/2500): Loss: 0.0960
===> Epoch[50](1200/2500): Loss: 0.0958
===> Epoch[50](1300/2500): Loss: 0.0954
===> Epoch[50](1400/2500): Loss: 0.0959
===> Epoch[50](1500/2500): Loss: 0.0960
===> Epoch[50](1600/2500): Loss: 0.0964
===> Epoch[50](1700/2500): Loss: 0.0966
===> Epoch[50](1800/2500): Loss: 0.0965
===> Epoch[50](1900/2500): Loss: 0.0962
===> Epoch[50](2000/2500): Loss: 0.0965
===> Epoch[50](2100/2500): Loss: 0.0964
===> Epoch[50](2200/2500): Loss: 0.0961
===> Epoch[50](2300/2500): Loss: 0.0959
===> Epoch[50](2400/2500): Loss: 0.0958
===> Epoch[50](2500/2500): Loss: 0.0966
===> Epoch 50 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:26:06]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.0969
===> Epoch[50](200/2500): Loss: 0.0963
===> Epoch[50](300/2500): Loss: 0.0962
===> Epoch[50](400/2500): Loss: 0.0963
===> Epoch[50](500/2500): Loss: 0.0961
===> Epoch[50](600/2500): Loss: 0.0962
===> Epoch[50](700/2500): Loss: 0.0965
===> Epoch[50](800/2500): Loss: 0.0971
===> Epoch[50](900/2500): Loss: 0.1062
===> Epoch[50](1000/2500): Loss: 0.0976
===> Epoch[50](1100/2500): Loss: 0.0960
===> Epoch[50](1200/2500): Loss: 0.0958
===> Epoch[50](1300/2500): Loss: 0.0954
===> Epoch[50](1400/2500): Loss: 0.0959
===> Epoch[50](1500/2500): Loss: 0.0960
===> Epoch[50](1600/2500): Loss: 0.0964
===> Epoch[50](1700/2500): Loss: 0.0966
===> Epoch[50](1800/2500): Loss: 0.0965
===> Epoch[50](1900/2500): Loss: 0.0962
===> Epoch[50](2000/2500): Loss: 0.0965
===> Epoch[50](2100/2500): Loss: 0.0964
===> Epoch[50](2200/2500): Loss: 0.0961
===> Epoch[50](2300/2500): Loss: 0.0959
===> Epoch[50](2400/2500): Loss: 0.0958
===> Epoch[50](2500/2500): Loss: 0.0966
===> Epoch 50 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:26:06]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.0969
===> Epoch[50](200/2500): Loss: 0.0963
===> Epoch[50](300/2500): Loss: 0.0962
===> Epoch[50](400/2500): Loss: 0.0963
===> Epoch[50](500/2500): Loss: 0.0961
===> Epoch[50](600/2500): Loss: 0.0962
===> Epoch[50](700/2500): Loss: 0.0965
===> Epoch[50](800/2500): Loss: 0.0971
===> Epoch[50](900/2500): Loss: 0.1062
===> Epoch[50](1000/2500): Loss: 0.0976
===> Epoch[50](1100/2500): Loss: 0.0960
===> Epoch[50](1200/2500): Loss: 0.0958
===> Epoch[50](1300/2500): Loss: 0.0954
===> Epoch[50](1400/2500): Loss: 0.0959
===> Epoch[50](1500/2500): Loss: 0.0960
===> Epoch[50](1600/2500): Loss: 0.0964
===> Epoch[50](1700/2500): Loss: 0.0966
===> Epoch[50](1800/2500): Loss: 0.0965
===> Epoch[50](1900/2500): Loss: 0.0962
===> Epoch[50](2000/2500): Loss: 0.0965
===> Epoch[50](2100/2500): Loss: 0.0964
===> Epoch[50](2200/2500): Loss: 0.0961
===> Epoch[50](2300/2500): Loss: 0.0959
===> Epoch[50](2400/2500): Loss: 0.0958
===> Epoch[50](2500/2500): Loss: 0.0966
===> Epoch 50 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:26:06]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.0969
===> Epoch[50](200/2500): Loss: 0.0963
===> Epoch[50](300/2500): Loss: 0.0962
===> Epoch[50](400/2500): Loss: 0.0963
===> Epoch[50](500/2500): Loss: 0.0961
===> Epoch[50](600/2500): Loss: 0.0962
===> Epoch[50](700/2500): Loss: 0.0965
===> Epoch[50](800/2500): Loss: 0.0971
===> Epoch[50](900/2500): Loss: 0.1062
===> Epoch[50](1000/2500): Loss: 0.0976
===> Epoch[50](1100/2500): Loss: 0.0960
===> Epoch[50](1200/2500): Loss: 0.0958
===> Epoch[50](1300/2500): Loss: 0.0954
===> Epoch[50](1400/2500): Loss: 0.0959
===> Epoch[50](1500/2500): Loss: 0.0960
===> Epoch[50](1600/2500): Loss: 0.0964
===> Epoch[50](1700/2500): Loss: 0.0966
===> Epoch[50](1800/2500): Loss: 0.0965
===> Epoch[50](1900/2500): Loss: 0.0962
===> Epoch[50](2000/2500): Loss: 0.0965
===> Epoch[50](2100/2500): Loss: 0.0964
===> Epoch[50](2200/2500): Loss: 0.0961
===> Epoch[50](2300/2500): Loss: 0.0959
===> Epoch[50](2400/2500): Loss: 0.0958
===> Epoch[50](2500/2500): Loss: 0.0966
===> Epoch 50 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:26:06]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.0969
===> Epoch[50](200/2500): Loss: 0.0963
===> Epoch[50](300/2500): Loss: 0.0962
===> Epoch[50](400/2500): Loss: 0.0963
===> Epoch[50](500/2500): Loss: 0.0961
===> Epoch[50](600/2500): Loss: 0.0962
===> Epoch[50](700/2500): Loss: 0.0965
===> Epoch[50](800/2500): Loss: 0.0971
===> Epoch[50](900/2500): Loss: 0.1062
===> Epoch[50](1000/2500): Loss: 0.0976
===> Epoch[50](1100/2500): Loss: 0.0960
===> Epoch[50](1200/2500): Loss: 0.0958
===> Epoch[50](1300/2500): Loss: 0.0954
===> Epoch[50](1400/2500): Loss: 0.0959
===> Epoch[50](1500/2500): Loss: 0.0960
===> Epoch[50](1600/2500): Loss: 0.0964
===> Epoch[50](1700/2500): Loss: 0.0966
===> Epoch[50](1800/2500): Loss: 0.0965
===> Epoch[50](1900/2500): Loss: 0.0962
===> Epoch[50](2000/2500): Loss: 0.0965
===> Epoch[50](2100/2500): Loss: 0.0964
===> Epoch[50](2200/2500): Loss: 0.0961
===> Epoch[50](2300/2500): Loss: 0.0959
===> Epoch[50](2400/2500): Loss: 0.0958
===> Epoch[50](2500/2500): Loss: 0.0966
===> Epoch 50 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:26:06]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.0969
===> Epoch[50](200/2500): Loss: 0.0963
===> Epoch[50](300/2500): Loss: 0.0962
===> Epoch[50](400/2500): Loss: 0.0963
===> Epoch[50](500/2500): Loss: 0.0961
===> Epoch[50](600/2500): Loss: 0.0962
===> Epoch[50](700/2500): Loss: 0.0965
===> Epoch[50](800/2500): Loss: 0.0971
===> Epoch[50](900/2500): Loss: 0.1062
===> Epoch[50](1000/2500): Loss: 0.0976
===> Epoch[50](1100/2500): Loss: 0.0960
===> Epoch[50](1200/2500): Loss: 0.0958
===> Epoch[50](1300/2500): Loss: 0.0954
===> Epoch[50](1400/2500): Loss: 0.0959
===> Epoch[50](1500/2500): Loss: 0.0960
===> Epoch[50](1600/2500): Loss: 0.0964
===> Epoch[50](1700/2500): Loss: 0.0966
===> Epoch[50](1800/2500): Loss: 0.0965
===> Epoch[50](1900/2500): Loss: 0.0962
===> Epoch[50](2000/2500): Loss: 0.0965
===> Epoch[50](2100/2500): Loss: 0.0964
===> Epoch[50](2200/2500): Loss: 0.0961
===> Epoch[50](2300/2500): Loss: 0.0959
===> Epoch[50](2400/2500): Loss: 0.0958
===> Epoch[50](2500/2500): Loss: 0.0966
===> Epoch 50 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:26:06]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.0969
===> Epoch[50](200/2500): Loss: 0.0963
===> Epoch[50](300/2500): Loss: 0.0962
===> Epoch[50](400/2500): Loss: 0.0963
===> Epoch[50](500/2500): Loss: 0.0961
===> Epoch[50](600/2500): Loss: 0.0962
===> Epoch[50](700/2500): Loss: 0.0965
===> Epoch[50](800/2500): Loss: 0.0971
===> Epoch[50](900/2500): Loss: 0.1062
===> Epoch[50](1000/2500): Loss: 0.0976
===> Epoch[50](1100/2500): Loss: 0.0960
===> Epoch[50](1200/2500): Loss: 0.0958
===> Epoch[50](1300/2500): Loss: 0.0954
===> Epoch[50](1400/2500): Loss: 0.0959
===> Epoch[50](1500/2500): Loss: 0.0960
===> Epoch[50](1600/2500): Loss: 0.0964
===> Epoch[50](1700/2500): Loss: 0.0966
===> Epoch[50](1800/2500): Loss: 0.0965
===> Epoch[50](1900/2500): Loss: 0.0962
===> Epoch[50](2000/2500): Loss: 0.0965
===> Epoch[50](2100/2500): Loss: 0.0964
===> Epoch[50](2200/2500): Loss: 0.0961
===> Epoch[50](2300/2500): Loss: 0.0959
===> Epoch[50](2400/2500): Loss: 0.0958
===> Epoch[50](2500/2500): Loss: 0.0966
===> Epoch 50 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:26:06]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.0969
===> Epoch[50](200/2500): Loss: 0.0963
===> Epoch[50](300/2500): Loss: 0.0962
===> Epoch[50](400/2500): Loss: 0.0963
===> Epoch[50](500/2500): Loss: 0.0961
===> Epoch[50](600/2500): Loss: 0.0962
===> Epoch[50](700/2500): Loss: 0.0965
===> Epoch[50](800/2500): Loss: 0.0971
===> Epoch[50](900/2500): Loss: 0.1062
===> Epoch[50](1000/2500): Loss: 0.0976
===> Epoch[50](1100/2500): Loss: 0.0960
===> Epoch[50](1200/2500): Loss: 0.0958
===> Epoch[50](1300/2500): Loss: 0.0954
===> Epoch[50](1400/2500): Loss: 0.0959
===> Epoch[50](1500/2500): Loss: 0.0960
===> Epoch[50](1600/2500): Loss: 0.0964
===> Epoch[50](1700/2500): Loss: 0.0966
===> Epoch[50](1800/2500): Loss: 0.0965
===> Epoch[50](1900/2500): Loss: 0.0962
===> Epoch[50](2000/2500): Loss: 0.0965
===> Epoch[50](2100/2500): Loss: 0.0964
===> Epoch[50](2200/2500): Loss: 0.0961
===> Epoch[50](2300/2500): Loss: 0.0959
===> Epoch[50](2400/2500): Loss: 0.0958
===> Epoch[50](2500/2500): Loss: 0.0966
===> Epoch 50 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:26:06]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.0969
===> Epoch[50](200/2500): Loss: 0.0963
===> Epoch[50](300/2500): Loss: 0.0962
===> Epoch[50](400/2500): Loss: 0.0963
===> Epoch[50](500/2500): Loss: 0.0961
===> Epoch[50](600/2500): Loss: 0.0962
===> Epoch[50](700/2500): Loss: 0.0965
===> Epoch[50](800/2500): Loss: 0.0971
===> Epoch[50](900/2500): Loss: 0.1062
===> Epoch[50](1000/2500): Loss: 0.0976
===> Epoch[50](1100/2500): Loss: 0.0960
===> Epoch[50](1200/2500): Loss: 0.0958
===> Epoch[50](1300/2500): Loss: 0.0954
===> Epoch[50](1400/2500): Loss: 0.0959
===> Epoch[50](1500/2500): Loss: 0.0960
===> Epoch[50](1600/2500): Loss: 0.0964
===> Epoch[50](1700/2500): Loss: 0.0966
===> Epoch[50](1800/2500): Loss: 0.0965
===> Epoch[50](1900/2500): Loss: 0.0962
===> Epoch[50](2000/2500): Loss: 0.0965
===> Epoch[50](2100/2500): Loss: 0.0964
===> Epoch[50](2200/2500): Loss: 0.0961
===> Epoch[50](2300/2500): Loss: 0.0959
===> Epoch[50](2400/2500): Loss: 0.0958
===> Epoch[50](2500/2500): Loss: 0.0966
===> Epoch 50 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:26:06]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.0969
===> Epoch[50](200/2500): Loss: 0.0963
===> Epoch[50](300/2500): Loss: 0.0962
===> Epoch[50](400/2500): Loss: 0.0963
===> Epoch[50](500/2500): Loss: 0.0961
===> Epoch[50](600/2500): Loss: 0.0962
===> Epoch[50](700/2500): Loss: 0.0965
===> Epoch[50](800/2500): Loss: 0.0971
===> Epoch[50](900/2500): Loss: 0.1062
===> Epoch[50](1000/2500): Loss: 0.0976
===> Epoch[50](1100/2500): Loss: 0.0960
===> Epoch[50](1200/2500): Loss: 0.0958
===> Epoch[50](1300/2500): Loss: 0.0954
===> Epoch[50](1400/2500): Loss: 0.0959
===> Epoch[50](1500/2500): Loss: 0.0960
===> Epoch[50](1600/2500): Loss: 0.0964
===> Epoch[50](1700/2500): Loss: 0.0966
===> Epoch[50](1800/2500): Loss: 0.0965
===> Epoch[50](1900/2500): Loss: 0.0962
===> Epoch[50](2000/2500): Loss: 0.0965
===> Epoch[50](2100/2500): Loss: 0.0964
===> Epoch[50](2200/2500): Loss: 0.0961
===> Epoch[50](2300/2500): Loss: 0.0959
===> Epoch[50](2400/2500): Loss: 0.0958
===> Epoch[50](2500/2500): Loss: 0.0966
===> Epoch 50 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:26:06]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.0969
===> Epoch[50](200/2500): Loss: 0.0963
===> Epoch[50](300/2500): Loss: 0.0962
===> Epoch[50](400/2500): Loss: 0.0963
===> Epoch[50](500/2500): Loss: 0.0961
===> Epoch[50](600/2500): Loss: 0.0962
===> Epoch[50](700/2500): Loss: 0.0965
===> Epoch[50](800/2500): Loss: 0.0971
===> Epoch[50](900/2500): Loss: 0.1062
===> Epoch[50](1000/2500): Loss: 0.0976
===> Epoch[50](1100/2500): Loss: 0.0960
===> Epoch[50](1200/2500): Loss: 0.0958
===> Epoch[50](1300/2500): Loss: 0.0954
===> Epoch[50](1400/2500): Loss: 0.0959
===> Epoch[50](1500/2500): Loss: 0.0960
===> Epoch[50](1600/2500): Loss: 0.0964
===> Epoch[50](1700/2500): Loss: 0.0966
===> Epoch[50](1800/2500): Loss: 0.0965
===> Epoch[50](1900/2500): Loss: 0.0962
===> Epoch[50](2000/2500): Loss: 0.0965
===> Epoch[50](2100/2500): Loss: 0.0964
===> Epoch[50](2200/2500): Loss: 0.0961
===> Epoch[50](2300/2500): Loss: 0.0959
===> Epoch[50](2400/2500): Loss: 0.0958
===> Epoch[50](2500/2500): Loss: 0.0966
===> Epoch 50 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:26:06]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.0969
===> Epoch[50](200/2500): Loss: 0.0963
===> Epoch[50](300/2500): Loss: 0.0962
===> Epoch[50](400/2500): Loss: 0.0963
===> Epoch[50](500/2500): Loss: 0.0961
===> Epoch[50](600/2500): Loss: 0.0962
===> Epoch[50](700/2500): Loss: 0.0965
===> Epoch[50](800/2500): Loss: 0.0971
===> Epoch[50](900/2500): Loss: 0.1062
===> Epoch[50](1000/2500): Loss: 0.0976
===> Epoch[50](1100/2500): Loss: 0.0960
===> Epoch[50](1200/2500): Loss: 0.0958
===> Epoch[50](1300/2500): Loss: 0.0954
===> Epoch[50](1400/2500): Loss: 0.0959
===> Epoch[50](1500/2500): Loss: 0.0960
===> Epoch[50](1600/2500): Loss: 0.0964
===> Epoch[50](1700/2500): Loss: 0.0966
===> Epoch[50](1800/2500): Loss: 0.0965
===> Epoch[50](1900/2500): Loss: 0.0962
===> Epoch[50](2000/2500): Loss: 0.0965
===> Epoch[50](2100/2500): Loss: 0.0964
===> Epoch[50](2200/2500): Loss: 0.0961
===> Epoch[50](2300/2500): Loss: 0.0959
===> Epoch[50](2400/2500): Loss: 0.0958
===> Epoch[50](2500/2500): Loss: 0.0966
===> Epoch 50 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:26:06]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.0969
===> Epoch[50](200/2500): Loss: 0.0963
===> Epoch[50](300/2500): Loss: 0.0962
===> Epoch[50](400/2500): Loss: 0.0963
===> Epoch[50](500/2500): Loss: 0.0961
===> Epoch[50](600/2500): Loss: 0.0962
===> Epoch[50](700/2500): Loss: 0.0965
===> Epoch[50](800/2500): Loss: 0.0971
===> Epoch[50](900/2500): Loss: 0.1062
===> Epoch[50](1000/2500): Loss: 0.0976
===> Epoch[50](1100/2500): Loss: 0.0960
===> Epoch[50](1200/2500): Loss: 0.0958
===> Epoch[50](1300/2500): Loss: 0.0954
===> Epoch[50](1400/2500): Loss: 0.0959
===> Epoch[50](1500/2500): Loss: 0.0960
===> Epoch[50](1600/2500): Loss: 0.0964
===> Epoch[50](1700/2500): Loss: 0.0966
===> Epoch[50](1800/2500): Loss: 0.0965
===> Epoch[50](1900/2500): Loss: 0.0962
===> Epoch[50](2000/2500): Loss: 0.0965
===> Epoch[50](2100/2500): Loss: 0.0964
===> Epoch[50](2200/2500): Loss: 0.0961
===> Epoch[50](2300/2500): Loss: 0.0959
===> Epoch[50](2400/2500): Loss: 0.0958
===> Epoch[50](2500/2500): Loss: 0.0966
===> Epoch 50 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:26:06]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.0969
===> Epoch[50](200/2500): Loss: 0.0963
===> Epoch[50](300/2500): Loss: 0.0962
===> Epoch[50](400/2500): Loss: 0.0963
===> Epoch[50](500/2500): Loss: 0.0961
===> Epoch[50](600/2500): Loss: 0.0962
===> Epoch[50](700/2500): Loss: 0.0965
===> Epoch[50](800/2500): Loss: 0.0971
===> Epoch[50](900/2500): Loss: 0.1062
===> Epoch[50](1000/2500): Loss: 0.0976
===> Epoch[50](1100/2500): Loss: 0.0960
===> Epoch[50](1200/2500): Loss: 0.0958
===> Epoch[50](1300/2500): Loss: 0.0954
===> Epoch[50](1400/2500): Loss: 0.0959
===> Epoch[50](1500/2500): Loss: 0.0960
===> Epoch[50](1600/2500): Loss: 0.0964
===> Epoch[50](1700/2500): Loss: 0.0966
===> Epoch[50](1800/2500): Loss: 0.0965
===> Epoch[50](1900/2500): Loss: 0.0962
===> Epoch[50](2000/2500): Loss: 0.0965
===> Epoch[50](2100/2500): Loss: 0.0964
===> Epoch[50](2200/2500): Loss: 0.0961
===> Epoch[50](2300/2500): Loss: 0.0959
===> Epoch[50](2400/2500): Loss: 0.0958
===> Epoch[50](2500/2500): Loss: 0.0966
===> Epoch 50 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:26:06]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.0969
===> Epoch[50](200/2500): Loss: 0.0963
===> Epoch[50](300/2500): Loss: 0.0962
===> Epoch[50](400/2500): Loss: 0.0963
===> Epoch[50](500/2500): Loss: 0.0961
===> Epoch[50](600/2500): Loss: 0.0962
===> Epoch[50](700/2500): Loss: 0.0965
===> Epoch[50](800/2500): Loss: 0.0971
===> Epoch[50](900/2500): Loss: 0.1062
===> Epoch[50](1000/2500): Loss: 0.0976
===> Epoch[50](1100/2500): Loss: 0.0960
===> Epoch[50](1200/2500): Loss: 0.0958
===> Epoch[50](1300/2500): Loss: 0.0954
===> Epoch[50](1400/2500): Loss: 0.0959
===> Epoch[50](1500/2500): Loss: 0.0960
===> Epoch[50](1600/2500): Loss: 0.0964
===> Epoch[50](1700/2500): Loss: 0.0966
===> Epoch[50](1800/2500): Loss: 0.0965
===> Epoch[50](1900/2500): Loss: 0.0962
===> Epoch[50](2000/2500): Loss: 0.0965
===> Epoch[50](2100/2500): Loss: 0.0964
===> Epoch[50](2200/2500): Loss: 0.0961
===> Epoch[50](2300/2500): Loss: 0.0959
===> Epoch[50](2400/2500): Loss: 0.0958
===> Epoch[50](2500/2500): Loss: 0.0966
===> Epoch 50 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:26:06]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Epoch[50](100/2500): Loss: 0.0969
===> Epoch[50](200/2500): Loss: 0.0963
===> Epoch[50](300/2500): Loss: 0.0962
===> Epoch[50](400/2500): Loss: 0.0963
===> Epoch[50](500/2500): Loss: 0.0961
===> Epoch[50](600/2500): Loss: 0.0962
===> Epoch[50](700/2500): Loss: 0.0965
===> Epoch[50](800/2500): Loss: 0.0971
===> Epoch[50](900/2500): Loss: 0.1062
===> Epoch[50](1000/2500): Loss: 0.0976
===> Epoch[50](1100/2500): Loss: 0.0960
===> Epoch[50](1200/2500): Loss: 0.0958
===> Epoch[50](1300/2500): Loss: 0.0954
===> Epoch[50](1400/2500): Loss: 0.0959
===> Epoch[50](1500/2500): Loss: 0.0960
===> Epoch[50](1600/2500): Loss: 0.0964
===> Epoch[50](1700/2500): Loss: 0.0966
===> Epoch[50](1800/2500): Loss: 0.0965
===> Epoch[50](1900/2500): Loss: 0.0962
===> Epoch[50](2000/2500): Loss: 0.0965
===> Epoch[50](2100/2500): Loss: 0.0964
===> Epoch[50](2200/2500): Loss: 0.0961
===> Epoch[50](2300/2500): Loss: 0.0959
===> Epoch[50](2400/2500): Loss: 0.0958
===> Epoch[50](2500/2500): Loss: 0.0966
===> Epoch 50 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:26:06]
Checkpoint saved to TrainedNet/_epoch_50.pth
===> Loading train datasets
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.0968
===> Epoch[51](200/2500): Loss: 0.0953
===> Epoch[51](300/2500): Loss: 0.0959
===> Epoch[51](400/2500): Loss: 0.0971
===> Epoch[51](500/2500): Loss: 0.0956
===> Epoch[51](600/2500): Loss: 0.0963
===> Epoch[51](700/2500): Loss: 0.0962
===> Epoch[51](800/2500): Loss: 0.0966
===> Epoch[51](900/2500): Loss: 0.0967
===> Epoch[51](1000/2500): Loss: 0.0958
===> Epoch[51](1100/2500): Loss: 0.0963
===> Epoch[51](1200/2500): Loss: 0.0964
===> Epoch[51](1300/2500): Loss: 0.0962
===> Epoch[51](1400/2500): Loss: 0.1031
===> Epoch[51](1500/2500): Loss: 0.0965
===> Epoch[51](1600/2500): Loss: 0.0958
===> Epoch[51](1700/2500): Loss: 0.0958
===> Epoch[51](1800/2500): Loss: 0.0961
===> Epoch[51](1900/2500): Loss: 0.0958
===> Epoch[51](2000/2500): Loss: 0.0962
===> Epoch[51](2100/2500): Loss: 0.0963
===> Epoch[51](2200/2500): Loss: 0.0963
===> Epoch[51](2300/2500): Loss: 0.0967
===> Epoch[51](2400/2500): Loss: 0.0957
===> Epoch[51](2500/2500): Loss: 0.0960
===> Epoch 51 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:31:09]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.0968
===> Epoch[51](200/2500): Loss: 0.0953
===> Epoch[51](300/2500): Loss: 0.0959
===> Epoch[51](400/2500): Loss: 0.0971
===> Epoch[51](500/2500): Loss: 0.0956
===> Epoch[51](600/2500): Loss: 0.0963
===> Epoch[51](700/2500): Loss: 0.0962
===> Epoch[51](800/2500): Loss: 0.0966
===> Epoch[51](900/2500): Loss: 0.0967
===> Epoch[51](1000/2500): Loss: 0.0958
===> Epoch[51](1100/2500): Loss: 0.0963
===> Epoch[51](1200/2500): Loss: 0.0964
===> Epoch[51](1300/2500): Loss: 0.0962
===> Epoch[51](1400/2500): Loss: 0.1031
===> Epoch[51](1500/2500): Loss: 0.0965
===> Epoch[51](1600/2500): Loss: 0.0958
===> Epoch[51](1700/2500): Loss: 0.0958
===> Epoch[51](1800/2500): Loss: 0.0961
===> Epoch[51](1900/2500): Loss: 0.0958
===> Epoch[51](2000/2500): Loss: 0.0962
===> Epoch[51](2100/2500): Loss: 0.0963
===> Epoch[51](2200/2500): Loss: 0.0963
===> Epoch[51](2300/2500): Loss: 0.0967
===> Epoch[51](2400/2500): Loss: 0.0957
===> Epoch[51](2500/2500): Loss: 0.0960
===> Epoch 51 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:31:09]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.0968
===> Epoch[51](200/2500): Loss: 0.0953
===> Epoch[51](300/2500): Loss: 0.0959
===> Epoch[51](400/2500): Loss: 0.0971
===> Epoch[51](500/2500): Loss: 0.0956
===> Epoch[51](600/2500): Loss: 0.0963
===> Epoch[51](700/2500): Loss: 0.0962
===> Epoch[51](800/2500): Loss: 0.0966
===> Epoch[51](900/2500): Loss: 0.0967
===> Epoch[51](1000/2500): Loss: 0.0958
===> Epoch[51](1100/2500): Loss: 0.0963
===> Epoch[51](1200/2500): Loss: 0.0964
===> Epoch[51](1300/2500): Loss: 0.0962
===> Epoch[51](1400/2500): Loss: 0.1031
===> Epoch[51](1500/2500): Loss: 0.0965
===> Epoch[51](1600/2500): Loss: 0.0958
===> Epoch[51](1700/2500): Loss: 0.0958
===> Epoch[51](1800/2500): Loss: 0.0961
===> Epoch[51](1900/2500): Loss: 0.0958
===> Epoch[51](2000/2500): Loss: 0.0962
===> Epoch[51](2100/2500): Loss: 0.0963
===> Epoch[51](2200/2500): Loss: 0.0963
===> Epoch[51](2300/2500): Loss: 0.0967
===> Epoch[51](2400/2500): Loss: 0.0957
===> Epoch[51](2500/2500): Loss: 0.0960
===> Epoch 51 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:31:09]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.0968
===> Epoch[51](200/2500): Loss: 0.0953
===> Epoch[51](300/2500): Loss: 0.0959
===> Epoch[51](400/2500): Loss: 0.0971
===> Epoch[51](500/2500): Loss: 0.0956
===> Epoch[51](600/2500): Loss: 0.0963
===> Epoch[51](700/2500): Loss: 0.0962
===> Epoch[51](800/2500): Loss: 0.0966
===> Epoch[51](900/2500): Loss: 0.0967
===> Epoch[51](1000/2500): Loss: 0.0958
===> Epoch[51](1100/2500): Loss: 0.0963
===> Epoch[51](1200/2500): Loss: 0.0964
===> Epoch[51](1300/2500): Loss: 0.0962
===> Epoch[51](1400/2500): Loss: 0.1031
===> Epoch[51](1500/2500): Loss: 0.0965
===> Epoch[51](1600/2500): Loss: 0.0958
===> Epoch[51](1700/2500): Loss: 0.0958
===> Epoch[51](1800/2500): Loss: 0.0961
===> Epoch[51](1900/2500): Loss: 0.0958
===> Epoch[51](2000/2500): Loss: 0.0962
===> Epoch[51](2100/2500): Loss: 0.0963
===> Epoch[51](2200/2500): Loss: 0.0963
===> Epoch[51](2300/2500): Loss: 0.0967
===> Epoch[51](2400/2500): Loss: 0.0957
===> Epoch[51](2500/2500): Loss: 0.0960
===> Epoch 51 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:31:09]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.0968
===> Epoch[51](200/2500): Loss: 0.0953
===> Epoch[51](300/2500): Loss: 0.0959
===> Epoch[51](400/2500): Loss: 0.0971
===> Epoch[51](500/2500): Loss: 0.0956
===> Epoch[51](600/2500): Loss: 0.0963
===> Epoch[51](700/2500): Loss: 0.0962
===> Epoch[51](800/2500): Loss: 0.0966
===> Epoch[51](900/2500): Loss: 0.0967
===> Epoch[51](1000/2500): Loss: 0.0958
===> Epoch[51](1100/2500): Loss: 0.0963
===> Epoch[51](1200/2500): Loss: 0.0964
===> Epoch[51](1300/2500): Loss: 0.0962
===> Epoch[51](1400/2500): Loss: 0.1031
===> Epoch[51](1500/2500): Loss: 0.0965
===> Epoch[51](1600/2500): Loss: 0.0958
===> Epoch[51](1700/2500): Loss: 0.0958
===> Epoch[51](1800/2500): Loss: 0.0961
===> Epoch[51](1900/2500): Loss: 0.0958
===> Epoch[51](2000/2500): Loss: 0.0962
===> Epoch[51](2100/2500): Loss: 0.0963
===> Epoch[51](2200/2500): Loss: 0.0963
===> Epoch[51](2300/2500): Loss: 0.0967
===> Epoch[51](2400/2500): Loss: 0.0957
===> Epoch[51](2500/2500): Loss: 0.0960
===> Epoch 51 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:31:09]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.0968
===> Epoch[51](200/2500): Loss: 0.0953
===> Epoch[51](300/2500): Loss: 0.0959
===> Epoch[51](400/2500): Loss: 0.0971
===> Epoch[51](500/2500): Loss: 0.0956
===> Epoch[51](600/2500): Loss: 0.0963
===> Epoch[51](700/2500): Loss: 0.0962
===> Epoch[51](800/2500): Loss: 0.0966
===> Epoch[51](900/2500): Loss: 0.0967
===> Epoch[51](1000/2500): Loss: 0.0958
===> Epoch[51](1100/2500): Loss: 0.0963
===> Epoch[51](1200/2500): Loss: 0.0964
===> Epoch[51](1300/2500): Loss: 0.0962
===> Epoch[51](1400/2500): Loss: 0.1031
===> Epoch[51](1500/2500): Loss: 0.0965
===> Epoch[51](1600/2500): Loss: 0.0958
===> Epoch[51](1700/2500): Loss: 0.0958
===> Epoch[51](1800/2500): Loss: 0.0961
===> Epoch[51](1900/2500): Loss: 0.0958
===> Epoch[51](2000/2500): Loss: 0.0962
===> Epoch[51](2100/2500): Loss: 0.0963
===> Epoch[51](2200/2500): Loss: 0.0963
===> Epoch[51](2300/2500): Loss: 0.0967
===> Epoch[51](2400/2500): Loss: 0.0957
===> Epoch[51](2500/2500): Loss: 0.0960
===> Epoch 51 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:31:09]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.0968
===> Epoch[51](200/2500): Loss: 0.0953
===> Epoch[51](300/2500): Loss: 0.0959
===> Epoch[51](400/2500): Loss: 0.0971
===> Epoch[51](500/2500): Loss: 0.0956
===> Epoch[51](600/2500): Loss: 0.0963
===> Epoch[51](700/2500): Loss: 0.0962
===> Epoch[51](800/2500): Loss: 0.0966
===> Epoch[51](900/2500): Loss: 0.0967
===> Epoch[51](1000/2500): Loss: 0.0958
===> Epoch[51](1100/2500): Loss: 0.0963
===> Epoch[51](1200/2500): Loss: 0.0964
===> Epoch[51](1300/2500): Loss: 0.0962
===> Epoch[51](1400/2500): Loss: 0.1031
===> Epoch[51](1500/2500): Loss: 0.0965
===> Epoch[51](1600/2500): Loss: 0.0958
===> Epoch[51](1700/2500): Loss: 0.0958
===> Epoch[51](1800/2500): Loss: 0.0961
===> Epoch[51](1900/2500): Loss: 0.0958
===> Epoch[51](2000/2500): Loss: 0.0962
===> Epoch[51](2100/2500): Loss: 0.0963
===> Epoch[51](2200/2500): Loss: 0.0963
===> Epoch[51](2300/2500): Loss: 0.0967
===> Epoch[51](2400/2500): Loss: 0.0957
===> Epoch[51](2500/2500): Loss: 0.0960
===> Epoch 51 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:31:09]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.0968
===> Epoch[51](200/2500): Loss: 0.0953
===> Epoch[51](300/2500): Loss: 0.0959
===> Epoch[51](400/2500): Loss: 0.0971
===> Epoch[51](500/2500): Loss: 0.0956
===> Epoch[51](600/2500): Loss: 0.0963
===> Epoch[51](700/2500): Loss: 0.0962
===> Epoch[51](800/2500): Loss: 0.0966
===> Epoch[51](900/2500): Loss: 0.0967
===> Epoch[51](1000/2500): Loss: 0.0958
===> Epoch[51](1100/2500): Loss: 0.0963
===> Epoch[51](1200/2500): Loss: 0.0964
===> Epoch[51](1300/2500): Loss: 0.0962
===> Epoch[51](1400/2500): Loss: 0.1031
===> Epoch[51](1500/2500): Loss: 0.0965
===> Epoch[51](1600/2500): Loss: 0.0958
===> Epoch[51](1700/2500): Loss: 0.0958
===> Epoch[51](1800/2500): Loss: 0.0961
===> Epoch[51](1900/2500): Loss: 0.0958
===> Epoch[51](2000/2500): Loss: 0.0962
===> Epoch[51](2100/2500): Loss: 0.0963
===> Epoch[51](2200/2500): Loss: 0.0963
===> Epoch[51](2300/2500): Loss: 0.0967
===> Epoch[51](2400/2500): Loss: 0.0957
===> Epoch[51](2500/2500): Loss: 0.0960
===> Epoch 51 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:31:09]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.0968
===> Epoch[51](200/2500): Loss: 0.0953
===> Epoch[51](300/2500): Loss: 0.0959
===> Epoch[51](400/2500): Loss: 0.0971
===> Epoch[51](500/2500): Loss: 0.0956
===> Epoch[51](600/2500): Loss: 0.0963
===> Epoch[51](700/2500): Loss: 0.0962
===> Epoch[51](800/2500): Loss: 0.0966
===> Epoch[51](900/2500): Loss: 0.0967
===> Epoch[51](1000/2500): Loss: 0.0958
===> Epoch[51](1100/2500): Loss: 0.0963
===> Epoch[51](1200/2500): Loss: 0.0964
===> Epoch[51](1300/2500): Loss: 0.0962
===> Epoch[51](1400/2500): Loss: 0.1031
===> Epoch[51](1500/2500): Loss: 0.0965
===> Epoch[51](1600/2500): Loss: 0.0958
===> Epoch[51](1700/2500): Loss: 0.0958
===> Epoch[51](1800/2500): Loss: 0.0961
===> Epoch[51](1900/2500): Loss: 0.0958
===> Epoch[51](2000/2500): Loss: 0.0962
===> Epoch[51](2100/2500): Loss: 0.0963
===> Epoch[51](2200/2500): Loss: 0.0963
===> Epoch[51](2300/2500): Loss: 0.0967
===> Epoch[51](2400/2500): Loss: 0.0957
===> Epoch[51](2500/2500): Loss: 0.0960
===> Epoch 51 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:31:09]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.0968
===> Epoch[51](200/2500): Loss: 0.0953
===> Epoch[51](300/2500): Loss: 0.0959
===> Epoch[51](400/2500): Loss: 0.0971
===> Epoch[51](500/2500): Loss: 0.0956
===> Epoch[51](600/2500): Loss: 0.0963
===> Epoch[51](700/2500): Loss: 0.0962
===> Epoch[51](800/2500): Loss: 0.0966
===> Epoch[51](900/2500): Loss: 0.0967
===> Epoch[51](1000/2500): Loss: 0.0958
===> Epoch[51](1100/2500): Loss: 0.0963
===> Epoch[51](1200/2500): Loss: 0.0964
===> Epoch[51](1300/2500): Loss: 0.0962
===> Epoch[51](1400/2500): Loss: 0.1031
===> Epoch[51](1500/2500): Loss: 0.0965
===> Epoch[51](1600/2500): Loss: 0.0958
===> Epoch[51](1700/2500): Loss: 0.0958
===> Epoch[51](1800/2500): Loss: 0.0961
===> Epoch[51](1900/2500): Loss: 0.0958
===> Epoch[51](2000/2500): Loss: 0.0962
===> Epoch[51](2100/2500): Loss: 0.0963
===> Epoch[51](2200/2500): Loss: 0.0963
===> Epoch[51](2300/2500): Loss: 0.0967
===> Epoch[51](2400/2500): Loss: 0.0957
===> Epoch[51](2500/2500): Loss: 0.0960
===> Epoch 51 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:31:09]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.0968
===> Epoch[51](200/2500): Loss: 0.0953
===> Epoch[51](300/2500): Loss: 0.0959
===> Epoch[51](400/2500): Loss: 0.0971
===> Epoch[51](500/2500): Loss: 0.0956
===> Epoch[51](600/2500): Loss: 0.0963
===> Epoch[51](700/2500): Loss: 0.0962
===> Epoch[51](800/2500): Loss: 0.0966
===> Epoch[51](900/2500): Loss: 0.0967
===> Epoch[51](1000/2500): Loss: 0.0958
===> Epoch[51](1100/2500): Loss: 0.0963
===> Epoch[51](1200/2500): Loss: 0.0964
===> Epoch[51](1300/2500): Loss: 0.0962
===> Epoch[51](1400/2500): Loss: 0.1031
===> Epoch[51](1500/2500): Loss: 0.0965
===> Epoch[51](1600/2500): Loss: 0.0958
===> Epoch[51](1700/2500): Loss: 0.0958
===> Epoch[51](1800/2500): Loss: 0.0961
===> Epoch[51](1900/2500): Loss: 0.0958
===> Epoch[51](2000/2500): Loss: 0.0962
===> Epoch[51](2100/2500): Loss: 0.0963
===> Epoch[51](2200/2500): Loss: 0.0963
===> Epoch[51](2300/2500): Loss: 0.0967
===> Epoch[51](2400/2500): Loss: 0.0957
===> Epoch[51](2500/2500): Loss: 0.0960
===> Epoch 51 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:31:09]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.0968
===> Epoch[51](200/2500): Loss: 0.0953
===> Epoch[51](300/2500): Loss: 0.0959
===> Epoch[51](400/2500): Loss: 0.0971
===> Epoch[51](500/2500): Loss: 0.0956
===> Epoch[51](600/2500): Loss: 0.0963
===> Epoch[51](700/2500): Loss: 0.0962
===> Epoch[51](800/2500): Loss: 0.0966
===> Epoch[51](900/2500): Loss: 0.0967
===> Epoch[51](1000/2500): Loss: 0.0958
===> Epoch[51](1100/2500): Loss: 0.0963
===> Epoch[51](1200/2500): Loss: 0.0964
===> Epoch[51](1300/2500): Loss: 0.0962
===> Epoch[51](1400/2500): Loss: 0.1031
===> Epoch[51](1500/2500): Loss: 0.0965
===> Epoch[51](1600/2500): Loss: 0.0958
===> Epoch[51](1700/2500): Loss: 0.0958
===> Epoch[51](1800/2500): Loss: 0.0961
===> Epoch[51](1900/2500): Loss: 0.0958
===> Epoch[51](2000/2500): Loss: 0.0962
===> Epoch[51](2100/2500): Loss: 0.0963
===> Epoch[51](2200/2500): Loss: 0.0963
===> Epoch[51](2300/2500): Loss: 0.0967
===> Epoch[51](2400/2500): Loss: 0.0957
===> Epoch[51](2500/2500): Loss: 0.0960
===> Epoch 51 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:31:09]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.0968
===> Epoch[51](200/2500): Loss: 0.0953
===> Epoch[51](300/2500): Loss: 0.0959
===> Epoch[51](400/2500): Loss: 0.0971
===> Epoch[51](500/2500): Loss: 0.0956
===> Epoch[51](600/2500): Loss: 0.0963
===> Epoch[51](700/2500): Loss: 0.0962
===> Epoch[51](800/2500): Loss: 0.0966
===> Epoch[51](900/2500): Loss: 0.0967
===> Epoch[51](1000/2500): Loss: 0.0958
===> Epoch[51](1100/2500): Loss: 0.0963
===> Epoch[51](1200/2500): Loss: 0.0964
===> Epoch[51](1300/2500): Loss: 0.0962
===> Epoch[51](1400/2500): Loss: 0.1031
===> Epoch[51](1500/2500): Loss: 0.0965
===> Epoch[51](1600/2500): Loss: 0.0958
===> Epoch[51](1700/2500): Loss: 0.0958
===> Epoch[51](1800/2500): Loss: 0.0961
===> Epoch[51](1900/2500): Loss: 0.0958
===> Epoch[51](2000/2500): Loss: 0.0962
===> Epoch[51](2100/2500): Loss: 0.0963
===> Epoch[51](2200/2500): Loss: 0.0963
===> Epoch[51](2300/2500): Loss: 0.0967
===> Epoch[51](2400/2500): Loss: 0.0957
===> Epoch[51](2500/2500): Loss: 0.0960
===> Epoch 51 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:31:09]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.0968
===> Epoch[51](200/2500): Loss: 0.0953
===> Epoch[51](300/2500): Loss: 0.0959
===> Epoch[51](400/2500): Loss: 0.0971
===> Epoch[51](500/2500): Loss: 0.0956
===> Epoch[51](600/2500): Loss: 0.0963
===> Epoch[51](700/2500): Loss: 0.0962
===> Epoch[51](800/2500): Loss: 0.0966
===> Epoch[51](900/2500): Loss: 0.0967
===> Epoch[51](1000/2500): Loss: 0.0958
===> Epoch[51](1100/2500): Loss: 0.0963
===> Epoch[51](1200/2500): Loss: 0.0964
===> Epoch[51](1300/2500): Loss: 0.0962
===> Epoch[51](1400/2500): Loss: 0.1031
===> Epoch[51](1500/2500): Loss: 0.0965
===> Epoch[51](1600/2500): Loss: 0.0958
===> Epoch[51](1700/2500): Loss: 0.0958
===> Epoch[51](1800/2500): Loss: 0.0961
===> Epoch[51](1900/2500): Loss: 0.0958
===> Epoch[51](2000/2500): Loss: 0.0962
===> Epoch[51](2100/2500): Loss: 0.0963
===> Epoch[51](2200/2500): Loss: 0.0963
===> Epoch[51](2300/2500): Loss: 0.0967
===> Epoch[51](2400/2500): Loss: 0.0957
===> Epoch[51](2500/2500): Loss: 0.0960
===> Epoch 51 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:31:09]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.0968
===> Epoch[51](200/2500): Loss: 0.0953
===> Epoch[51](300/2500): Loss: 0.0959
===> Epoch[51](400/2500): Loss: 0.0971
===> Epoch[51](500/2500): Loss: 0.0956
===> Epoch[51](600/2500): Loss: 0.0963
===> Epoch[51](700/2500): Loss: 0.0962
===> Epoch[51](800/2500): Loss: 0.0966
===> Epoch[51](900/2500): Loss: 0.0967
===> Epoch[51](1000/2500): Loss: 0.0958
===> Epoch[51](1100/2500): Loss: 0.0963
===> Epoch[51](1200/2500): Loss: 0.0964
===> Epoch[51](1300/2500): Loss: 0.0962
===> Epoch[51](1400/2500): Loss: 0.1031
===> Epoch[51](1500/2500): Loss: 0.0965
===> Epoch[51](1600/2500): Loss: 0.0958
===> Epoch[51](1700/2500): Loss: 0.0958
===> Epoch[51](1800/2500): Loss: 0.0961
===> Epoch[51](1900/2500): Loss: 0.0958
===> Epoch[51](2000/2500): Loss: 0.0962
===> Epoch[51](2100/2500): Loss: 0.0963
===> Epoch[51](2200/2500): Loss: 0.0963
===> Epoch[51](2300/2500): Loss: 0.0967
===> Epoch[51](2400/2500): Loss: 0.0957
===> Epoch[51](2500/2500): Loss: 0.0960
===> Epoch 51 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:31:09]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.0968
===> Epoch[51](200/2500): Loss: 0.0953
===> Epoch[51](300/2500): Loss: 0.0959
===> Epoch[51](400/2500): Loss: 0.0971
===> Epoch[51](500/2500): Loss: 0.0956
===> Epoch[51](600/2500): Loss: 0.0963
===> Epoch[51](700/2500): Loss: 0.0962
===> Epoch[51](800/2500): Loss: 0.0966
===> Epoch[51](900/2500): Loss: 0.0967
===> Epoch[51](1000/2500): Loss: 0.0958
===> Epoch[51](1100/2500): Loss: 0.0963
===> Epoch[51](1200/2500): Loss: 0.0964
===> Epoch[51](1300/2500): Loss: 0.0962
===> Epoch[51](1400/2500): Loss: 0.1031
===> Epoch[51](1500/2500): Loss: 0.0965
===> Epoch[51](1600/2500): Loss: 0.0958
===> Epoch[51](1700/2500): Loss: 0.0958
===> Epoch[51](1800/2500): Loss: 0.0961
===> Epoch[51](1900/2500): Loss: 0.0958
===> Epoch[51](2000/2500): Loss: 0.0962
===> Epoch[51](2100/2500): Loss: 0.0963
===> Epoch[51](2200/2500): Loss: 0.0963
===> Epoch[51](2300/2500): Loss: 0.0967
===> Epoch[51](2400/2500): Loss: 0.0957
===> Epoch[51](2500/2500): Loss: 0.0960
===> Epoch 51 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:31:09]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.0968
===> Epoch[51](200/2500): Loss: 0.0953
===> Epoch[51](300/2500): Loss: 0.0959
===> Epoch[51](400/2500): Loss: 0.0971
===> Epoch[51](500/2500): Loss: 0.0956
===> Epoch[51](600/2500): Loss: 0.0963
===> Epoch[51](700/2500): Loss: 0.0962
===> Epoch[51](800/2500): Loss: 0.0966
===> Epoch[51](900/2500): Loss: 0.0967
===> Epoch[51](1000/2500): Loss: 0.0958
===> Epoch[51](1100/2500): Loss: 0.0963
===> Epoch[51](1200/2500): Loss: 0.0964
===> Epoch[51](1300/2500): Loss: 0.0962
===> Epoch[51](1400/2500): Loss: 0.1031
===> Epoch[51](1500/2500): Loss: 0.0965
===> Epoch[51](1600/2500): Loss: 0.0958
===> Epoch[51](1700/2500): Loss: 0.0958
===> Epoch[51](1800/2500): Loss: 0.0961
===> Epoch[51](1900/2500): Loss: 0.0958
===> Epoch[51](2000/2500): Loss: 0.0962
===> Epoch[51](2100/2500): Loss: 0.0963
===> Epoch[51](2200/2500): Loss: 0.0963
===> Epoch[51](2300/2500): Loss: 0.0967
===> Epoch[51](2400/2500): Loss: 0.0957
===> Epoch[51](2500/2500): Loss: 0.0960
===> Epoch 51 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:31:09]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.0968
===> Epoch[51](200/2500): Loss: 0.0953
===> Epoch[51](300/2500): Loss: 0.0959
===> Epoch[51](400/2500): Loss: 0.0971
===> Epoch[51](500/2500): Loss: 0.0956
===> Epoch[51](600/2500): Loss: 0.0963
===> Epoch[51](700/2500): Loss: 0.0962
===> Epoch[51](800/2500): Loss: 0.0966
===> Epoch[51](900/2500): Loss: 0.0967
===> Epoch[51](1000/2500): Loss: 0.0958
===> Epoch[51](1100/2500): Loss: 0.0963
===> Epoch[51](1200/2500): Loss: 0.0964
===> Epoch[51](1300/2500): Loss: 0.0962
===> Epoch[51](1400/2500): Loss: 0.1031
===> Epoch[51](1500/2500): Loss: 0.0965
===> Epoch[51](1600/2500): Loss: 0.0958
===> Epoch[51](1700/2500): Loss: 0.0958
===> Epoch[51](1800/2500): Loss: 0.0961
===> Epoch[51](1900/2500): Loss: 0.0958
===> Epoch[51](2000/2500): Loss: 0.0962
===> Epoch[51](2100/2500): Loss: 0.0963
===> Epoch[51](2200/2500): Loss: 0.0963
===> Epoch[51](2300/2500): Loss: 0.0967
===> Epoch[51](2400/2500): Loss: 0.0957
===> Epoch[51](2500/2500): Loss: 0.0960
===> Epoch 51 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:31:09]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.0968
===> Epoch[51](200/2500): Loss: 0.0953
===> Epoch[51](300/2500): Loss: 0.0959
===> Epoch[51](400/2500): Loss: 0.0971
===> Epoch[51](500/2500): Loss: 0.0956
===> Epoch[51](600/2500): Loss: 0.0963
===> Epoch[51](700/2500): Loss: 0.0962
===> Epoch[51](800/2500): Loss: 0.0966
===> Epoch[51](900/2500): Loss: 0.0967
===> Epoch[51](1000/2500): Loss: 0.0958
===> Epoch[51](1100/2500): Loss: 0.0963
===> Epoch[51](1200/2500): Loss: 0.0964
===> Epoch[51](1300/2500): Loss: 0.0962
===> Epoch[51](1400/2500): Loss: 0.1031
===> Epoch[51](1500/2500): Loss: 0.0965
===> Epoch[51](1600/2500): Loss: 0.0958
===> Epoch[51](1700/2500): Loss: 0.0958
===> Epoch[51](1800/2500): Loss: 0.0961
===> Epoch[51](1900/2500): Loss: 0.0958
===> Epoch[51](2000/2500): Loss: 0.0962
===> Epoch[51](2100/2500): Loss: 0.0963
===> Epoch[51](2200/2500): Loss: 0.0963
===> Epoch[51](2300/2500): Loss: 0.0967
===> Epoch[51](2400/2500): Loss: 0.0957
===> Epoch[51](2500/2500): Loss: 0.0960
===> Epoch 51 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:31:09]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.0968
===> Epoch[51](200/2500): Loss: 0.0953
===> Epoch[51](300/2500): Loss: 0.0959
===> Epoch[51](400/2500): Loss: 0.0971
===> Epoch[51](500/2500): Loss: 0.0956
===> Epoch[51](600/2500): Loss: 0.0963
===> Epoch[51](700/2500): Loss: 0.0962
===> Epoch[51](800/2500): Loss: 0.0966
===> Epoch[51](900/2500): Loss: 0.0967
===> Epoch[51](1000/2500): Loss: 0.0958
===> Epoch[51](1100/2500): Loss: 0.0963
===> Epoch[51](1200/2500): Loss: 0.0964
===> Epoch[51](1300/2500): Loss: 0.0962
===> Epoch[51](1400/2500): Loss: 0.1031
===> Epoch[51](1500/2500): Loss: 0.0965
===> Epoch[51](1600/2500): Loss: 0.0958
===> Epoch[51](1700/2500): Loss: 0.0958
===> Epoch[51](1800/2500): Loss: 0.0961
===> Epoch[51](1900/2500): Loss: 0.0958
===> Epoch[51](2000/2500): Loss: 0.0962
===> Epoch[51](2100/2500): Loss: 0.0963
===> Epoch[51](2200/2500): Loss: 0.0963
===> Epoch[51](2300/2500): Loss: 0.0967
===> Epoch[51](2400/2500): Loss: 0.0957
===> Epoch[51](2500/2500): Loss: 0.0960
===> Epoch 51 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:31:09]
===> Loading train datasets
===> Epoch[51](100/2500): Loss: 0.0968
===> Epoch[51](200/2500): Loss: 0.0953
===> Epoch[51](300/2500): Loss: 0.0959
===> Epoch[51](400/2500): Loss: 0.0971
===> Epoch[51](500/2500): Loss: 0.0956
===> Epoch[51](600/2500): Loss: 0.0963
===> Epoch[51](700/2500): Loss: 0.0962
===> Epoch[51](800/2500): Loss: 0.0966
===> Epoch[51](900/2500): Loss: 0.0967
===> Epoch[51](1000/2500): Loss: 0.0958
===> Epoch[51](1100/2500): Loss: 0.0963
===> Epoch[51](1200/2500): Loss: 0.0964
===> Epoch[51](1300/2500): Loss: 0.0962
===> Epoch[51](1400/2500): Loss: 0.1031
===> Epoch[51](1500/2500): Loss: 0.0965
===> Epoch[51](1600/2500): Loss: 0.0958
===> Epoch[51](1700/2500): Loss: 0.0958
===> Epoch[51](1800/2500): Loss: 0.0961
===> Epoch[51](1900/2500): Loss: 0.0958
===> Epoch[51](2000/2500): Loss: 0.0962
===> Epoch[51](2100/2500): Loss: 0.0963
===> Epoch[51](2200/2500): Loss: 0.0963
===> Epoch[51](2300/2500): Loss: 0.0967
===> Epoch[51](2400/2500): Loss: 0.0957
===> Epoch[51](2500/2500): Loss: 0.0960
===> Epoch 51 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:31:09]
===> Loading train datasets
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.0962
===> Epoch[52](200/2500): Loss: 0.0960
===> Epoch[52](300/2500): Loss: 0.0955
===> Epoch[52](400/2500): Loss: 0.0967
===> Epoch[52](500/2500): Loss: 0.0961
===> Epoch[52](600/2500): Loss: 0.0962
===> Epoch[52](700/2500): Loss: 0.0966
===> Epoch[52](800/2500): Loss: 0.0962
===> Epoch[52](900/2500): Loss: 0.0960
===> Epoch[52](1000/2500): Loss: 0.0965
===> Epoch[52](1100/2500): Loss: 0.0964
===> Epoch[52](1200/2500): Loss: 0.0962
===> Epoch[52](1300/2500): Loss: 0.0959
===> Epoch[52](1400/2500): Loss: 0.0961
===> Epoch[52](1500/2500): Loss: 0.0958
===> Epoch[52](1600/2500): Loss: 0.0957
===> Epoch[52](1700/2500): Loss: 0.0958
===> Epoch[52](1800/2500): Loss: 0.0957
===> Epoch[52](1900/2500): Loss: 0.0972
===> Epoch[52](2000/2500): Loss: 0.1005
===> Epoch[52](2100/2500): Loss: 0.0962
===> Epoch[52](2200/2500): Loss: 0.0961
===> Epoch[52](2300/2500): Loss: 0.0963
===> Epoch[52](2400/2500): Loss: 0.0963
===> Epoch[52](2500/2500): Loss: 0.0965
===> Epoch 52 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:36:11]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.0962
===> Epoch[52](200/2500): Loss: 0.0960
===> Epoch[52](300/2500): Loss: 0.0955
===> Epoch[52](400/2500): Loss: 0.0967
===> Epoch[52](500/2500): Loss: 0.0961
===> Epoch[52](600/2500): Loss: 0.0962
===> Epoch[52](700/2500): Loss: 0.0966
===> Epoch[52](800/2500): Loss: 0.0962
===> Epoch[52](900/2500): Loss: 0.0960
===> Epoch[52](1000/2500): Loss: 0.0965
===> Epoch[52](1100/2500): Loss: 0.0964
===> Epoch[52](1200/2500): Loss: 0.0962
===> Epoch[52](1300/2500): Loss: 0.0959
===> Epoch[52](1400/2500): Loss: 0.0961
===> Epoch[52](1500/2500): Loss: 0.0958
===> Epoch[52](1600/2500): Loss: 0.0957
===> Epoch[52](1700/2500): Loss: 0.0958
===> Epoch[52](1800/2500): Loss: 0.0957
===> Epoch[52](1900/2500): Loss: 0.0972
===> Epoch[52](2000/2500): Loss: 0.1005
===> Epoch[52](2100/2500): Loss: 0.0962
===> Epoch[52](2200/2500): Loss: 0.0961
===> Epoch[52](2300/2500): Loss: 0.0963
===> Epoch[52](2400/2500): Loss: 0.0963
===> Epoch[52](2500/2500): Loss: 0.0965
===> Epoch 52 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:36:11]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.0962
===> Epoch[52](200/2500): Loss: 0.0960
===> Epoch[52](300/2500): Loss: 0.0955
===> Epoch[52](400/2500): Loss: 0.0967
===> Epoch[52](500/2500): Loss: 0.0961
===> Epoch[52](600/2500): Loss: 0.0962
===> Epoch[52](700/2500): Loss: 0.0966
===> Epoch[52](800/2500): Loss: 0.0962
===> Epoch[52](900/2500): Loss: 0.0960
===> Epoch[52](1000/2500): Loss: 0.0965
===> Epoch[52](1100/2500): Loss: 0.0964
===> Epoch[52](1200/2500): Loss: 0.0962
===> Epoch[52](1300/2500): Loss: 0.0959
===> Epoch[52](1400/2500): Loss: 0.0961
===> Epoch[52](1500/2500): Loss: 0.0958
===> Epoch[52](1600/2500): Loss: 0.0957
===> Epoch[52](1700/2500): Loss: 0.0958
===> Epoch[52](1800/2500): Loss: 0.0957
===> Epoch[52](1900/2500): Loss: 0.0972
===> Epoch[52](2000/2500): Loss: 0.1005
===> Epoch[52](2100/2500): Loss: 0.0962
===> Epoch[52](2200/2500): Loss: 0.0961
===> Epoch[52](2300/2500): Loss: 0.0963
===> Epoch[52](2400/2500): Loss: 0.0963
===> Epoch[52](2500/2500): Loss: 0.0965
===> Epoch 52 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:36:11]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.0962
===> Epoch[52](200/2500): Loss: 0.0960
===> Epoch[52](300/2500): Loss: 0.0955
===> Epoch[52](400/2500): Loss: 0.0967
===> Epoch[52](500/2500): Loss: 0.0961
===> Epoch[52](600/2500): Loss: 0.0962
===> Epoch[52](700/2500): Loss: 0.0966
===> Epoch[52](800/2500): Loss: 0.0962
===> Epoch[52](900/2500): Loss: 0.0960
===> Epoch[52](1000/2500): Loss: 0.0965
===> Epoch[52](1100/2500): Loss: 0.0964
===> Epoch[52](1200/2500): Loss: 0.0962
===> Epoch[52](1300/2500): Loss: 0.0959
===> Epoch[52](1400/2500): Loss: 0.0961
===> Epoch[52](1500/2500): Loss: 0.0958
===> Epoch[52](1600/2500): Loss: 0.0957
===> Epoch[52](1700/2500): Loss: 0.0958
===> Epoch[52](1800/2500): Loss: 0.0957
===> Epoch[52](1900/2500): Loss: 0.0972
===> Epoch[52](2000/2500): Loss: 0.1005
===> Epoch[52](2100/2500): Loss: 0.0962
===> Epoch[52](2200/2500): Loss: 0.0961
===> Epoch[52](2300/2500): Loss: 0.0963
===> Epoch[52](2400/2500): Loss: 0.0963
===> Epoch[52](2500/2500): Loss: 0.0965
===> Epoch 52 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:36:11]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.0962
===> Epoch[52](200/2500): Loss: 0.0960
===> Epoch[52](300/2500): Loss: 0.0955
===> Epoch[52](400/2500): Loss: 0.0967
===> Epoch[52](500/2500): Loss: 0.0961
===> Epoch[52](600/2500): Loss: 0.0962
===> Epoch[52](700/2500): Loss: 0.0966
===> Epoch[52](800/2500): Loss: 0.0962
===> Epoch[52](900/2500): Loss: 0.0960
===> Epoch[52](1000/2500): Loss: 0.0965
===> Epoch[52](1100/2500): Loss: 0.0964
===> Epoch[52](1200/2500): Loss: 0.0962
===> Epoch[52](1300/2500): Loss: 0.0959
===> Epoch[52](1400/2500): Loss: 0.0961
===> Epoch[52](1500/2500): Loss: 0.0958
===> Epoch[52](1600/2500): Loss: 0.0957
===> Epoch[52](1700/2500): Loss: 0.0958
===> Epoch[52](1800/2500): Loss: 0.0957
===> Epoch[52](1900/2500): Loss: 0.0972
===> Epoch[52](2000/2500): Loss: 0.1005
===> Epoch[52](2100/2500): Loss: 0.0962
===> Epoch[52](2200/2500): Loss: 0.0961
===> Epoch[52](2300/2500): Loss: 0.0963
===> Epoch[52](2400/2500): Loss: 0.0963
===> Epoch[52](2500/2500): Loss: 0.0965
===> Epoch 52 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:36:11]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.0962
===> Epoch[52](200/2500): Loss: 0.0960
===> Epoch[52](300/2500): Loss: 0.0955
===> Epoch[52](400/2500): Loss: 0.0967
===> Epoch[52](500/2500): Loss: 0.0961
===> Epoch[52](600/2500): Loss: 0.0962
===> Epoch[52](700/2500): Loss: 0.0966
===> Epoch[52](800/2500): Loss: 0.0962
===> Epoch[52](900/2500): Loss: 0.0960
===> Epoch[52](1000/2500): Loss: 0.0965
===> Epoch[52](1100/2500): Loss: 0.0964
===> Epoch[52](1200/2500): Loss: 0.0962
===> Epoch[52](1300/2500): Loss: 0.0959
===> Epoch[52](1400/2500): Loss: 0.0961
===> Epoch[52](1500/2500): Loss: 0.0958
===> Epoch[52](1600/2500): Loss: 0.0957
===> Epoch[52](1700/2500): Loss: 0.0958
===> Epoch[52](1800/2500): Loss: 0.0957
===> Epoch[52](1900/2500): Loss: 0.0972
===> Epoch[52](2000/2500): Loss: 0.1005
===> Epoch[52](2100/2500): Loss: 0.0962
===> Epoch[52](2200/2500): Loss: 0.0961
===> Epoch[52](2300/2500): Loss: 0.0963
===> Epoch[52](2400/2500): Loss: 0.0963
===> Epoch[52](2500/2500): Loss: 0.0965
===> Epoch 52 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:36:11]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.0962
===> Epoch[52](200/2500): Loss: 0.0960
===> Epoch[52](300/2500): Loss: 0.0955
===> Epoch[52](400/2500): Loss: 0.0967
===> Epoch[52](500/2500): Loss: 0.0961
===> Epoch[52](600/2500): Loss: 0.0962
===> Epoch[52](700/2500): Loss: 0.0966
===> Epoch[52](800/2500): Loss: 0.0962
===> Epoch[52](900/2500): Loss: 0.0960
===> Epoch[52](1000/2500): Loss: 0.0965
===> Epoch[52](1100/2500): Loss: 0.0964
===> Epoch[52](1200/2500): Loss: 0.0962
===> Epoch[52](1300/2500): Loss: 0.0959
===> Epoch[52](1400/2500): Loss: 0.0961
===> Epoch[52](1500/2500): Loss: 0.0958
===> Epoch[52](1600/2500): Loss: 0.0957
===> Epoch[52](1700/2500): Loss: 0.0958
===> Epoch[52](1800/2500): Loss: 0.0957
===> Epoch[52](1900/2500): Loss: 0.0972
===> Epoch[52](2000/2500): Loss: 0.1005
===> Epoch[52](2100/2500): Loss: 0.0962
===> Epoch[52](2200/2500): Loss: 0.0961
===> Epoch[52](2300/2500): Loss: 0.0963
===> Epoch[52](2400/2500): Loss: 0.0963
===> Epoch[52](2500/2500): Loss: 0.0965
===> Epoch 52 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:36:11]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.0962
===> Epoch[52](200/2500): Loss: 0.0960
===> Epoch[52](300/2500): Loss: 0.0955
===> Epoch[52](400/2500): Loss: 0.0967
===> Epoch[52](500/2500): Loss: 0.0961
===> Epoch[52](600/2500): Loss: 0.0962
===> Epoch[52](700/2500): Loss: 0.0966
===> Epoch[52](800/2500): Loss: 0.0962
===> Epoch[52](900/2500): Loss: 0.0960
===> Epoch[52](1000/2500): Loss: 0.0965
===> Epoch[52](1100/2500): Loss: 0.0964
===> Epoch[52](1200/2500): Loss: 0.0962
===> Epoch[52](1300/2500): Loss: 0.0959
===> Epoch[52](1400/2500): Loss: 0.0961
===> Epoch[52](1500/2500): Loss: 0.0958
===> Epoch[52](1600/2500): Loss: 0.0957
===> Epoch[52](1700/2500): Loss: 0.0958
===> Epoch[52](1800/2500): Loss: 0.0957
===> Epoch[52](1900/2500): Loss: 0.0972
===> Epoch[52](2000/2500): Loss: 0.1005
===> Epoch[52](2100/2500): Loss: 0.0962
===> Epoch[52](2200/2500): Loss: 0.0961
===> Epoch[52](2300/2500): Loss: 0.0963
===> Epoch[52](2400/2500): Loss: 0.0963
===> Epoch[52](2500/2500): Loss: 0.0965
===> Epoch 52 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:36:11]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.0962
===> Epoch[52](200/2500): Loss: 0.0960
===> Epoch[52](300/2500): Loss: 0.0955
===> Epoch[52](400/2500): Loss: 0.0967
===> Epoch[52](500/2500): Loss: 0.0961
===> Epoch[52](600/2500): Loss: 0.0962
===> Epoch[52](700/2500): Loss: 0.0966
===> Epoch[52](800/2500): Loss: 0.0962
===> Epoch[52](900/2500): Loss: 0.0960
===> Epoch[52](1000/2500): Loss: 0.0965
===> Epoch[52](1100/2500): Loss: 0.0964
===> Epoch[52](1200/2500): Loss: 0.0962
===> Epoch[52](1300/2500): Loss: 0.0959
===> Epoch[52](1400/2500): Loss: 0.0961
===> Epoch[52](1500/2500): Loss: 0.0958
===> Epoch[52](1600/2500): Loss: 0.0957
===> Epoch[52](1700/2500): Loss: 0.0958
===> Epoch[52](1800/2500): Loss: 0.0957
===> Epoch[52](1900/2500): Loss: 0.0972
===> Epoch[52](2000/2500): Loss: 0.1005
===> Epoch[52](2100/2500): Loss: 0.0962
===> Epoch[52](2200/2500): Loss: 0.0961
===> Epoch[52](2300/2500): Loss: 0.0963
===> Epoch[52](2400/2500): Loss: 0.0963
===> Epoch[52](2500/2500): Loss: 0.0965
===> Epoch 52 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:36:11]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.0962
===> Epoch[52](200/2500): Loss: 0.0960
===> Epoch[52](300/2500): Loss: 0.0955
===> Epoch[52](400/2500): Loss: 0.0967
===> Epoch[52](500/2500): Loss: 0.0961
===> Epoch[52](600/2500): Loss: 0.0962
===> Epoch[52](700/2500): Loss: 0.0966
===> Epoch[52](800/2500): Loss: 0.0962
===> Epoch[52](900/2500): Loss: 0.0960
===> Epoch[52](1000/2500): Loss: 0.0965
===> Epoch[52](1100/2500): Loss: 0.0964
===> Epoch[52](1200/2500): Loss: 0.0962
===> Epoch[52](1300/2500): Loss: 0.0959
===> Epoch[52](1400/2500): Loss: 0.0961
===> Epoch[52](1500/2500): Loss: 0.0958
===> Epoch[52](1600/2500): Loss: 0.0957
===> Epoch[52](1700/2500): Loss: 0.0958
===> Epoch[52](1800/2500): Loss: 0.0957
===> Epoch[52](1900/2500): Loss: 0.0972
===> Epoch[52](2000/2500): Loss: 0.1005
===> Epoch[52](2100/2500): Loss: 0.0962
===> Epoch[52](2200/2500): Loss: 0.0961
===> Epoch[52](2300/2500): Loss: 0.0963
===> Epoch[52](2400/2500): Loss: 0.0963
===> Epoch[52](2500/2500): Loss: 0.0965
===> Epoch 52 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:36:11]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.0962
===> Epoch[52](200/2500): Loss: 0.0960
===> Epoch[52](300/2500): Loss: 0.0955
===> Epoch[52](400/2500): Loss: 0.0967
===> Epoch[52](500/2500): Loss: 0.0961
===> Epoch[52](600/2500): Loss: 0.0962
===> Epoch[52](700/2500): Loss: 0.0966
===> Epoch[52](800/2500): Loss: 0.0962
===> Epoch[52](900/2500): Loss: 0.0960
===> Epoch[52](1000/2500): Loss: 0.0965
===> Epoch[52](1100/2500): Loss: 0.0964
===> Epoch[52](1200/2500): Loss: 0.0962
===> Epoch[52](1300/2500): Loss: 0.0959
===> Epoch[52](1400/2500): Loss: 0.0961
===> Epoch[52](1500/2500): Loss: 0.0958
===> Epoch[52](1600/2500): Loss: 0.0957
===> Epoch[52](1700/2500): Loss: 0.0958
===> Epoch[52](1800/2500): Loss: 0.0957
===> Epoch[52](1900/2500): Loss: 0.0972
===> Epoch[52](2000/2500): Loss: 0.1005
===> Epoch[52](2100/2500): Loss: 0.0962
===> Epoch[52](2200/2500): Loss: 0.0961
===> Epoch[52](2300/2500): Loss: 0.0963
===> Epoch[52](2400/2500): Loss: 0.0963
===> Epoch[52](2500/2500): Loss: 0.0965
===> Epoch 52 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:36:11]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.0962
===> Epoch[52](200/2500): Loss: 0.0960
===> Epoch[52](300/2500): Loss: 0.0955
===> Epoch[52](400/2500): Loss: 0.0967
===> Epoch[52](500/2500): Loss: 0.0961
===> Epoch[52](600/2500): Loss: 0.0962
===> Epoch[52](700/2500): Loss: 0.0966
===> Epoch[52](800/2500): Loss: 0.0962
===> Epoch[52](900/2500): Loss: 0.0960
===> Epoch[52](1000/2500): Loss: 0.0965
===> Epoch[52](1100/2500): Loss: 0.0964
===> Epoch[52](1200/2500): Loss: 0.0962
===> Epoch[52](1300/2500): Loss: 0.0959
===> Epoch[52](1400/2500): Loss: 0.0961
===> Epoch[52](1500/2500): Loss: 0.0958
===> Epoch[52](1600/2500): Loss: 0.0957
===> Epoch[52](1700/2500): Loss: 0.0958
===> Epoch[52](1800/2500): Loss: 0.0957
===> Epoch[52](1900/2500): Loss: 0.0972
===> Epoch[52](2000/2500): Loss: 0.1005
===> Epoch[52](2100/2500): Loss: 0.0962
===> Epoch[52](2200/2500): Loss: 0.0961
===> Epoch[52](2300/2500): Loss: 0.0963
===> Epoch[52](2400/2500): Loss: 0.0963
===> Epoch[52](2500/2500): Loss: 0.0965
===> Epoch 52 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:36:11]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.0962
===> Epoch[52](200/2500): Loss: 0.0960
===> Epoch[52](300/2500): Loss: 0.0955
===> Epoch[52](400/2500): Loss: 0.0967
===> Epoch[52](500/2500): Loss: 0.0961
===> Epoch[52](600/2500): Loss: 0.0962
===> Epoch[52](700/2500): Loss: 0.0966
===> Epoch[52](800/2500): Loss: 0.0962
===> Epoch[52](900/2500): Loss: 0.0960
===> Epoch[52](1000/2500): Loss: 0.0965
===> Epoch[52](1100/2500): Loss: 0.0964
===> Epoch[52](1200/2500): Loss: 0.0962
===> Epoch[52](1300/2500): Loss: 0.0959
===> Epoch[52](1400/2500): Loss: 0.0961
===> Epoch[52](1500/2500): Loss: 0.0958
===> Epoch[52](1600/2500): Loss: 0.0957
===> Epoch[52](1700/2500): Loss: 0.0958
===> Epoch[52](1800/2500): Loss: 0.0957
===> Epoch[52](1900/2500): Loss: 0.0972
===> Epoch[52](2000/2500): Loss: 0.1005
===> Epoch[52](2100/2500): Loss: 0.0962
===> Epoch[52](2200/2500): Loss: 0.0961
===> Epoch[52](2300/2500): Loss: 0.0963
===> Epoch[52](2400/2500): Loss: 0.0963
===> Epoch[52](2500/2500): Loss: 0.0965
===> Epoch 52 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:36:11]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.0962
===> Epoch[52](200/2500): Loss: 0.0960
===> Epoch[52](300/2500): Loss: 0.0955
===> Epoch[52](400/2500): Loss: 0.0967
===> Epoch[52](500/2500): Loss: 0.0961
===> Epoch[52](600/2500): Loss: 0.0962
===> Epoch[52](700/2500): Loss: 0.0966
===> Epoch[52](800/2500): Loss: 0.0962
===> Epoch[52](900/2500): Loss: 0.0960
===> Epoch[52](1000/2500): Loss: 0.0965
===> Epoch[52](1100/2500): Loss: 0.0964
===> Epoch[52](1200/2500): Loss: 0.0962
===> Epoch[52](1300/2500): Loss: 0.0959
===> Epoch[52](1400/2500): Loss: 0.0961
===> Epoch[52](1500/2500): Loss: 0.0958
===> Epoch[52](1600/2500): Loss: 0.0957
===> Epoch[52](1700/2500): Loss: 0.0958
===> Epoch[52](1800/2500): Loss: 0.0957
===> Epoch[52](1900/2500): Loss: 0.0972
===> Epoch[52](2000/2500): Loss: 0.1005
===> Epoch[52](2100/2500): Loss: 0.0962
===> Epoch[52](2200/2500): Loss: 0.0961
===> Epoch[52](2300/2500): Loss: 0.0963
===> Epoch[52](2400/2500): Loss: 0.0963
===> Epoch[52](2500/2500): Loss: 0.0965
===> Epoch 52 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:36:11]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.0962
===> Epoch[52](200/2500): Loss: 0.0960
===> Epoch[52](300/2500): Loss: 0.0955
===> Epoch[52](400/2500): Loss: 0.0967
===> Epoch[52](500/2500): Loss: 0.0961
===> Epoch[52](600/2500): Loss: 0.0962
===> Epoch[52](700/2500): Loss: 0.0966
===> Epoch[52](800/2500): Loss: 0.0962
===> Epoch[52](900/2500): Loss: 0.0960
===> Epoch[52](1000/2500): Loss: 0.0965
===> Epoch[52](1100/2500): Loss: 0.0964
===> Epoch[52](1200/2500): Loss: 0.0962
===> Epoch[52](1300/2500): Loss: 0.0959
===> Epoch[52](1400/2500): Loss: 0.0961
===> Epoch[52](1500/2500): Loss: 0.0958
===> Epoch[52](1600/2500): Loss: 0.0957
===> Epoch[52](1700/2500): Loss: 0.0958
===> Epoch[52](1800/2500): Loss: 0.0957
===> Epoch[52](1900/2500): Loss: 0.0972
===> Epoch[52](2000/2500): Loss: 0.1005
===> Epoch[52](2100/2500): Loss: 0.0962
===> Epoch[52](2200/2500): Loss: 0.0961
===> Epoch[52](2300/2500): Loss: 0.0963
===> Epoch[52](2400/2500): Loss: 0.0963
===> Epoch[52](2500/2500): Loss: 0.0965
===> Epoch 52 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:36:11]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.0962
===> Epoch[52](200/2500): Loss: 0.0960
===> Epoch[52](300/2500): Loss: 0.0955
===> Epoch[52](400/2500): Loss: 0.0967
===> Epoch[52](500/2500): Loss: 0.0961
===> Epoch[52](600/2500): Loss: 0.0962
===> Epoch[52](700/2500): Loss: 0.0966
===> Epoch[52](800/2500): Loss: 0.0962
===> Epoch[52](900/2500): Loss: 0.0960
===> Epoch[52](1000/2500): Loss: 0.0965
===> Epoch[52](1100/2500): Loss: 0.0964
===> Epoch[52](1200/2500): Loss: 0.0962
===> Epoch[52](1300/2500): Loss: 0.0959
===> Epoch[52](1400/2500): Loss: 0.0961
===> Epoch[52](1500/2500): Loss: 0.0958
===> Epoch[52](1600/2500): Loss: 0.0957
===> Epoch[52](1700/2500): Loss: 0.0958
===> Epoch[52](1800/2500): Loss: 0.0957
===> Epoch[52](1900/2500): Loss: 0.0972
===> Epoch[52](2000/2500): Loss: 0.1005
===> Epoch[52](2100/2500): Loss: 0.0962
===> Epoch[52](2200/2500): Loss: 0.0961
===> Epoch[52](2300/2500): Loss: 0.0963
===> Epoch[52](2400/2500): Loss: 0.0963
===> Epoch[52](2500/2500): Loss: 0.0965
===> Epoch 52 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:36:11]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.0962
===> Epoch[52](200/2500): Loss: 0.0960
===> Epoch[52](300/2500): Loss: 0.0955
===> Epoch[52](400/2500): Loss: 0.0967
===> Epoch[52](500/2500): Loss: 0.0961
===> Epoch[52](600/2500): Loss: 0.0962
===> Epoch[52](700/2500): Loss: 0.0966
===> Epoch[52](800/2500): Loss: 0.0962
===> Epoch[52](900/2500): Loss: 0.0960
===> Epoch[52](1000/2500): Loss: 0.0965
===> Epoch[52](1100/2500): Loss: 0.0964
===> Epoch[52](1200/2500): Loss: 0.0962
===> Epoch[52](1300/2500): Loss: 0.0959
===> Epoch[52](1400/2500): Loss: 0.0961
===> Epoch[52](1500/2500): Loss: 0.0958
===> Epoch[52](1600/2500): Loss: 0.0957
===> Epoch[52](1700/2500): Loss: 0.0958
===> Epoch[52](1800/2500): Loss: 0.0957
===> Epoch[52](1900/2500): Loss: 0.0972
===> Epoch[52](2000/2500): Loss: 0.1005
===> Epoch[52](2100/2500): Loss: 0.0962
===> Epoch[52](2200/2500): Loss: 0.0961
===> Epoch[52](2300/2500): Loss: 0.0963
===> Epoch[52](2400/2500): Loss: 0.0963
===> Epoch[52](2500/2500): Loss: 0.0965
===> Epoch 52 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:36:11]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.0962
===> Epoch[52](200/2500): Loss: 0.0960
===> Epoch[52](300/2500): Loss: 0.0955
===> Epoch[52](400/2500): Loss: 0.0967
===> Epoch[52](500/2500): Loss: 0.0961
===> Epoch[52](600/2500): Loss: 0.0962
===> Epoch[52](700/2500): Loss: 0.0966
===> Epoch[52](800/2500): Loss: 0.0962
===> Epoch[52](900/2500): Loss: 0.0960
===> Epoch[52](1000/2500): Loss: 0.0965
===> Epoch[52](1100/2500): Loss: 0.0964
===> Epoch[52](1200/2500): Loss: 0.0962
===> Epoch[52](1300/2500): Loss: 0.0959
===> Epoch[52](1400/2500): Loss: 0.0961
===> Epoch[52](1500/2500): Loss: 0.0958
===> Epoch[52](1600/2500): Loss: 0.0957
===> Epoch[52](1700/2500): Loss: 0.0958
===> Epoch[52](1800/2500): Loss: 0.0957
===> Epoch[52](1900/2500): Loss: 0.0972
===> Epoch[52](2000/2500): Loss: 0.1005
===> Epoch[52](2100/2500): Loss: 0.0962
===> Epoch[52](2200/2500): Loss: 0.0961
===> Epoch[52](2300/2500): Loss: 0.0963
===> Epoch[52](2400/2500): Loss: 0.0963
===> Epoch[52](2500/2500): Loss: 0.0965
===> Epoch 52 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:36:11]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.0962
===> Epoch[52](200/2500): Loss: 0.0960
===> Epoch[52](300/2500): Loss: 0.0955
===> Epoch[52](400/2500): Loss: 0.0967
===> Epoch[52](500/2500): Loss: 0.0961
===> Epoch[52](600/2500): Loss: 0.0962
===> Epoch[52](700/2500): Loss: 0.0966
===> Epoch[52](800/2500): Loss: 0.0962
===> Epoch[52](900/2500): Loss: 0.0960
===> Epoch[52](1000/2500): Loss: 0.0965
===> Epoch[52](1100/2500): Loss: 0.0964
===> Epoch[52](1200/2500): Loss: 0.0962
===> Epoch[52](1300/2500): Loss: 0.0959
===> Epoch[52](1400/2500): Loss: 0.0961
===> Epoch[52](1500/2500): Loss: 0.0958
===> Epoch[52](1600/2500): Loss: 0.0957
===> Epoch[52](1700/2500): Loss: 0.0958
===> Epoch[52](1800/2500): Loss: 0.0957
===> Epoch[52](1900/2500): Loss: 0.0972
===> Epoch[52](2000/2500): Loss: 0.1005
===> Epoch[52](2100/2500): Loss: 0.0962
===> Epoch[52](2200/2500): Loss: 0.0961
===> Epoch[52](2300/2500): Loss: 0.0963
===> Epoch[52](2400/2500): Loss: 0.0963
===> Epoch[52](2500/2500): Loss: 0.0965
===> Epoch 52 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:36:11]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.0962
===> Epoch[52](200/2500): Loss: 0.0960
===> Epoch[52](300/2500): Loss: 0.0955
===> Epoch[52](400/2500): Loss: 0.0967
===> Epoch[52](500/2500): Loss: 0.0961
===> Epoch[52](600/2500): Loss: 0.0962
===> Epoch[52](700/2500): Loss: 0.0966
===> Epoch[52](800/2500): Loss: 0.0962
===> Epoch[52](900/2500): Loss: 0.0960
===> Epoch[52](1000/2500): Loss: 0.0965
===> Epoch[52](1100/2500): Loss: 0.0964
===> Epoch[52](1200/2500): Loss: 0.0962
===> Epoch[52](1300/2500): Loss: 0.0959
===> Epoch[52](1400/2500): Loss: 0.0961
===> Epoch[52](1500/2500): Loss: 0.0958
===> Epoch[52](1600/2500): Loss: 0.0957
===> Epoch[52](1700/2500): Loss: 0.0958
===> Epoch[52](1800/2500): Loss: 0.0957
===> Epoch[52](1900/2500): Loss: 0.0972
===> Epoch[52](2000/2500): Loss: 0.1005
===> Epoch[52](2100/2500): Loss: 0.0962
===> Epoch[52](2200/2500): Loss: 0.0961
===> Epoch[52](2300/2500): Loss: 0.0963
===> Epoch[52](2400/2500): Loss: 0.0963
===> Epoch[52](2500/2500): Loss: 0.0965
===> Epoch 52 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:36:11]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.0962
===> Epoch[52](200/2500): Loss: 0.0960
===> Epoch[52](300/2500): Loss: 0.0955
===> Epoch[52](400/2500): Loss: 0.0967
===> Epoch[52](500/2500): Loss: 0.0961
===> Epoch[52](600/2500): Loss: 0.0962
===> Epoch[52](700/2500): Loss: 0.0966
===> Epoch[52](800/2500): Loss: 0.0962
===> Epoch[52](900/2500): Loss: 0.0960
===> Epoch[52](1000/2500): Loss: 0.0965
===> Epoch[52](1100/2500): Loss: 0.0964
===> Epoch[52](1200/2500): Loss: 0.0962
===> Epoch[52](1300/2500): Loss: 0.0959
===> Epoch[52](1400/2500): Loss: 0.0961
===> Epoch[52](1500/2500): Loss: 0.0958
===> Epoch[52](1600/2500): Loss: 0.0957
===> Epoch[52](1700/2500): Loss: 0.0958
===> Epoch[52](1800/2500): Loss: 0.0957
===> Epoch[52](1900/2500): Loss: 0.0972
===> Epoch[52](2000/2500): Loss: 0.1005
===> Epoch[52](2100/2500): Loss: 0.0962
===> Epoch[52](2200/2500): Loss: 0.0961
===> Epoch[52](2300/2500): Loss: 0.0963
===> Epoch[52](2400/2500): Loss: 0.0963
===> Epoch[52](2500/2500): Loss: 0.0965
===> Epoch 52 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:36:11]
===> Loading train datasets
===> Epoch[52](100/2500): Loss: 0.0962
===> Epoch[52](200/2500): Loss: 0.0960
===> Epoch[52](300/2500): Loss: 0.0955
===> Epoch[52](400/2500): Loss: 0.0967
===> Epoch[52](500/2500): Loss: 0.0961
===> Epoch[52](600/2500): Loss: 0.0962
===> Epoch[52](700/2500): Loss: 0.0966
===> Epoch[52](800/2500): Loss: 0.0962
===> Epoch[52](900/2500): Loss: 0.0960
===> Epoch[52](1000/2500): Loss: 0.0965
===> Epoch[52](1100/2500): Loss: 0.0964
===> Epoch[52](1200/2500): Loss: 0.0962
===> Epoch[52](1300/2500): Loss: 0.0959
===> Epoch[52](1400/2500): Loss: 0.0961
===> Epoch[52](1500/2500): Loss: 0.0958
===> Epoch[52](1600/2500): Loss: 0.0957
===> Epoch[52](1700/2500): Loss: 0.0958
===> Epoch[52](1800/2500): Loss: 0.0957
===> Epoch[52](1900/2500): Loss: 0.0972
===> Epoch[52](2000/2500): Loss: 0.1005
===> Epoch[52](2100/2500): Loss: 0.0962
===> Epoch[52](2200/2500): Loss: 0.0961
===> Epoch[52](2300/2500): Loss: 0.0963
===> Epoch[52](2400/2500): Loss: 0.0963
===> Epoch[52](2500/2500): Loss: 0.0965
===> Epoch 52 Complete: Avg. Loss: 0.0966
===> Timestamp: [2025-07-29 19:36:11]
===> Loading train datasets
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.0964
===> Epoch[53](200/2500): Loss: 0.0961
===> Epoch[53](300/2500): Loss: 0.0955
===> Epoch[53](400/2500): Loss: 0.0961
===> Epoch[53](500/2500): Loss: 0.0961
===> Epoch[53](600/2500): Loss: 0.0965
===> Epoch[53](700/2500): Loss: 0.0960
===> Epoch[53](800/2500): Loss: 0.0956
===> Epoch[53](900/2500): Loss: 0.0954
===> Epoch[53](1000/2500): Loss: 0.0961
===> Epoch[53](1100/2500): Loss: 0.0962
===> Epoch[53](1200/2500): Loss: 0.0964
===> Epoch[53](1300/2500): Loss: 0.0959
===> Epoch[53](1400/2500): Loss: 0.0964
===> Epoch[53](1500/2500): Loss: 0.0961
===> Epoch[53](1600/2500): Loss: 0.0956
===> Epoch[53](1700/2500): Loss: 0.0965
===> Epoch[53](1800/2500): Loss: 0.0958
===> Epoch[53](1900/2500): Loss: 0.0964
===> Epoch[53](2000/2500): Loss: 0.0956
===> Epoch[53](2100/2500): Loss: 0.0964
===> Epoch[53](2200/2500): Loss: 0.0955
===> Epoch[53](2300/2500): Loss: 0.0959
===> Epoch[53](2400/2500): Loss: 0.0963
===> Epoch[53](2500/2500): Loss: 0.0960
===> Epoch 53 Complete: Avg. Loss: 0.0961
===> Timestamp: [2025-07-29 19:41:14]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.0964
===> Epoch[53](200/2500): Loss: 0.0961
===> Epoch[53](300/2500): Loss: 0.0955
===> Epoch[53](400/2500): Loss: 0.0961
===> Epoch[53](500/2500): Loss: 0.0961
===> Epoch[53](600/2500): Loss: 0.0965
===> Epoch[53](700/2500): Loss: 0.0960
===> Epoch[53](800/2500): Loss: 0.0956
===> Epoch[53](900/2500): Loss: 0.0954
===> Epoch[53](1000/2500): Loss: 0.0961
===> Epoch[53](1100/2500): Loss: 0.0962
===> Epoch[53](1200/2500): Loss: 0.0964
===> Epoch[53](1300/2500): Loss: 0.0959
===> Epoch[53](1400/2500): Loss: 0.0964
===> Epoch[53](1500/2500): Loss: 0.0961
===> Epoch[53](1600/2500): Loss: 0.0956
===> Epoch[53](1700/2500): Loss: 0.0965
===> Epoch[53](1800/2500): Loss: 0.0958
===> Epoch[53](1900/2500): Loss: 0.0964
===> Epoch[53](2000/2500): Loss: 0.0956
===> Epoch[53](2100/2500): Loss: 0.0964
===> Epoch[53](2200/2500): Loss: 0.0955
===> Epoch[53](2300/2500): Loss: 0.0959
===> Epoch[53](2400/2500): Loss: 0.0963
===> Epoch[53](2500/2500): Loss: 0.0960
===> Epoch 53 Complete: Avg. Loss: 0.0961
===> Timestamp: [2025-07-29 19:41:14]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.0964
===> Epoch[53](200/2500): Loss: 0.0961
===> Epoch[53](300/2500): Loss: 0.0955
===> Epoch[53](400/2500): Loss: 0.0961
===> Epoch[53](500/2500): Loss: 0.0961
===> Epoch[53](600/2500): Loss: 0.0965
===> Epoch[53](700/2500): Loss: 0.0960
===> Epoch[53](800/2500): Loss: 0.0956
===> Epoch[53](900/2500): Loss: 0.0954
===> Epoch[53](1000/2500): Loss: 0.0961
===> Epoch[53](1100/2500): Loss: 0.0962
===> Epoch[53](1200/2500): Loss: 0.0964
===> Epoch[53](1300/2500): Loss: 0.0959
===> Epoch[53](1400/2500): Loss: 0.0964
===> Epoch[53](1500/2500): Loss: 0.0961
===> Epoch[53](1600/2500): Loss: 0.0956
===> Epoch[53](1700/2500): Loss: 0.0965
===> Epoch[53](1800/2500): Loss: 0.0958
===> Epoch[53](1900/2500): Loss: 0.0964
===> Epoch[53](2000/2500): Loss: 0.0956
===> Epoch[53](2100/2500): Loss: 0.0964
===> Epoch[53](2200/2500): Loss: 0.0955
===> Epoch[53](2300/2500): Loss: 0.0959
===> Epoch[53](2400/2500): Loss: 0.0963
===> Epoch[53](2500/2500): Loss: 0.0960
===> Epoch 53 Complete: Avg. Loss: 0.0961
===> Timestamp: [2025-07-29 19:41:14]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.0964
===> Epoch[53](200/2500): Loss: 0.0961
===> Epoch[53](300/2500): Loss: 0.0955
===> Epoch[53](400/2500): Loss: 0.0961
===> Epoch[53](500/2500): Loss: 0.0961
===> Epoch[53](600/2500): Loss: 0.0965
===> Epoch[53](700/2500): Loss: 0.0960
===> Epoch[53](800/2500): Loss: 0.0956
===> Epoch[53](900/2500): Loss: 0.0954
===> Epoch[53](1000/2500): Loss: 0.0961
===> Epoch[53](1100/2500): Loss: 0.0962
===> Epoch[53](1200/2500): Loss: 0.0964
===> Epoch[53](1300/2500): Loss: 0.0959
===> Epoch[53](1400/2500): Loss: 0.0964
===> Epoch[53](1500/2500): Loss: 0.0961
===> Epoch[53](1600/2500): Loss: 0.0956
===> Epoch[53](1700/2500): Loss: 0.0965
===> Epoch[53](1800/2500): Loss: 0.0958
===> Epoch[53](1900/2500): Loss: 0.0964
===> Epoch[53](2000/2500): Loss: 0.0956
===> Epoch[53](2100/2500): Loss: 0.0964
===> Epoch[53](2200/2500): Loss: 0.0955
===> Epoch[53](2300/2500): Loss: 0.0959
===> Epoch[53](2400/2500): Loss: 0.0963
===> Epoch[53](2500/2500): Loss: 0.0960
===> Epoch 53 Complete: Avg. Loss: 0.0961
===> Timestamp: [2025-07-29 19:41:14]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.0964
===> Epoch[53](200/2500): Loss: 0.0961
===> Epoch[53](300/2500): Loss: 0.0955
===> Epoch[53](400/2500): Loss: 0.0961
===> Epoch[53](500/2500): Loss: 0.0961
===> Epoch[53](600/2500): Loss: 0.0965
===> Epoch[53](700/2500): Loss: 0.0960
===> Epoch[53](800/2500): Loss: 0.0956
===> Epoch[53](900/2500): Loss: 0.0954
===> Epoch[53](1000/2500): Loss: 0.0961
===> Epoch[53](1100/2500): Loss: 0.0962
===> Epoch[53](1200/2500): Loss: 0.0964
===> Epoch[53](1300/2500): Loss: 0.0959
===> Epoch[53](1400/2500): Loss: 0.0964
===> Epoch[53](1500/2500): Loss: 0.0961
===> Epoch[53](1600/2500): Loss: 0.0956
===> Epoch[53](1700/2500): Loss: 0.0965
===> Epoch[53](1800/2500): Loss: 0.0958
===> Epoch[53](1900/2500): Loss: 0.0964
===> Epoch[53](2000/2500): Loss: 0.0956
===> Epoch[53](2100/2500): Loss: 0.0964
===> Epoch[53](2200/2500): Loss: 0.0955
===> Epoch[53](2300/2500): Loss: 0.0959
===> Epoch[53](2400/2500): Loss: 0.0963
===> Epoch[53](2500/2500): Loss: 0.0960
===> Epoch 53 Complete: Avg. Loss: 0.0961
===> Timestamp: [2025-07-29 19:41:14]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.0964
===> Epoch[53](200/2500): Loss: 0.0961
===> Epoch[53](300/2500): Loss: 0.0955
===> Epoch[53](400/2500): Loss: 0.0961
===> Epoch[53](500/2500): Loss: 0.0961
===> Epoch[53](600/2500): Loss: 0.0965
===> Epoch[53](700/2500): Loss: 0.0960
===> Epoch[53](800/2500): Loss: 0.0956
===> Epoch[53](900/2500): Loss: 0.0954
===> Epoch[53](1000/2500): Loss: 0.0961
===> Epoch[53](1100/2500): Loss: 0.0962
===> Epoch[53](1200/2500): Loss: 0.0964
===> Epoch[53](1300/2500): Loss: 0.0959
===> Epoch[53](1400/2500): Loss: 0.0964
===> Epoch[53](1500/2500): Loss: 0.0961
===> Epoch[53](1600/2500): Loss: 0.0956
===> Epoch[53](1700/2500): Loss: 0.0965
===> Epoch[53](1800/2500): Loss: 0.0958
===> Epoch[53](1900/2500): Loss: 0.0964
===> Epoch[53](2000/2500): Loss: 0.0956
===> Epoch[53](2100/2500): Loss: 0.0964
===> Epoch[53](2200/2500): Loss: 0.0955
===> Epoch[53](2300/2500): Loss: 0.0959
===> Epoch[53](2400/2500): Loss: 0.0963
===> Epoch[53](2500/2500): Loss: 0.0960
===> Epoch 53 Complete: Avg. Loss: 0.0961
===> Timestamp: [2025-07-29 19:41:14]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.0964
===> Epoch[53](200/2500): Loss: 0.0961
===> Epoch[53](300/2500): Loss: 0.0955
===> Epoch[53](400/2500): Loss: 0.0961
===> Epoch[53](500/2500): Loss: 0.0961
===> Epoch[53](600/2500): Loss: 0.0965
===> Epoch[53](700/2500): Loss: 0.0960
===> Epoch[53](800/2500): Loss: 0.0956
===> Epoch[53](900/2500): Loss: 0.0954
===> Epoch[53](1000/2500): Loss: 0.0961
===> Epoch[53](1100/2500): Loss: 0.0962
===> Epoch[53](1200/2500): Loss: 0.0964
===> Epoch[53](1300/2500): Loss: 0.0959
===> Epoch[53](1400/2500): Loss: 0.0964
===> Epoch[53](1500/2500): Loss: 0.0961
===> Epoch[53](1600/2500): Loss: 0.0956
===> Epoch[53](1700/2500): Loss: 0.0965
===> Epoch[53](1800/2500): Loss: 0.0958
===> Epoch[53](1900/2500): Loss: 0.0964
===> Epoch[53](2000/2500): Loss: 0.0956
===> Epoch[53](2100/2500): Loss: 0.0964
===> Epoch[53](2200/2500): Loss: 0.0955
===> Epoch[53](2300/2500): Loss: 0.0959
===> Epoch[53](2400/2500): Loss: 0.0963
===> Epoch[53](2500/2500): Loss: 0.0960
===> Epoch 53 Complete: Avg. Loss: 0.0961
===> Timestamp: [2025-07-29 19:41:14]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.0964
===> Epoch[53](200/2500): Loss: 0.0961
===> Epoch[53](300/2500): Loss: 0.0955
===> Epoch[53](400/2500): Loss: 0.0961
===> Epoch[53](500/2500): Loss: 0.0961
===> Epoch[53](600/2500): Loss: 0.0965
===> Epoch[53](700/2500): Loss: 0.0960
===> Epoch[53](800/2500): Loss: 0.0956
===> Epoch[53](900/2500): Loss: 0.0954
===> Epoch[53](1000/2500): Loss: 0.0961
===> Epoch[53](1100/2500): Loss: 0.0962
===> Epoch[53](1200/2500): Loss: 0.0964
===> Epoch[53](1300/2500): Loss: 0.0959
===> Epoch[53](1400/2500): Loss: 0.0964
===> Epoch[53](1500/2500): Loss: 0.0961
===> Epoch[53](1600/2500): Loss: 0.0956
===> Epoch[53](1700/2500): Loss: 0.0965
===> Epoch[53](1800/2500): Loss: 0.0958
===> Epoch[53](1900/2500): Loss: 0.0964
===> Epoch[53](2000/2500): Loss: 0.0956
===> Epoch[53](2100/2500): Loss: 0.0964
===> Epoch[53](2200/2500): Loss: 0.0955
===> Epoch[53](2300/2500): Loss: 0.0959
===> Epoch[53](2400/2500): Loss: 0.0963
===> Epoch[53](2500/2500): Loss: 0.0960
===> Epoch 53 Complete: Avg. Loss: 0.0961
===> Timestamp: [2025-07-29 19:41:14]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.0964
===> Epoch[53](200/2500): Loss: 0.0961
===> Epoch[53](300/2500): Loss: 0.0955
===> Epoch[53](400/2500): Loss: 0.0961
===> Epoch[53](500/2500): Loss: 0.0961
===> Epoch[53](600/2500): Loss: 0.0965
===> Epoch[53](700/2500): Loss: 0.0960
===> Epoch[53](800/2500): Loss: 0.0956
===> Epoch[53](900/2500): Loss: 0.0954
===> Epoch[53](1000/2500): Loss: 0.0961
===> Epoch[53](1100/2500): Loss: 0.0962
===> Epoch[53](1200/2500): Loss: 0.0964
===> Epoch[53](1300/2500): Loss: 0.0959
===> Epoch[53](1400/2500): Loss: 0.0964
===> Epoch[53](1500/2500): Loss: 0.0961
===> Epoch[53](1600/2500): Loss: 0.0956
===> Epoch[53](1700/2500): Loss: 0.0965
===> Epoch[53](1800/2500): Loss: 0.0958
===> Epoch[53](1900/2500): Loss: 0.0964
===> Epoch[53](2000/2500): Loss: 0.0956
===> Epoch[53](2100/2500): Loss: 0.0964
===> Epoch[53](2200/2500): Loss: 0.0955
===> Epoch[53](2300/2500): Loss: 0.0959
===> Epoch[53](2400/2500): Loss: 0.0963
===> Epoch[53](2500/2500): Loss: 0.0960
===> Epoch 53 Complete: Avg. Loss: 0.0961
===> Timestamp: [2025-07-29 19:41:14]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.0964
===> Epoch[53](200/2500): Loss: 0.0961
===> Epoch[53](300/2500): Loss: 0.0955
===> Epoch[53](400/2500): Loss: 0.0961
===> Epoch[53](500/2500): Loss: 0.0961
===> Epoch[53](600/2500): Loss: 0.0965
===> Epoch[53](700/2500): Loss: 0.0960
===> Epoch[53](800/2500): Loss: 0.0956
===> Epoch[53](900/2500): Loss: 0.0954
===> Epoch[53](1000/2500): Loss: 0.0961
===> Epoch[53](1100/2500): Loss: 0.0962
===> Epoch[53](1200/2500): Loss: 0.0964
===> Epoch[53](1300/2500): Loss: 0.0959
===> Epoch[53](1400/2500): Loss: 0.0964
===> Epoch[53](1500/2500): Loss: 0.0961
===> Epoch[53](1600/2500): Loss: 0.0956
===> Epoch[53](1700/2500): Loss: 0.0965
===> Epoch[53](1800/2500): Loss: 0.0958
===> Epoch[53](1900/2500): Loss: 0.0964
===> Epoch[53](2000/2500): Loss: 0.0956
===> Epoch[53](2100/2500): Loss: 0.0964
===> Epoch[53](2200/2500): Loss: 0.0955
===> Epoch[53](2300/2500): Loss: 0.0959
===> Epoch[53](2400/2500): Loss: 0.0963
===> Epoch[53](2500/2500): Loss: 0.0960
===> Epoch 53 Complete: Avg. Loss: 0.0961
===> Timestamp: [2025-07-29 19:41:14]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.0964
===> Epoch[53](200/2500): Loss: 0.0961
===> Epoch[53](300/2500): Loss: 0.0955
===> Epoch[53](400/2500): Loss: 0.0961
===> Epoch[53](500/2500): Loss: 0.0961
===> Epoch[53](600/2500): Loss: 0.0965
===> Epoch[53](700/2500): Loss: 0.0960
===> Epoch[53](800/2500): Loss: 0.0956
===> Epoch[53](900/2500): Loss: 0.0954
===> Epoch[53](1000/2500): Loss: 0.0961
===> Epoch[53](1100/2500): Loss: 0.0962
===> Epoch[53](1200/2500): Loss: 0.0964
===> Epoch[53](1300/2500): Loss: 0.0959
===> Epoch[53](1400/2500): Loss: 0.0964
===> Epoch[53](1500/2500): Loss: 0.0961
===> Epoch[53](1600/2500): Loss: 0.0956
===> Epoch[53](1700/2500): Loss: 0.0965
===> Epoch[53](1800/2500): Loss: 0.0958
===> Epoch[53](1900/2500): Loss: 0.0964
===> Epoch[53](2000/2500): Loss: 0.0956
===> Epoch[53](2100/2500): Loss: 0.0964
===> Epoch[53](2200/2500): Loss: 0.0955
===> Epoch[53](2300/2500): Loss: 0.0959
===> Epoch[53](2400/2500): Loss: 0.0963
===> Epoch[53](2500/2500): Loss: 0.0960
===> Epoch 53 Complete: Avg. Loss: 0.0961
===> Timestamp: [2025-07-29 19:41:14]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.0964
===> Epoch[53](200/2500): Loss: 0.0961
===> Epoch[53](300/2500): Loss: 0.0955
===> Epoch[53](400/2500): Loss: 0.0961
===> Epoch[53](500/2500): Loss: 0.0961
===> Epoch[53](600/2500): Loss: 0.0965
===> Epoch[53](700/2500): Loss: 0.0960
===> Epoch[53](800/2500): Loss: 0.0956
===> Epoch[53](900/2500): Loss: 0.0954
===> Epoch[53](1000/2500): Loss: 0.0961
===> Epoch[53](1100/2500): Loss: 0.0962
===> Epoch[53](1200/2500): Loss: 0.0964
===> Epoch[53](1300/2500): Loss: 0.0959
===> Epoch[53](1400/2500): Loss: 0.0964
===> Epoch[53](1500/2500): Loss: 0.0961
===> Epoch[53](1600/2500): Loss: 0.0956
===> Epoch[53](1700/2500): Loss: 0.0965
===> Epoch[53](1800/2500): Loss: 0.0958
===> Epoch[53](1900/2500): Loss: 0.0964
===> Epoch[53](2000/2500): Loss: 0.0956
===> Epoch[53](2100/2500): Loss: 0.0964
===> Epoch[53](2200/2500): Loss: 0.0955
===> Epoch[53](2300/2500): Loss: 0.0959
===> Epoch[53](2400/2500): Loss: 0.0963
===> Epoch[53](2500/2500): Loss: 0.0960
===> Epoch 53 Complete: Avg. Loss: 0.0961
===> Timestamp: [2025-07-29 19:41:14]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.0964
===> Epoch[53](200/2500): Loss: 0.0961
===> Epoch[53](300/2500): Loss: 0.0955
===> Epoch[53](400/2500): Loss: 0.0961
===> Epoch[53](500/2500): Loss: 0.0961
===> Epoch[53](600/2500): Loss: 0.0965
===> Epoch[53](700/2500): Loss: 0.0960
===> Epoch[53](800/2500): Loss: 0.0956
===> Epoch[53](900/2500): Loss: 0.0954
===> Epoch[53](1000/2500): Loss: 0.0961
===> Epoch[53](1100/2500): Loss: 0.0962
===> Epoch[53](1200/2500): Loss: 0.0964
===> Epoch[53](1300/2500): Loss: 0.0959
===> Epoch[53](1400/2500): Loss: 0.0964
===> Epoch[53](1500/2500): Loss: 0.0961
===> Epoch[53](1600/2500): Loss: 0.0956
===> Epoch[53](1700/2500): Loss: 0.0965
===> Epoch[53](1800/2500): Loss: 0.0958
===> Epoch[53](1900/2500): Loss: 0.0964
===> Epoch[53](2000/2500): Loss: 0.0956
===> Epoch[53](2100/2500): Loss: 0.0964
===> Epoch[53](2200/2500): Loss: 0.0955
===> Epoch[53](2300/2500): Loss: 0.0959
===> Epoch[53](2400/2500): Loss: 0.0963
===> Epoch[53](2500/2500): Loss: 0.0960
===> Epoch 53 Complete: Avg. Loss: 0.0961
===> Timestamp: [2025-07-29 19:41:14]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.0964
===> Epoch[53](200/2500): Loss: 0.0961
===> Epoch[53](300/2500): Loss: 0.0955
===> Epoch[53](400/2500): Loss: 0.0961
===> Epoch[53](500/2500): Loss: 0.0961
===> Epoch[53](600/2500): Loss: 0.0965
===> Epoch[53](700/2500): Loss: 0.0960
===> Epoch[53](800/2500): Loss: 0.0956
===> Epoch[53](900/2500): Loss: 0.0954
===> Epoch[53](1000/2500): Loss: 0.0961
===> Epoch[53](1100/2500): Loss: 0.0962
===> Epoch[53](1200/2500): Loss: 0.0964
===> Epoch[53](1300/2500): Loss: 0.0959
===> Epoch[53](1400/2500): Loss: 0.0964
===> Epoch[53](1500/2500): Loss: 0.0961
===> Epoch[53](1600/2500): Loss: 0.0956
===> Epoch[53](1700/2500): Loss: 0.0965
===> Epoch[53](1800/2500): Loss: 0.0958
===> Epoch[53](1900/2500): Loss: 0.0964
===> Epoch[53](2000/2500): Loss: 0.0956
===> Epoch[53](2100/2500): Loss: 0.0964
===> Epoch[53](2200/2500): Loss: 0.0955
===> Epoch[53](2300/2500): Loss: 0.0959
===> Epoch[53](2400/2500): Loss: 0.0963
===> Epoch[53](2500/2500): Loss: 0.0960
===> Epoch 53 Complete: Avg. Loss: 0.0961
===> Timestamp: [2025-07-29 19:41:14]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.0964
===> Epoch[53](200/2500): Loss: 0.0961
===> Epoch[53](300/2500): Loss: 0.0955
===> Epoch[53](400/2500): Loss: 0.0961
===> Epoch[53](500/2500): Loss: 0.0961
===> Epoch[53](600/2500): Loss: 0.0965
===> Epoch[53](700/2500): Loss: 0.0960
===> Epoch[53](800/2500): Loss: 0.0956
===> Epoch[53](900/2500): Loss: 0.0954
===> Epoch[53](1000/2500): Loss: 0.0961
===> Epoch[53](1100/2500): Loss: 0.0962
===> Epoch[53](1200/2500): Loss: 0.0964
===> Epoch[53](1300/2500): Loss: 0.0959
===> Epoch[53](1400/2500): Loss: 0.0964
===> Epoch[53](1500/2500): Loss: 0.0961
===> Epoch[53](1600/2500): Loss: 0.0956
===> Epoch[53](1700/2500): Loss: 0.0965
===> Epoch[53](1800/2500): Loss: 0.0958
===> Epoch[53](1900/2500): Loss: 0.0964
===> Epoch[53](2000/2500): Loss: 0.0956
===> Epoch[53](2100/2500): Loss: 0.0964
===> Epoch[53](2200/2500): Loss: 0.0955
===> Epoch[53](2300/2500): Loss: 0.0959
===> Epoch[53](2400/2500): Loss: 0.0963
===> Epoch[53](2500/2500): Loss: 0.0960
===> Epoch 53 Complete: Avg. Loss: 0.0961
===> Timestamp: [2025-07-29 19:41:14]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.0964
===> Epoch[53](200/2500): Loss: 0.0961
===> Epoch[53](300/2500): Loss: 0.0955
===> Epoch[53](400/2500): Loss: 0.0961
===> Epoch[53](500/2500): Loss: 0.0961
===> Epoch[53](600/2500): Loss: 0.0965
===> Epoch[53](700/2500): Loss: 0.0960
===> Epoch[53](800/2500): Loss: 0.0956
===> Epoch[53](900/2500): Loss: 0.0954
===> Epoch[53](1000/2500): Loss: 0.0961
===> Epoch[53](1100/2500): Loss: 0.0962
===> Epoch[53](1200/2500): Loss: 0.0964
===> Epoch[53](1300/2500): Loss: 0.0959
===> Epoch[53](1400/2500): Loss: 0.0964
===> Epoch[53](1500/2500): Loss: 0.0961
===> Epoch[53](1600/2500): Loss: 0.0956
===> Epoch[53](1700/2500): Loss: 0.0965
===> Epoch[53](1800/2500): Loss: 0.0958
===> Epoch[53](1900/2500): Loss: 0.0964
===> Epoch[53](2000/2500): Loss: 0.0956
===> Epoch[53](2100/2500): Loss: 0.0964
===> Epoch[53](2200/2500): Loss: 0.0955
===> Epoch[53](2300/2500): Loss: 0.0959
===> Epoch[53](2400/2500): Loss: 0.0963
===> Epoch[53](2500/2500): Loss: 0.0960
===> Epoch 53 Complete: Avg. Loss: 0.0961
===> Timestamp: [2025-07-29 19:41:14]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.0964
===> Epoch[53](200/2500): Loss: 0.0961
===> Epoch[53](300/2500): Loss: 0.0955
===> Epoch[53](400/2500): Loss: 0.0961
===> Epoch[53](500/2500): Loss: 0.0961
===> Epoch[53](600/2500): Loss: 0.0965
===> Epoch[53](700/2500): Loss: 0.0960
===> Epoch[53](800/2500): Loss: 0.0956
===> Epoch[53](900/2500): Loss: 0.0954
===> Epoch[53](1000/2500): Loss: 0.0961
===> Epoch[53](1100/2500): Loss: 0.0962
===> Epoch[53](1200/2500): Loss: 0.0964
===> Epoch[53](1300/2500): Loss: 0.0959
===> Epoch[53](1400/2500): Loss: 0.0964
===> Epoch[53](1500/2500): Loss: 0.0961
===> Epoch[53](1600/2500): Loss: 0.0956
===> Epoch[53](1700/2500): Loss: 0.0965
===> Epoch[53](1800/2500): Loss: 0.0958
===> Epoch[53](1900/2500): Loss: 0.0964
===> Epoch[53](2000/2500): Loss: 0.0956
===> Epoch[53](2100/2500): Loss: 0.0964
===> Epoch[53](2200/2500): Loss: 0.0955
===> Epoch[53](2300/2500): Loss: 0.0959
===> Epoch[53](2400/2500): Loss: 0.0963
===> Epoch[53](2500/2500): Loss: 0.0960
===> Epoch 53 Complete: Avg. Loss: 0.0961
===> Timestamp: [2025-07-29 19:41:14]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.0964
===> Epoch[53](200/2500): Loss: 0.0961
===> Epoch[53](300/2500): Loss: 0.0955
===> Epoch[53](400/2500): Loss: 0.0961
===> Epoch[53](500/2500): Loss: 0.0961
===> Epoch[53](600/2500): Loss: 0.0965
===> Epoch[53](700/2500): Loss: 0.0960
===> Epoch[53](800/2500): Loss: 0.0956
===> Epoch[53](900/2500): Loss: 0.0954
===> Epoch[53](1000/2500): Loss: 0.0961
===> Epoch[53](1100/2500): Loss: 0.0962
===> Epoch[53](1200/2500): Loss: 0.0964
===> Epoch[53](1300/2500): Loss: 0.0959
===> Epoch[53](1400/2500): Loss: 0.0964
===> Epoch[53](1500/2500): Loss: 0.0961
===> Epoch[53](1600/2500): Loss: 0.0956
===> Epoch[53](1700/2500): Loss: 0.0965
===> Epoch[53](1800/2500): Loss: 0.0958
===> Epoch[53](1900/2500): Loss: 0.0964
===> Epoch[53](2000/2500): Loss: 0.0956
===> Epoch[53](2100/2500): Loss: 0.0964
===> Epoch[53](2200/2500): Loss: 0.0955
===> Epoch[53](2300/2500): Loss: 0.0959
===> Epoch[53](2400/2500): Loss: 0.0963
===> Epoch[53](2500/2500): Loss: 0.0960
===> Epoch 53 Complete: Avg. Loss: 0.0961
===> Timestamp: [2025-07-29 19:41:14]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.0964
===> Epoch[53](200/2500): Loss: 0.0961
===> Epoch[53](300/2500): Loss: 0.0955
===> Epoch[53](400/2500): Loss: 0.0961
===> Epoch[53](500/2500): Loss: 0.0961
===> Epoch[53](600/2500): Loss: 0.0965
===> Epoch[53](700/2500): Loss: 0.0960
===> Epoch[53](800/2500): Loss: 0.0956
===> Epoch[53](900/2500): Loss: 0.0954
===> Epoch[53](1000/2500): Loss: 0.0961
===> Epoch[53](1100/2500): Loss: 0.0962
===> Epoch[53](1200/2500): Loss: 0.0964
===> Epoch[53](1300/2500): Loss: 0.0959
===> Epoch[53](1400/2500): Loss: 0.0964
===> Epoch[53](1500/2500): Loss: 0.0961
===> Epoch[53](1600/2500): Loss: 0.0956
===> Epoch[53](1700/2500): Loss: 0.0965
===> Epoch[53](1800/2500): Loss: 0.0958
===> Epoch[53](1900/2500): Loss: 0.0964
===> Epoch[53](2000/2500): Loss: 0.0956
===> Epoch[53](2100/2500): Loss: 0.0964
===> Epoch[53](2200/2500): Loss: 0.0955
===> Epoch[53](2300/2500): Loss: 0.0959
===> Epoch[53](2400/2500): Loss: 0.0963
===> Epoch[53](2500/2500): Loss: 0.0960
===> Epoch 53 Complete: Avg. Loss: 0.0961
===> Timestamp: [2025-07-29 19:41:14]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.0964
===> Epoch[53](200/2500): Loss: 0.0961
===> Epoch[53](300/2500): Loss: 0.0955
===> Epoch[53](400/2500): Loss: 0.0961
===> Epoch[53](500/2500): Loss: 0.0961
===> Epoch[53](600/2500): Loss: 0.0965
===> Epoch[53](700/2500): Loss: 0.0960
===> Epoch[53](800/2500): Loss: 0.0956
===> Epoch[53](900/2500): Loss: 0.0954
===> Epoch[53](1000/2500): Loss: 0.0961
===> Epoch[53](1100/2500): Loss: 0.0962
===> Epoch[53](1200/2500): Loss: 0.0964
===> Epoch[53](1300/2500): Loss: 0.0959
===> Epoch[53](1400/2500): Loss: 0.0964
===> Epoch[53](1500/2500): Loss: 0.0961
===> Epoch[53](1600/2500): Loss: 0.0956
===> Epoch[53](1700/2500): Loss: 0.0965
===> Epoch[53](1800/2500): Loss: 0.0958
===> Epoch[53](1900/2500): Loss: 0.0964
===> Epoch[53](2000/2500): Loss: 0.0956
===> Epoch[53](2100/2500): Loss: 0.0964
===> Epoch[53](2200/2500): Loss: 0.0955
===> Epoch[53](2300/2500): Loss: 0.0959
===> Epoch[53](2400/2500): Loss: 0.0963
===> Epoch[53](2500/2500): Loss: 0.0960
===> Epoch 53 Complete: Avg. Loss: 0.0961
===> Timestamp: [2025-07-29 19:41:14]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.0964
===> Epoch[53](200/2500): Loss: 0.0961
===> Epoch[53](300/2500): Loss: 0.0955
===> Epoch[53](400/2500): Loss: 0.0961
===> Epoch[53](500/2500): Loss: 0.0961
===> Epoch[53](600/2500): Loss: 0.0965
===> Epoch[53](700/2500): Loss: 0.0960
===> Epoch[53](800/2500): Loss: 0.0956
===> Epoch[53](900/2500): Loss: 0.0954
===> Epoch[53](1000/2500): Loss: 0.0961
===> Epoch[53](1100/2500): Loss: 0.0962
===> Epoch[53](1200/2500): Loss: 0.0964
===> Epoch[53](1300/2500): Loss: 0.0959
===> Epoch[53](1400/2500): Loss: 0.0964
===> Epoch[53](1500/2500): Loss: 0.0961
===> Epoch[53](1600/2500): Loss: 0.0956
===> Epoch[53](1700/2500): Loss: 0.0965
===> Epoch[53](1800/2500): Loss: 0.0958
===> Epoch[53](1900/2500): Loss: 0.0964
===> Epoch[53](2000/2500): Loss: 0.0956
===> Epoch[53](2100/2500): Loss: 0.0964
===> Epoch[53](2200/2500): Loss: 0.0955
===> Epoch[53](2300/2500): Loss: 0.0959
===> Epoch[53](2400/2500): Loss: 0.0963
===> Epoch[53](2500/2500): Loss: 0.0960
===> Epoch 53 Complete: Avg. Loss: 0.0961
===> Timestamp: [2025-07-29 19:41:14]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.0964
===> Epoch[53](200/2500): Loss: 0.0961
===> Epoch[53](300/2500): Loss: 0.0955
===> Epoch[53](400/2500): Loss: 0.0961
===> Epoch[53](500/2500): Loss: 0.0961
===> Epoch[53](600/2500): Loss: 0.0965
===> Epoch[53](700/2500): Loss: 0.0960
===> Epoch[53](800/2500): Loss: 0.0956
===> Epoch[53](900/2500): Loss: 0.0954
===> Epoch[53](1000/2500): Loss: 0.0961
===> Epoch[53](1100/2500): Loss: 0.0962
===> Epoch[53](1200/2500): Loss: 0.0964
===> Epoch[53](1300/2500): Loss: 0.0959
===> Epoch[53](1400/2500): Loss: 0.0964
===> Epoch[53](1500/2500): Loss: 0.0961
===> Epoch[53](1600/2500): Loss: 0.0956
===> Epoch[53](1700/2500): Loss: 0.0965
===> Epoch[53](1800/2500): Loss: 0.0958
===> Epoch[53](1900/2500): Loss: 0.0964
===> Epoch[53](2000/2500): Loss: 0.0956
===> Epoch[53](2100/2500): Loss: 0.0964
===> Epoch[53](2200/2500): Loss: 0.0955
===> Epoch[53](2300/2500): Loss: 0.0959
===> Epoch[53](2400/2500): Loss: 0.0963
===> Epoch[53](2500/2500): Loss: 0.0960
===> Epoch 53 Complete: Avg. Loss: 0.0961
===> Timestamp: [2025-07-29 19:41:14]
===> Loading train datasets
===> Epoch[53](100/2500): Loss: 0.0964
===> Epoch[53](200/2500): Loss: 0.0961
===> Epoch[53](300/2500): Loss: 0.0955
===> Epoch[53](400/2500): Loss: 0.0961
===> Epoch[53](500/2500): Loss: 0.0961
===> Epoch[53](600/2500): Loss: 0.0965
===> Epoch[53](700/2500): Loss: 0.0960
===> Epoch[53](800/2500): Loss: 0.0956
===> Epoch[53](900/2500): Loss: 0.0954
===> Epoch[53](1000/2500): Loss: 0.0961
===> Epoch[53](1100/2500): Loss: 0.0962
===> Epoch[53](1200/2500): Loss: 0.0964
===> Epoch[53](1300/2500): Loss: 0.0959
===> Epoch[53](1400/2500): Loss: 0.0964
===> Epoch[53](1500/2500): Loss: 0.0961
===> Epoch[53](1600/2500): Loss: 0.0956
===> Epoch[53](1700/2500): Loss: 0.0965
===> Epoch[53](1800/2500): Loss: 0.0958
===> Epoch[53](1900/2500): Loss: 0.0964
===> Epoch[53](2000/2500): Loss: 0.0956
===> Epoch[53](2100/2500): Loss: 0.0964
===> Epoch[53](2200/2500): Loss: 0.0955
===> Epoch[53](2300/2500): Loss: 0.0959
===> Epoch[53](2400/2500): Loss: 0.0963
===> Epoch[53](2500/2500): Loss: 0.0960
===> Epoch 53 Complete: Avg. Loss: 0.0961
===> Timestamp: [2025-07-29 19:41:14]
===> Loading train datasets
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.0961
===> Epoch[54](200/2500): Loss: 0.1035
===> Epoch[54](300/2500): Loss: 0.0975
===> Epoch[54](400/2500): Loss: 0.0963
===> Epoch[54](500/2500): Loss: 0.0959
===> Epoch[54](600/2500): Loss: 0.0964
===> Epoch[54](700/2500): Loss: 0.0960
===> Epoch[54](800/2500): Loss: 0.0962
===> Epoch[54](900/2500): Loss: 0.0956
===> Epoch[54](1000/2500): Loss: 0.0959
===> Epoch[54](1100/2500): Loss: 0.0963
===> Epoch[54](1200/2500): Loss: 0.0956
===> Epoch[54](1300/2500): Loss: 0.0967
===> Epoch[54](1400/2500): Loss: 0.0954
===> Epoch[54](1500/2500): Loss: 0.0961
===> Epoch[54](1600/2500): Loss: 0.0956
===> Epoch[54](1700/2500): Loss: 0.0959
===> Epoch[54](1800/2500): Loss: 0.0969
===> Epoch[54](1900/2500): Loss: 0.0961
===> Epoch[54](2000/2500): Loss: 0.0962
===> Epoch[54](2100/2500): Loss: 0.0956
===> Epoch[54](2200/2500): Loss: 0.0955
===> Epoch[54](2300/2500): Loss: 0.0958
===> Epoch[54](2400/2500): Loss: 0.0961
===> Epoch[54](2500/2500): Loss: 0.0956
===> Epoch 54 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:46:16]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.0961
===> Epoch[54](200/2500): Loss: 0.1035
===> Epoch[54](300/2500): Loss: 0.0975
===> Epoch[54](400/2500): Loss: 0.0963
===> Epoch[54](500/2500): Loss: 0.0959
===> Epoch[54](600/2500): Loss: 0.0964
===> Epoch[54](700/2500): Loss: 0.0960
===> Epoch[54](800/2500): Loss: 0.0962
===> Epoch[54](900/2500): Loss: 0.0956
===> Epoch[54](1000/2500): Loss: 0.0959
===> Epoch[54](1100/2500): Loss: 0.0963
===> Epoch[54](1200/2500): Loss: 0.0956
===> Epoch[54](1300/2500): Loss: 0.0967
===> Epoch[54](1400/2500): Loss: 0.0954
===> Epoch[54](1500/2500): Loss: 0.0961
===> Epoch[54](1600/2500): Loss: 0.0956
===> Epoch[54](1700/2500): Loss: 0.0959
===> Epoch[54](1800/2500): Loss: 0.0969
===> Epoch[54](1900/2500): Loss: 0.0961
===> Epoch[54](2000/2500): Loss: 0.0962
===> Epoch[54](2100/2500): Loss: 0.0956
===> Epoch[54](2200/2500): Loss: 0.0955
===> Epoch[54](2300/2500): Loss: 0.0958
===> Epoch[54](2400/2500): Loss: 0.0961
===> Epoch[54](2500/2500): Loss: 0.0956
===> Epoch 54 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:46:16]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.0961
===> Epoch[54](200/2500): Loss: 0.1035
===> Epoch[54](300/2500): Loss: 0.0975
===> Epoch[54](400/2500): Loss: 0.0963
===> Epoch[54](500/2500): Loss: 0.0959
===> Epoch[54](600/2500): Loss: 0.0964
===> Epoch[54](700/2500): Loss: 0.0960
===> Epoch[54](800/2500): Loss: 0.0962
===> Epoch[54](900/2500): Loss: 0.0956
===> Epoch[54](1000/2500): Loss: 0.0959
===> Epoch[54](1100/2500): Loss: 0.0963
===> Epoch[54](1200/2500): Loss: 0.0956
===> Epoch[54](1300/2500): Loss: 0.0967
===> Epoch[54](1400/2500): Loss: 0.0954
===> Epoch[54](1500/2500): Loss: 0.0961
===> Epoch[54](1600/2500): Loss: 0.0956
===> Epoch[54](1700/2500): Loss: 0.0959
===> Epoch[54](1800/2500): Loss: 0.0969
===> Epoch[54](1900/2500): Loss: 0.0961
===> Epoch[54](2000/2500): Loss: 0.0962
===> Epoch[54](2100/2500): Loss: 0.0956
===> Epoch[54](2200/2500): Loss: 0.0955
===> Epoch[54](2300/2500): Loss: 0.0958
===> Epoch[54](2400/2500): Loss: 0.0961
===> Epoch[54](2500/2500): Loss: 0.0956
===> Epoch 54 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:46:16]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.0961
===> Epoch[54](200/2500): Loss: 0.1035
===> Epoch[54](300/2500): Loss: 0.0975
===> Epoch[54](400/2500): Loss: 0.0963
===> Epoch[54](500/2500): Loss: 0.0959
===> Epoch[54](600/2500): Loss: 0.0964
===> Epoch[54](700/2500): Loss: 0.0960
===> Epoch[54](800/2500): Loss: 0.0962
===> Epoch[54](900/2500): Loss: 0.0956
===> Epoch[54](1000/2500): Loss: 0.0959
===> Epoch[54](1100/2500): Loss: 0.0963
===> Epoch[54](1200/2500): Loss: 0.0956
===> Epoch[54](1300/2500): Loss: 0.0967
===> Epoch[54](1400/2500): Loss: 0.0954
===> Epoch[54](1500/2500): Loss: 0.0961
===> Epoch[54](1600/2500): Loss: 0.0956
===> Epoch[54](1700/2500): Loss: 0.0959
===> Epoch[54](1800/2500): Loss: 0.0969
===> Epoch[54](1900/2500): Loss: 0.0961
===> Epoch[54](2000/2500): Loss: 0.0962
===> Epoch[54](2100/2500): Loss: 0.0956
===> Epoch[54](2200/2500): Loss: 0.0955
===> Epoch[54](2300/2500): Loss: 0.0958
===> Epoch[54](2400/2500): Loss: 0.0961
===> Epoch[54](2500/2500): Loss: 0.0956
===> Epoch 54 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:46:16]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.0961
===> Epoch[54](200/2500): Loss: 0.1035
===> Epoch[54](300/2500): Loss: 0.0975
===> Epoch[54](400/2500): Loss: 0.0963
===> Epoch[54](500/2500): Loss: 0.0959
===> Epoch[54](600/2500): Loss: 0.0964
===> Epoch[54](700/2500): Loss: 0.0960
===> Epoch[54](800/2500): Loss: 0.0962
===> Epoch[54](900/2500): Loss: 0.0956
===> Epoch[54](1000/2500): Loss: 0.0959
===> Epoch[54](1100/2500): Loss: 0.0963
===> Epoch[54](1200/2500): Loss: 0.0956
===> Epoch[54](1300/2500): Loss: 0.0967
===> Epoch[54](1400/2500): Loss: 0.0954
===> Epoch[54](1500/2500): Loss: 0.0961
===> Epoch[54](1600/2500): Loss: 0.0956
===> Epoch[54](1700/2500): Loss: 0.0959
===> Epoch[54](1800/2500): Loss: 0.0969
===> Epoch[54](1900/2500): Loss: 0.0961
===> Epoch[54](2000/2500): Loss: 0.0962
===> Epoch[54](2100/2500): Loss: 0.0956
===> Epoch[54](2200/2500): Loss: 0.0955
===> Epoch[54](2300/2500): Loss: 0.0958
===> Epoch[54](2400/2500): Loss: 0.0961
===> Epoch[54](2500/2500): Loss: 0.0956
===> Epoch 54 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:46:16]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.0961
===> Epoch[54](200/2500): Loss: 0.1035
===> Epoch[54](300/2500): Loss: 0.0975
===> Epoch[54](400/2500): Loss: 0.0963
===> Epoch[54](500/2500): Loss: 0.0959
===> Epoch[54](600/2500): Loss: 0.0964
===> Epoch[54](700/2500): Loss: 0.0960
===> Epoch[54](800/2500): Loss: 0.0962
===> Epoch[54](900/2500): Loss: 0.0956
===> Epoch[54](1000/2500): Loss: 0.0959
===> Epoch[54](1100/2500): Loss: 0.0963
===> Epoch[54](1200/2500): Loss: 0.0956
===> Epoch[54](1300/2500): Loss: 0.0967
===> Epoch[54](1400/2500): Loss: 0.0954
===> Epoch[54](1500/2500): Loss: 0.0961
===> Epoch[54](1600/2500): Loss: 0.0956
===> Epoch[54](1700/2500): Loss: 0.0959
===> Epoch[54](1800/2500): Loss: 0.0969
===> Epoch[54](1900/2500): Loss: 0.0961
===> Epoch[54](2000/2500): Loss: 0.0962
===> Epoch[54](2100/2500): Loss: 0.0956
===> Epoch[54](2200/2500): Loss: 0.0955
===> Epoch[54](2300/2500): Loss: 0.0958
===> Epoch[54](2400/2500): Loss: 0.0961
===> Epoch[54](2500/2500): Loss: 0.0956
===> Epoch 54 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:46:16]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.0961
===> Epoch[54](200/2500): Loss: 0.1035
===> Epoch[54](300/2500): Loss: 0.0975
===> Epoch[54](400/2500): Loss: 0.0963
===> Epoch[54](500/2500): Loss: 0.0959
===> Epoch[54](600/2500): Loss: 0.0964
===> Epoch[54](700/2500): Loss: 0.0960
===> Epoch[54](800/2500): Loss: 0.0962
===> Epoch[54](900/2500): Loss: 0.0956
===> Epoch[54](1000/2500): Loss: 0.0959
===> Epoch[54](1100/2500): Loss: 0.0963
===> Epoch[54](1200/2500): Loss: 0.0956
===> Epoch[54](1300/2500): Loss: 0.0967
===> Epoch[54](1400/2500): Loss: 0.0954
===> Epoch[54](1500/2500): Loss: 0.0961
===> Epoch[54](1600/2500): Loss: 0.0956
===> Epoch[54](1700/2500): Loss: 0.0959
===> Epoch[54](1800/2500): Loss: 0.0969
===> Epoch[54](1900/2500): Loss: 0.0961
===> Epoch[54](2000/2500): Loss: 0.0962
===> Epoch[54](2100/2500): Loss: 0.0956
===> Epoch[54](2200/2500): Loss: 0.0955
===> Epoch[54](2300/2500): Loss: 0.0958
===> Epoch[54](2400/2500): Loss: 0.0961
===> Epoch[54](2500/2500): Loss: 0.0956
===> Epoch 54 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:46:16]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.0961
===> Epoch[54](200/2500): Loss: 0.1035
===> Epoch[54](300/2500): Loss: 0.0975
===> Epoch[54](400/2500): Loss: 0.0963
===> Epoch[54](500/2500): Loss: 0.0959
===> Epoch[54](600/2500): Loss: 0.0964
===> Epoch[54](700/2500): Loss: 0.0960
===> Epoch[54](800/2500): Loss: 0.0962
===> Epoch[54](900/2500): Loss: 0.0956
===> Epoch[54](1000/2500): Loss: 0.0959
===> Epoch[54](1100/2500): Loss: 0.0963
===> Epoch[54](1200/2500): Loss: 0.0956
===> Epoch[54](1300/2500): Loss: 0.0967
===> Epoch[54](1400/2500): Loss: 0.0954
===> Epoch[54](1500/2500): Loss: 0.0961
===> Epoch[54](1600/2500): Loss: 0.0956
===> Epoch[54](1700/2500): Loss: 0.0959
===> Epoch[54](1800/2500): Loss: 0.0969
===> Epoch[54](1900/2500): Loss: 0.0961
===> Epoch[54](2000/2500): Loss: 0.0962
===> Epoch[54](2100/2500): Loss: 0.0956
===> Epoch[54](2200/2500): Loss: 0.0955
===> Epoch[54](2300/2500): Loss: 0.0958
===> Epoch[54](2400/2500): Loss: 0.0961
===> Epoch[54](2500/2500): Loss: 0.0956
===> Epoch 54 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:46:16]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.0961
===> Epoch[54](200/2500): Loss: 0.1035
===> Epoch[54](300/2500): Loss: 0.0975
===> Epoch[54](400/2500): Loss: 0.0963
===> Epoch[54](500/2500): Loss: 0.0959
===> Epoch[54](600/2500): Loss: 0.0964
===> Epoch[54](700/2500): Loss: 0.0960
===> Epoch[54](800/2500): Loss: 0.0962
===> Epoch[54](900/2500): Loss: 0.0956
===> Epoch[54](1000/2500): Loss: 0.0959
===> Epoch[54](1100/2500): Loss: 0.0963
===> Epoch[54](1200/2500): Loss: 0.0956
===> Epoch[54](1300/2500): Loss: 0.0967
===> Epoch[54](1400/2500): Loss: 0.0954
===> Epoch[54](1500/2500): Loss: 0.0961
===> Epoch[54](1600/2500): Loss: 0.0956
===> Epoch[54](1700/2500): Loss: 0.0959
===> Epoch[54](1800/2500): Loss: 0.0969
===> Epoch[54](1900/2500): Loss: 0.0961
===> Epoch[54](2000/2500): Loss: 0.0962
===> Epoch[54](2100/2500): Loss: 0.0956
===> Epoch[54](2200/2500): Loss: 0.0955
===> Epoch[54](2300/2500): Loss: 0.0958
===> Epoch[54](2400/2500): Loss: 0.0961
===> Epoch[54](2500/2500): Loss: 0.0956
===> Epoch 54 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:46:16]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.0961
===> Epoch[54](200/2500): Loss: 0.1035
===> Epoch[54](300/2500): Loss: 0.0975
===> Epoch[54](400/2500): Loss: 0.0963
===> Epoch[54](500/2500): Loss: 0.0959
===> Epoch[54](600/2500): Loss: 0.0964
===> Epoch[54](700/2500): Loss: 0.0960
===> Epoch[54](800/2500): Loss: 0.0962
===> Epoch[54](900/2500): Loss: 0.0956
===> Epoch[54](1000/2500): Loss: 0.0959
===> Epoch[54](1100/2500): Loss: 0.0963
===> Epoch[54](1200/2500): Loss: 0.0956
===> Epoch[54](1300/2500): Loss: 0.0967
===> Epoch[54](1400/2500): Loss: 0.0954
===> Epoch[54](1500/2500): Loss: 0.0961
===> Epoch[54](1600/2500): Loss: 0.0956
===> Epoch[54](1700/2500): Loss: 0.0959
===> Epoch[54](1800/2500): Loss: 0.0969
===> Epoch[54](1900/2500): Loss: 0.0961
===> Epoch[54](2000/2500): Loss: 0.0962
===> Epoch[54](2100/2500): Loss: 0.0956
===> Epoch[54](2200/2500): Loss: 0.0955
===> Epoch[54](2300/2500): Loss: 0.0958
===> Epoch[54](2400/2500): Loss: 0.0961
===> Epoch[54](2500/2500): Loss: 0.0956
===> Epoch 54 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:46:16]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.0961
===> Epoch[54](200/2500): Loss: 0.1035
===> Epoch[54](300/2500): Loss: 0.0975
===> Epoch[54](400/2500): Loss: 0.0963
===> Epoch[54](500/2500): Loss: 0.0959
===> Epoch[54](600/2500): Loss: 0.0964
===> Epoch[54](700/2500): Loss: 0.0960
===> Epoch[54](800/2500): Loss: 0.0962
===> Epoch[54](900/2500): Loss: 0.0956
===> Epoch[54](1000/2500): Loss: 0.0959
===> Epoch[54](1100/2500): Loss: 0.0963
===> Epoch[54](1200/2500): Loss: 0.0956
===> Epoch[54](1300/2500): Loss: 0.0967
===> Epoch[54](1400/2500): Loss: 0.0954
===> Epoch[54](1500/2500): Loss: 0.0961
===> Epoch[54](1600/2500): Loss: 0.0956
===> Epoch[54](1700/2500): Loss: 0.0959
===> Epoch[54](1800/2500): Loss: 0.0969
===> Epoch[54](1900/2500): Loss: 0.0961
===> Epoch[54](2000/2500): Loss: 0.0962
===> Epoch[54](2100/2500): Loss: 0.0956
===> Epoch[54](2200/2500): Loss: 0.0955
===> Epoch[54](2300/2500): Loss: 0.0958
===> Epoch[54](2400/2500): Loss: 0.0961
===> Epoch[54](2500/2500): Loss: 0.0956
===> Epoch 54 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:46:16]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.0961
===> Epoch[54](200/2500): Loss: 0.1035
===> Epoch[54](300/2500): Loss: 0.0975
===> Epoch[54](400/2500): Loss: 0.0963
===> Epoch[54](500/2500): Loss: 0.0959
===> Epoch[54](600/2500): Loss: 0.0964
===> Epoch[54](700/2500): Loss: 0.0960
===> Epoch[54](800/2500): Loss: 0.0962
===> Epoch[54](900/2500): Loss: 0.0956
===> Epoch[54](1000/2500): Loss: 0.0959
===> Epoch[54](1100/2500): Loss: 0.0963
===> Epoch[54](1200/2500): Loss: 0.0956
===> Epoch[54](1300/2500): Loss: 0.0967
===> Epoch[54](1400/2500): Loss: 0.0954
===> Epoch[54](1500/2500): Loss: 0.0961
===> Epoch[54](1600/2500): Loss: 0.0956
===> Epoch[54](1700/2500): Loss: 0.0959
===> Epoch[54](1800/2500): Loss: 0.0969
===> Epoch[54](1900/2500): Loss: 0.0961
===> Epoch[54](2000/2500): Loss: 0.0962
===> Epoch[54](2100/2500): Loss: 0.0956
===> Epoch[54](2200/2500): Loss: 0.0955
===> Epoch[54](2300/2500): Loss: 0.0958
===> Epoch[54](2400/2500): Loss: 0.0961
===> Epoch[54](2500/2500): Loss: 0.0956
===> Epoch 54 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:46:16]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.0961
===> Epoch[54](200/2500): Loss: 0.1035
===> Epoch[54](300/2500): Loss: 0.0975
===> Epoch[54](400/2500): Loss: 0.0963
===> Epoch[54](500/2500): Loss: 0.0959
===> Epoch[54](600/2500): Loss: 0.0964
===> Epoch[54](700/2500): Loss: 0.0960
===> Epoch[54](800/2500): Loss: 0.0962
===> Epoch[54](900/2500): Loss: 0.0956
===> Epoch[54](1000/2500): Loss: 0.0959
===> Epoch[54](1100/2500): Loss: 0.0963
===> Epoch[54](1200/2500): Loss: 0.0956
===> Epoch[54](1300/2500): Loss: 0.0967
===> Epoch[54](1400/2500): Loss: 0.0954
===> Epoch[54](1500/2500): Loss: 0.0961
===> Epoch[54](1600/2500): Loss: 0.0956
===> Epoch[54](1700/2500): Loss: 0.0959
===> Epoch[54](1800/2500): Loss: 0.0969
===> Epoch[54](1900/2500): Loss: 0.0961
===> Epoch[54](2000/2500): Loss: 0.0962
===> Epoch[54](2100/2500): Loss: 0.0956
===> Epoch[54](2200/2500): Loss: 0.0955
===> Epoch[54](2300/2500): Loss: 0.0958
===> Epoch[54](2400/2500): Loss: 0.0961
===> Epoch[54](2500/2500): Loss: 0.0956
===> Epoch 54 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:46:16]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.0961
===> Epoch[54](200/2500): Loss: 0.1035
===> Epoch[54](300/2500): Loss: 0.0975
===> Epoch[54](400/2500): Loss: 0.0963
===> Epoch[54](500/2500): Loss: 0.0959
===> Epoch[54](600/2500): Loss: 0.0964
===> Epoch[54](700/2500): Loss: 0.0960
===> Epoch[54](800/2500): Loss: 0.0962
===> Epoch[54](900/2500): Loss: 0.0956
===> Epoch[54](1000/2500): Loss: 0.0959
===> Epoch[54](1100/2500): Loss: 0.0963
===> Epoch[54](1200/2500): Loss: 0.0956
===> Epoch[54](1300/2500): Loss: 0.0967
===> Epoch[54](1400/2500): Loss: 0.0954
===> Epoch[54](1500/2500): Loss: 0.0961
===> Epoch[54](1600/2500): Loss: 0.0956
===> Epoch[54](1700/2500): Loss: 0.0959
===> Epoch[54](1800/2500): Loss: 0.0969
===> Epoch[54](1900/2500): Loss: 0.0961
===> Epoch[54](2000/2500): Loss: 0.0962
===> Epoch[54](2100/2500): Loss: 0.0956
===> Epoch[54](2200/2500): Loss: 0.0955
===> Epoch[54](2300/2500): Loss: 0.0958
===> Epoch[54](2400/2500): Loss: 0.0961
===> Epoch[54](2500/2500): Loss: 0.0956
===> Epoch 54 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:46:16]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.0961
===> Epoch[54](200/2500): Loss: 0.1035
===> Epoch[54](300/2500): Loss: 0.0975
===> Epoch[54](400/2500): Loss: 0.0963
===> Epoch[54](500/2500): Loss: 0.0959
===> Epoch[54](600/2500): Loss: 0.0964
===> Epoch[54](700/2500): Loss: 0.0960
===> Epoch[54](800/2500): Loss: 0.0962
===> Epoch[54](900/2500): Loss: 0.0956
===> Epoch[54](1000/2500): Loss: 0.0959
===> Epoch[54](1100/2500): Loss: 0.0963
===> Epoch[54](1200/2500): Loss: 0.0956
===> Epoch[54](1300/2500): Loss: 0.0967
===> Epoch[54](1400/2500): Loss: 0.0954
===> Epoch[54](1500/2500): Loss: 0.0961
===> Epoch[54](1600/2500): Loss: 0.0956
===> Epoch[54](1700/2500): Loss: 0.0959
===> Epoch[54](1800/2500): Loss: 0.0969
===> Epoch[54](1900/2500): Loss: 0.0961
===> Epoch[54](2000/2500): Loss: 0.0962
===> Epoch[54](2100/2500): Loss: 0.0956
===> Epoch[54](2200/2500): Loss: 0.0955
===> Epoch[54](2300/2500): Loss: 0.0958
===> Epoch[54](2400/2500): Loss: 0.0961
===> Epoch[54](2500/2500): Loss: 0.0956
===> Epoch 54 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:46:16]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.0961
===> Epoch[54](200/2500): Loss: 0.1035
===> Epoch[54](300/2500): Loss: 0.0975
===> Epoch[54](400/2500): Loss: 0.0963
===> Epoch[54](500/2500): Loss: 0.0959
===> Epoch[54](600/2500): Loss: 0.0964
===> Epoch[54](700/2500): Loss: 0.0960
===> Epoch[54](800/2500): Loss: 0.0962
===> Epoch[54](900/2500): Loss: 0.0956
===> Epoch[54](1000/2500): Loss: 0.0959
===> Epoch[54](1100/2500): Loss: 0.0963
===> Epoch[54](1200/2500): Loss: 0.0956
===> Epoch[54](1300/2500): Loss: 0.0967
===> Epoch[54](1400/2500): Loss: 0.0954
===> Epoch[54](1500/2500): Loss: 0.0961
===> Epoch[54](1600/2500): Loss: 0.0956
===> Epoch[54](1700/2500): Loss: 0.0959
===> Epoch[54](1800/2500): Loss: 0.0969
===> Epoch[54](1900/2500): Loss: 0.0961
===> Epoch[54](2000/2500): Loss: 0.0962
===> Epoch[54](2100/2500): Loss: 0.0956
===> Epoch[54](2200/2500): Loss: 0.0955
===> Epoch[54](2300/2500): Loss: 0.0958
===> Epoch[54](2400/2500): Loss: 0.0961
===> Epoch[54](2500/2500): Loss: 0.0956
===> Epoch 54 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:46:16]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.0961
===> Epoch[54](200/2500): Loss: 0.1035
===> Epoch[54](300/2500): Loss: 0.0975
===> Epoch[54](400/2500): Loss: 0.0963
===> Epoch[54](500/2500): Loss: 0.0959
===> Epoch[54](600/2500): Loss: 0.0964
===> Epoch[54](700/2500): Loss: 0.0960
===> Epoch[54](800/2500): Loss: 0.0962
===> Epoch[54](900/2500): Loss: 0.0956
===> Epoch[54](1000/2500): Loss: 0.0959
===> Epoch[54](1100/2500): Loss: 0.0963
===> Epoch[54](1200/2500): Loss: 0.0956
===> Epoch[54](1300/2500): Loss: 0.0967
===> Epoch[54](1400/2500): Loss: 0.0954
===> Epoch[54](1500/2500): Loss: 0.0961
===> Epoch[54](1600/2500): Loss: 0.0956
===> Epoch[54](1700/2500): Loss: 0.0959
===> Epoch[54](1800/2500): Loss: 0.0969
===> Epoch[54](1900/2500): Loss: 0.0961
===> Epoch[54](2000/2500): Loss: 0.0962
===> Epoch[54](2100/2500): Loss: 0.0956
===> Epoch[54](2200/2500): Loss: 0.0955
===> Epoch[54](2300/2500): Loss: 0.0958
===> Epoch[54](2400/2500): Loss: 0.0961
===> Epoch[54](2500/2500): Loss: 0.0956
===> Epoch 54 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:46:16]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.0961
===> Epoch[54](200/2500): Loss: 0.1035
===> Epoch[54](300/2500): Loss: 0.0975
===> Epoch[54](400/2500): Loss: 0.0963
===> Epoch[54](500/2500): Loss: 0.0959
===> Epoch[54](600/2500): Loss: 0.0964
===> Epoch[54](700/2500): Loss: 0.0960
===> Epoch[54](800/2500): Loss: 0.0962
===> Epoch[54](900/2500): Loss: 0.0956
===> Epoch[54](1000/2500): Loss: 0.0959
===> Epoch[54](1100/2500): Loss: 0.0963
===> Epoch[54](1200/2500): Loss: 0.0956
===> Epoch[54](1300/2500): Loss: 0.0967
===> Epoch[54](1400/2500): Loss: 0.0954
===> Epoch[54](1500/2500): Loss: 0.0961
===> Epoch[54](1600/2500): Loss: 0.0956
===> Epoch[54](1700/2500): Loss: 0.0959
===> Epoch[54](1800/2500): Loss: 0.0969
===> Epoch[54](1900/2500): Loss: 0.0961
===> Epoch[54](2000/2500): Loss: 0.0962
===> Epoch[54](2100/2500): Loss: 0.0956
===> Epoch[54](2200/2500): Loss: 0.0955
===> Epoch[54](2300/2500): Loss: 0.0958
===> Epoch[54](2400/2500): Loss: 0.0961
===> Epoch[54](2500/2500): Loss: 0.0956
===> Epoch 54 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:46:16]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.0961
===> Epoch[54](200/2500): Loss: 0.1035
===> Epoch[54](300/2500): Loss: 0.0975
===> Epoch[54](400/2500): Loss: 0.0963
===> Epoch[54](500/2500): Loss: 0.0959
===> Epoch[54](600/2500): Loss: 0.0964
===> Epoch[54](700/2500): Loss: 0.0960
===> Epoch[54](800/2500): Loss: 0.0962
===> Epoch[54](900/2500): Loss: 0.0956
===> Epoch[54](1000/2500): Loss: 0.0959
===> Epoch[54](1100/2500): Loss: 0.0963
===> Epoch[54](1200/2500): Loss: 0.0956
===> Epoch[54](1300/2500): Loss: 0.0967
===> Epoch[54](1400/2500): Loss: 0.0954
===> Epoch[54](1500/2500): Loss: 0.0961
===> Epoch[54](1600/2500): Loss: 0.0956
===> Epoch[54](1700/2500): Loss: 0.0959
===> Epoch[54](1800/2500): Loss: 0.0969
===> Epoch[54](1900/2500): Loss: 0.0961
===> Epoch[54](2000/2500): Loss: 0.0962
===> Epoch[54](2100/2500): Loss: 0.0956
===> Epoch[54](2200/2500): Loss: 0.0955
===> Epoch[54](2300/2500): Loss: 0.0958
===> Epoch[54](2400/2500): Loss: 0.0961
===> Epoch[54](2500/2500): Loss: 0.0956
===> Epoch 54 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:46:16]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.0961
===> Epoch[54](200/2500): Loss: 0.1035
===> Epoch[54](300/2500): Loss: 0.0975
===> Epoch[54](400/2500): Loss: 0.0963
===> Epoch[54](500/2500): Loss: 0.0959
===> Epoch[54](600/2500): Loss: 0.0964
===> Epoch[54](700/2500): Loss: 0.0960
===> Epoch[54](800/2500): Loss: 0.0962
===> Epoch[54](900/2500): Loss: 0.0956
===> Epoch[54](1000/2500): Loss: 0.0959
===> Epoch[54](1100/2500): Loss: 0.0963
===> Epoch[54](1200/2500): Loss: 0.0956
===> Epoch[54](1300/2500): Loss: 0.0967
===> Epoch[54](1400/2500): Loss: 0.0954
===> Epoch[54](1500/2500): Loss: 0.0961
===> Epoch[54](1600/2500): Loss: 0.0956
===> Epoch[54](1700/2500): Loss: 0.0959
===> Epoch[54](1800/2500): Loss: 0.0969
===> Epoch[54](1900/2500): Loss: 0.0961
===> Epoch[54](2000/2500): Loss: 0.0962
===> Epoch[54](2100/2500): Loss: 0.0956
===> Epoch[54](2200/2500): Loss: 0.0955
===> Epoch[54](2300/2500): Loss: 0.0958
===> Epoch[54](2400/2500): Loss: 0.0961
===> Epoch[54](2500/2500): Loss: 0.0956
===> Epoch 54 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:46:16]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.0961
===> Epoch[54](200/2500): Loss: 0.1035
===> Epoch[54](300/2500): Loss: 0.0975
===> Epoch[54](400/2500): Loss: 0.0963
===> Epoch[54](500/2500): Loss: 0.0959
===> Epoch[54](600/2500): Loss: 0.0964
===> Epoch[54](700/2500): Loss: 0.0960
===> Epoch[54](800/2500): Loss: 0.0962
===> Epoch[54](900/2500): Loss: 0.0956
===> Epoch[54](1000/2500): Loss: 0.0959
===> Epoch[54](1100/2500): Loss: 0.0963
===> Epoch[54](1200/2500): Loss: 0.0956
===> Epoch[54](1300/2500): Loss: 0.0967
===> Epoch[54](1400/2500): Loss: 0.0954
===> Epoch[54](1500/2500): Loss: 0.0961
===> Epoch[54](1600/2500): Loss: 0.0956
===> Epoch[54](1700/2500): Loss: 0.0959
===> Epoch[54](1800/2500): Loss: 0.0969
===> Epoch[54](1900/2500): Loss: 0.0961
===> Epoch[54](2000/2500): Loss: 0.0962
===> Epoch[54](2100/2500): Loss: 0.0956
===> Epoch[54](2200/2500): Loss: 0.0955
===> Epoch[54](2300/2500): Loss: 0.0958
===> Epoch[54](2400/2500): Loss: 0.0961
===> Epoch[54](2500/2500): Loss: 0.0956
===> Epoch 54 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:46:16]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.0961
===> Epoch[54](200/2500): Loss: 0.1035
===> Epoch[54](300/2500): Loss: 0.0975
===> Epoch[54](400/2500): Loss: 0.0963
===> Epoch[54](500/2500): Loss: 0.0959
===> Epoch[54](600/2500): Loss: 0.0964
===> Epoch[54](700/2500): Loss: 0.0960
===> Epoch[54](800/2500): Loss: 0.0962
===> Epoch[54](900/2500): Loss: 0.0956
===> Epoch[54](1000/2500): Loss: 0.0959
===> Epoch[54](1100/2500): Loss: 0.0963
===> Epoch[54](1200/2500): Loss: 0.0956
===> Epoch[54](1300/2500): Loss: 0.0967
===> Epoch[54](1400/2500): Loss: 0.0954
===> Epoch[54](1500/2500): Loss: 0.0961
===> Epoch[54](1600/2500): Loss: 0.0956
===> Epoch[54](1700/2500): Loss: 0.0959
===> Epoch[54](1800/2500): Loss: 0.0969
===> Epoch[54](1900/2500): Loss: 0.0961
===> Epoch[54](2000/2500): Loss: 0.0962
===> Epoch[54](2100/2500): Loss: 0.0956
===> Epoch[54](2200/2500): Loss: 0.0955
===> Epoch[54](2300/2500): Loss: 0.0958
===> Epoch[54](2400/2500): Loss: 0.0961
===> Epoch[54](2500/2500): Loss: 0.0956
===> Epoch 54 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:46:16]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.0961
===> Epoch[54](200/2500): Loss: 0.1035
===> Epoch[54](300/2500): Loss: 0.0975
===> Epoch[54](400/2500): Loss: 0.0963
===> Epoch[54](500/2500): Loss: 0.0959
===> Epoch[54](600/2500): Loss: 0.0964
===> Epoch[54](700/2500): Loss: 0.0960
===> Epoch[54](800/2500): Loss: 0.0962
===> Epoch[54](900/2500): Loss: 0.0956
===> Epoch[54](1000/2500): Loss: 0.0959
===> Epoch[54](1100/2500): Loss: 0.0963
===> Epoch[54](1200/2500): Loss: 0.0956
===> Epoch[54](1300/2500): Loss: 0.0967
===> Epoch[54](1400/2500): Loss: 0.0954
===> Epoch[54](1500/2500): Loss: 0.0961
===> Epoch[54](1600/2500): Loss: 0.0956
===> Epoch[54](1700/2500): Loss: 0.0959
===> Epoch[54](1800/2500): Loss: 0.0969
===> Epoch[54](1900/2500): Loss: 0.0961
===> Epoch[54](2000/2500): Loss: 0.0962
===> Epoch[54](2100/2500): Loss: 0.0956
===> Epoch[54](2200/2500): Loss: 0.0955
===> Epoch[54](2300/2500): Loss: 0.0958
===> Epoch[54](2400/2500): Loss: 0.0961
===> Epoch[54](2500/2500): Loss: 0.0956
===> Epoch 54 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:46:16]
===> Loading train datasets
===> Epoch[54](100/2500): Loss: 0.0961
===> Epoch[54](200/2500): Loss: 0.1035
===> Epoch[54](300/2500): Loss: 0.0975
===> Epoch[54](400/2500): Loss: 0.0963
===> Epoch[54](500/2500): Loss: 0.0959
===> Epoch[54](600/2500): Loss: 0.0964
===> Epoch[54](700/2500): Loss: 0.0960
===> Epoch[54](800/2500): Loss: 0.0962
===> Epoch[54](900/2500): Loss: 0.0956
===> Epoch[54](1000/2500): Loss: 0.0959
===> Epoch[54](1100/2500): Loss: 0.0963
===> Epoch[54](1200/2500): Loss: 0.0956
===> Epoch[54](1300/2500): Loss: 0.0967
===> Epoch[54](1400/2500): Loss: 0.0954
===> Epoch[54](1500/2500): Loss: 0.0961
===> Epoch[54](1600/2500): Loss: 0.0956
===> Epoch[54](1700/2500): Loss: 0.0959
===> Epoch[54](1800/2500): Loss: 0.0969
===> Epoch[54](1900/2500): Loss: 0.0961
===> Epoch[54](2000/2500): Loss: 0.0962
===> Epoch[54](2100/2500): Loss: 0.0956
===> Epoch[54](2200/2500): Loss: 0.0955
===> Epoch[54](2300/2500): Loss: 0.0958
===> Epoch[54](2400/2500): Loss: 0.0961
===> Epoch[54](2500/2500): Loss: 0.0956
===> Epoch 54 Complete: Avg. Loss: 0.0965
===> Timestamp: [2025-07-29 19:46:16]
===> Loading train datasets
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.0962
===> Epoch[55](200/2500): Loss: 0.0962
===> Epoch[55](300/2500): Loss: 0.0964
===> Epoch[55](400/2500): Loss: 0.0965
===> Epoch[55](500/2500): Loss: 0.0966
===> Epoch[55](600/2500): Loss: 0.0958
===> Epoch[55](700/2500): Loss: 0.0959
===> Epoch[55](800/2500): Loss: 0.1066
===> Epoch[55](900/2500): Loss: 0.0978
===> Epoch[55](1000/2500): Loss: 0.0958
===> Epoch[55](1100/2500): Loss: 0.0961
===> Epoch[55](1200/2500): Loss: 0.0964
===> Epoch[55](1300/2500): Loss: 0.0967
===> Epoch[55](1400/2500): Loss: 0.0953
===> Epoch[55](1500/2500): Loss: 0.0961
===> Epoch[55](1600/2500): Loss: 0.0962
===> Epoch[55](1700/2500): Loss: 0.0961
===> Epoch[55](1800/2500): Loss: 0.0959
===> Epoch[55](1900/2500): Loss: 0.0961
===> Epoch[55](2000/2500): Loss: 0.0960
===> Epoch[55](2100/2500): Loss: 0.0965
===> Epoch[55](2200/2500): Loss: 0.0965
===> Epoch[55](2300/2500): Loss: 0.0961
===> Epoch[55](2400/2500): Loss: 0.0959
===> Epoch[55](2500/2500): Loss: 0.0965
===> Epoch 55 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:51:19]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.0962
===> Epoch[55](200/2500): Loss: 0.0962
===> Epoch[55](300/2500): Loss: 0.0964
===> Epoch[55](400/2500): Loss: 0.0965
===> Epoch[55](500/2500): Loss: 0.0966
===> Epoch[55](600/2500): Loss: 0.0958
===> Epoch[55](700/2500): Loss: 0.0959
===> Epoch[55](800/2500): Loss: 0.1066
===> Epoch[55](900/2500): Loss: 0.0978
===> Epoch[55](1000/2500): Loss: 0.0958
===> Epoch[55](1100/2500): Loss: 0.0961
===> Epoch[55](1200/2500): Loss: 0.0964
===> Epoch[55](1300/2500): Loss: 0.0967
===> Epoch[55](1400/2500): Loss: 0.0953
===> Epoch[55](1500/2500): Loss: 0.0961
===> Epoch[55](1600/2500): Loss: 0.0962
===> Epoch[55](1700/2500): Loss: 0.0961
===> Epoch[55](1800/2500): Loss: 0.0959
===> Epoch[55](1900/2500): Loss: 0.0961
===> Epoch[55](2000/2500): Loss: 0.0960
===> Epoch[55](2100/2500): Loss: 0.0965
===> Epoch[55](2200/2500): Loss: 0.0965
===> Epoch[55](2300/2500): Loss: 0.0961
===> Epoch[55](2400/2500): Loss: 0.0959
===> Epoch[55](2500/2500): Loss: 0.0965
===> Epoch 55 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:51:19]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.0962
===> Epoch[55](200/2500): Loss: 0.0962
===> Epoch[55](300/2500): Loss: 0.0964
===> Epoch[55](400/2500): Loss: 0.0965
===> Epoch[55](500/2500): Loss: 0.0966
===> Epoch[55](600/2500): Loss: 0.0958
===> Epoch[55](700/2500): Loss: 0.0959
===> Epoch[55](800/2500): Loss: 0.1066
===> Epoch[55](900/2500): Loss: 0.0978
===> Epoch[55](1000/2500): Loss: 0.0958
===> Epoch[55](1100/2500): Loss: 0.0961
===> Epoch[55](1200/2500): Loss: 0.0964
===> Epoch[55](1300/2500): Loss: 0.0967
===> Epoch[55](1400/2500): Loss: 0.0953
===> Epoch[55](1500/2500): Loss: 0.0961
===> Epoch[55](1600/2500): Loss: 0.0962
===> Epoch[55](1700/2500): Loss: 0.0961
===> Epoch[55](1800/2500): Loss: 0.0959
===> Epoch[55](1900/2500): Loss: 0.0961
===> Epoch[55](2000/2500): Loss: 0.0960
===> Epoch[55](2100/2500): Loss: 0.0965
===> Epoch[55](2200/2500): Loss: 0.0965
===> Epoch[55](2300/2500): Loss: 0.0961
===> Epoch[55](2400/2500): Loss: 0.0959
===> Epoch[55](2500/2500): Loss: 0.0965
===> Epoch 55 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:51:19]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.0962
===> Epoch[55](200/2500): Loss: 0.0962
===> Epoch[55](300/2500): Loss: 0.0964
===> Epoch[55](400/2500): Loss: 0.0965
===> Epoch[55](500/2500): Loss: 0.0966
===> Epoch[55](600/2500): Loss: 0.0958
===> Epoch[55](700/2500): Loss: 0.0959
===> Epoch[55](800/2500): Loss: 0.1066
===> Epoch[55](900/2500): Loss: 0.0978
===> Epoch[55](1000/2500): Loss: 0.0958
===> Epoch[55](1100/2500): Loss: 0.0961
===> Epoch[55](1200/2500): Loss: 0.0964
===> Epoch[55](1300/2500): Loss: 0.0967
===> Epoch[55](1400/2500): Loss: 0.0953
===> Epoch[55](1500/2500): Loss: 0.0961
===> Epoch[55](1600/2500): Loss: 0.0962
===> Epoch[55](1700/2500): Loss: 0.0961
===> Epoch[55](1800/2500): Loss: 0.0959
===> Epoch[55](1900/2500): Loss: 0.0961
===> Epoch[55](2000/2500): Loss: 0.0960
===> Epoch[55](2100/2500): Loss: 0.0965
===> Epoch[55](2200/2500): Loss: 0.0965
===> Epoch[55](2300/2500): Loss: 0.0961
===> Epoch[55](2400/2500): Loss: 0.0959
===> Epoch[55](2500/2500): Loss: 0.0965
===> Epoch 55 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:51:19]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.0962
===> Epoch[55](200/2500): Loss: 0.0962
===> Epoch[55](300/2500): Loss: 0.0964
===> Epoch[55](400/2500): Loss: 0.0965
===> Epoch[55](500/2500): Loss: 0.0966
===> Epoch[55](600/2500): Loss: 0.0958
===> Epoch[55](700/2500): Loss: 0.0959
===> Epoch[55](800/2500): Loss: 0.1066
===> Epoch[55](900/2500): Loss: 0.0978
===> Epoch[55](1000/2500): Loss: 0.0958
===> Epoch[55](1100/2500): Loss: 0.0961
===> Epoch[55](1200/2500): Loss: 0.0964
===> Epoch[55](1300/2500): Loss: 0.0967
===> Epoch[55](1400/2500): Loss: 0.0953
===> Epoch[55](1500/2500): Loss: 0.0961
===> Epoch[55](1600/2500): Loss: 0.0962
===> Epoch[55](1700/2500): Loss: 0.0961
===> Epoch[55](1800/2500): Loss: 0.0959
===> Epoch[55](1900/2500): Loss: 0.0961
===> Epoch[55](2000/2500): Loss: 0.0960
===> Epoch[55](2100/2500): Loss: 0.0965
===> Epoch[55](2200/2500): Loss: 0.0965
===> Epoch[55](2300/2500): Loss: 0.0961
===> Epoch[55](2400/2500): Loss: 0.0959
===> Epoch[55](2500/2500): Loss: 0.0965
===> Epoch 55 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:51:19]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.0962
===> Epoch[55](200/2500): Loss: 0.0962
===> Epoch[55](300/2500): Loss: 0.0964
===> Epoch[55](400/2500): Loss: 0.0965
===> Epoch[55](500/2500): Loss: 0.0966
===> Epoch[55](600/2500): Loss: 0.0958
===> Epoch[55](700/2500): Loss: 0.0959
===> Epoch[55](800/2500): Loss: 0.1066
===> Epoch[55](900/2500): Loss: 0.0978
===> Epoch[55](1000/2500): Loss: 0.0958
===> Epoch[55](1100/2500): Loss: 0.0961
===> Epoch[55](1200/2500): Loss: 0.0964
===> Epoch[55](1300/2500): Loss: 0.0967
===> Epoch[55](1400/2500): Loss: 0.0953
===> Epoch[55](1500/2500): Loss: 0.0961
===> Epoch[55](1600/2500): Loss: 0.0962
===> Epoch[55](1700/2500): Loss: 0.0961
===> Epoch[55](1800/2500): Loss: 0.0959
===> Epoch[55](1900/2500): Loss: 0.0961
===> Epoch[55](2000/2500): Loss: 0.0960
===> Epoch[55](2100/2500): Loss: 0.0965
===> Epoch[55](2200/2500): Loss: 0.0965
===> Epoch[55](2300/2500): Loss: 0.0961
===> Epoch[55](2400/2500): Loss: 0.0959
===> Epoch[55](2500/2500): Loss: 0.0965
===> Epoch 55 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:51:19]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.0962
===> Epoch[55](200/2500): Loss: 0.0962
===> Epoch[55](300/2500): Loss: 0.0964
===> Epoch[55](400/2500): Loss: 0.0965
===> Epoch[55](500/2500): Loss: 0.0966
===> Epoch[55](600/2500): Loss: 0.0958
===> Epoch[55](700/2500): Loss: 0.0959
===> Epoch[55](800/2500): Loss: 0.1066
===> Epoch[55](900/2500): Loss: 0.0978
===> Epoch[55](1000/2500): Loss: 0.0958
===> Epoch[55](1100/2500): Loss: 0.0961
===> Epoch[55](1200/2500): Loss: 0.0964
===> Epoch[55](1300/2500): Loss: 0.0967
===> Epoch[55](1400/2500): Loss: 0.0953
===> Epoch[55](1500/2500): Loss: 0.0961
===> Epoch[55](1600/2500): Loss: 0.0962
===> Epoch[55](1700/2500): Loss: 0.0961
===> Epoch[55](1800/2500): Loss: 0.0959
===> Epoch[55](1900/2500): Loss: 0.0961
===> Epoch[55](2000/2500): Loss: 0.0960
===> Epoch[55](2100/2500): Loss: 0.0965
===> Epoch[55](2200/2500): Loss: 0.0965
===> Epoch[55](2300/2500): Loss: 0.0961
===> Epoch[55](2400/2500): Loss: 0.0959
===> Epoch[55](2500/2500): Loss: 0.0965
===> Epoch 55 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:51:19]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.0962
===> Epoch[55](200/2500): Loss: 0.0962
===> Epoch[55](300/2500): Loss: 0.0964
===> Epoch[55](400/2500): Loss: 0.0965
===> Epoch[55](500/2500): Loss: 0.0966
===> Epoch[55](600/2500): Loss: 0.0958
===> Epoch[55](700/2500): Loss: 0.0959
===> Epoch[55](800/2500): Loss: 0.1066
===> Epoch[55](900/2500): Loss: 0.0978
===> Epoch[55](1000/2500): Loss: 0.0958
===> Epoch[55](1100/2500): Loss: 0.0961
===> Epoch[55](1200/2500): Loss: 0.0964
===> Epoch[55](1300/2500): Loss: 0.0967
===> Epoch[55](1400/2500): Loss: 0.0953
===> Epoch[55](1500/2500): Loss: 0.0961
===> Epoch[55](1600/2500): Loss: 0.0962
===> Epoch[55](1700/2500): Loss: 0.0961
===> Epoch[55](1800/2500): Loss: 0.0959
===> Epoch[55](1900/2500): Loss: 0.0961
===> Epoch[55](2000/2500): Loss: 0.0960
===> Epoch[55](2100/2500): Loss: 0.0965
===> Epoch[55](2200/2500): Loss: 0.0965
===> Epoch[55](2300/2500): Loss: 0.0961
===> Epoch[55](2400/2500): Loss: 0.0959
===> Epoch[55](2500/2500): Loss: 0.0965
===> Epoch 55 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:51:19]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.0962
===> Epoch[55](200/2500): Loss: 0.0962
===> Epoch[55](300/2500): Loss: 0.0964
===> Epoch[55](400/2500): Loss: 0.0965
===> Epoch[55](500/2500): Loss: 0.0966
===> Epoch[55](600/2500): Loss: 0.0958
===> Epoch[55](700/2500): Loss: 0.0959
===> Epoch[55](800/2500): Loss: 0.1066
===> Epoch[55](900/2500): Loss: 0.0978
===> Epoch[55](1000/2500): Loss: 0.0958
===> Epoch[55](1100/2500): Loss: 0.0961
===> Epoch[55](1200/2500): Loss: 0.0964
===> Epoch[55](1300/2500): Loss: 0.0967
===> Epoch[55](1400/2500): Loss: 0.0953
===> Epoch[55](1500/2500): Loss: 0.0961
===> Epoch[55](1600/2500): Loss: 0.0962
===> Epoch[55](1700/2500): Loss: 0.0961
===> Epoch[55](1800/2500): Loss: 0.0959
===> Epoch[55](1900/2500): Loss: 0.0961
===> Epoch[55](2000/2500): Loss: 0.0960
===> Epoch[55](2100/2500): Loss: 0.0965
===> Epoch[55](2200/2500): Loss: 0.0965
===> Epoch[55](2300/2500): Loss: 0.0961
===> Epoch[55](2400/2500): Loss: 0.0959
===> Epoch[55](2500/2500): Loss: 0.0965
===> Epoch 55 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:51:19]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.0962
===> Epoch[55](200/2500): Loss: 0.0962
===> Epoch[55](300/2500): Loss: 0.0964
===> Epoch[55](400/2500): Loss: 0.0965
===> Epoch[55](500/2500): Loss: 0.0966
===> Epoch[55](600/2500): Loss: 0.0958
===> Epoch[55](700/2500): Loss: 0.0959
===> Epoch[55](800/2500): Loss: 0.1066
===> Epoch[55](900/2500): Loss: 0.0978
===> Epoch[55](1000/2500): Loss: 0.0958
===> Epoch[55](1100/2500): Loss: 0.0961
===> Epoch[55](1200/2500): Loss: 0.0964
===> Epoch[55](1300/2500): Loss: 0.0967
===> Epoch[55](1400/2500): Loss: 0.0953
===> Epoch[55](1500/2500): Loss: 0.0961
===> Epoch[55](1600/2500): Loss: 0.0962
===> Epoch[55](1700/2500): Loss: 0.0961
===> Epoch[55](1800/2500): Loss: 0.0959
===> Epoch[55](1900/2500): Loss: 0.0961
===> Epoch[55](2000/2500): Loss: 0.0960
===> Epoch[55](2100/2500): Loss: 0.0965
===> Epoch[55](2200/2500): Loss: 0.0965
===> Epoch[55](2300/2500): Loss: 0.0961
===> Epoch[55](2400/2500): Loss: 0.0959
===> Epoch[55](2500/2500): Loss: 0.0965
===> Epoch 55 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:51:19]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.0962
===> Epoch[55](200/2500): Loss: 0.0962
===> Epoch[55](300/2500): Loss: 0.0964
===> Epoch[55](400/2500): Loss: 0.0965
===> Epoch[55](500/2500): Loss: 0.0966
===> Epoch[55](600/2500): Loss: 0.0958
===> Epoch[55](700/2500): Loss: 0.0959
===> Epoch[55](800/2500): Loss: 0.1066
===> Epoch[55](900/2500): Loss: 0.0978
===> Epoch[55](1000/2500): Loss: 0.0958
===> Epoch[55](1100/2500): Loss: 0.0961
===> Epoch[55](1200/2500): Loss: 0.0964
===> Epoch[55](1300/2500): Loss: 0.0967
===> Epoch[55](1400/2500): Loss: 0.0953
===> Epoch[55](1500/2500): Loss: 0.0961
===> Epoch[55](1600/2500): Loss: 0.0962
===> Epoch[55](1700/2500): Loss: 0.0961
===> Epoch[55](1800/2500): Loss: 0.0959
===> Epoch[55](1900/2500): Loss: 0.0961
===> Epoch[55](2000/2500): Loss: 0.0960
===> Epoch[55](2100/2500): Loss: 0.0965
===> Epoch[55](2200/2500): Loss: 0.0965
===> Epoch[55](2300/2500): Loss: 0.0961
===> Epoch[55](2400/2500): Loss: 0.0959
===> Epoch[55](2500/2500): Loss: 0.0965
===> Epoch 55 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:51:19]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.0962
===> Epoch[55](200/2500): Loss: 0.0962
===> Epoch[55](300/2500): Loss: 0.0964
===> Epoch[55](400/2500): Loss: 0.0965
===> Epoch[55](500/2500): Loss: 0.0966
===> Epoch[55](600/2500): Loss: 0.0958
===> Epoch[55](700/2500): Loss: 0.0959
===> Epoch[55](800/2500): Loss: 0.1066
===> Epoch[55](900/2500): Loss: 0.0978
===> Epoch[55](1000/2500): Loss: 0.0958
===> Epoch[55](1100/2500): Loss: 0.0961
===> Epoch[55](1200/2500): Loss: 0.0964
===> Epoch[55](1300/2500): Loss: 0.0967
===> Epoch[55](1400/2500): Loss: 0.0953
===> Epoch[55](1500/2500): Loss: 0.0961
===> Epoch[55](1600/2500): Loss: 0.0962
===> Epoch[55](1700/2500): Loss: 0.0961
===> Epoch[55](1800/2500): Loss: 0.0959
===> Epoch[55](1900/2500): Loss: 0.0961
===> Epoch[55](2000/2500): Loss: 0.0960
===> Epoch[55](2100/2500): Loss: 0.0965
===> Epoch[55](2200/2500): Loss: 0.0965
===> Epoch[55](2300/2500): Loss: 0.0961
===> Epoch[55](2400/2500): Loss: 0.0959
===> Epoch[55](2500/2500): Loss: 0.0965
===> Epoch 55 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:51:19]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.0962
===> Epoch[55](200/2500): Loss: 0.0962
===> Epoch[55](300/2500): Loss: 0.0964
===> Epoch[55](400/2500): Loss: 0.0965
===> Epoch[55](500/2500): Loss: 0.0966
===> Epoch[55](600/2500): Loss: 0.0958
===> Epoch[55](700/2500): Loss: 0.0959
===> Epoch[55](800/2500): Loss: 0.1066
===> Epoch[55](900/2500): Loss: 0.0978
===> Epoch[55](1000/2500): Loss: 0.0958
===> Epoch[55](1100/2500): Loss: 0.0961
===> Epoch[55](1200/2500): Loss: 0.0964
===> Epoch[55](1300/2500): Loss: 0.0967
===> Epoch[55](1400/2500): Loss: 0.0953
===> Epoch[55](1500/2500): Loss: 0.0961
===> Epoch[55](1600/2500): Loss: 0.0962
===> Epoch[55](1700/2500): Loss: 0.0961
===> Epoch[55](1800/2500): Loss: 0.0959
===> Epoch[55](1900/2500): Loss: 0.0961
===> Epoch[55](2000/2500): Loss: 0.0960
===> Epoch[55](2100/2500): Loss: 0.0965
===> Epoch[55](2200/2500): Loss: 0.0965
===> Epoch[55](2300/2500): Loss: 0.0961
===> Epoch[55](2400/2500): Loss: 0.0959
===> Epoch[55](2500/2500): Loss: 0.0965
===> Epoch 55 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:51:19]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.0962
===> Epoch[55](200/2500): Loss: 0.0962
===> Epoch[55](300/2500): Loss: 0.0964
===> Epoch[55](400/2500): Loss: 0.0965
===> Epoch[55](500/2500): Loss: 0.0966
===> Epoch[55](600/2500): Loss: 0.0958
===> Epoch[55](700/2500): Loss: 0.0959
===> Epoch[55](800/2500): Loss: 0.1066
===> Epoch[55](900/2500): Loss: 0.0978
===> Epoch[55](1000/2500): Loss: 0.0958
===> Epoch[55](1100/2500): Loss: 0.0961
===> Epoch[55](1200/2500): Loss: 0.0964
===> Epoch[55](1300/2500): Loss: 0.0967
===> Epoch[55](1400/2500): Loss: 0.0953
===> Epoch[55](1500/2500): Loss: 0.0961
===> Epoch[55](1600/2500): Loss: 0.0962
===> Epoch[55](1700/2500): Loss: 0.0961
===> Epoch[55](1800/2500): Loss: 0.0959
===> Epoch[55](1900/2500): Loss: 0.0961
===> Epoch[55](2000/2500): Loss: 0.0960
===> Epoch[55](2100/2500): Loss: 0.0965
===> Epoch[55](2200/2500): Loss: 0.0965
===> Epoch[55](2300/2500): Loss: 0.0961
===> Epoch[55](2400/2500): Loss: 0.0959
===> Epoch[55](2500/2500): Loss: 0.0965
===> Epoch 55 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:51:19]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.0962
===> Epoch[55](200/2500): Loss: 0.0962
===> Epoch[55](300/2500): Loss: 0.0964
===> Epoch[55](400/2500): Loss: 0.0965
===> Epoch[55](500/2500): Loss: 0.0966
===> Epoch[55](600/2500): Loss: 0.0958
===> Epoch[55](700/2500): Loss: 0.0959
===> Epoch[55](800/2500): Loss: 0.1066
===> Epoch[55](900/2500): Loss: 0.0978
===> Epoch[55](1000/2500): Loss: 0.0958
===> Epoch[55](1100/2500): Loss: 0.0961
===> Epoch[55](1200/2500): Loss: 0.0964
===> Epoch[55](1300/2500): Loss: 0.0967
===> Epoch[55](1400/2500): Loss: 0.0953
===> Epoch[55](1500/2500): Loss: 0.0961
===> Epoch[55](1600/2500): Loss: 0.0962
===> Epoch[55](1700/2500): Loss: 0.0961
===> Epoch[55](1800/2500): Loss: 0.0959
===> Epoch[55](1900/2500): Loss: 0.0961
===> Epoch[55](2000/2500): Loss: 0.0960
===> Epoch[55](2100/2500): Loss: 0.0965
===> Epoch[55](2200/2500): Loss: 0.0965
===> Epoch[55](2300/2500): Loss: 0.0961
===> Epoch[55](2400/2500): Loss: 0.0959
===> Epoch[55](2500/2500): Loss: 0.0965
===> Epoch 55 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:51:19]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.0962
===> Epoch[55](200/2500): Loss: 0.0962
===> Epoch[55](300/2500): Loss: 0.0964
===> Epoch[55](400/2500): Loss: 0.0965
===> Epoch[55](500/2500): Loss: 0.0966
===> Epoch[55](600/2500): Loss: 0.0958
===> Epoch[55](700/2500): Loss: 0.0959
===> Epoch[55](800/2500): Loss: 0.1066
===> Epoch[55](900/2500): Loss: 0.0978
===> Epoch[55](1000/2500): Loss: 0.0958
===> Epoch[55](1100/2500): Loss: 0.0961
===> Epoch[55](1200/2500): Loss: 0.0964
===> Epoch[55](1300/2500): Loss: 0.0967
===> Epoch[55](1400/2500): Loss: 0.0953
===> Epoch[55](1500/2500): Loss: 0.0961
===> Epoch[55](1600/2500): Loss: 0.0962
===> Epoch[55](1700/2500): Loss: 0.0961
===> Epoch[55](1800/2500): Loss: 0.0959
===> Epoch[55](1900/2500): Loss: 0.0961
===> Epoch[55](2000/2500): Loss: 0.0960
===> Epoch[55](2100/2500): Loss: 0.0965
===> Epoch[55](2200/2500): Loss: 0.0965
===> Epoch[55](2300/2500): Loss: 0.0961
===> Epoch[55](2400/2500): Loss: 0.0959
===> Epoch[55](2500/2500): Loss: 0.0965
===> Epoch 55 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:51:19]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.0962
===> Epoch[55](200/2500): Loss: 0.0962
===> Epoch[55](300/2500): Loss: 0.0964
===> Epoch[55](400/2500): Loss: 0.0965
===> Epoch[55](500/2500): Loss: 0.0966
===> Epoch[55](600/2500): Loss: 0.0958
===> Epoch[55](700/2500): Loss: 0.0959
===> Epoch[55](800/2500): Loss: 0.1066
===> Epoch[55](900/2500): Loss: 0.0978
===> Epoch[55](1000/2500): Loss: 0.0958
===> Epoch[55](1100/2500): Loss: 0.0961
===> Epoch[55](1200/2500): Loss: 0.0964
===> Epoch[55](1300/2500): Loss: 0.0967
===> Epoch[55](1400/2500): Loss: 0.0953
===> Epoch[55](1500/2500): Loss: 0.0961
===> Epoch[55](1600/2500): Loss: 0.0962
===> Epoch[55](1700/2500): Loss: 0.0961
===> Epoch[55](1800/2500): Loss: 0.0959
===> Epoch[55](1900/2500): Loss: 0.0961
===> Epoch[55](2000/2500): Loss: 0.0960
===> Epoch[55](2100/2500): Loss: 0.0965
===> Epoch[55](2200/2500): Loss: 0.0965
===> Epoch[55](2300/2500): Loss: 0.0961
===> Epoch[55](2400/2500): Loss: 0.0959
===> Epoch[55](2500/2500): Loss: 0.0965
===> Epoch 55 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:51:19]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.0962
===> Epoch[55](200/2500): Loss: 0.0962
===> Epoch[55](300/2500): Loss: 0.0964
===> Epoch[55](400/2500): Loss: 0.0965
===> Epoch[55](500/2500): Loss: 0.0966
===> Epoch[55](600/2500): Loss: 0.0958
===> Epoch[55](700/2500): Loss: 0.0959
===> Epoch[55](800/2500): Loss: 0.1066
===> Epoch[55](900/2500): Loss: 0.0978
===> Epoch[55](1000/2500): Loss: 0.0958
===> Epoch[55](1100/2500): Loss: 0.0961
===> Epoch[55](1200/2500): Loss: 0.0964
===> Epoch[55](1300/2500): Loss: 0.0967
===> Epoch[55](1400/2500): Loss: 0.0953
===> Epoch[55](1500/2500): Loss: 0.0961
===> Epoch[55](1600/2500): Loss: 0.0962
===> Epoch[55](1700/2500): Loss: 0.0961
===> Epoch[55](1800/2500): Loss: 0.0959
===> Epoch[55](1900/2500): Loss: 0.0961
===> Epoch[55](2000/2500): Loss: 0.0960
===> Epoch[55](2100/2500): Loss: 0.0965
===> Epoch[55](2200/2500): Loss: 0.0965
===> Epoch[55](2300/2500): Loss: 0.0961
===> Epoch[55](2400/2500): Loss: 0.0959
===> Epoch[55](2500/2500): Loss: 0.0965
===> Epoch 55 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:51:19]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.0962
===> Epoch[55](200/2500): Loss: 0.0962
===> Epoch[55](300/2500): Loss: 0.0964
===> Epoch[55](400/2500): Loss: 0.0965
===> Epoch[55](500/2500): Loss: 0.0966
===> Epoch[55](600/2500): Loss: 0.0958
===> Epoch[55](700/2500): Loss: 0.0959
===> Epoch[55](800/2500): Loss: 0.1066
===> Epoch[55](900/2500): Loss: 0.0978
===> Epoch[55](1000/2500): Loss: 0.0958
===> Epoch[55](1100/2500): Loss: 0.0961
===> Epoch[55](1200/2500): Loss: 0.0964
===> Epoch[55](1300/2500): Loss: 0.0967
===> Epoch[55](1400/2500): Loss: 0.0953
===> Epoch[55](1500/2500): Loss: 0.0961
===> Epoch[55](1600/2500): Loss: 0.0962
===> Epoch[55](1700/2500): Loss: 0.0961
===> Epoch[55](1800/2500): Loss: 0.0959
===> Epoch[55](1900/2500): Loss: 0.0961
===> Epoch[55](2000/2500): Loss: 0.0960
===> Epoch[55](2100/2500): Loss: 0.0965
===> Epoch[55](2200/2500): Loss: 0.0965
===> Epoch[55](2300/2500): Loss: 0.0961
===> Epoch[55](2400/2500): Loss: 0.0959
===> Epoch[55](2500/2500): Loss: 0.0965
===> Epoch 55 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:51:19]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.0962
===> Epoch[55](200/2500): Loss: 0.0962
===> Epoch[55](300/2500): Loss: 0.0964
===> Epoch[55](400/2500): Loss: 0.0965
===> Epoch[55](500/2500): Loss: 0.0966
===> Epoch[55](600/2500): Loss: 0.0958
===> Epoch[55](700/2500): Loss: 0.0959
===> Epoch[55](800/2500): Loss: 0.1066
===> Epoch[55](900/2500): Loss: 0.0978
===> Epoch[55](1000/2500): Loss: 0.0958
===> Epoch[55](1100/2500): Loss: 0.0961
===> Epoch[55](1200/2500): Loss: 0.0964
===> Epoch[55](1300/2500): Loss: 0.0967
===> Epoch[55](1400/2500): Loss: 0.0953
===> Epoch[55](1500/2500): Loss: 0.0961
===> Epoch[55](1600/2500): Loss: 0.0962
===> Epoch[55](1700/2500): Loss: 0.0961
===> Epoch[55](1800/2500): Loss: 0.0959
===> Epoch[55](1900/2500): Loss: 0.0961
===> Epoch[55](2000/2500): Loss: 0.0960
===> Epoch[55](2100/2500): Loss: 0.0965
===> Epoch[55](2200/2500): Loss: 0.0965
===> Epoch[55](2300/2500): Loss: 0.0961
===> Epoch[55](2400/2500): Loss: 0.0959
===> Epoch[55](2500/2500): Loss: 0.0965
===> Epoch 55 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:51:19]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.0962
===> Epoch[55](200/2500): Loss: 0.0962
===> Epoch[55](300/2500): Loss: 0.0964
===> Epoch[55](400/2500): Loss: 0.0965
===> Epoch[55](500/2500): Loss: 0.0966
===> Epoch[55](600/2500): Loss: 0.0958
===> Epoch[55](700/2500): Loss: 0.0959
===> Epoch[55](800/2500): Loss: 0.1066
===> Epoch[55](900/2500): Loss: 0.0978
===> Epoch[55](1000/2500): Loss: 0.0958
===> Epoch[55](1100/2500): Loss: 0.0961
===> Epoch[55](1200/2500): Loss: 0.0964
===> Epoch[55](1300/2500): Loss: 0.0967
===> Epoch[55](1400/2500): Loss: 0.0953
===> Epoch[55](1500/2500): Loss: 0.0961
===> Epoch[55](1600/2500): Loss: 0.0962
===> Epoch[55](1700/2500): Loss: 0.0961
===> Epoch[55](1800/2500): Loss: 0.0959
===> Epoch[55](1900/2500): Loss: 0.0961
===> Epoch[55](2000/2500): Loss: 0.0960
===> Epoch[55](2100/2500): Loss: 0.0965
===> Epoch[55](2200/2500): Loss: 0.0965
===> Epoch[55](2300/2500): Loss: 0.0961
===> Epoch[55](2400/2500): Loss: 0.0959
===> Epoch[55](2500/2500): Loss: 0.0965
===> Epoch 55 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:51:19]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.0962
===> Epoch[55](200/2500): Loss: 0.0962
===> Epoch[55](300/2500): Loss: 0.0964
===> Epoch[55](400/2500): Loss: 0.0965
===> Epoch[55](500/2500): Loss: 0.0966
===> Epoch[55](600/2500): Loss: 0.0958
===> Epoch[55](700/2500): Loss: 0.0959
===> Epoch[55](800/2500): Loss: 0.1066
===> Epoch[55](900/2500): Loss: 0.0978
===> Epoch[55](1000/2500): Loss: 0.0958
===> Epoch[55](1100/2500): Loss: 0.0961
===> Epoch[55](1200/2500): Loss: 0.0964
===> Epoch[55](1300/2500): Loss: 0.0967
===> Epoch[55](1400/2500): Loss: 0.0953
===> Epoch[55](1500/2500): Loss: 0.0961
===> Epoch[55](1600/2500): Loss: 0.0962
===> Epoch[55](1700/2500): Loss: 0.0961
===> Epoch[55](1800/2500): Loss: 0.0959
===> Epoch[55](1900/2500): Loss: 0.0961
===> Epoch[55](2000/2500): Loss: 0.0960
===> Epoch[55](2100/2500): Loss: 0.0965
===> Epoch[55](2200/2500): Loss: 0.0965
===> Epoch[55](2300/2500): Loss: 0.0961
===> Epoch[55](2400/2500): Loss: 0.0959
===> Epoch[55](2500/2500): Loss: 0.0965
===> Epoch 55 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:51:19]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.0962
===> Epoch[55](200/2500): Loss: 0.0962
===> Epoch[55](300/2500): Loss: 0.0964
===> Epoch[55](400/2500): Loss: 0.0965
===> Epoch[55](500/2500): Loss: 0.0966
===> Epoch[55](600/2500): Loss: 0.0958
===> Epoch[55](700/2500): Loss: 0.0959
===> Epoch[55](800/2500): Loss: 0.1066
===> Epoch[55](900/2500): Loss: 0.0978
===> Epoch[55](1000/2500): Loss: 0.0958
===> Epoch[55](1100/2500): Loss: 0.0961
===> Epoch[55](1200/2500): Loss: 0.0964
===> Epoch[55](1300/2500): Loss: 0.0967
===> Epoch[55](1400/2500): Loss: 0.0953
===> Epoch[55](1500/2500): Loss: 0.0961
===> Epoch[55](1600/2500): Loss: 0.0962
===> Epoch[55](1700/2500): Loss: 0.0961
===> Epoch[55](1800/2500): Loss: 0.0959
===> Epoch[55](1900/2500): Loss: 0.0961
===> Epoch[55](2000/2500): Loss: 0.0960
===> Epoch[55](2100/2500): Loss: 0.0965
===> Epoch[55](2200/2500): Loss: 0.0965
===> Epoch[55](2300/2500): Loss: 0.0961
===> Epoch[55](2400/2500): Loss: 0.0959
===> Epoch[55](2500/2500): Loss: 0.0965
===> Epoch 55 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:51:19]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.0962
===> Epoch[55](200/2500): Loss: 0.0962
===> Epoch[55](300/2500): Loss: 0.0964
===> Epoch[55](400/2500): Loss: 0.0965
===> Epoch[55](500/2500): Loss: 0.0966
===> Epoch[55](600/2500): Loss: 0.0958
===> Epoch[55](700/2500): Loss: 0.0959
===> Epoch[55](800/2500): Loss: 0.1066
===> Epoch[55](900/2500): Loss: 0.0978
===> Epoch[55](1000/2500): Loss: 0.0958
===> Epoch[55](1100/2500): Loss: 0.0961
===> Epoch[55](1200/2500): Loss: 0.0964
===> Epoch[55](1300/2500): Loss: 0.0967
===> Epoch[55](1400/2500): Loss: 0.0953
===> Epoch[55](1500/2500): Loss: 0.0961
===> Epoch[55](1600/2500): Loss: 0.0962
===> Epoch[55](1700/2500): Loss: 0.0961
===> Epoch[55](1800/2500): Loss: 0.0959
===> Epoch[55](1900/2500): Loss: 0.0961
===> Epoch[55](2000/2500): Loss: 0.0960
===> Epoch[55](2100/2500): Loss: 0.0965
===> Epoch[55](2200/2500): Loss: 0.0965
===> Epoch[55](2300/2500): Loss: 0.0961
===> Epoch[55](2400/2500): Loss: 0.0959
===> Epoch[55](2500/2500): Loss: 0.0965
===> Epoch 55 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:51:19]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Epoch[55](100/2500): Loss: 0.0962
===> Epoch[55](200/2500): Loss: 0.0962
===> Epoch[55](300/2500): Loss: 0.0964
===> Epoch[55](400/2500): Loss: 0.0965
===> Epoch[55](500/2500): Loss: 0.0966
===> Epoch[55](600/2500): Loss: 0.0958
===> Epoch[55](700/2500): Loss: 0.0959
===> Epoch[55](800/2500): Loss: 0.1066
===> Epoch[55](900/2500): Loss: 0.0978
===> Epoch[55](1000/2500): Loss: 0.0958
===> Epoch[55](1100/2500): Loss: 0.0961
===> Epoch[55](1200/2500): Loss: 0.0964
===> Epoch[55](1300/2500): Loss: 0.0967
===> Epoch[55](1400/2500): Loss: 0.0953
===> Epoch[55](1500/2500): Loss: 0.0961
===> Epoch[55](1600/2500): Loss: 0.0962
===> Epoch[55](1700/2500): Loss: 0.0961
===> Epoch[55](1800/2500): Loss: 0.0959
===> Epoch[55](1900/2500): Loss: 0.0961
===> Epoch[55](2000/2500): Loss: 0.0960
===> Epoch[55](2100/2500): Loss: 0.0965
===> Epoch[55](2200/2500): Loss: 0.0965
===> Epoch[55](2300/2500): Loss: 0.0961
===> Epoch[55](2400/2500): Loss: 0.0959
===> Epoch[55](2500/2500): Loss: 0.0965
===> Epoch 55 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:51:19]
Checkpoint saved to TrainedNet/_epoch_55.pth
===> Loading train datasets
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.0959
===> Epoch[56](200/2500): Loss: 0.0967
===> Epoch[56](300/2500): Loss: 0.0957
===> Epoch[56](400/2500): Loss: 0.0963
===> Epoch[56](500/2500): Loss: 0.0962
===> Epoch[56](600/2500): Loss: 0.0961
===> Epoch[56](700/2500): Loss: 0.0963
===> Epoch[56](800/2500): Loss: 0.0963
===> Epoch[56](900/2500): Loss: 0.0960
===> Epoch[56](1000/2500): Loss: 0.0961
===> Epoch[56](1100/2500): Loss: 0.0955
===> Epoch[56](1200/2500): Loss: 0.0958
===> Epoch[56](1300/2500): Loss: 0.1044
===> Epoch[56](1400/2500): Loss: 0.0959
===> Epoch[56](1500/2500): Loss: 0.0965
===> Epoch[56](1600/2500): Loss: 0.0953
===> Epoch[56](1700/2500): Loss: 0.0964
===> Epoch[56](1800/2500): Loss: 0.0959
===> Epoch[56](1900/2500): Loss: 0.0964
===> Epoch[56](2000/2500): Loss: 0.0954
===> Epoch[56](2100/2500): Loss: 0.0957
===> Epoch[56](2200/2500): Loss: 0.0959
===> Epoch[56](2300/2500): Loss: 0.0959
===> Epoch[56](2400/2500): Loss: 0.0962
===> Epoch[56](2500/2500): Loss: 0.0958
===> Epoch 56 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:56:22]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.0959
===> Epoch[56](200/2500): Loss: 0.0967
===> Epoch[56](300/2500): Loss: 0.0957
===> Epoch[56](400/2500): Loss: 0.0963
===> Epoch[56](500/2500): Loss: 0.0962
===> Epoch[56](600/2500): Loss: 0.0961
===> Epoch[56](700/2500): Loss: 0.0963
===> Epoch[56](800/2500): Loss: 0.0963
===> Epoch[56](900/2500): Loss: 0.0960
===> Epoch[56](1000/2500): Loss: 0.0961
===> Epoch[56](1100/2500): Loss: 0.0955
===> Epoch[56](1200/2500): Loss: 0.0958
===> Epoch[56](1300/2500): Loss: 0.1044
===> Epoch[56](1400/2500): Loss: 0.0959
===> Epoch[56](1500/2500): Loss: 0.0965
===> Epoch[56](1600/2500): Loss: 0.0953
===> Epoch[56](1700/2500): Loss: 0.0964
===> Epoch[56](1800/2500): Loss: 0.0959
===> Epoch[56](1900/2500): Loss: 0.0964
===> Epoch[56](2000/2500): Loss: 0.0954
===> Epoch[56](2100/2500): Loss: 0.0957
===> Epoch[56](2200/2500): Loss: 0.0959
===> Epoch[56](2300/2500): Loss: 0.0959
===> Epoch[56](2400/2500): Loss: 0.0962
===> Epoch[56](2500/2500): Loss: 0.0958
===> Epoch 56 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:56:22]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.0959
===> Epoch[56](200/2500): Loss: 0.0967
===> Epoch[56](300/2500): Loss: 0.0957
===> Epoch[56](400/2500): Loss: 0.0963
===> Epoch[56](500/2500): Loss: 0.0962
===> Epoch[56](600/2500): Loss: 0.0961
===> Epoch[56](700/2500): Loss: 0.0963
===> Epoch[56](800/2500): Loss: 0.0963
===> Epoch[56](900/2500): Loss: 0.0960
===> Epoch[56](1000/2500): Loss: 0.0961
===> Epoch[56](1100/2500): Loss: 0.0955
===> Epoch[56](1200/2500): Loss: 0.0958
===> Epoch[56](1300/2500): Loss: 0.1044
===> Epoch[56](1400/2500): Loss: 0.0959
===> Epoch[56](1500/2500): Loss: 0.0965
===> Epoch[56](1600/2500): Loss: 0.0953
===> Epoch[56](1700/2500): Loss: 0.0964
===> Epoch[56](1800/2500): Loss: 0.0959
===> Epoch[56](1900/2500): Loss: 0.0964
===> Epoch[56](2000/2500): Loss: 0.0954
===> Epoch[56](2100/2500): Loss: 0.0957
===> Epoch[56](2200/2500): Loss: 0.0959
===> Epoch[56](2300/2500): Loss: 0.0959
===> Epoch[56](2400/2500): Loss: 0.0962
===> Epoch[56](2500/2500): Loss: 0.0958
===> Epoch 56 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:56:22]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.0959
===> Epoch[56](200/2500): Loss: 0.0967
===> Epoch[56](300/2500): Loss: 0.0957
===> Epoch[56](400/2500): Loss: 0.0963
===> Epoch[56](500/2500): Loss: 0.0962
===> Epoch[56](600/2500): Loss: 0.0961
===> Epoch[56](700/2500): Loss: 0.0963
===> Epoch[56](800/2500): Loss: 0.0963
===> Epoch[56](900/2500): Loss: 0.0960
===> Epoch[56](1000/2500): Loss: 0.0961
===> Epoch[56](1100/2500): Loss: 0.0955
===> Epoch[56](1200/2500): Loss: 0.0958
===> Epoch[56](1300/2500): Loss: 0.1044
===> Epoch[56](1400/2500): Loss: 0.0959
===> Epoch[56](1500/2500): Loss: 0.0965
===> Epoch[56](1600/2500): Loss: 0.0953
===> Epoch[56](1700/2500): Loss: 0.0964
===> Epoch[56](1800/2500): Loss: 0.0959
===> Epoch[56](1900/2500): Loss: 0.0964
===> Epoch[56](2000/2500): Loss: 0.0954
===> Epoch[56](2100/2500): Loss: 0.0957
===> Epoch[56](2200/2500): Loss: 0.0959
===> Epoch[56](2300/2500): Loss: 0.0959
===> Epoch[56](2400/2500): Loss: 0.0962
===> Epoch[56](2500/2500): Loss: 0.0958
===> Epoch 56 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:56:22]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.0959
===> Epoch[56](200/2500): Loss: 0.0967
===> Epoch[56](300/2500): Loss: 0.0957
===> Epoch[56](400/2500): Loss: 0.0963
===> Epoch[56](500/2500): Loss: 0.0962
===> Epoch[56](600/2500): Loss: 0.0961
===> Epoch[56](700/2500): Loss: 0.0963
===> Epoch[56](800/2500): Loss: 0.0963
===> Epoch[56](900/2500): Loss: 0.0960
===> Epoch[56](1000/2500): Loss: 0.0961
===> Epoch[56](1100/2500): Loss: 0.0955
===> Epoch[56](1200/2500): Loss: 0.0958
===> Epoch[56](1300/2500): Loss: 0.1044
===> Epoch[56](1400/2500): Loss: 0.0959
===> Epoch[56](1500/2500): Loss: 0.0965
===> Epoch[56](1600/2500): Loss: 0.0953
===> Epoch[56](1700/2500): Loss: 0.0964
===> Epoch[56](1800/2500): Loss: 0.0959
===> Epoch[56](1900/2500): Loss: 0.0964
===> Epoch[56](2000/2500): Loss: 0.0954
===> Epoch[56](2100/2500): Loss: 0.0957
===> Epoch[56](2200/2500): Loss: 0.0959
===> Epoch[56](2300/2500): Loss: 0.0959
===> Epoch[56](2400/2500): Loss: 0.0962
===> Epoch[56](2500/2500): Loss: 0.0958
===> Epoch 56 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:56:22]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.0959
===> Epoch[56](200/2500): Loss: 0.0967
===> Epoch[56](300/2500): Loss: 0.0957
===> Epoch[56](400/2500): Loss: 0.0963
===> Epoch[56](500/2500): Loss: 0.0962
===> Epoch[56](600/2500): Loss: 0.0961
===> Epoch[56](700/2500): Loss: 0.0963
===> Epoch[56](800/2500): Loss: 0.0963
===> Epoch[56](900/2500): Loss: 0.0960
===> Epoch[56](1000/2500): Loss: 0.0961
===> Epoch[56](1100/2500): Loss: 0.0955
===> Epoch[56](1200/2500): Loss: 0.0958
===> Epoch[56](1300/2500): Loss: 0.1044
===> Epoch[56](1400/2500): Loss: 0.0959
===> Epoch[56](1500/2500): Loss: 0.0965
===> Epoch[56](1600/2500): Loss: 0.0953
===> Epoch[56](1700/2500): Loss: 0.0964
===> Epoch[56](1800/2500): Loss: 0.0959
===> Epoch[56](1900/2500): Loss: 0.0964
===> Epoch[56](2000/2500): Loss: 0.0954
===> Epoch[56](2100/2500): Loss: 0.0957
===> Epoch[56](2200/2500): Loss: 0.0959
===> Epoch[56](2300/2500): Loss: 0.0959
===> Epoch[56](2400/2500): Loss: 0.0962
===> Epoch[56](2500/2500): Loss: 0.0958
===> Epoch 56 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:56:22]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.0959
===> Epoch[56](200/2500): Loss: 0.0967
===> Epoch[56](300/2500): Loss: 0.0957
===> Epoch[56](400/2500): Loss: 0.0963
===> Epoch[56](500/2500): Loss: 0.0962
===> Epoch[56](600/2500): Loss: 0.0961
===> Epoch[56](700/2500): Loss: 0.0963
===> Epoch[56](800/2500): Loss: 0.0963
===> Epoch[56](900/2500): Loss: 0.0960
===> Epoch[56](1000/2500): Loss: 0.0961
===> Epoch[56](1100/2500): Loss: 0.0955
===> Epoch[56](1200/2500): Loss: 0.0958
===> Epoch[56](1300/2500): Loss: 0.1044
===> Epoch[56](1400/2500): Loss: 0.0959
===> Epoch[56](1500/2500): Loss: 0.0965
===> Epoch[56](1600/2500): Loss: 0.0953
===> Epoch[56](1700/2500): Loss: 0.0964
===> Epoch[56](1800/2500): Loss: 0.0959
===> Epoch[56](1900/2500): Loss: 0.0964
===> Epoch[56](2000/2500): Loss: 0.0954
===> Epoch[56](2100/2500): Loss: 0.0957
===> Epoch[56](2200/2500): Loss: 0.0959
===> Epoch[56](2300/2500): Loss: 0.0959
===> Epoch[56](2400/2500): Loss: 0.0962
===> Epoch[56](2500/2500): Loss: 0.0958
===> Epoch 56 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:56:22]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.0959
===> Epoch[56](200/2500): Loss: 0.0967
===> Epoch[56](300/2500): Loss: 0.0957
===> Epoch[56](400/2500): Loss: 0.0963
===> Epoch[56](500/2500): Loss: 0.0962
===> Epoch[56](600/2500): Loss: 0.0961
===> Epoch[56](700/2500): Loss: 0.0963
===> Epoch[56](800/2500): Loss: 0.0963
===> Epoch[56](900/2500): Loss: 0.0960
===> Epoch[56](1000/2500): Loss: 0.0961
===> Epoch[56](1100/2500): Loss: 0.0955
===> Epoch[56](1200/2500): Loss: 0.0958
===> Epoch[56](1300/2500): Loss: 0.1044
===> Epoch[56](1400/2500): Loss: 0.0959
===> Epoch[56](1500/2500): Loss: 0.0965
===> Epoch[56](1600/2500): Loss: 0.0953
===> Epoch[56](1700/2500): Loss: 0.0964
===> Epoch[56](1800/2500): Loss: 0.0959
===> Epoch[56](1900/2500): Loss: 0.0964
===> Epoch[56](2000/2500): Loss: 0.0954
===> Epoch[56](2100/2500): Loss: 0.0957
===> Epoch[56](2200/2500): Loss: 0.0959
===> Epoch[56](2300/2500): Loss: 0.0959
===> Epoch[56](2400/2500): Loss: 0.0962
===> Epoch[56](2500/2500): Loss: 0.0958
===> Epoch 56 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:56:22]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.0959
===> Epoch[56](200/2500): Loss: 0.0967
===> Epoch[56](300/2500): Loss: 0.0957
===> Epoch[56](400/2500): Loss: 0.0963
===> Epoch[56](500/2500): Loss: 0.0962
===> Epoch[56](600/2500): Loss: 0.0961
===> Epoch[56](700/2500): Loss: 0.0963
===> Epoch[56](800/2500): Loss: 0.0963
===> Epoch[56](900/2500): Loss: 0.0960
===> Epoch[56](1000/2500): Loss: 0.0961
===> Epoch[56](1100/2500): Loss: 0.0955
===> Epoch[56](1200/2500): Loss: 0.0958
===> Epoch[56](1300/2500): Loss: 0.1044
===> Epoch[56](1400/2500): Loss: 0.0959
===> Epoch[56](1500/2500): Loss: 0.0965
===> Epoch[56](1600/2500): Loss: 0.0953
===> Epoch[56](1700/2500): Loss: 0.0964
===> Epoch[56](1800/2500): Loss: 0.0959
===> Epoch[56](1900/2500): Loss: 0.0964
===> Epoch[56](2000/2500): Loss: 0.0954
===> Epoch[56](2100/2500): Loss: 0.0957
===> Epoch[56](2200/2500): Loss: 0.0959
===> Epoch[56](2300/2500): Loss: 0.0959
===> Epoch[56](2400/2500): Loss: 0.0962
===> Epoch[56](2500/2500): Loss: 0.0958
===> Epoch 56 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:56:22]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.0959
===> Epoch[56](200/2500): Loss: 0.0967
===> Epoch[56](300/2500): Loss: 0.0957
===> Epoch[56](400/2500): Loss: 0.0963
===> Epoch[56](500/2500): Loss: 0.0962
===> Epoch[56](600/2500): Loss: 0.0961
===> Epoch[56](700/2500): Loss: 0.0963
===> Epoch[56](800/2500): Loss: 0.0963
===> Epoch[56](900/2500): Loss: 0.0960
===> Epoch[56](1000/2500): Loss: 0.0961
===> Epoch[56](1100/2500): Loss: 0.0955
===> Epoch[56](1200/2500): Loss: 0.0958
===> Epoch[56](1300/2500): Loss: 0.1044
===> Epoch[56](1400/2500): Loss: 0.0959
===> Epoch[56](1500/2500): Loss: 0.0965
===> Epoch[56](1600/2500): Loss: 0.0953
===> Epoch[56](1700/2500): Loss: 0.0964
===> Epoch[56](1800/2500): Loss: 0.0959
===> Epoch[56](1900/2500): Loss: 0.0964
===> Epoch[56](2000/2500): Loss: 0.0954
===> Epoch[56](2100/2500): Loss: 0.0957
===> Epoch[56](2200/2500): Loss: 0.0959
===> Epoch[56](2300/2500): Loss: 0.0959
===> Epoch[56](2400/2500): Loss: 0.0962
===> Epoch[56](2500/2500): Loss: 0.0958
===> Epoch 56 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:56:22]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.0959
===> Epoch[56](200/2500): Loss: 0.0967
===> Epoch[56](300/2500): Loss: 0.0957
===> Epoch[56](400/2500): Loss: 0.0963
===> Epoch[56](500/2500): Loss: 0.0962
===> Epoch[56](600/2500): Loss: 0.0961
===> Epoch[56](700/2500): Loss: 0.0963
===> Epoch[56](800/2500): Loss: 0.0963
===> Epoch[56](900/2500): Loss: 0.0960
===> Epoch[56](1000/2500): Loss: 0.0961
===> Epoch[56](1100/2500): Loss: 0.0955
===> Epoch[56](1200/2500): Loss: 0.0958
===> Epoch[56](1300/2500): Loss: 0.1044
===> Epoch[56](1400/2500): Loss: 0.0959
===> Epoch[56](1500/2500): Loss: 0.0965
===> Epoch[56](1600/2500): Loss: 0.0953
===> Epoch[56](1700/2500): Loss: 0.0964
===> Epoch[56](1800/2500): Loss: 0.0959
===> Epoch[56](1900/2500): Loss: 0.0964
===> Epoch[56](2000/2500): Loss: 0.0954
===> Epoch[56](2100/2500): Loss: 0.0957
===> Epoch[56](2200/2500): Loss: 0.0959
===> Epoch[56](2300/2500): Loss: 0.0959
===> Epoch[56](2400/2500): Loss: 0.0962
===> Epoch[56](2500/2500): Loss: 0.0958
===> Epoch 56 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:56:22]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.0959
===> Epoch[56](200/2500): Loss: 0.0967
===> Epoch[56](300/2500): Loss: 0.0957
===> Epoch[56](400/2500): Loss: 0.0963
===> Epoch[56](500/2500): Loss: 0.0962
===> Epoch[56](600/2500): Loss: 0.0961
===> Epoch[56](700/2500): Loss: 0.0963
===> Epoch[56](800/2500): Loss: 0.0963
===> Epoch[56](900/2500): Loss: 0.0960
===> Epoch[56](1000/2500): Loss: 0.0961
===> Epoch[56](1100/2500): Loss: 0.0955
===> Epoch[56](1200/2500): Loss: 0.0958
===> Epoch[56](1300/2500): Loss: 0.1044
===> Epoch[56](1400/2500): Loss: 0.0959
===> Epoch[56](1500/2500): Loss: 0.0965
===> Epoch[56](1600/2500): Loss: 0.0953
===> Epoch[56](1700/2500): Loss: 0.0964
===> Epoch[56](1800/2500): Loss: 0.0959
===> Epoch[56](1900/2500): Loss: 0.0964
===> Epoch[56](2000/2500): Loss: 0.0954
===> Epoch[56](2100/2500): Loss: 0.0957
===> Epoch[56](2200/2500): Loss: 0.0959
===> Epoch[56](2300/2500): Loss: 0.0959
===> Epoch[56](2400/2500): Loss: 0.0962
===> Epoch[56](2500/2500): Loss: 0.0958
===> Epoch 56 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:56:22]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.0959
===> Epoch[56](200/2500): Loss: 0.0967
===> Epoch[56](300/2500): Loss: 0.0957
===> Epoch[56](400/2500): Loss: 0.0963
===> Epoch[56](500/2500): Loss: 0.0962
===> Epoch[56](600/2500): Loss: 0.0961
===> Epoch[56](700/2500): Loss: 0.0963
===> Epoch[56](800/2500): Loss: 0.0963
===> Epoch[56](900/2500): Loss: 0.0960
===> Epoch[56](1000/2500): Loss: 0.0961
===> Epoch[56](1100/2500): Loss: 0.0955
===> Epoch[56](1200/2500): Loss: 0.0958
===> Epoch[56](1300/2500): Loss: 0.1044
===> Epoch[56](1400/2500): Loss: 0.0959
===> Epoch[56](1500/2500): Loss: 0.0965
===> Epoch[56](1600/2500): Loss: 0.0953
===> Epoch[56](1700/2500): Loss: 0.0964
===> Epoch[56](1800/2500): Loss: 0.0959
===> Epoch[56](1900/2500): Loss: 0.0964
===> Epoch[56](2000/2500): Loss: 0.0954
===> Epoch[56](2100/2500): Loss: 0.0957
===> Epoch[56](2200/2500): Loss: 0.0959
===> Epoch[56](2300/2500): Loss: 0.0959
===> Epoch[56](2400/2500): Loss: 0.0962
===> Epoch[56](2500/2500): Loss: 0.0958
===> Epoch 56 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:56:22]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.0959
===> Epoch[56](200/2500): Loss: 0.0967
===> Epoch[56](300/2500): Loss: 0.0957
===> Epoch[56](400/2500): Loss: 0.0963
===> Epoch[56](500/2500): Loss: 0.0962
===> Epoch[56](600/2500): Loss: 0.0961
===> Epoch[56](700/2500): Loss: 0.0963
===> Epoch[56](800/2500): Loss: 0.0963
===> Epoch[56](900/2500): Loss: 0.0960
===> Epoch[56](1000/2500): Loss: 0.0961
===> Epoch[56](1100/2500): Loss: 0.0955
===> Epoch[56](1200/2500): Loss: 0.0958
===> Epoch[56](1300/2500): Loss: 0.1044
===> Epoch[56](1400/2500): Loss: 0.0959
===> Epoch[56](1500/2500): Loss: 0.0965
===> Epoch[56](1600/2500): Loss: 0.0953
===> Epoch[56](1700/2500): Loss: 0.0964
===> Epoch[56](1800/2500): Loss: 0.0959
===> Epoch[56](1900/2500): Loss: 0.0964
===> Epoch[56](2000/2500): Loss: 0.0954
===> Epoch[56](2100/2500): Loss: 0.0957
===> Epoch[56](2200/2500): Loss: 0.0959
===> Epoch[56](2300/2500): Loss: 0.0959
===> Epoch[56](2400/2500): Loss: 0.0962
===> Epoch[56](2500/2500): Loss: 0.0958
===> Epoch 56 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:56:22]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.0959
===> Epoch[56](200/2500): Loss: 0.0967
===> Epoch[56](300/2500): Loss: 0.0957
===> Epoch[56](400/2500): Loss: 0.0963
===> Epoch[56](500/2500): Loss: 0.0962
===> Epoch[56](600/2500): Loss: 0.0961
===> Epoch[56](700/2500): Loss: 0.0963
===> Epoch[56](800/2500): Loss: 0.0963
===> Epoch[56](900/2500): Loss: 0.0960
===> Epoch[56](1000/2500): Loss: 0.0961
===> Epoch[56](1100/2500): Loss: 0.0955
===> Epoch[56](1200/2500): Loss: 0.0958
===> Epoch[56](1300/2500): Loss: 0.1044
===> Epoch[56](1400/2500): Loss: 0.0959
===> Epoch[56](1500/2500): Loss: 0.0965
===> Epoch[56](1600/2500): Loss: 0.0953
===> Epoch[56](1700/2500): Loss: 0.0964
===> Epoch[56](1800/2500): Loss: 0.0959
===> Epoch[56](1900/2500): Loss: 0.0964
===> Epoch[56](2000/2500): Loss: 0.0954
===> Epoch[56](2100/2500): Loss: 0.0957
===> Epoch[56](2200/2500): Loss: 0.0959
===> Epoch[56](2300/2500): Loss: 0.0959
===> Epoch[56](2400/2500): Loss: 0.0962
===> Epoch[56](2500/2500): Loss: 0.0958
===> Epoch 56 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:56:22]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.0959
===> Epoch[56](200/2500): Loss: 0.0967
===> Epoch[56](300/2500): Loss: 0.0957
===> Epoch[56](400/2500): Loss: 0.0963
===> Epoch[56](500/2500): Loss: 0.0962
===> Epoch[56](600/2500): Loss: 0.0961
===> Epoch[56](700/2500): Loss: 0.0963
===> Epoch[56](800/2500): Loss: 0.0963
===> Epoch[56](900/2500): Loss: 0.0960
===> Epoch[56](1000/2500): Loss: 0.0961
===> Epoch[56](1100/2500): Loss: 0.0955
===> Epoch[56](1200/2500): Loss: 0.0958
===> Epoch[56](1300/2500): Loss: 0.1044
===> Epoch[56](1400/2500): Loss: 0.0959
===> Epoch[56](1500/2500): Loss: 0.0965
===> Epoch[56](1600/2500): Loss: 0.0953
===> Epoch[56](1700/2500): Loss: 0.0964
===> Epoch[56](1800/2500): Loss: 0.0959
===> Epoch[56](1900/2500): Loss: 0.0964
===> Epoch[56](2000/2500): Loss: 0.0954
===> Epoch[56](2100/2500): Loss: 0.0957
===> Epoch[56](2200/2500): Loss: 0.0959
===> Epoch[56](2300/2500): Loss: 0.0959
===> Epoch[56](2400/2500): Loss: 0.0962
===> Epoch[56](2500/2500): Loss: 0.0958
===> Epoch 56 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:56:22]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.0959
===> Epoch[56](200/2500): Loss: 0.0967
===> Epoch[56](300/2500): Loss: 0.0957
===> Epoch[56](400/2500): Loss: 0.0963
===> Epoch[56](500/2500): Loss: 0.0962
===> Epoch[56](600/2500): Loss: 0.0961
===> Epoch[56](700/2500): Loss: 0.0963
===> Epoch[56](800/2500): Loss: 0.0963
===> Epoch[56](900/2500): Loss: 0.0960
===> Epoch[56](1000/2500): Loss: 0.0961
===> Epoch[56](1100/2500): Loss: 0.0955
===> Epoch[56](1200/2500): Loss: 0.0958
===> Epoch[56](1300/2500): Loss: 0.1044
===> Epoch[56](1400/2500): Loss: 0.0959
===> Epoch[56](1500/2500): Loss: 0.0965
===> Epoch[56](1600/2500): Loss: 0.0953
===> Epoch[56](1700/2500): Loss: 0.0964
===> Epoch[56](1800/2500): Loss: 0.0959
===> Epoch[56](1900/2500): Loss: 0.0964
===> Epoch[56](2000/2500): Loss: 0.0954
===> Epoch[56](2100/2500): Loss: 0.0957
===> Epoch[56](2200/2500): Loss: 0.0959
===> Epoch[56](2300/2500): Loss: 0.0959
===> Epoch[56](2400/2500): Loss: 0.0962
===> Epoch[56](2500/2500): Loss: 0.0958
===> Epoch 56 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:56:22]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.0959
===> Epoch[56](200/2500): Loss: 0.0967
===> Epoch[56](300/2500): Loss: 0.0957
===> Epoch[56](400/2500): Loss: 0.0963
===> Epoch[56](500/2500): Loss: 0.0962
===> Epoch[56](600/2500): Loss: 0.0961
===> Epoch[56](700/2500): Loss: 0.0963
===> Epoch[56](800/2500): Loss: 0.0963
===> Epoch[56](900/2500): Loss: 0.0960
===> Epoch[56](1000/2500): Loss: 0.0961
===> Epoch[56](1100/2500): Loss: 0.0955
===> Epoch[56](1200/2500): Loss: 0.0958
===> Epoch[56](1300/2500): Loss: 0.1044
===> Epoch[56](1400/2500): Loss: 0.0959
===> Epoch[56](1500/2500): Loss: 0.0965
===> Epoch[56](1600/2500): Loss: 0.0953
===> Epoch[56](1700/2500): Loss: 0.0964
===> Epoch[56](1800/2500): Loss: 0.0959
===> Epoch[56](1900/2500): Loss: 0.0964
===> Epoch[56](2000/2500): Loss: 0.0954
===> Epoch[56](2100/2500): Loss: 0.0957
===> Epoch[56](2200/2500): Loss: 0.0959
===> Epoch[56](2300/2500): Loss: 0.0959
===> Epoch[56](2400/2500): Loss: 0.0962
===> Epoch[56](2500/2500): Loss: 0.0958
===> Epoch 56 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:56:22]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.0959
===> Epoch[56](200/2500): Loss: 0.0967
===> Epoch[56](300/2500): Loss: 0.0957
===> Epoch[56](400/2500): Loss: 0.0963
===> Epoch[56](500/2500): Loss: 0.0962
===> Epoch[56](600/2500): Loss: 0.0961
===> Epoch[56](700/2500): Loss: 0.0963
===> Epoch[56](800/2500): Loss: 0.0963
===> Epoch[56](900/2500): Loss: 0.0960
===> Epoch[56](1000/2500): Loss: 0.0961
===> Epoch[56](1100/2500): Loss: 0.0955
===> Epoch[56](1200/2500): Loss: 0.0958
===> Epoch[56](1300/2500): Loss: 0.1044
===> Epoch[56](1400/2500): Loss: 0.0959
===> Epoch[56](1500/2500): Loss: 0.0965
===> Epoch[56](1600/2500): Loss: 0.0953
===> Epoch[56](1700/2500): Loss: 0.0964
===> Epoch[56](1800/2500): Loss: 0.0959
===> Epoch[56](1900/2500): Loss: 0.0964
===> Epoch[56](2000/2500): Loss: 0.0954
===> Epoch[56](2100/2500): Loss: 0.0957
===> Epoch[56](2200/2500): Loss: 0.0959
===> Epoch[56](2300/2500): Loss: 0.0959
===> Epoch[56](2400/2500): Loss: 0.0962
===> Epoch[56](2500/2500): Loss: 0.0958
===> Epoch 56 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:56:22]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.0959
===> Epoch[56](200/2500): Loss: 0.0967
===> Epoch[56](300/2500): Loss: 0.0957
===> Epoch[56](400/2500): Loss: 0.0963
===> Epoch[56](500/2500): Loss: 0.0962
===> Epoch[56](600/2500): Loss: 0.0961
===> Epoch[56](700/2500): Loss: 0.0963
===> Epoch[56](800/2500): Loss: 0.0963
===> Epoch[56](900/2500): Loss: 0.0960
===> Epoch[56](1000/2500): Loss: 0.0961
===> Epoch[56](1100/2500): Loss: 0.0955
===> Epoch[56](1200/2500): Loss: 0.0958
===> Epoch[56](1300/2500): Loss: 0.1044
===> Epoch[56](1400/2500): Loss: 0.0959
===> Epoch[56](1500/2500): Loss: 0.0965
===> Epoch[56](1600/2500): Loss: 0.0953
===> Epoch[56](1700/2500): Loss: 0.0964
===> Epoch[56](1800/2500): Loss: 0.0959
===> Epoch[56](1900/2500): Loss: 0.0964
===> Epoch[56](2000/2500): Loss: 0.0954
===> Epoch[56](2100/2500): Loss: 0.0957
===> Epoch[56](2200/2500): Loss: 0.0959
===> Epoch[56](2300/2500): Loss: 0.0959
===> Epoch[56](2400/2500): Loss: 0.0962
===> Epoch[56](2500/2500): Loss: 0.0958
===> Epoch 56 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:56:22]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.0959
===> Epoch[56](200/2500): Loss: 0.0967
===> Epoch[56](300/2500): Loss: 0.0957
===> Epoch[56](400/2500): Loss: 0.0963
===> Epoch[56](500/2500): Loss: 0.0962
===> Epoch[56](600/2500): Loss: 0.0961
===> Epoch[56](700/2500): Loss: 0.0963
===> Epoch[56](800/2500): Loss: 0.0963
===> Epoch[56](900/2500): Loss: 0.0960
===> Epoch[56](1000/2500): Loss: 0.0961
===> Epoch[56](1100/2500): Loss: 0.0955
===> Epoch[56](1200/2500): Loss: 0.0958
===> Epoch[56](1300/2500): Loss: 0.1044
===> Epoch[56](1400/2500): Loss: 0.0959
===> Epoch[56](1500/2500): Loss: 0.0965
===> Epoch[56](1600/2500): Loss: 0.0953
===> Epoch[56](1700/2500): Loss: 0.0964
===> Epoch[56](1800/2500): Loss: 0.0959
===> Epoch[56](1900/2500): Loss: 0.0964
===> Epoch[56](2000/2500): Loss: 0.0954
===> Epoch[56](2100/2500): Loss: 0.0957
===> Epoch[56](2200/2500): Loss: 0.0959
===> Epoch[56](2300/2500): Loss: 0.0959
===> Epoch[56](2400/2500): Loss: 0.0962
===> Epoch[56](2500/2500): Loss: 0.0958
===> Epoch 56 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:56:22]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.0959
===> Epoch[56](200/2500): Loss: 0.0967
===> Epoch[56](300/2500): Loss: 0.0957
===> Epoch[56](400/2500): Loss: 0.0963
===> Epoch[56](500/2500): Loss: 0.0962
===> Epoch[56](600/2500): Loss: 0.0961
===> Epoch[56](700/2500): Loss: 0.0963
===> Epoch[56](800/2500): Loss: 0.0963
===> Epoch[56](900/2500): Loss: 0.0960
===> Epoch[56](1000/2500): Loss: 0.0961
===> Epoch[56](1100/2500): Loss: 0.0955
===> Epoch[56](1200/2500): Loss: 0.0958
===> Epoch[56](1300/2500): Loss: 0.1044
===> Epoch[56](1400/2500): Loss: 0.0959
===> Epoch[56](1500/2500): Loss: 0.0965
===> Epoch[56](1600/2500): Loss: 0.0953
===> Epoch[56](1700/2500): Loss: 0.0964
===> Epoch[56](1800/2500): Loss: 0.0959
===> Epoch[56](1900/2500): Loss: 0.0964
===> Epoch[56](2000/2500): Loss: 0.0954
===> Epoch[56](2100/2500): Loss: 0.0957
===> Epoch[56](2200/2500): Loss: 0.0959
===> Epoch[56](2300/2500): Loss: 0.0959
===> Epoch[56](2400/2500): Loss: 0.0962
===> Epoch[56](2500/2500): Loss: 0.0958
===> Epoch 56 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:56:22]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.0959
===> Epoch[56](200/2500): Loss: 0.0967
===> Epoch[56](300/2500): Loss: 0.0957
===> Epoch[56](400/2500): Loss: 0.0963
===> Epoch[56](500/2500): Loss: 0.0962
===> Epoch[56](600/2500): Loss: 0.0961
===> Epoch[56](700/2500): Loss: 0.0963
===> Epoch[56](800/2500): Loss: 0.0963
===> Epoch[56](900/2500): Loss: 0.0960
===> Epoch[56](1000/2500): Loss: 0.0961
===> Epoch[56](1100/2500): Loss: 0.0955
===> Epoch[56](1200/2500): Loss: 0.0958
===> Epoch[56](1300/2500): Loss: 0.1044
===> Epoch[56](1400/2500): Loss: 0.0959
===> Epoch[56](1500/2500): Loss: 0.0965
===> Epoch[56](1600/2500): Loss: 0.0953
===> Epoch[56](1700/2500): Loss: 0.0964
===> Epoch[56](1800/2500): Loss: 0.0959
===> Epoch[56](1900/2500): Loss: 0.0964
===> Epoch[56](2000/2500): Loss: 0.0954
===> Epoch[56](2100/2500): Loss: 0.0957
===> Epoch[56](2200/2500): Loss: 0.0959
===> Epoch[56](2300/2500): Loss: 0.0959
===> Epoch[56](2400/2500): Loss: 0.0962
===> Epoch[56](2500/2500): Loss: 0.0958
===> Epoch 56 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:56:22]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.0959
===> Epoch[56](200/2500): Loss: 0.0967
===> Epoch[56](300/2500): Loss: 0.0957
===> Epoch[56](400/2500): Loss: 0.0963
===> Epoch[56](500/2500): Loss: 0.0962
===> Epoch[56](600/2500): Loss: 0.0961
===> Epoch[56](700/2500): Loss: 0.0963
===> Epoch[56](800/2500): Loss: 0.0963
===> Epoch[56](900/2500): Loss: 0.0960
===> Epoch[56](1000/2500): Loss: 0.0961
===> Epoch[56](1100/2500): Loss: 0.0955
===> Epoch[56](1200/2500): Loss: 0.0958
===> Epoch[56](1300/2500): Loss: 0.1044
===> Epoch[56](1400/2500): Loss: 0.0959
===> Epoch[56](1500/2500): Loss: 0.0965
===> Epoch[56](1600/2500): Loss: 0.0953
===> Epoch[56](1700/2500): Loss: 0.0964
===> Epoch[56](1800/2500): Loss: 0.0959
===> Epoch[56](1900/2500): Loss: 0.0964
===> Epoch[56](2000/2500): Loss: 0.0954
===> Epoch[56](2100/2500): Loss: 0.0957
===> Epoch[56](2200/2500): Loss: 0.0959
===> Epoch[56](2300/2500): Loss: 0.0959
===> Epoch[56](2400/2500): Loss: 0.0962
===> Epoch[56](2500/2500): Loss: 0.0958
===> Epoch 56 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:56:22]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.0959
===> Epoch[56](200/2500): Loss: 0.0967
===> Epoch[56](300/2500): Loss: 0.0957
===> Epoch[56](400/2500): Loss: 0.0963
===> Epoch[56](500/2500): Loss: 0.0962
===> Epoch[56](600/2500): Loss: 0.0961
===> Epoch[56](700/2500): Loss: 0.0963
===> Epoch[56](800/2500): Loss: 0.0963
===> Epoch[56](900/2500): Loss: 0.0960
===> Epoch[56](1000/2500): Loss: 0.0961
===> Epoch[56](1100/2500): Loss: 0.0955
===> Epoch[56](1200/2500): Loss: 0.0958
===> Epoch[56](1300/2500): Loss: 0.1044
===> Epoch[56](1400/2500): Loss: 0.0959
===> Epoch[56](1500/2500): Loss: 0.0965
===> Epoch[56](1600/2500): Loss: 0.0953
===> Epoch[56](1700/2500): Loss: 0.0964
===> Epoch[56](1800/2500): Loss: 0.0959
===> Epoch[56](1900/2500): Loss: 0.0964
===> Epoch[56](2000/2500): Loss: 0.0954
===> Epoch[56](2100/2500): Loss: 0.0957
===> Epoch[56](2200/2500): Loss: 0.0959
===> Epoch[56](2300/2500): Loss: 0.0959
===> Epoch[56](2400/2500): Loss: 0.0962
===> Epoch[56](2500/2500): Loss: 0.0958
===> Epoch 56 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:56:22]
===> Loading train datasets
===> Epoch[56](100/2500): Loss: 0.0959
===> Epoch[56](200/2500): Loss: 0.0967
===> Epoch[56](300/2500): Loss: 0.0957
===> Epoch[56](400/2500): Loss: 0.0963
===> Epoch[56](500/2500): Loss: 0.0962
===> Epoch[56](600/2500): Loss: 0.0961
===> Epoch[56](700/2500): Loss: 0.0963
===> Epoch[56](800/2500): Loss: 0.0963
===> Epoch[56](900/2500): Loss: 0.0960
===> Epoch[56](1000/2500): Loss: 0.0961
===> Epoch[56](1100/2500): Loss: 0.0955
===> Epoch[56](1200/2500): Loss: 0.0958
===> Epoch[56](1300/2500): Loss: 0.1044
===> Epoch[56](1400/2500): Loss: 0.0959
===> Epoch[56](1500/2500): Loss: 0.0965
===> Epoch[56](1600/2500): Loss: 0.0953
===> Epoch[56](1700/2500): Loss: 0.0964
===> Epoch[56](1800/2500): Loss: 0.0959
===> Epoch[56](1900/2500): Loss: 0.0964
===> Epoch[56](2000/2500): Loss: 0.0954
===> Epoch[56](2100/2500): Loss: 0.0957
===> Epoch[56](2200/2500): Loss: 0.0959
===> Epoch[56](2300/2500): Loss: 0.0959
===> Epoch[56](2400/2500): Loss: 0.0962
===> Epoch[56](2500/2500): Loss: 0.0958
===> Epoch 56 Complete: Avg. Loss: 0.0964
===> Timestamp: [2025-07-29 19:56:22]
===> Loading train datasets
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.0958
===> Epoch[57](200/2500): Loss: 0.0961
===> Epoch[57](300/2500): Loss: 0.0961
===> Epoch[57](400/2500): Loss: 0.0962
===> Epoch[57](500/2500): Loss: 0.0956
===> Epoch[57](600/2500): Loss: 0.0963
===> Epoch[57](700/2500): Loss: 0.0962
===> Epoch[57](800/2500): Loss: 0.0964
===> Epoch[57](900/2500): Loss: 0.0964
===> Epoch[57](1000/2500): Loss: 0.0957
===> Epoch[57](1100/2500): Loss: 0.0963
===> Epoch[57](1200/2500): Loss: 0.0955
===> Epoch[57](1300/2500): Loss: 0.0958
===> Epoch[57](1400/2500): Loss: 0.0964
===> Epoch[57](1500/2500): Loss: 0.0961
===> Epoch[57](1600/2500): Loss: 0.0956
===> Epoch[57](1700/2500): Loss: 0.0953
===> Epoch[57](1800/2500): Loss: 0.1029
===> Epoch[57](1900/2500): Loss: 0.0976
===> Epoch[57](2000/2500): Loss: 0.0959
===> Epoch[57](2100/2500): Loss: 0.0959
===> Epoch[57](2200/2500): Loss: 0.0955
===> Epoch[57](2300/2500): Loss: 0.0959
===> Epoch[57](2400/2500): Loss: 0.0954
===> Epoch[57](2500/2500): Loss: 0.0960
===> Epoch 57 Complete: Avg. Loss: 0.0963
===> Timestamp: [2025-07-29 20:01:25]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.0958
===> Epoch[57](200/2500): Loss: 0.0961
===> Epoch[57](300/2500): Loss: 0.0961
===> Epoch[57](400/2500): Loss: 0.0962
===> Epoch[57](500/2500): Loss: 0.0956
===> Epoch[57](600/2500): Loss: 0.0963
===> Epoch[57](700/2500): Loss: 0.0962
===> Epoch[57](800/2500): Loss: 0.0964
===> Epoch[57](900/2500): Loss: 0.0964
===> Epoch[57](1000/2500): Loss: 0.0957
===> Epoch[57](1100/2500): Loss: 0.0963
===> Epoch[57](1200/2500): Loss: 0.0955
===> Epoch[57](1300/2500): Loss: 0.0958
===> Epoch[57](1400/2500): Loss: 0.0964
===> Epoch[57](1500/2500): Loss: 0.0961
===> Epoch[57](1600/2500): Loss: 0.0956
===> Epoch[57](1700/2500): Loss: 0.0953
===> Epoch[57](1800/2500): Loss: 0.1029
===> Epoch[57](1900/2500): Loss: 0.0976
===> Epoch[57](2000/2500): Loss: 0.0959
===> Epoch[57](2100/2500): Loss: 0.0959
===> Epoch[57](2200/2500): Loss: 0.0955
===> Epoch[57](2300/2500): Loss: 0.0959
===> Epoch[57](2400/2500): Loss: 0.0954
===> Epoch[57](2500/2500): Loss: 0.0960
===> Epoch 57 Complete: Avg. Loss: 0.0963
===> Timestamp: [2025-07-29 20:01:25]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.0958
===> Epoch[57](200/2500): Loss: 0.0961
===> Epoch[57](300/2500): Loss: 0.0961
===> Epoch[57](400/2500): Loss: 0.0962
===> Epoch[57](500/2500): Loss: 0.0956
===> Epoch[57](600/2500): Loss: 0.0963
===> Epoch[57](700/2500): Loss: 0.0962
===> Epoch[57](800/2500): Loss: 0.0964
===> Epoch[57](900/2500): Loss: 0.0964
===> Epoch[57](1000/2500): Loss: 0.0957
===> Epoch[57](1100/2500): Loss: 0.0963
===> Epoch[57](1200/2500): Loss: 0.0955
===> Epoch[57](1300/2500): Loss: 0.0958
===> Epoch[57](1400/2500): Loss: 0.0964
===> Epoch[57](1500/2500): Loss: 0.0961
===> Epoch[57](1600/2500): Loss: 0.0956
===> Epoch[57](1700/2500): Loss: 0.0953
===> Epoch[57](1800/2500): Loss: 0.1029
===> Epoch[57](1900/2500): Loss: 0.0976
===> Epoch[57](2000/2500): Loss: 0.0959
===> Epoch[57](2100/2500): Loss: 0.0959
===> Epoch[57](2200/2500): Loss: 0.0955
===> Epoch[57](2300/2500): Loss: 0.0959
===> Epoch[57](2400/2500): Loss: 0.0954
===> Epoch[57](2500/2500): Loss: 0.0960
===> Epoch 57 Complete: Avg. Loss: 0.0963
===> Timestamp: [2025-07-29 20:01:25]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.0958
===> Epoch[57](200/2500): Loss: 0.0961
===> Epoch[57](300/2500): Loss: 0.0961
===> Epoch[57](400/2500): Loss: 0.0962
===> Epoch[57](500/2500): Loss: 0.0956
===> Epoch[57](600/2500): Loss: 0.0963
===> Epoch[57](700/2500): Loss: 0.0962
===> Epoch[57](800/2500): Loss: 0.0964
===> Epoch[57](900/2500): Loss: 0.0964
===> Epoch[57](1000/2500): Loss: 0.0957
===> Epoch[57](1100/2500): Loss: 0.0963
===> Epoch[57](1200/2500): Loss: 0.0955
===> Epoch[57](1300/2500): Loss: 0.0958
===> Epoch[57](1400/2500): Loss: 0.0964
===> Epoch[57](1500/2500): Loss: 0.0961
===> Epoch[57](1600/2500): Loss: 0.0956
===> Epoch[57](1700/2500): Loss: 0.0953
===> Epoch[57](1800/2500): Loss: 0.1029
===> Epoch[57](1900/2500): Loss: 0.0976
===> Epoch[57](2000/2500): Loss: 0.0959
===> Epoch[57](2100/2500): Loss: 0.0959
===> Epoch[57](2200/2500): Loss: 0.0955
===> Epoch[57](2300/2500): Loss: 0.0959
===> Epoch[57](2400/2500): Loss: 0.0954
===> Epoch[57](2500/2500): Loss: 0.0960
===> Epoch 57 Complete: Avg. Loss: 0.0963
===> Timestamp: [2025-07-29 20:01:25]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.0958
===> Epoch[57](200/2500): Loss: 0.0961
===> Epoch[57](300/2500): Loss: 0.0961
===> Epoch[57](400/2500): Loss: 0.0962
===> Epoch[57](500/2500): Loss: 0.0956
===> Epoch[57](600/2500): Loss: 0.0963
===> Epoch[57](700/2500): Loss: 0.0962
===> Epoch[57](800/2500): Loss: 0.0964
===> Epoch[57](900/2500): Loss: 0.0964
===> Epoch[57](1000/2500): Loss: 0.0957
===> Epoch[57](1100/2500): Loss: 0.0963
===> Epoch[57](1200/2500): Loss: 0.0955
===> Epoch[57](1300/2500): Loss: 0.0958
===> Epoch[57](1400/2500): Loss: 0.0964
===> Epoch[57](1500/2500): Loss: 0.0961
===> Epoch[57](1600/2500): Loss: 0.0956
===> Epoch[57](1700/2500): Loss: 0.0953
===> Epoch[57](1800/2500): Loss: 0.1029
===> Epoch[57](1900/2500): Loss: 0.0976
===> Epoch[57](2000/2500): Loss: 0.0959
===> Epoch[57](2100/2500): Loss: 0.0959
===> Epoch[57](2200/2500): Loss: 0.0955
===> Epoch[57](2300/2500): Loss: 0.0959
===> Epoch[57](2400/2500): Loss: 0.0954
===> Epoch[57](2500/2500): Loss: 0.0960
===> Epoch 57 Complete: Avg. Loss: 0.0963
===> Timestamp: [2025-07-29 20:01:25]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.0958
===> Epoch[57](200/2500): Loss: 0.0961
===> Epoch[57](300/2500): Loss: 0.0961
===> Epoch[57](400/2500): Loss: 0.0962
===> Epoch[57](500/2500): Loss: 0.0956
===> Epoch[57](600/2500): Loss: 0.0963
===> Epoch[57](700/2500): Loss: 0.0962
===> Epoch[57](800/2500): Loss: 0.0964
===> Epoch[57](900/2500): Loss: 0.0964
===> Epoch[57](1000/2500): Loss: 0.0957
===> Epoch[57](1100/2500): Loss: 0.0963
===> Epoch[57](1200/2500): Loss: 0.0955
===> Epoch[57](1300/2500): Loss: 0.0958
===> Epoch[57](1400/2500): Loss: 0.0964
===> Epoch[57](1500/2500): Loss: 0.0961
===> Epoch[57](1600/2500): Loss: 0.0956
===> Epoch[57](1700/2500): Loss: 0.0953
===> Epoch[57](1800/2500): Loss: 0.1029
===> Epoch[57](1900/2500): Loss: 0.0976
===> Epoch[57](2000/2500): Loss: 0.0959
===> Epoch[57](2100/2500): Loss: 0.0959
===> Epoch[57](2200/2500): Loss: 0.0955
===> Epoch[57](2300/2500): Loss: 0.0959
===> Epoch[57](2400/2500): Loss: 0.0954
===> Epoch[57](2500/2500): Loss: 0.0960
===> Epoch 57 Complete: Avg. Loss: 0.0963
===> Timestamp: [2025-07-29 20:01:25]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.0958
===> Epoch[57](200/2500): Loss: 0.0961
===> Epoch[57](300/2500): Loss: 0.0961
===> Epoch[57](400/2500): Loss: 0.0962
===> Epoch[57](500/2500): Loss: 0.0956
===> Epoch[57](600/2500): Loss: 0.0963
===> Epoch[57](700/2500): Loss: 0.0962
===> Epoch[57](800/2500): Loss: 0.0964
===> Epoch[57](900/2500): Loss: 0.0964
===> Epoch[57](1000/2500): Loss: 0.0957
===> Epoch[57](1100/2500): Loss: 0.0963
===> Epoch[57](1200/2500): Loss: 0.0955
===> Epoch[57](1300/2500): Loss: 0.0958
===> Epoch[57](1400/2500): Loss: 0.0964
===> Epoch[57](1500/2500): Loss: 0.0961
===> Epoch[57](1600/2500): Loss: 0.0956
===> Epoch[57](1700/2500): Loss: 0.0953
===> Epoch[57](1800/2500): Loss: 0.1029
===> Epoch[57](1900/2500): Loss: 0.0976
===> Epoch[57](2000/2500): Loss: 0.0959
===> Epoch[57](2100/2500): Loss: 0.0959
===> Epoch[57](2200/2500): Loss: 0.0955
===> Epoch[57](2300/2500): Loss: 0.0959
===> Epoch[57](2400/2500): Loss: 0.0954
===> Epoch[57](2500/2500): Loss: 0.0960
===> Epoch 57 Complete: Avg. Loss: 0.0963
===> Timestamp: [2025-07-29 20:01:25]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.0958
===> Epoch[57](200/2500): Loss: 0.0961
===> Epoch[57](300/2500): Loss: 0.0961
===> Epoch[57](400/2500): Loss: 0.0962
===> Epoch[57](500/2500): Loss: 0.0956
===> Epoch[57](600/2500): Loss: 0.0963
===> Epoch[57](700/2500): Loss: 0.0962
===> Epoch[57](800/2500): Loss: 0.0964
===> Epoch[57](900/2500): Loss: 0.0964
===> Epoch[57](1000/2500): Loss: 0.0957
===> Epoch[57](1100/2500): Loss: 0.0963
===> Epoch[57](1200/2500): Loss: 0.0955
===> Epoch[57](1300/2500): Loss: 0.0958
===> Epoch[57](1400/2500): Loss: 0.0964
===> Epoch[57](1500/2500): Loss: 0.0961
===> Epoch[57](1600/2500): Loss: 0.0956
===> Epoch[57](1700/2500): Loss: 0.0953
===> Epoch[57](1800/2500): Loss: 0.1029
===> Epoch[57](1900/2500): Loss: 0.0976
===> Epoch[57](2000/2500): Loss: 0.0959
===> Epoch[57](2100/2500): Loss: 0.0959
===> Epoch[57](2200/2500): Loss: 0.0955
===> Epoch[57](2300/2500): Loss: 0.0959
===> Epoch[57](2400/2500): Loss: 0.0954
===> Epoch[57](2500/2500): Loss: 0.0960
===> Epoch 57 Complete: Avg. Loss: 0.0963
===> Timestamp: [2025-07-29 20:01:25]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.0958
===> Epoch[57](200/2500): Loss: 0.0961
===> Epoch[57](300/2500): Loss: 0.0961
===> Epoch[57](400/2500): Loss: 0.0962
===> Epoch[57](500/2500): Loss: 0.0956
===> Epoch[57](600/2500): Loss: 0.0963
===> Epoch[57](700/2500): Loss: 0.0962
===> Epoch[57](800/2500): Loss: 0.0964
===> Epoch[57](900/2500): Loss: 0.0964
===> Epoch[57](1000/2500): Loss: 0.0957
===> Epoch[57](1100/2500): Loss: 0.0963
===> Epoch[57](1200/2500): Loss: 0.0955
===> Epoch[57](1300/2500): Loss: 0.0958
===> Epoch[57](1400/2500): Loss: 0.0964
===> Epoch[57](1500/2500): Loss: 0.0961
===> Epoch[57](1600/2500): Loss: 0.0956
===> Epoch[57](1700/2500): Loss: 0.0953
===> Epoch[57](1800/2500): Loss: 0.1029
===> Epoch[57](1900/2500): Loss: 0.0976
===> Epoch[57](2000/2500): Loss: 0.0959
===> Epoch[57](2100/2500): Loss: 0.0959
===> Epoch[57](2200/2500): Loss: 0.0955
===> Epoch[57](2300/2500): Loss: 0.0959
===> Epoch[57](2400/2500): Loss: 0.0954
===> Epoch[57](2500/2500): Loss: 0.0960
===> Epoch 57 Complete: Avg. Loss: 0.0963
===> Timestamp: [2025-07-29 20:01:25]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.0958
===> Epoch[57](200/2500): Loss: 0.0961
===> Epoch[57](300/2500): Loss: 0.0961
===> Epoch[57](400/2500): Loss: 0.0962
===> Epoch[57](500/2500): Loss: 0.0956
===> Epoch[57](600/2500): Loss: 0.0963
===> Epoch[57](700/2500): Loss: 0.0962
===> Epoch[57](800/2500): Loss: 0.0964
===> Epoch[57](900/2500): Loss: 0.0964
===> Epoch[57](1000/2500): Loss: 0.0957
===> Epoch[57](1100/2500): Loss: 0.0963
===> Epoch[57](1200/2500): Loss: 0.0955
===> Epoch[57](1300/2500): Loss: 0.0958
===> Epoch[57](1400/2500): Loss: 0.0964
===> Epoch[57](1500/2500): Loss: 0.0961
===> Epoch[57](1600/2500): Loss: 0.0956
===> Epoch[57](1700/2500): Loss: 0.0953
===> Epoch[57](1800/2500): Loss: 0.1029
===> Epoch[57](1900/2500): Loss: 0.0976
===> Epoch[57](2000/2500): Loss: 0.0959
===> Epoch[57](2100/2500): Loss: 0.0959
===> Epoch[57](2200/2500): Loss: 0.0955
===> Epoch[57](2300/2500): Loss: 0.0959
===> Epoch[57](2400/2500): Loss: 0.0954
===> Epoch[57](2500/2500): Loss: 0.0960
===> Epoch 57 Complete: Avg. Loss: 0.0963
===> Timestamp: [2025-07-29 20:01:25]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.0958
===> Epoch[57](200/2500): Loss: 0.0961
===> Epoch[57](300/2500): Loss: 0.0961
===> Epoch[57](400/2500): Loss: 0.0962
===> Epoch[57](500/2500): Loss: 0.0956
===> Epoch[57](600/2500): Loss: 0.0963
===> Epoch[57](700/2500): Loss: 0.0962
===> Epoch[57](800/2500): Loss: 0.0964
===> Epoch[57](900/2500): Loss: 0.0964
===> Epoch[57](1000/2500): Loss: 0.0957
===> Epoch[57](1100/2500): Loss: 0.0963
===> Epoch[57](1200/2500): Loss: 0.0955
===> Epoch[57](1300/2500): Loss: 0.0958
===> Epoch[57](1400/2500): Loss: 0.0964
===> Epoch[57](1500/2500): Loss: 0.0961
===> Epoch[57](1600/2500): Loss: 0.0956
===> Epoch[57](1700/2500): Loss: 0.0953
===> Epoch[57](1800/2500): Loss: 0.1029
===> Epoch[57](1900/2500): Loss: 0.0976
===> Epoch[57](2000/2500): Loss: 0.0959
===> Epoch[57](2100/2500): Loss: 0.0959
===> Epoch[57](2200/2500): Loss: 0.0955
===> Epoch[57](2300/2500): Loss: 0.0959
===> Epoch[57](2400/2500): Loss: 0.0954
===> Epoch[57](2500/2500): Loss: 0.0960
===> Epoch 57 Complete: Avg. Loss: 0.0963
===> Timestamp: [2025-07-29 20:01:25]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.0958
===> Epoch[57](200/2500): Loss: 0.0961
===> Epoch[57](300/2500): Loss: 0.0961
===> Epoch[57](400/2500): Loss: 0.0962
===> Epoch[57](500/2500): Loss: 0.0956
===> Epoch[57](600/2500): Loss: 0.0963
===> Epoch[57](700/2500): Loss: 0.0962
===> Epoch[57](800/2500): Loss: 0.0964
===> Epoch[57](900/2500): Loss: 0.0964
===> Epoch[57](1000/2500): Loss: 0.0957
===> Epoch[57](1100/2500): Loss: 0.0963
===> Epoch[57](1200/2500): Loss: 0.0955
===> Epoch[57](1300/2500): Loss: 0.0958
===> Epoch[57](1400/2500): Loss: 0.0964
===> Epoch[57](1500/2500): Loss: 0.0961
===> Epoch[57](1600/2500): Loss: 0.0956
===> Epoch[57](1700/2500): Loss: 0.0953
===> Epoch[57](1800/2500): Loss: 0.1029
===> Epoch[57](1900/2500): Loss: 0.0976
===> Epoch[57](2000/2500): Loss: 0.0959
===> Epoch[57](2100/2500): Loss: 0.0959
===> Epoch[57](2200/2500): Loss: 0.0955
===> Epoch[57](2300/2500): Loss: 0.0959
===> Epoch[57](2400/2500): Loss: 0.0954
===> Epoch[57](2500/2500): Loss: 0.0960
===> Epoch 57 Complete: Avg. Loss: 0.0963
===> Timestamp: [2025-07-29 20:01:25]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.0958
===> Epoch[57](200/2500): Loss: 0.0961
===> Epoch[57](300/2500): Loss: 0.0961
===> Epoch[57](400/2500): Loss: 0.0962
===> Epoch[57](500/2500): Loss: 0.0956
===> Epoch[57](600/2500): Loss: 0.0963
===> Epoch[57](700/2500): Loss: 0.0962
===> Epoch[57](800/2500): Loss: 0.0964
===> Epoch[57](900/2500): Loss: 0.0964
===> Epoch[57](1000/2500): Loss: 0.0957
===> Epoch[57](1100/2500): Loss: 0.0963
===> Epoch[57](1200/2500): Loss: 0.0955
===> Epoch[57](1300/2500): Loss: 0.0958
===> Epoch[57](1400/2500): Loss: 0.0964
===> Epoch[57](1500/2500): Loss: 0.0961
===> Epoch[57](1600/2500): Loss: 0.0956
===> Epoch[57](1700/2500): Loss: 0.0953
===> Epoch[57](1800/2500): Loss: 0.1029
===> Epoch[57](1900/2500): Loss: 0.0976
===> Epoch[57](2000/2500): Loss: 0.0959
===> Epoch[57](2100/2500): Loss: 0.0959
===> Epoch[57](2200/2500): Loss: 0.0955
===> Epoch[57](2300/2500): Loss: 0.0959
===> Epoch[57](2400/2500): Loss: 0.0954
===> Epoch[57](2500/2500): Loss: 0.0960
===> Epoch 57 Complete: Avg. Loss: 0.0963
===> Timestamp: [2025-07-29 20:01:25]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.0958
===> Epoch[57](200/2500): Loss: 0.0961
===> Epoch[57](300/2500): Loss: 0.0961
===> Epoch[57](400/2500): Loss: 0.0962
===> Epoch[57](500/2500): Loss: 0.0956
===> Epoch[57](600/2500): Loss: 0.0963
===> Epoch[57](700/2500): Loss: 0.0962
===> Epoch[57](800/2500): Loss: 0.0964
===> Epoch[57](900/2500): Loss: 0.0964
===> Epoch[57](1000/2500): Loss: 0.0957
===> Epoch[57](1100/2500): Loss: 0.0963
===> Epoch[57](1200/2500): Loss: 0.0955
===> Epoch[57](1300/2500): Loss: 0.0958
===> Epoch[57](1400/2500): Loss: 0.0964
===> Epoch[57](1500/2500): Loss: 0.0961
===> Epoch[57](1600/2500): Loss: 0.0956
===> Epoch[57](1700/2500): Loss: 0.0953
===> Epoch[57](1800/2500): Loss: 0.1029
===> Epoch[57](1900/2500): Loss: 0.0976
===> Epoch[57](2000/2500): Loss: 0.0959
===> Epoch[57](2100/2500): Loss: 0.0959
===> Epoch[57](2200/2500): Loss: 0.0955
===> Epoch[57](2300/2500): Loss: 0.0959
===> Epoch[57](2400/2500): Loss: 0.0954
===> Epoch[57](2500/2500): Loss: 0.0960
===> Epoch 57 Complete: Avg. Loss: 0.0963
===> Timestamp: [2025-07-29 20:01:25]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.0958
===> Epoch[57](200/2500): Loss: 0.0961
===> Epoch[57](300/2500): Loss: 0.0961
===> Epoch[57](400/2500): Loss: 0.0962
===> Epoch[57](500/2500): Loss: 0.0956
===> Epoch[57](600/2500): Loss: 0.0963
===> Epoch[57](700/2500): Loss: 0.0962
===> Epoch[57](800/2500): Loss: 0.0964
===> Epoch[57](900/2500): Loss: 0.0964
===> Epoch[57](1000/2500): Loss: 0.0957
===> Epoch[57](1100/2500): Loss: 0.0963
===> Epoch[57](1200/2500): Loss: 0.0955
===> Epoch[57](1300/2500): Loss: 0.0958
===> Epoch[57](1400/2500): Loss: 0.0964
===> Epoch[57](1500/2500): Loss: 0.0961
===> Epoch[57](1600/2500): Loss: 0.0956
===> Epoch[57](1700/2500): Loss: 0.0953
===> Epoch[57](1800/2500): Loss: 0.1029
===> Epoch[57](1900/2500): Loss: 0.0976
===> Epoch[57](2000/2500): Loss: 0.0959
===> Epoch[57](2100/2500): Loss: 0.0959
===> Epoch[57](2200/2500): Loss: 0.0955
===> Epoch[57](2300/2500): Loss: 0.0959
===> Epoch[57](2400/2500): Loss: 0.0954
===> Epoch[57](2500/2500): Loss: 0.0960
===> Epoch 57 Complete: Avg. Loss: 0.0963
===> Timestamp: [2025-07-29 20:01:25]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.0958
===> Epoch[57](200/2500): Loss: 0.0961
===> Epoch[57](300/2500): Loss: 0.0961
===> Epoch[57](400/2500): Loss: 0.0962
===> Epoch[57](500/2500): Loss: 0.0956
===> Epoch[57](600/2500): Loss: 0.0963
===> Epoch[57](700/2500): Loss: 0.0962
===> Epoch[57](800/2500): Loss: 0.0964
===> Epoch[57](900/2500): Loss: 0.0964
===> Epoch[57](1000/2500): Loss: 0.0957
===> Epoch[57](1100/2500): Loss: 0.0963
===> Epoch[57](1200/2500): Loss: 0.0955
===> Epoch[57](1300/2500): Loss: 0.0958
===> Epoch[57](1400/2500): Loss: 0.0964
===> Epoch[57](1500/2500): Loss: 0.0961
===> Epoch[57](1600/2500): Loss: 0.0956
===> Epoch[57](1700/2500): Loss: 0.0953
===> Epoch[57](1800/2500): Loss: 0.1029
===> Epoch[57](1900/2500): Loss: 0.0976
===> Epoch[57](2000/2500): Loss: 0.0959
===> Epoch[57](2100/2500): Loss: 0.0959
===> Epoch[57](2200/2500): Loss: 0.0955
===> Epoch[57](2300/2500): Loss: 0.0959
===> Epoch[57](2400/2500): Loss: 0.0954
===> Epoch[57](2500/2500): Loss: 0.0960
===> Epoch 57 Complete: Avg. Loss: 0.0963
===> Timestamp: [2025-07-29 20:01:25]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.0958
===> Epoch[57](200/2500): Loss: 0.0961
===> Epoch[57](300/2500): Loss: 0.0961
===> Epoch[57](400/2500): Loss: 0.0962
===> Epoch[57](500/2500): Loss: 0.0956
===> Epoch[57](600/2500): Loss: 0.0963
===> Epoch[57](700/2500): Loss: 0.0962
===> Epoch[57](800/2500): Loss: 0.0964
===> Epoch[57](900/2500): Loss: 0.0964
===> Epoch[57](1000/2500): Loss: 0.0957
===> Epoch[57](1100/2500): Loss: 0.0963
===> Epoch[57](1200/2500): Loss: 0.0955
===> Epoch[57](1300/2500): Loss: 0.0958
===> Epoch[57](1400/2500): Loss: 0.0964
===> Epoch[57](1500/2500): Loss: 0.0961
===> Epoch[57](1600/2500): Loss: 0.0956
===> Epoch[57](1700/2500): Loss: 0.0953
===> Epoch[57](1800/2500): Loss: 0.1029
===> Epoch[57](1900/2500): Loss: 0.0976
===> Epoch[57](2000/2500): Loss: 0.0959
===> Epoch[57](2100/2500): Loss: 0.0959
===> Epoch[57](2200/2500): Loss: 0.0955
===> Epoch[57](2300/2500): Loss: 0.0959
===> Epoch[57](2400/2500): Loss: 0.0954
===> Epoch[57](2500/2500): Loss: 0.0960
===> Epoch 57 Complete: Avg. Loss: 0.0963
===> Timestamp: [2025-07-29 20:01:25]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.0958
===> Epoch[57](200/2500): Loss: 0.0961
===> Epoch[57](300/2500): Loss: 0.0961
===> Epoch[57](400/2500): Loss: 0.0962
===> Epoch[57](500/2500): Loss: 0.0956
===> Epoch[57](600/2500): Loss: 0.0963
===> Epoch[57](700/2500): Loss: 0.0962
===> Epoch[57](800/2500): Loss: 0.0964
===> Epoch[57](900/2500): Loss: 0.0964
===> Epoch[57](1000/2500): Loss: 0.0957
===> Epoch[57](1100/2500): Loss: 0.0963
===> Epoch[57](1200/2500): Loss: 0.0955
===> Epoch[57](1300/2500): Loss: 0.0958
===> Epoch[57](1400/2500): Loss: 0.0964
===> Epoch[57](1500/2500): Loss: 0.0961
===> Epoch[57](1600/2500): Loss: 0.0956
===> Epoch[57](1700/2500): Loss: 0.0953
===> Epoch[57](1800/2500): Loss: 0.1029
===> Epoch[57](1900/2500): Loss: 0.0976
===> Epoch[57](2000/2500): Loss: 0.0959
===> Epoch[57](2100/2500): Loss: 0.0959
===> Epoch[57](2200/2500): Loss: 0.0955
===> Epoch[57](2300/2500): Loss: 0.0959
===> Epoch[57](2400/2500): Loss: 0.0954
===> Epoch[57](2500/2500): Loss: 0.0960
===> Epoch 57 Complete: Avg. Loss: 0.0963
===> Timestamp: [2025-07-29 20:01:25]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.0958
===> Epoch[57](200/2500): Loss: 0.0961
===> Epoch[57](300/2500): Loss: 0.0961
===> Epoch[57](400/2500): Loss: 0.0962
===> Epoch[57](500/2500): Loss: 0.0956
===> Epoch[57](600/2500): Loss: 0.0963
===> Epoch[57](700/2500): Loss: 0.0962
===> Epoch[57](800/2500): Loss: 0.0964
===> Epoch[57](900/2500): Loss: 0.0964
===> Epoch[57](1000/2500): Loss: 0.0957
===> Epoch[57](1100/2500): Loss: 0.0963
===> Epoch[57](1200/2500): Loss: 0.0955
===> Epoch[57](1300/2500): Loss: 0.0958
===> Epoch[57](1400/2500): Loss: 0.0964
===> Epoch[57](1500/2500): Loss: 0.0961
===> Epoch[57](1600/2500): Loss: 0.0956
===> Epoch[57](1700/2500): Loss: 0.0953
===> Epoch[57](1800/2500): Loss: 0.1029
===> Epoch[57](1900/2500): Loss: 0.0976
===> Epoch[57](2000/2500): Loss: 0.0959
===> Epoch[57](2100/2500): Loss: 0.0959
===> Epoch[57](2200/2500): Loss: 0.0955
===> Epoch[57](2300/2500): Loss: 0.0959
===> Epoch[57](2400/2500): Loss: 0.0954
===> Epoch[57](2500/2500): Loss: 0.0960
===> Epoch 57 Complete: Avg. Loss: 0.0963
===> Timestamp: [2025-07-29 20:01:25]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.0958
===> Epoch[57](200/2500): Loss: 0.0961
===> Epoch[57](300/2500): Loss: 0.0961
===> Epoch[57](400/2500): Loss: 0.0962
===> Epoch[57](500/2500): Loss: 0.0956
===> Epoch[57](600/2500): Loss: 0.0963
===> Epoch[57](700/2500): Loss: 0.0962
===> Epoch[57](800/2500): Loss: 0.0964
===> Epoch[57](900/2500): Loss: 0.0964
===> Epoch[57](1000/2500): Loss: 0.0957
===> Epoch[57](1100/2500): Loss: 0.0963
===> Epoch[57](1200/2500): Loss: 0.0955
===> Epoch[57](1300/2500): Loss: 0.0958
===> Epoch[57](1400/2500): Loss: 0.0964
===> Epoch[57](1500/2500): Loss: 0.0961
===> Epoch[57](1600/2500): Loss: 0.0956
===> Epoch[57](1700/2500): Loss: 0.0953
===> Epoch[57](1800/2500): Loss: 0.1029
===> Epoch[57](1900/2500): Loss: 0.0976
===> Epoch[57](2000/2500): Loss: 0.0959
===> Epoch[57](2100/2500): Loss: 0.0959
===> Epoch[57](2200/2500): Loss: 0.0955
===> Epoch[57](2300/2500): Loss: 0.0959
===> Epoch[57](2400/2500): Loss: 0.0954
===> Epoch[57](2500/2500): Loss: 0.0960
===> Epoch 57 Complete: Avg. Loss: 0.0963
===> Timestamp: [2025-07-29 20:01:25]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.0958
===> Epoch[57](200/2500): Loss: 0.0961
===> Epoch[57](300/2500): Loss: 0.0961
===> Epoch[57](400/2500): Loss: 0.0962
===> Epoch[57](500/2500): Loss: 0.0956
===> Epoch[57](600/2500): Loss: 0.0963
===> Epoch[57](700/2500): Loss: 0.0962
===> Epoch[57](800/2500): Loss: 0.0964
===> Epoch[57](900/2500): Loss: 0.0964
===> Epoch[57](1000/2500): Loss: 0.0957
===> Epoch[57](1100/2500): Loss: 0.0963
===> Epoch[57](1200/2500): Loss: 0.0955
===> Epoch[57](1300/2500): Loss: 0.0958
===> Epoch[57](1400/2500): Loss: 0.0964
===> Epoch[57](1500/2500): Loss: 0.0961
===> Epoch[57](1600/2500): Loss: 0.0956
===> Epoch[57](1700/2500): Loss: 0.0953
===> Epoch[57](1800/2500): Loss: 0.1029
===> Epoch[57](1900/2500): Loss: 0.0976
===> Epoch[57](2000/2500): Loss: 0.0959
===> Epoch[57](2100/2500): Loss: 0.0959
===> Epoch[57](2200/2500): Loss: 0.0955
===> Epoch[57](2300/2500): Loss: 0.0959
===> Epoch[57](2400/2500): Loss: 0.0954
===> Epoch[57](2500/2500): Loss: 0.0960
===> Epoch 57 Complete: Avg. Loss: 0.0963
===> Timestamp: [2025-07-29 20:01:25]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.0958
===> Epoch[57](200/2500): Loss: 0.0961
===> Epoch[57](300/2500): Loss: 0.0961
===> Epoch[57](400/2500): Loss: 0.0962
===> Epoch[57](500/2500): Loss: 0.0956
===> Epoch[57](600/2500): Loss: 0.0963
===> Epoch[57](700/2500): Loss: 0.0962
===> Epoch[57](800/2500): Loss: 0.0964
===> Epoch[57](900/2500): Loss: 0.0964
===> Epoch[57](1000/2500): Loss: 0.0957
===> Epoch[57](1100/2500): Loss: 0.0963
===> Epoch[57](1200/2500): Loss: 0.0955
===> Epoch[57](1300/2500): Loss: 0.0958
===> Epoch[57](1400/2500): Loss: 0.0964
===> Epoch[57](1500/2500): Loss: 0.0961
===> Epoch[57](1600/2500): Loss: 0.0956
===> Epoch[57](1700/2500): Loss: 0.0953
===> Epoch[57](1800/2500): Loss: 0.1029
===> Epoch[57](1900/2500): Loss: 0.0976
===> Epoch[57](2000/2500): Loss: 0.0959
===> Epoch[57](2100/2500): Loss: 0.0959
===> Epoch[57](2200/2500): Loss: 0.0955
===> Epoch[57](2300/2500): Loss: 0.0959
===> Epoch[57](2400/2500): Loss: 0.0954
===> Epoch[57](2500/2500): Loss: 0.0960
===> Epoch 57 Complete: Avg. Loss: 0.0963
===> Timestamp: [2025-07-29 20:01:25]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.0958
===> Epoch[57](200/2500): Loss: 0.0961
===> Epoch[57](300/2500): Loss: 0.0961
===> Epoch[57](400/2500): Loss: 0.0962
===> Epoch[57](500/2500): Loss: 0.0956
===> Epoch[57](600/2500): Loss: 0.0963
===> Epoch[57](700/2500): Loss: 0.0962
===> Epoch[57](800/2500): Loss: 0.0964
===> Epoch[57](900/2500): Loss: 0.0964
===> Epoch[57](1000/2500): Loss: 0.0957
===> Epoch[57](1100/2500): Loss: 0.0963
===> Epoch[57](1200/2500): Loss: 0.0955
===> Epoch[57](1300/2500): Loss: 0.0958
===> Epoch[57](1400/2500): Loss: 0.0964
===> Epoch[57](1500/2500): Loss: 0.0961
===> Epoch[57](1600/2500): Loss: 0.0956
===> Epoch[57](1700/2500): Loss: 0.0953
===> Epoch[57](1800/2500): Loss: 0.1029
===> Epoch[57](1900/2500): Loss: 0.0976
===> Epoch[57](2000/2500): Loss: 0.0959
===> Epoch[57](2100/2500): Loss: 0.0959
===> Epoch[57](2200/2500): Loss: 0.0955
===> Epoch[57](2300/2500): Loss: 0.0959
===> Epoch[57](2400/2500): Loss: 0.0954
===> Epoch[57](2500/2500): Loss: 0.0960
===> Epoch 57 Complete: Avg. Loss: 0.0963
===> Timestamp: [2025-07-29 20:01:25]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.0958
===> Epoch[57](200/2500): Loss: 0.0961
===> Epoch[57](300/2500): Loss: 0.0961
===> Epoch[57](400/2500): Loss: 0.0962
===> Epoch[57](500/2500): Loss: 0.0956
===> Epoch[57](600/2500): Loss: 0.0963
===> Epoch[57](700/2500): Loss: 0.0962
===> Epoch[57](800/2500): Loss: 0.0964
===> Epoch[57](900/2500): Loss: 0.0964
===> Epoch[57](1000/2500): Loss: 0.0957
===> Epoch[57](1100/2500): Loss: 0.0963
===> Epoch[57](1200/2500): Loss: 0.0955
===> Epoch[57](1300/2500): Loss: 0.0958
===> Epoch[57](1400/2500): Loss: 0.0964
===> Epoch[57](1500/2500): Loss: 0.0961
===> Epoch[57](1600/2500): Loss: 0.0956
===> Epoch[57](1700/2500): Loss: 0.0953
===> Epoch[57](1800/2500): Loss: 0.1029
===> Epoch[57](1900/2500): Loss: 0.0976
===> Epoch[57](2000/2500): Loss: 0.0959
===> Epoch[57](2100/2500): Loss: 0.0959
===> Epoch[57](2200/2500): Loss: 0.0955
===> Epoch[57](2300/2500): Loss: 0.0959
===> Epoch[57](2400/2500): Loss: 0.0954
===> Epoch[57](2500/2500): Loss: 0.0960
===> Epoch 57 Complete: Avg. Loss: 0.0963
===> Timestamp: [2025-07-29 20:01:25]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.0958
===> Epoch[57](200/2500): Loss: 0.0961
===> Epoch[57](300/2500): Loss: 0.0961
===> Epoch[57](400/2500): Loss: 0.0962
===> Epoch[57](500/2500): Loss: 0.0956
===> Epoch[57](600/2500): Loss: 0.0963
===> Epoch[57](700/2500): Loss: 0.0962
===> Epoch[57](800/2500): Loss: 0.0964
===> Epoch[57](900/2500): Loss: 0.0964
===> Epoch[57](1000/2500): Loss: 0.0957
===> Epoch[57](1100/2500): Loss: 0.0963
===> Epoch[57](1200/2500): Loss: 0.0955
===> Epoch[57](1300/2500): Loss: 0.0958
===> Epoch[57](1400/2500): Loss: 0.0964
===> Epoch[57](1500/2500): Loss: 0.0961
===> Epoch[57](1600/2500): Loss: 0.0956
===> Epoch[57](1700/2500): Loss: 0.0953
===> Epoch[57](1800/2500): Loss: 0.1029
===> Epoch[57](1900/2500): Loss: 0.0976
===> Epoch[57](2000/2500): Loss: 0.0959
===> Epoch[57](2100/2500): Loss: 0.0959
===> Epoch[57](2200/2500): Loss: 0.0955
===> Epoch[57](2300/2500): Loss: 0.0959
===> Epoch[57](2400/2500): Loss: 0.0954
===> Epoch[57](2500/2500): Loss: 0.0960
===> Epoch 57 Complete: Avg. Loss: 0.0963
===> Timestamp: [2025-07-29 20:01:25]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.0958
===> Epoch[57](200/2500): Loss: 0.0961
===> Epoch[57](300/2500): Loss: 0.0961
===> Epoch[57](400/2500): Loss: 0.0962
===> Epoch[57](500/2500): Loss: 0.0956
===> Epoch[57](600/2500): Loss: 0.0963
===> Epoch[57](700/2500): Loss: 0.0962
===> Epoch[57](800/2500): Loss: 0.0964
===> Epoch[57](900/2500): Loss: 0.0964
===> Epoch[57](1000/2500): Loss: 0.0957
===> Epoch[57](1100/2500): Loss: 0.0963
===> Epoch[57](1200/2500): Loss: 0.0955
===> Epoch[57](1300/2500): Loss: 0.0958
===> Epoch[57](1400/2500): Loss: 0.0964
===> Epoch[57](1500/2500): Loss: 0.0961
===> Epoch[57](1600/2500): Loss: 0.0956
===> Epoch[57](1700/2500): Loss: 0.0953
===> Epoch[57](1800/2500): Loss: 0.1029
===> Epoch[57](1900/2500): Loss: 0.0976
===> Epoch[57](2000/2500): Loss: 0.0959
===> Epoch[57](2100/2500): Loss: 0.0959
===> Epoch[57](2200/2500): Loss: 0.0955
===> Epoch[57](2300/2500): Loss: 0.0959
===> Epoch[57](2400/2500): Loss: 0.0954
===> Epoch[57](2500/2500): Loss: 0.0960
===> Epoch 57 Complete: Avg. Loss: 0.0963
===> Timestamp: [2025-07-29 20:01:25]
===> Loading train datasets
===> Epoch[57](100/2500): Loss: 0.0958
===> Epoch[57](200/2500): Loss: 0.0961
===> Epoch[57](300/2500): Loss: 0.0961
===> Epoch[57](400/2500): Loss: 0.0962
===> Epoch[57](500/2500): Loss: 0.0956
===> Epoch[57](600/2500): Loss: 0.0963
===> Epoch[57](700/2500): Loss: 0.0962
===> Epoch[57](800/2500): Loss: 0.0964
===> Epoch[57](900/2500): Loss: 0.0964
===> Epoch[57](1000/2500): Loss: 0.0957
===> Epoch[57](1100/2500): Loss: 0.0963
===> Epoch[57](1200/2500): Loss: 0.0955
===> Epoch[57](1300/2500): Loss: 0.0958
===> Epoch[57](1400/2500): Loss: 0.0964
===> Epoch[57](1500/2500): Loss: 0.0961
===> Epoch[57](1600/2500): Loss: 0.0956
===> Epoch[57](1700/2500): Loss: 0.0953
===> Epoch[57](1800/2500): Loss: 0.1029
===> Epoch[57](1900/2500): Loss: 0.0976
===> Epoch[57](2000/2500): Loss: 0.0959
===> Epoch[57](2100/2500): Loss: 0.0959
===> Epoch[57](2200/2500): Loss: 0.0955
===> Epoch[57](2300/2500): Loss: 0.0959
===> Epoch[57](2400/2500): Loss: 0.0954
===> Epoch[57](2500/2500): Loss: 0.0960
===> Epoch 57 Complete: Avg. Loss: 0.0963
===> Timestamp: [2025-07-29 20:01:25]
===> Loading train datasets
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.0959
===> Epoch[58](200/2500): Loss: 0.0958
===> Epoch[58](300/2500): Loss: 0.0959
===> Epoch[58](400/2500): Loss: 0.0953
===> Epoch[58](500/2500): Loss: 0.0955
===> Epoch[58](600/2500): Loss: 0.0957
===> Epoch[58](700/2500): Loss: 0.0962
===> Epoch[58](800/2500): Loss: 0.0958
===> Epoch[58](900/2500): Loss: 0.0960
===> Epoch[58](1000/2500): Loss: 0.0954
===> Epoch[58](1100/2500): Loss: 0.0953
===> Epoch[58](1200/2500): Loss: 0.0958
===> Epoch[58](1300/2500): Loss: 0.0957
===> Epoch[58](1400/2500): Loss: 0.0956
===> Epoch[58](1500/2500): Loss: 0.0960
===> Epoch[58](1600/2500): Loss: 0.0961
===> Epoch[58](1700/2500): Loss: 0.0952
===> Epoch[58](1800/2500): Loss: 0.0960
===> Epoch[58](1900/2500): Loss: 0.0955
===> Epoch[58](2000/2500): Loss: 0.0959
===> Epoch[58](2100/2500): Loss: 0.0959
===> Epoch[58](2200/2500): Loss: 0.0958
===> Epoch[58](2300/2500): Loss: 0.0957
===> Epoch[58](2400/2500): Loss: 0.0953
===> Epoch[58](2500/2500): Loss: 0.0958
===> Epoch 58 Complete: Avg. Loss: 0.0957
===> Timestamp: [2025-07-29 20:06:29]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.0959
===> Epoch[58](200/2500): Loss: 0.0958
===> Epoch[58](300/2500): Loss: 0.0959
===> Epoch[58](400/2500): Loss: 0.0953
===> Epoch[58](500/2500): Loss: 0.0955
===> Epoch[58](600/2500): Loss: 0.0957
===> Epoch[58](700/2500): Loss: 0.0962
===> Epoch[58](800/2500): Loss: 0.0958
===> Epoch[58](900/2500): Loss: 0.0960
===> Epoch[58](1000/2500): Loss: 0.0954
===> Epoch[58](1100/2500): Loss: 0.0953
===> Epoch[58](1200/2500): Loss: 0.0958
===> Epoch[58](1300/2500): Loss: 0.0957
===> Epoch[58](1400/2500): Loss: 0.0956
===> Epoch[58](1500/2500): Loss: 0.0960
===> Epoch[58](1600/2500): Loss: 0.0961
===> Epoch[58](1700/2500): Loss: 0.0952
===> Epoch[58](1800/2500): Loss: 0.0960
===> Epoch[58](1900/2500): Loss: 0.0955
===> Epoch[58](2000/2500): Loss: 0.0959
===> Epoch[58](2100/2500): Loss: 0.0959
===> Epoch[58](2200/2500): Loss: 0.0958
===> Epoch[58](2300/2500): Loss: 0.0957
===> Epoch[58](2400/2500): Loss: 0.0953
===> Epoch[58](2500/2500): Loss: 0.0958
===> Epoch 58 Complete: Avg. Loss: 0.0957
===> Timestamp: [2025-07-29 20:06:29]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.0959
===> Epoch[58](200/2500): Loss: 0.0958
===> Epoch[58](300/2500): Loss: 0.0959
===> Epoch[58](400/2500): Loss: 0.0953
===> Epoch[58](500/2500): Loss: 0.0955
===> Epoch[58](600/2500): Loss: 0.0957
===> Epoch[58](700/2500): Loss: 0.0962
===> Epoch[58](800/2500): Loss: 0.0958
===> Epoch[58](900/2500): Loss: 0.0960
===> Epoch[58](1000/2500): Loss: 0.0954
===> Epoch[58](1100/2500): Loss: 0.0953
===> Epoch[58](1200/2500): Loss: 0.0958
===> Epoch[58](1300/2500): Loss: 0.0957
===> Epoch[58](1400/2500): Loss: 0.0956
===> Epoch[58](1500/2500): Loss: 0.0960
===> Epoch[58](1600/2500): Loss: 0.0961
===> Epoch[58](1700/2500): Loss: 0.0952
===> Epoch[58](1800/2500): Loss: 0.0960
===> Epoch[58](1900/2500): Loss: 0.0955
===> Epoch[58](2000/2500): Loss: 0.0959
===> Epoch[58](2100/2500): Loss: 0.0959
===> Epoch[58](2200/2500): Loss: 0.0958
===> Epoch[58](2300/2500): Loss: 0.0957
===> Epoch[58](2400/2500): Loss: 0.0953
===> Epoch[58](2500/2500): Loss: 0.0958
===> Epoch 58 Complete: Avg. Loss: 0.0957
===> Timestamp: [2025-07-29 20:06:29]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.0959
===> Epoch[58](200/2500): Loss: 0.0958
===> Epoch[58](300/2500): Loss: 0.0959
===> Epoch[58](400/2500): Loss: 0.0953
===> Epoch[58](500/2500): Loss: 0.0955
===> Epoch[58](600/2500): Loss: 0.0957
===> Epoch[58](700/2500): Loss: 0.0962
===> Epoch[58](800/2500): Loss: 0.0958
===> Epoch[58](900/2500): Loss: 0.0960
===> Epoch[58](1000/2500): Loss: 0.0954
===> Epoch[58](1100/2500): Loss: 0.0953
===> Epoch[58](1200/2500): Loss: 0.0958
===> Epoch[58](1300/2500): Loss: 0.0957
===> Epoch[58](1400/2500): Loss: 0.0956
===> Epoch[58](1500/2500): Loss: 0.0960
===> Epoch[58](1600/2500): Loss: 0.0961
===> Epoch[58](1700/2500): Loss: 0.0952
===> Epoch[58](1800/2500): Loss: 0.0960
===> Epoch[58](1900/2500): Loss: 0.0955
===> Epoch[58](2000/2500): Loss: 0.0959
===> Epoch[58](2100/2500): Loss: 0.0959
===> Epoch[58](2200/2500): Loss: 0.0958
===> Epoch[58](2300/2500): Loss: 0.0957
===> Epoch[58](2400/2500): Loss: 0.0953
===> Epoch[58](2500/2500): Loss: 0.0958
===> Epoch 58 Complete: Avg. Loss: 0.0957
===> Timestamp: [2025-07-29 20:06:29]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.0959
===> Epoch[58](200/2500): Loss: 0.0958
===> Epoch[58](300/2500): Loss: 0.0959
===> Epoch[58](400/2500): Loss: 0.0953
===> Epoch[58](500/2500): Loss: 0.0955
===> Epoch[58](600/2500): Loss: 0.0957
===> Epoch[58](700/2500): Loss: 0.0962
===> Epoch[58](800/2500): Loss: 0.0958
===> Epoch[58](900/2500): Loss: 0.0960
===> Epoch[58](1000/2500): Loss: 0.0954
===> Epoch[58](1100/2500): Loss: 0.0953
===> Epoch[58](1200/2500): Loss: 0.0958
===> Epoch[58](1300/2500): Loss: 0.0957
===> Epoch[58](1400/2500): Loss: 0.0956
===> Epoch[58](1500/2500): Loss: 0.0960
===> Epoch[58](1600/2500): Loss: 0.0961
===> Epoch[58](1700/2500): Loss: 0.0952
===> Epoch[58](1800/2500): Loss: 0.0960
===> Epoch[58](1900/2500): Loss: 0.0955
===> Epoch[58](2000/2500): Loss: 0.0959
===> Epoch[58](2100/2500): Loss: 0.0959
===> Epoch[58](2200/2500): Loss: 0.0958
===> Epoch[58](2300/2500): Loss: 0.0957
===> Epoch[58](2400/2500): Loss: 0.0953
===> Epoch[58](2500/2500): Loss: 0.0958
===> Epoch 58 Complete: Avg. Loss: 0.0957
===> Timestamp: [2025-07-29 20:06:29]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.0959
===> Epoch[58](200/2500): Loss: 0.0958
===> Epoch[58](300/2500): Loss: 0.0959
===> Epoch[58](400/2500): Loss: 0.0953
===> Epoch[58](500/2500): Loss: 0.0955
===> Epoch[58](600/2500): Loss: 0.0957
===> Epoch[58](700/2500): Loss: 0.0962
===> Epoch[58](800/2500): Loss: 0.0958
===> Epoch[58](900/2500): Loss: 0.0960
===> Epoch[58](1000/2500): Loss: 0.0954
===> Epoch[58](1100/2500): Loss: 0.0953
===> Epoch[58](1200/2500): Loss: 0.0958
===> Epoch[58](1300/2500): Loss: 0.0957
===> Epoch[58](1400/2500): Loss: 0.0956
===> Epoch[58](1500/2500): Loss: 0.0960
===> Epoch[58](1600/2500): Loss: 0.0961
===> Epoch[58](1700/2500): Loss: 0.0952
===> Epoch[58](1800/2500): Loss: 0.0960
===> Epoch[58](1900/2500): Loss: 0.0955
===> Epoch[58](2000/2500): Loss: 0.0959
===> Epoch[58](2100/2500): Loss: 0.0959
===> Epoch[58](2200/2500): Loss: 0.0958
===> Epoch[58](2300/2500): Loss: 0.0957
===> Epoch[58](2400/2500): Loss: 0.0953
===> Epoch[58](2500/2500): Loss: 0.0958
===> Epoch 58 Complete: Avg. Loss: 0.0957
===> Timestamp: [2025-07-29 20:06:29]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.0959
===> Epoch[58](200/2500): Loss: 0.0958
===> Epoch[58](300/2500): Loss: 0.0959
===> Epoch[58](400/2500): Loss: 0.0953
===> Epoch[58](500/2500): Loss: 0.0955
===> Epoch[58](600/2500): Loss: 0.0957
===> Epoch[58](700/2500): Loss: 0.0962
===> Epoch[58](800/2500): Loss: 0.0958
===> Epoch[58](900/2500): Loss: 0.0960
===> Epoch[58](1000/2500): Loss: 0.0954
===> Epoch[58](1100/2500): Loss: 0.0953
===> Epoch[58](1200/2500): Loss: 0.0958
===> Epoch[58](1300/2500): Loss: 0.0957
===> Epoch[58](1400/2500): Loss: 0.0956
===> Epoch[58](1500/2500): Loss: 0.0960
===> Epoch[58](1600/2500): Loss: 0.0961
===> Epoch[58](1700/2500): Loss: 0.0952
===> Epoch[58](1800/2500): Loss: 0.0960
===> Epoch[58](1900/2500): Loss: 0.0955
===> Epoch[58](2000/2500): Loss: 0.0959
===> Epoch[58](2100/2500): Loss: 0.0959
===> Epoch[58](2200/2500): Loss: 0.0958
===> Epoch[58](2300/2500): Loss: 0.0957
===> Epoch[58](2400/2500): Loss: 0.0953
===> Epoch[58](2500/2500): Loss: 0.0958
===> Epoch 58 Complete: Avg. Loss: 0.0957
===> Timestamp: [2025-07-29 20:06:29]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.0959
===> Epoch[58](200/2500): Loss: 0.0958
===> Epoch[58](300/2500): Loss: 0.0959
===> Epoch[58](400/2500): Loss: 0.0953
===> Epoch[58](500/2500): Loss: 0.0955
===> Epoch[58](600/2500): Loss: 0.0957
===> Epoch[58](700/2500): Loss: 0.0962
===> Epoch[58](800/2500): Loss: 0.0958
===> Epoch[58](900/2500): Loss: 0.0960
===> Epoch[58](1000/2500): Loss: 0.0954
===> Epoch[58](1100/2500): Loss: 0.0953
===> Epoch[58](1200/2500): Loss: 0.0958
===> Epoch[58](1300/2500): Loss: 0.0957
===> Epoch[58](1400/2500): Loss: 0.0956
===> Epoch[58](1500/2500): Loss: 0.0960
===> Epoch[58](1600/2500): Loss: 0.0961
===> Epoch[58](1700/2500): Loss: 0.0952
===> Epoch[58](1800/2500): Loss: 0.0960
===> Epoch[58](1900/2500): Loss: 0.0955
===> Epoch[58](2000/2500): Loss: 0.0959
===> Epoch[58](2100/2500): Loss: 0.0959
===> Epoch[58](2200/2500): Loss: 0.0958
===> Epoch[58](2300/2500): Loss: 0.0957
===> Epoch[58](2400/2500): Loss: 0.0953
===> Epoch[58](2500/2500): Loss: 0.0958
===> Epoch 58 Complete: Avg. Loss: 0.0957
===> Timestamp: [2025-07-29 20:06:29]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.0959
===> Epoch[58](200/2500): Loss: 0.0958
===> Epoch[58](300/2500): Loss: 0.0959
===> Epoch[58](400/2500): Loss: 0.0953
===> Epoch[58](500/2500): Loss: 0.0955
===> Epoch[58](600/2500): Loss: 0.0957
===> Epoch[58](700/2500): Loss: 0.0962
===> Epoch[58](800/2500): Loss: 0.0958
===> Epoch[58](900/2500): Loss: 0.0960
===> Epoch[58](1000/2500): Loss: 0.0954
===> Epoch[58](1100/2500): Loss: 0.0953
===> Epoch[58](1200/2500): Loss: 0.0958
===> Epoch[58](1300/2500): Loss: 0.0957
===> Epoch[58](1400/2500): Loss: 0.0956
===> Epoch[58](1500/2500): Loss: 0.0960
===> Epoch[58](1600/2500): Loss: 0.0961
===> Epoch[58](1700/2500): Loss: 0.0952
===> Epoch[58](1800/2500): Loss: 0.0960
===> Epoch[58](1900/2500): Loss: 0.0955
===> Epoch[58](2000/2500): Loss: 0.0959
===> Epoch[58](2100/2500): Loss: 0.0959
===> Epoch[58](2200/2500): Loss: 0.0958
===> Epoch[58](2300/2500): Loss: 0.0957
===> Epoch[58](2400/2500): Loss: 0.0953
===> Epoch[58](2500/2500): Loss: 0.0958
===> Epoch 58 Complete: Avg. Loss: 0.0957
===> Timestamp: [2025-07-29 20:06:29]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.0959
===> Epoch[58](200/2500): Loss: 0.0958
===> Epoch[58](300/2500): Loss: 0.0959
===> Epoch[58](400/2500): Loss: 0.0953
===> Epoch[58](500/2500): Loss: 0.0955
===> Epoch[58](600/2500): Loss: 0.0957
===> Epoch[58](700/2500): Loss: 0.0962
===> Epoch[58](800/2500): Loss: 0.0958
===> Epoch[58](900/2500): Loss: 0.0960
===> Epoch[58](1000/2500): Loss: 0.0954
===> Epoch[58](1100/2500): Loss: 0.0953
===> Epoch[58](1200/2500): Loss: 0.0958
===> Epoch[58](1300/2500): Loss: 0.0957
===> Epoch[58](1400/2500): Loss: 0.0956
===> Epoch[58](1500/2500): Loss: 0.0960
===> Epoch[58](1600/2500): Loss: 0.0961
===> Epoch[58](1700/2500): Loss: 0.0952
===> Epoch[58](1800/2500): Loss: 0.0960
===> Epoch[58](1900/2500): Loss: 0.0955
===> Epoch[58](2000/2500): Loss: 0.0959
===> Epoch[58](2100/2500): Loss: 0.0959
===> Epoch[58](2200/2500): Loss: 0.0958
===> Epoch[58](2300/2500): Loss: 0.0957
===> Epoch[58](2400/2500): Loss: 0.0953
===> Epoch[58](2500/2500): Loss: 0.0958
===> Epoch 58 Complete: Avg. Loss: 0.0957
===> Timestamp: [2025-07-29 20:06:29]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.0959
===> Epoch[58](200/2500): Loss: 0.0958
===> Epoch[58](300/2500): Loss: 0.0959
===> Epoch[58](400/2500): Loss: 0.0953
===> Epoch[58](500/2500): Loss: 0.0955
===> Epoch[58](600/2500): Loss: 0.0957
===> Epoch[58](700/2500): Loss: 0.0962
===> Epoch[58](800/2500): Loss: 0.0958
===> Epoch[58](900/2500): Loss: 0.0960
===> Epoch[58](1000/2500): Loss: 0.0954
===> Epoch[58](1100/2500): Loss: 0.0953
===> Epoch[58](1200/2500): Loss: 0.0958
===> Epoch[58](1300/2500): Loss: 0.0957
===> Epoch[58](1400/2500): Loss: 0.0956
===> Epoch[58](1500/2500): Loss: 0.0960
===> Epoch[58](1600/2500): Loss: 0.0961
===> Epoch[58](1700/2500): Loss: 0.0952
===> Epoch[58](1800/2500): Loss: 0.0960
===> Epoch[58](1900/2500): Loss: 0.0955
===> Epoch[58](2000/2500): Loss: 0.0959
===> Epoch[58](2100/2500): Loss: 0.0959
===> Epoch[58](2200/2500): Loss: 0.0958
===> Epoch[58](2300/2500): Loss: 0.0957
===> Epoch[58](2400/2500): Loss: 0.0953
===> Epoch[58](2500/2500): Loss: 0.0958
===> Epoch 58 Complete: Avg. Loss: 0.0957
===> Timestamp: [2025-07-29 20:06:29]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.0959
===> Epoch[58](200/2500): Loss: 0.0958
===> Epoch[58](300/2500): Loss: 0.0959
===> Epoch[58](400/2500): Loss: 0.0953
===> Epoch[58](500/2500): Loss: 0.0955
===> Epoch[58](600/2500): Loss: 0.0957
===> Epoch[58](700/2500): Loss: 0.0962
===> Epoch[58](800/2500): Loss: 0.0958
===> Epoch[58](900/2500): Loss: 0.0960
===> Epoch[58](1000/2500): Loss: 0.0954
===> Epoch[58](1100/2500): Loss: 0.0953
===> Epoch[58](1200/2500): Loss: 0.0958
===> Epoch[58](1300/2500): Loss: 0.0957
===> Epoch[58](1400/2500): Loss: 0.0956
===> Epoch[58](1500/2500): Loss: 0.0960
===> Epoch[58](1600/2500): Loss: 0.0961
===> Epoch[58](1700/2500): Loss: 0.0952
===> Epoch[58](1800/2500): Loss: 0.0960
===> Epoch[58](1900/2500): Loss: 0.0955
===> Epoch[58](2000/2500): Loss: 0.0959
===> Epoch[58](2100/2500): Loss: 0.0959
===> Epoch[58](2200/2500): Loss: 0.0958
===> Epoch[58](2300/2500): Loss: 0.0957
===> Epoch[58](2400/2500): Loss: 0.0953
===> Epoch[58](2500/2500): Loss: 0.0958
===> Epoch 58 Complete: Avg. Loss: 0.0957
===> Timestamp: [2025-07-29 20:06:29]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.0959
===> Epoch[58](200/2500): Loss: 0.0958
===> Epoch[58](300/2500): Loss: 0.0959
===> Epoch[58](400/2500): Loss: 0.0953
===> Epoch[58](500/2500): Loss: 0.0955
===> Epoch[58](600/2500): Loss: 0.0957
===> Epoch[58](700/2500): Loss: 0.0962
===> Epoch[58](800/2500): Loss: 0.0958
===> Epoch[58](900/2500): Loss: 0.0960
===> Epoch[58](1000/2500): Loss: 0.0954
===> Epoch[58](1100/2500): Loss: 0.0953
===> Epoch[58](1200/2500): Loss: 0.0958
===> Epoch[58](1300/2500): Loss: 0.0957
===> Epoch[58](1400/2500): Loss: 0.0956
===> Epoch[58](1500/2500): Loss: 0.0960
===> Epoch[58](1600/2500): Loss: 0.0961
===> Epoch[58](1700/2500): Loss: 0.0952
===> Epoch[58](1800/2500): Loss: 0.0960
===> Epoch[58](1900/2500): Loss: 0.0955
===> Epoch[58](2000/2500): Loss: 0.0959
===> Epoch[58](2100/2500): Loss: 0.0959
===> Epoch[58](2200/2500): Loss: 0.0958
===> Epoch[58](2300/2500): Loss: 0.0957
===> Epoch[58](2400/2500): Loss: 0.0953
===> Epoch[58](2500/2500): Loss: 0.0958
===> Epoch 58 Complete: Avg. Loss: 0.0957
===> Timestamp: [2025-07-29 20:06:29]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.0959
===> Epoch[58](200/2500): Loss: 0.0958
===> Epoch[58](300/2500): Loss: 0.0959
===> Epoch[58](400/2500): Loss: 0.0953
===> Epoch[58](500/2500): Loss: 0.0955
===> Epoch[58](600/2500): Loss: 0.0957
===> Epoch[58](700/2500): Loss: 0.0962
===> Epoch[58](800/2500): Loss: 0.0958
===> Epoch[58](900/2500): Loss: 0.0960
===> Epoch[58](1000/2500): Loss: 0.0954
===> Epoch[58](1100/2500): Loss: 0.0953
===> Epoch[58](1200/2500): Loss: 0.0958
===> Epoch[58](1300/2500): Loss: 0.0957
===> Epoch[58](1400/2500): Loss: 0.0956
===> Epoch[58](1500/2500): Loss: 0.0960
===> Epoch[58](1600/2500): Loss: 0.0961
===> Epoch[58](1700/2500): Loss: 0.0952
===> Epoch[58](1800/2500): Loss: 0.0960
===> Epoch[58](1900/2500): Loss: 0.0955
===> Epoch[58](2000/2500): Loss: 0.0959
===> Epoch[58](2100/2500): Loss: 0.0959
===> Epoch[58](2200/2500): Loss: 0.0958
===> Epoch[58](2300/2500): Loss: 0.0957
===> Epoch[58](2400/2500): Loss: 0.0953
===> Epoch[58](2500/2500): Loss: 0.0958
===> Epoch 58 Complete: Avg. Loss: 0.0957
===> Timestamp: [2025-07-29 20:06:29]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.0959
===> Epoch[58](200/2500): Loss: 0.0958
===> Epoch[58](300/2500): Loss: 0.0959
===> Epoch[58](400/2500): Loss: 0.0953
===> Epoch[58](500/2500): Loss: 0.0955
===> Epoch[58](600/2500): Loss: 0.0957
===> Epoch[58](700/2500): Loss: 0.0962
===> Epoch[58](800/2500): Loss: 0.0958
===> Epoch[58](900/2500): Loss: 0.0960
===> Epoch[58](1000/2500): Loss: 0.0954
===> Epoch[58](1100/2500): Loss: 0.0953
===> Epoch[58](1200/2500): Loss: 0.0958
===> Epoch[58](1300/2500): Loss: 0.0957
===> Epoch[58](1400/2500): Loss: 0.0956
===> Epoch[58](1500/2500): Loss: 0.0960
===> Epoch[58](1600/2500): Loss: 0.0961
===> Epoch[58](1700/2500): Loss: 0.0952
===> Epoch[58](1800/2500): Loss: 0.0960
===> Epoch[58](1900/2500): Loss: 0.0955
===> Epoch[58](2000/2500): Loss: 0.0959
===> Epoch[58](2100/2500): Loss: 0.0959
===> Epoch[58](2200/2500): Loss: 0.0958
===> Epoch[58](2300/2500): Loss: 0.0957
===> Epoch[58](2400/2500): Loss: 0.0953
===> Epoch[58](2500/2500): Loss: 0.0958
===> Epoch 58 Complete: Avg. Loss: 0.0957
===> Timestamp: [2025-07-29 20:06:29]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.0959
===> Epoch[58](200/2500): Loss: 0.0958
===> Epoch[58](300/2500): Loss: 0.0959
===> Epoch[58](400/2500): Loss: 0.0953
===> Epoch[58](500/2500): Loss: 0.0955
===> Epoch[58](600/2500): Loss: 0.0957
===> Epoch[58](700/2500): Loss: 0.0962
===> Epoch[58](800/2500): Loss: 0.0958
===> Epoch[58](900/2500): Loss: 0.0960
===> Epoch[58](1000/2500): Loss: 0.0954
===> Epoch[58](1100/2500): Loss: 0.0953
===> Epoch[58](1200/2500): Loss: 0.0958
===> Epoch[58](1300/2500): Loss: 0.0957
===> Epoch[58](1400/2500): Loss: 0.0956
===> Epoch[58](1500/2500): Loss: 0.0960
===> Epoch[58](1600/2500): Loss: 0.0961
===> Epoch[58](1700/2500): Loss: 0.0952
===> Epoch[58](1800/2500): Loss: 0.0960
===> Epoch[58](1900/2500): Loss: 0.0955
===> Epoch[58](2000/2500): Loss: 0.0959
===> Epoch[58](2100/2500): Loss: 0.0959
===> Epoch[58](2200/2500): Loss: 0.0958
===> Epoch[58](2300/2500): Loss: 0.0957
===> Epoch[58](2400/2500): Loss: 0.0953
===> Epoch[58](2500/2500): Loss: 0.0958
===> Epoch 58 Complete: Avg. Loss: 0.0957
===> Timestamp: [2025-07-29 20:06:29]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.0959
===> Epoch[58](200/2500): Loss: 0.0958
===> Epoch[58](300/2500): Loss: 0.0959
===> Epoch[58](400/2500): Loss: 0.0953
===> Epoch[58](500/2500): Loss: 0.0955
===> Epoch[58](600/2500): Loss: 0.0957
===> Epoch[58](700/2500): Loss: 0.0962
===> Epoch[58](800/2500): Loss: 0.0958
===> Epoch[58](900/2500): Loss: 0.0960
===> Epoch[58](1000/2500): Loss: 0.0954
===> Epoch[58](1100/2500): Loss: 0.0953
===> Epoch[58](1200/2500): Loss: 0.0958
===> Epoch[58](1300/2500): Loss: 0.0957
===> Epoch[58](1400/2500): Loss: 0.0956
===> Epoch[58](1500/2500): Loss: 0.0960
===> Epoch[58](1600/2500): Loss: 0.0961
===> Epoch[58](1700/2500): Loss: 0.0952
===> Epoch[58](1800/2500): Loss: 0.0960
===> Epoch[58](1900/2500): Loss: 0.0955
===> Epoch[58](2000/2500): Loss: 0.0959
===> Epoch[58](2100/2500): Loss: 0.0959
===> Epoch[58](2200/2500): Loss: 0.0958
===> Epoch[58](2300/2500): Loss: 0.0957
===> Epoch[58](2400/2500): Loss: 0.0953
===> Epoch[58](2500/2500): Loss: 0.0958
===> Epoch 58 Complete: Avg. Loss: 0.0957
===> Timestamp: [2025-07-29 20:06:29]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.0959
===> Epoch[58](200/2500): Loss: 0.0958
===> Epoch[58](300/2500): Loss: 0.0959
===> Epoch[58](400/2500): Loss: 0.0953
===> Epoch[58](500/2500): Loss: 0.0955
===> Epoch[58](600/2500): Loss: 0.0957
===> Epoch[58](700/2500): Loss: 0.0962
===> Epoch[58](800/2500): Loss: 0.0958
===> Epoch[58](900/2500): Loss: 0.0960
===> Epoch[58](1000/2500): Loss: 0.0954
===> Epoch[58](1100/2500): Loss: 0.0953
===> Epoch[58](1200/2500): Loss: 0.0958
===> Epoch[58](1300/2500): Loss: 0.0957
===> Epoch[58](1400/2500): Loss: 0.0956
===> Epoch[58](1500/2500): Loss: 0.0960
===> Epoch[58](1600/2500): Loss: 0.0961
===> Epoch[58](1700/2500): Loss: 0.0952
===> Epoch[58](1800/2500): Loss: 0.0960
===> Epoch[58](1900/2500): Loss: 0.0955
===> Epoch[58](2000/2500): Loss: 0.0959
===> Epoch[58](2100/2500): Loss: 0.0959
===> Epoch[58](2200/2500): Loss: 0.0958
===> Epoch[58](2300/2500): Loss: 0.0957
===> Epoch[58](2400/2500): Loss: 0.0953
===> Epoch[58](2500/2500): Loss: 0.0958
===> Epoch 58 Complete: Avg. Loss: 0.0957
===> Timestamp: [2025-07-29 20:06:29]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.0959
===> Epoch[58](200/2500): Loss: 0.0958
===> Epoch[58](300/2500): Loss: 0.0959
===> Epoch[58](400/2500): Loss: 0.0953
===> Epoch[58](500/2500): Loss: 0.0955
===> Epoch[58](600/2500): Loss: 0.0957
===> Epoch[58](700/2500): Loss: 0.0962
===> Epoch[58](800/2500): Loss: 0.0958
===> Epoch[58](900/2500): Loss: 0.0960
===> Epoch[58](1000/2500): Loss: 0.0954
===> Epoch[58](1100/2500): Loss: 0.0953
===> Epoch[58](1200/2500): Loss: 0.0958
===> Epoch[58](1300/2500): Loss: 0.0957
===> Epoch[58](1400/2500): Loss: 0.0956
===> Epoch[58](1500/2500): Loss: 0.0960
===> Epoch[58](1600/2500): Loss: 0.0961
===> Epoch[58](1700/2500): Loss: 0.0952
===> Epoch[58](1800/2500): Loss: 0.0960
===> Epoch[58](1900/2500): Loss: 0.0955
===> Epoch[58](2000/2500): Loss: 0.0959
===> Epoch[58](2100/2500): Loss: 0.0959
===> Epoch[58](2200/2500): Loss: 0.0958
===> Epoch[58](2300/2500): Loss: 0.0957
===> Epoch[58](2400/2500): Loss: 0.0953
===> Epoch[58](2500/2500): Loss: 0.0958
===> Epoch 58 Complete: Avg. Loss: 0.0957
===> Timestamp: [2025-07-29 20:06:29]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.0959
===> Epoch[58](200/2500): Loss: 0.0958
===> Epoch[58](300/2500): Loss: 0.0959
===> Epoch[58](400/2500): Loss: 0.0953
===> Epoch[58](500/2500): Loss: 0.0955
===> Epoch[58](600/2500): Loss: 0.0957
===> Epoch[58](700/2500): Loss: 0.0962
===> Epoch[58](800/2500): Loss: 0.0958
===> Epoch[58](900/2500): Loss: 0.0960
===> Epoch[58](1000/2500): Loss: 0.0954
===> Epoch[58](1100/2500): Loss: 0.0953
===> Epoch[58](1200/2500): Loss: 0.0958
===> Epoch[58](1300/2500): Loss: 0.0957
===> Epoch[58](1400/2500): Loss: 0.0956
===> Epoch[58](1500/2500): Loss: 0.0960
===> Epoch[58](1600/2500): Loss: 0.0961
===> Epoch[58](1700/2500): Loss: 0.0952
===> Epoch[58](1800/2500): Loss: 0.0960
===> Epoch[58](1900/2500): Loss: 0.0955
===> Epoch[58](2000/2500): Loss: 0.0959
===> Epoch[58](2100/2500): Loss: 0.0959
===> Epoch[58](2200/2500): Loss: 0.0958
===> Epoch[58](2300/2500): Loss: 0.0957
===> Epoch[58](2400/2500): Loss: 0.0953
===> Epoch[58](2500/2500): Loss: 0.0958
===> Epoch 58 Complete: Avg. Loss: 0.0957
===> Timestamp: [2025-07-29 20:06:29]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.0959
===> Epoch[58](200/2500): Loss: 0.0958
===> Epoch[58](300/2500): Loss: 0.0959
===> Epoch[58](400/2500): Loss: 0.0953
===> Epoch[58](500/2500): Loss: 0.0955
===> Epoch[58](600/2500): Loss: 0.0957
===> Epoch[58](700/2500): Loss: 0.0962
===> Epoch[58](800/2500): Loss: 0.0958
===> Epoch[58](900/2500): Loss: 0.0960
===> Epoch[58](1000/2500): Loss: 0.0954
===> Epoch[58](1100/2500): Loss: 0.0953
===> Epoch[58](1200/2500): Loss: 0.0958
===> Epoch[58](1300/2500): Loss: 0.0957
===> Epoch[58](1400/2500): Loss: 0.0956
===> Epoch[58](1500/2500): Loss: 0.0960
===> Epoch[58](1600/2500): Loss: 0.0961
===> Epoch[58](1700/2500): Loss: 0.0952
===> Epoch[58](1800/2500): Loss: 0.0960
===> Epoch[58](1900/2500): Loss: 0.0955
===> Epoch[58](2000/2500): Loss: 0.0959
===> Epoch[58](2100/2500): Loss: 0.0959
===> Epoch[58](2200/2500): Loss: 0.0958
===> Epoch[58](2300/2500): Loss: 0.0957
===> Epoch[58](2400/2500): Loss: 0.0953
===> Epoch[58](2500/2500): Loss: 0.0958
===> Epoch 58 Complete: Avg. Loss: 0.0957
===> Timestamp: [2025-07-29 20:06:29]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.0959
===> Epoch[58](200/2500): Loss: 0.0958
===> Epoch[58](300/2500): Loss: 0.0959
===> Epoch[58](400/2500): Loss: 0.0953
===> Epoch[58](500/2500): Loss: 0.0955
===> Epoch[58](600/2500): Loss: 0.0957
===> Epoch[58](700/2500): Loss: 0.0962
===> Epoch[58](800/2500): Loss: 0.0958
===> Epoch[58](900/2500): Loss: 0.0960
===> Epoch[58](1000/2500): Loss: 0.0954
===> Epoch[58](1100/2500): Loss: 0.0953
===> Epoch[58](1200/2500): Loss: 0.0958
===> Epoch[58](1300/2500): Loss: 0.0957
===> Epoch[58](1400/2500): Loss: 0.0956
===> Epoch[58](1500/2500): Loss: 0.0960
===> Epoch[58](1600/2500): Loss: 0.0961
===> Epoch[58](1700/2500): Loss: 0.0952
===> Epoch[58](1800/2500): Loss: 0.0960
===> Epoch[58](1900/2500): Loss: 0.0955
===> Epoch[58](2000/2500): Loss: 0.0959
===> Epoch[58](2100/2500): Loss: 0.0959
===> Epoch[58](2200/2500): Loss: 0.0958
===> Epoch[58](2300/2500): Loss: 0.0957
===> Epoch[58](2400/2500): Loss: 0.0953
===> Epoch[58](2500/2500): Loss: 0.0958
===> Epoch 58 Complete: Avg. Loss: 0.0957
===> Timestamp: [2025-07-29 20:06:29]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.0959
===> Epoch[58](200/2500): Loss: 0.0958
===> Epoch[58](300/2500): Loss: 0.0959
===> Epoch[58](400/2500): Loss: 0.0953
===> Epoch[58](500/2500): Loss: 0.0955
===> Epoch[58](600/2500): Loss: 0.0957
===> Epoch[58](700/2500): Loss: 0.0962
===> Epoch[58](800/2500): Loss: 0.0958
===> Epoch[58](900/2500): Loss: 0.0960
===> Epoch[58](1000/2500): Loss: 0.0954
===> Epoch[58](1100/2500): Loss: 0.0953
===> Epoch[58](1200/2500): Loss: 0.0958
===> Epoch[58](1300/2500): Loss: 0.0957
===> Epoch[58](1400/2500): Loss: 0.0956
===> Epoch[58](1500/2500): Loss: 0.0960
===> Epoch[58](1600/2500): Loss: 0.0961
===> Epoch[58](1700/2500): Loss: 0.0952
===> Epoch[58](1800/2500): Loss: 0.0960
===> Epoch[58](1900/2500): Loss: 0.0955
===> Epoch[58](2000/2500): Loss: 0.0959
===> Epoch[58](2100/2500): Loss: 0.0959
===> Epoch[58](2200/2500): Loss: 0.0958
===> Epoch[58](2300/2500): Loss: 0.0957
===> Epoch[58](2400/2500): Loss: 0.0953
===> Epoch[58](2500/2500): Loss: 0.0958
===> Epoch 58 Complete: Avg. Loss: 0.0957
===> Timestamp: [2025-07-29 20:06:29]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.0959
===> Epoch[58](200/2500): Loss: 0.0958
===> Epoch[58](300/2500): Loss: 0.0959
===> Epoch[58](400/2500): Loss: 0.0953
===> Epoch[58](500/2500): Loss: 0.0955
===> Epoch[58](600/2500): Loss: 0.0957
===> Epoch[58](700/2500): Loss: 0.0962
===> Epoch[58](800/2500): Loss: 0.0958
===> Epoch[58](900/2500): Loss: 0.0960
===> Epoch[58](1000/2500): Loss: 0.0954
===> Epoch[58](1100/2500): Loss: 0.0953
===> Epoch[58](1200/2500): Loss: 0.0958
===> Epoch[58](1300/2500): Loss: 0.0957
===> Epoch[58](1400/2500): Loss: 0.0956
===> Epoch[58](1500/2500): Loss: 0.0960
===> Epoch[58](1600/2500): Loss: 0.0961
===> Epoch[58](1700/2500): Loss: 0.0952
===> Epoch[58](1800/2500): Loss: 0.0960
===> Epoch[58](1900/2500): Loss: 0.0955
===> Epoch[58](2000/2500): Loss: 0.0959
===> Epoch[58](2100/2500): Loss: 0.0959
===> Epoch[58](2200/2500): Loss: 0.0958
===> Epoch[58](2300/2500): Loss: 0.0957
===> Epoch[58](2400/2500): Loss: 0.0953
===> Epoch[58](2500/2500): Loss: 0.0958
===> Epoch 58 Complete: Avg. Loss: 0.0957
===> Timestamp: [2025-07-29 20:06:29]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.0959
===> Epoch[58](200/2500): Loss: 0.0958
===> Epoch[58](300/2500): Loss: 0.0959
===> Epoch[58](400/2500): Loss: 0.0953
===> Epoch[58](500/2500): Loss: 0.0955
===> Epoch[58](600/2500): Loss: 0.0957
===> Epoch[58](700/2500): Loss: 0.0962
===> Epoch[58](800/2500): Loss: 0.0958
===> Epoch[58](900/2500): Loss: 0.0960
===> Epoch[58](1000/2500): Loss: 0.0954
===> Epoch[58](1100/2500): Loss: 0.0953
===> Epoch[58](1200/2500): Loss: 0.0958
===> Epoch[58](1300/2500): Loss: 0.0957
===> Epoch[58](1400/2500): Loss: 0.0956
===> Epoch[58](1500/2500): Loss: 0.0960
===> Epoch[58](1600/2500): Loss: 0.0961
===> Epoch[58](1700/2500): Loss: 0.0952
===> Epoch[58](1800/2500): Loss: 0.0960
===> Epoch[58](1900/2500): Loss: 0.0955
===> Epoch[58](2000/2500): Loss: 0.0959
===> Epoch[58](2100/2500): Loss: 0.0959
===> Epoch[58](2200/2500): Loss: 0.0958
===> Epoch[58](2300/2500): Loss: 0.0957
===> Epoch[58](2400/2500): Loss: 0.0953
===> Epoch[58](2500/2500): Loss: 0.0958
===> Epoch 58 Complete: Avg. Loss: 0.0957
===> Timestamp: [2025-07-29 20:06:29]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.0959
===> Epoch[58](200/2500): Loss: 0.0958
===> Epoch[58](300/2500): Loss: 0.0959
===> Epoch[58](400/2500): Loss: 0.0953
===> Epoch[58](500/2500): Loss: 0.0955
===> Epoch[58](600/2500): Loss: 0.0957
===> Epoch[58](700/2500): Loss: 0.0962
===> Epoch[58](800/2500): Loss: 0.0958
===> Epoch[58](900/2500): Loss: 0.0960
===> Epoch[58](1000/2500): Loss: 0.0954
===> Epoch[58](1100/2500): Loss: 0.0953
===> Epoch[58](1200/2500): Loss: 0.0958
===> Epoch[58](1300/2500): Loss: 0.0957
===> Epoch[58](1400/2500): Loss: 0.0956
===> Epoch[58](1500/2500): Loss: 0.0960
===> Epoch[58](1600/2500): Loss: 0.0961
===> Epoch[58](1700/2500): Loss: 0.0952
===> Epoch[58](1800/2500): Loss: 0.0960
===> Epoch[58](1900/2500): Loss: 0.0955
===> Epoch[58](2000/2500): Loss: 0.0959
===> Epoch[58](2100/2500): Loss: 0.0959
===> Epoch[58](2200/2500): Loss: 0.0958
===> Epoch[58](2300/2500): Loss: 0.0957
===> Epoch[58](2400/2500): Loss: 0.0953
===> Epoch[58](2500/2500): Loss: 0.0958
===> Epoch 58 Complete: Avg. Loss: 0.0957
===> Timestamp: [2025-07-29 20:06:29]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.0959
===> Epoch[58](200/2500): Loss: 0.0958
===> Epoch[58](300/2500): Loss: 0.0959
===> Epoch[58](400/2500): Loss: 0.0953
===> Epoch[58](500/2500): Loss: 0.0955
===> Epoch[58](600/2500): Loss: 0.0957
===> Epoch[58](700/2500): Loss: 0.0962
===> Epoch[58](800/2500): Loss: 0.0958
===> Epoch[58](900/2500): Loss: 0.0960
===> Epoch[58](1000/2500): Loss: 0.0954
===> Epoch[58](1100/2500): Loss: 0.0953
===> Epoch[58](1200/2500): Loss: 0.0958
===> Epoch[58](1300/2500): Loss: 0.0957
===> Epoch[58](1400/2500): Loss: 0.0956
===> Epoch[58](1500/2500): Loss: 0.0960
===> Epoch[58](1600/2500): Loss: 0.0961
===> Epoch[58](1700/2500): Loss: 0.0952
===> Epoch[58](1800/2500): Loss: 0.0960
===> Epoch[58](1900/2500): Loss: 0.0955
===> Epoch[58](2000/2500): Loss: 0.0959
===> Epoch[58](2100/2500): Loss: 0.0959
===> Epoch[58](2200/2500): Loss: 0.0958
===> Epoch[58](2300/2500): Loss: 0.0957
===> Epoch[58](2400/2500): Loss: 0.0953
===> Epoch[58](2500/2500): Loss: 0.0958
===> Epoch 58 Complete: Avg. Loss: 0.0957
===> Timestamp: [2025-07-29 20:06:29]
===> Loading train datasets
===> Epoch[58](100/2500): Loss: 0.0959
===> Epoch[58](200/2500): Loss: 0.0958
===> Epoch[58](300/2500): Loss: 0.0959
===> Epoch[58](400/2500): Loss: 0.0953
===> Epoch[58](500/2500): Loss: 0.0955
===> Epoch[58](600/2500): Loss: 0.0957
===> Epoch[58](700/2500): Loss: 0.0962
===> Epoch[58](800/2500): Loss: 0.0958
===> Epoch[58](900/2500): Loss: 0.0960
===> Epoch[58](1000/2500): Loss: 0.0954
===> Epoch[58](1100/2500): Loss: 0.0953
===> Epoch[58](1200/2500): Loss: 0.0958
===> Epoch[58](1300/2500): Loss: 0.0957
===> Epoch[58](1400/2500): Loss: 0.0956
===> Epoch[58](1500/2500): Loss: 0.0960
===> Epoch[58](1600/2500): Loss: 0.0961
===> Epoch[58](1700/2500): Loss: 0.0952
===> Epoch[58](1800/2500): Loss: 0.0960
===> Epoch[58](1900/2500): Loss: 0.0955
===> Epoch[58](2000/2500): Loss: 0.0959
===> Epoch[58](2100/2500): Loss: 0.0959
===> Epoch[58](2200/2500): Loss: 0.0958
===> Epoch[58](2300/2500): Loss: 0.0957
===> Epoch[58](2400/2500): Loss: 0.0953
===> Epoch[58](2500/2500): Loss: 0.0958
===> Epoch 58 Complete: Avg. Loss: 0.0957
===> Timestamp: [2025-07-29 20:06:29]
===> Loading train datasets
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.1014
===> Epoch[59](200/2500): Loss: 0.0961
===> Epoch[59](300/2500): Loss: 0.0949
===> Epoch[59](400/2500): Loss: 0.0953
===> Epoch[59](500/2500): Loss: 0.0956
===> Epoch[59](600/2500): Loss: 0.0960
===> Epoch[59](700/2500): Loss: 0.0961
===> Epoch[59](800/2500): Loss: 0.0962
===> Epoch[59](900/2500): Loss: 0.0959
===> Epoch[59](1000/2500): Loss: 0.0954
===> Epoch[59](1100/2500): Loss: 0.0959
===> Epoch[59](1200/2500): Loss: 0.0953
===> Epoch[59](1300/2500): Loss: 0.0956
===> Epoch[59](1400/2500): Loss: 0.0961
===> Epoch[59](1500/2500): Loss: 0.0960
===> Epoch[59](1600/2500): Loss: 0.0958
===> Epoch[59](1700/2500): Loss: 0.0957
===> Epoch[59](1800/2500): Loss: 0.0951
===> Epoch[59](1900/2500): Loss: 0.0960
===> Epoch[59](2000/2500): Loss: 0.0954
===> Epoch[59](2100/2500): Loss: 0.0961
===> Epoch[59](2200/2500): Loss: 0.0946
===> Epoch[59](2300/2500): Loss: 0.0952
===> Epoch[59](2400/2500): Loss: 0.0958
===> Epoch[59](2500/2500): Loss: 0.0956
===> Epoch 59 Complete: Avg. Loss: 0.0960
===> Timestamp: [2025-07-29 20:11:34]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.1014
===> Epoch[59](200/2500): Loss: 0.0961
===> Epoch[59](300/2500): Loss: 0.0949
===> Epoch[59](400/2500): Loss: 0.0953
===> Epoch[59](500/2500): Loss: 0.0956
===> Epoch[59](600/2500): Loss: 0.0960
===> Epoch[59](700/2500): Loss: 0.0961
===> Epoch[59](800/2500): Loss: 0.0962
===> Epoch[59](900/2500): Loss: 0.0959
===> Epoch[59](1000/2500): Loss: 0.0954
===> Epoch[59](1100/2500): Loss: 0.0959
===> Epoch[59](1200/2500): Loss: 0.0953
===> Epoch[59](1300/2500): Loss: 0.0956
===> Epoch[59](1400/2500): Loss: 0.0961
===> Epoch[59](1500/2500): Loss: 0.0960
===> Epoch[59](1600/2500): Loss: 0.0958
===> Epoch[59](1700/2500): Loss: 0.0957
===> Epoch[59](1800/2500): Loss: 0.0951
===> Epoch[59](1900/2500): Loss: 0.0960
===> Epoch[59](2000/2500): Loss: 0.0954
===> Epoch[59](2100/2500): Loss: 0.0961
===> Epoch[59](2200/2500): Loss: 0.0946
===> Epoch[59](2300/2500): Loss: 0.0952
===> Epoch[59](2400/2500): Loss: 0.0958
===> Epoch[59](2500/2500): Loss: 0.0956
===> Epoch 59 Complete: Avg. Loss: 0.0960
===> Timestamp: [2025-07-29 20:11:34]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.1014
===> Epoch[59](200/2500): Loss: 0.0961
===> Epoch[59](300/2500): Loss: 0.0949
===> Epoch[59](400/2500): Loss: 0.0953
===> Epoch[59](500/2500): Loss: 0.0956
===> Epoch[59](600/2500): Loss: 0.0960
===> Epoch[59](700/2500): Loss: 0.0961
===> Epoch[59](800/2500): Loss: 0.0962
===> Epoch[59](900/2500): Loss: 0.0959
===> Epoch[59](1000/2500): Loss: 0.0954
===> Epoch[59](1100/2500): Loss: 0.0959
===> Epoch[59](1200/2500): Loss: 0.0953
===> Epoch[59](1300/2500): Loss: 0.0956
===> Epoch[59](1400/2500): Loss: 0.0961
===> Epoch[59](1500/2500): Loss: 0.0960
===> Epoch[59](1600/2500): Loss: 0.0958
===> Epoch[59](1700/2500): Loss: 0.0957
===> Epoch[59](1800/2500): Loss: 0.0951
===> Epoch[59](1900/2500): Loss: 0.0960
===> Epoch[59](2000/2500): Loss: 0.0954
===> Epoch[59](2100/2500): Loss: 0.0961
===> Epoch[59](2200/2500): Loss: 0.0946
===> Epoch[59](2300/2500): Loss: 0.0952
===> Epoch[59](2400/2500): Loss: 0.0958
===> Epoch[59](2500/2500): Loss: 0.0956
===> Epoch 59 Complete: Avg. Loss: 0.0960
===> Timestamp: [2025-07-29 20:11:34]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.1014
===> Epoch[59](200/2500): Loss: 0.0961
===> Epoch[59](300/2500): Loss: 0.0949
===> Epoch[59](400/2500): Loss: 0.0953
===> Epoch[59](500/2500): Loss: 0.0956
===> Epoch[59](600/2500): Loss: 0.0960
===> Epoch[59](700/2500): Loss: 0.0961
===> Epoch[59](800/2500): Loss: 0.0962
===> Epoch[59](900/2500): Loss: 0.0959
===> Epoch[59](1000/2500): Loss: 0.0954
===> Epoch[59](1100/2500): Loss: 0.0959
===> Epoch[59](1200/2500): Loss: 0.0953
===> Epoch[59](1300/2500): Loss: 0.0956
===> Epoch[59](1400/2500): Loss: 0.0961
===> Epoch[59](1500/2500): Loss: 0.0960
===> Epoch[59](1600/2500): Loss: 0.0958
===> Epoch[59](1700/2500): Loss: 0.0957
===> Epoch[59](1800/2500): Loss: 0.0951
===> Epoch[59](1900/2500): Loss: 0.0960
===> Epoch[59](2000/2500): Loss: 0.0954
===> Epoch[59](2100/2500): Loss: 0.0961
===> Epoch[59](2200/2500): Loss: 0.0946
===> Epoch[59](2300/2500): Loss: 0.0952
===> Epoch[59](2400/2500): Loss: 0.0958
===> Epoch[59](2500/2500): Loss: 0.0956
===> Epoch 59 Complete: Avg. Loss: 0.0960
===> Timestamp: [2025-07-29 20:11:34]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.1014
===> Epoch[59](200/2500): Loss: 0.0961
===> Epoch[59](300/2500): Loss: 0.0949
===> Epoch[59](400/2500): Loss: 0.0953
===> Epoch[59](500/2500): Loss: 0.0956
===> Epoch[59](600/2500): Loss: 0.0960
===> Epoch[59](700/2500): Loss: 0.0961
===> Epoch[59](800/2500): Loss: 0.0962
===> Epoch[59](900/2500): Loss: 0.0959
===> Epoch[59](1000/2500): Loss: 0.0954
===> Epoch[59](1100/2500): Loss: 0.0959
===> Epoch[59](1200/2500): Loss: 0.0953
===> Epoch[59](1300/2500): Loss: 0.0956
===> Epoch[59](1400/2500): Loss: 0.0961
===> Epoch[59](1500/2500): Loss: 0.0960
===> Epoch[59](1600/2500): Loss: 0.0958
===> Epoch[59](1700/2500): Loss: 0.0957
===> Epoch[59](1800/2500): Loss: 0.0951
===> Epoch[59](1900/2500): Loss: 0.0960
===> Epoch[59](2000/2500): Loss: 0.0954
===> Epoch[59](2100/2500): Loss: 0.0961
===> Epoch[59](2200/2500): Loss: 0.0946
===> Epoch[59](2300/2500): Loss: 0.0952
===> Epoch[59](2400/2500): Loss: 0.0958
===> Epoch[59](2500/2500): Loss: 0.0956
===> Epoch 59 Complete: Avg. Loss: 0.0960
===> Timestamp: [2025-07-29 20:11:34]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.1014
===> Epoch[59](200/2500): Loss: 0.0961
===> Epoch[59](300/2500): Loss: 0.0949
===> Epoch[59](400/2500): Loss: 0.0953
===> Epoch[59](500/2500): Loss: 0.0956
===> Epoch[59](600/2500): Loss: 0.0960
===> Epoch[59](700/2500): Loss: 0.0961
===> Epoch[59](800/2500): Loss: 0.0962
===> Epoch[59](900/2500): Loss: 0.0959
===> Epoch[59](1000/2500): Loss: 0.0954
===> Epoch[59](1100/2500): Loss: 0.0959
===> Epoch[59](1200/2500): Loss: 0.0953
===> Epoch[59](1300/2500): Loss: 0.0956
===> Epoch[59](1400/2500): Loss: 0.0961
===> Epoch[59](1500/2500): Loss: 0.0960
===> Epoch[59](1600/2500): Loss: 0.0958
===> Epoch[59](1700/2500): Loss: 0.0957
===> Epoch[59](1800/2500): Loss: 0.0951
===> Epoch[59](1900/2500): Loss: 0.0960
===> Epoch[59](2000/2500): Loss: 0.0954
===> Epoch[59](2100/2500): Loss: 0.0961
===> Epoch[59](2200/2500): Loss: 0.0946
===> Epoch[59](2300/2500): Loss: 0.0952
===> Epoch[59](2400/2500): Loss: 0.0958
===> Epoch[59](2500/2500): Loss: 0.0956
===> Epoch 59 Complete: Avg. Loss: 0.0960
===> Timestamp: [2025-07-29 20:11:34]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.1014
===> Epoch[59](200/2500): Loss: 0.0961
===> Epoch[59](300/2500): Loss: 0.0949
===> Epoch[59](400/2500): Loss: 0.0953
===> Epoch[59](500/2500): Loss: 0.0956
===> Epoch[59](600/2500): Loss: 0.0960
===> Epoch[59](700/2500): Loss: 0.0961
===> Epoch[59](800/2500): Loss: 0.0962
===> Epoch[59](900/2500): Loss: 0.0959
===> Epoch[59](1000/2500): Loss: 0.0954
===> Epoch[59](1100/2500): Loss: 0.0959
===> Epoch[59](1200/2500): Loss: 0.0953
===> Epoch[59](1300/2500): Loss: 0.0956
===> Epoch[59](1400/2500): Loss: 0.0961
===> Epoch[59](1500/2500): Loss: 0.0960
===> Epoch[59](1600/2500): Loss: 0.0958
===> Epoch[59](1700/2500): Loss: 0.0957
===> Epoch[59](1800/2500): Loss: 0.0951
===> Epoch[59](1900/2500): Loss: 0.0960
===> Epoch[59](2000/2500): Loss: 0.0954
===> Epoch[59](2100/2500): Loss: 0.0961
===> Epoch[59](2200/2500): Loss: 0.0946
===> Epoch[59](2300/2500): Loss: 0.0952
===> Epoch[59](2400/2500): Loss: 0.0958
===> Epoch[59](2500/2500): Loss: 0.0956
===> Epoch 59 Complete: Avg. Loss: 0.0960
===> Timestamp: [2025-07-29 20:11:34]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.1014
===> Epoch[59](200/2500): Loss: 0.0961
===> Epoch[59](300/2500): Loss: 0.0949
===> Epoch[59](400/2500): Loss: 0.0953
===> Epoch[59](500/2500): Loss: 0.0956
===> Epoch[59](600/2500): Loss: 0.0960
===> Epoch[59](700/2500): Loss: 0.0961
===> Epoch[59](800/2500): Loss: 0.0962
===> Epoch[59](900/2500): Loss: 0.0959
===> Epoch[59](1000/2500): Loss: 0.0954
===> Epoch[59](1100/2500): Loss: 0.0959
===> Epoch[59](1200/2500): Loss: 0.0953
===> Epoch[59](1300/2500): Loss: 0.0956
===> Epoch[59](1400/2500): Loss: 0.0961
===> Epoch[59](1500/2500): Loss: 0.0960
===> Epoch[59](1600/2500): Loss: 0.0958
===> Epoch[59](1700/2500): Loss: 0.0957
===> Epoch[59](1800/2500): Loss: 0.0951
===> Epoch[59](1900/2500): Loss: 0.0960
===> Epoch[59](2000/2500): Loss: 0.0954
===> Epoch[59](2100/2500): Loss: 0.0961
===> Epoch[59](2200/2500): Loss: 0.0946
===> Epoch[59](2300/2500): Loss: 0.0952
===> Epoch[59](2400/2500): Loss: 0.0958
===> Epoch[59](2500/2500): Loss: 0.0956
===> Epoch 59 Complete: Avg. Loss: 0.0960
===> Timestamp: [2025-07-29 20:11:34]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.1014
===> Epoch[59](200/2500): Loss: 0.0961
===> Epoch[59](300/2500): Loss: 0.0949
===> Epoch[59](400/2500): Loss: 0.0953
===> Epoch[59](500/2500): Loss: 0.0956
===> Epoch[59](600/2500): Loss: 0.0960
===> Epoch[59](700/2500): Loss: 0.0961
===> Epoch[59](800/2500): Loss: 0.0962
===> Epoch[59](900/2500): Loss: 0.0959
===> Epoch[59](1000/2500): Loss: 0.0954
===> Epoch[59](1100/2500): Loss: 0.0959
===> Epoch[59](1200/2500): Loss: 0.0953
===> Epoch[59](1300/2500): Loss: 0.0956
===> Epoch[59](1400/2500): Loss: 0.0961
===> Epoch[59](1500/2500): Loss: 0.0960
===> Epoch[59](1600/2500): Loss: 0.0958
===> Epoch[59](1700/2500): Loss: 0.0957
===> Epoch[59](1800/2500): Loss: 0.0951
===> Epoch[59](1900/2500): Loss: 0.0960
===> Epoch[59](2000/2500): Loss: 0.0954
===> Epoch[59](2100/2500): Loss: 0.0961
===> Epoch[59](2200/2500): Loss: 0.0946
===> Epoch[59](2300/2500): Loss: 0.0952
===> Epoch[59](2400/2500): Loss: 0.0958
===> Epoch[59](2500/2500): Loss: 0.0956
===> Epoch 59 Complete: Avg. Loss: 0.0960
===> Timestamp: [2025-07-29 20:11:34]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.1014
===> Epoch[59](200/2500): Loss: 0.0961
===> Epoch[59](300/2500): Loss: 0.0949
===> Epoch[59](400/2500): Loss: 0.0953
===> Epoch[59](500/2500): Loss: 0.0956
===> Epoch[59](600/2500): Loss: 0.0960
===> Epoch[59](700/2500): Loss: 0.0961
===> Epoch[59](800/2500): Loss: 0.0962
===> Epoch[59](900/2500): Loss: 0.0959
===> Epoch[59](1000/2500): Loss: 0.0954
===> Epoch[59](1100/2500): Loss: 0.0959
===> Epoch[59](1200/2500): Loss: 0.0953
===> Epoch[59](1300/2500): Loss: 0.0956
===> Epoch[59](1400/2500): Loss: 0.0961
===> Epoch[59](1500/2500): Loss: 0.0960
===> Epoch[59](1600/2500): Loss: 0.0958
===> Epoch[59](1700/2500): Loss: 0.0957
===> Epoch[59](1800/2500): Loss: 0.0951
===> Epoch[59](1900/2500): Loss: 0.0960
===> Epoch[59](2000/2500): Loss: 0.0954
===> Epoch[59](2100/2500): Loss: 0.0961
===> Epoch[59](2200/2500): Loss: 0.0946
===> Epoch[59](2300/2500): Loss: 0.0952
===> Epoch[59](2400/2500): Loss: 0.0958
===> Epoch[59](2500/2500): Loss: 0.0956
===> Epoch 59 Complete: Avg. Loss: 0.0960
===> Timestamp: [2025-07-29 20:11:34]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.1014
===> Epoch[59](200/2500): Loss: 0.0961
===> Epoch[59](300/2500): Loss: 0.0949
===> Epoch[59](400/2500): Loss: 0.0953
===> Epoch[59](500/2500): Loss: 0.0956
===> Epoch[59](600/2500): Loss: 0.0960
===> Epoch[59](700/2500): Loss: 0.0961
===> Epoch[59](800/2500): Loss: 0.0962
===> Epoch[59](900/2500): Loss: 0.0959
===> Epoch[59](1000/2500): Loss: 0.0954
===> Epoch[59](1100/2500): Loss: 0.0959
===> Epoch[59](1200/2500): Loss: 0.0953
===> Epoch[59](1300/2500): Loss: 0.0956
===> Epoch[59](1400/2500): Loss: 0.0961
===> Epoch[59](1500/2500): Loss: 0.0960
===> Epoch[59](1600/2500): Loss: 0.0958
===> Epoch[59](1700/2500): Loss: 0.0957
===> Epoch[59](1800/2500): Loss: 0.0951
===> Epoch[59](1900/2500): Loss: 0.0960
===> Epoch[59](2000/2500): Loss: 0.0954
===> Epoch[59](2100/2500): Loss: 0.0961
===> Epoch[59](2200/2500): Loss: 0.0946
===> Epoch[59](2300/2500): Loss: 0.0952
===> Epoch[59](2400/2500): Loss: 0.0958
===> Epoch[59](2500/2500): Loss: 0.0956
===> Epoch 59 Complete: Avg. Loss: 0.0960
===> Timestamp: [2025-07-29 20:11:34]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.1014
===> Epoch[59](200/2500): Loss: 0.0961
===> Epoch[59](300/2500): Loss: 0.0949
===> Epoch[59](400/2500): Loss: 0.0953
===> Epoch[59](500/2500): Loss: 0.0956
===> Epoch[59](600/2500): Loss: 0.0960
===> Epoch[59](700/2500): Loss: 0.0961
===> Epoch[59](800/2500): Loss: 0.0962
===> Epoch[59](900/2500): Loss: 0.0959
===> Epoch[59](1000/2500): Loss: 0.0954
===> Epoch[59](1100/2500): Loss: 0.0959
===> Epoch[59](1200/2500): Loss: 0.0953
===> Epoch[59](1300/2500): Loss: 0.0956
===> Epoch[59](1400/2500): Loss: 0.0961
===> Epoch[59](1500/2500): Loss: 0.0960
===> Epoch[59](1600/2500): Loss: 0.0958
===> Epoch[59](1700/2500): Loss: 0.0957
===> Epoch[59](1800/2500): Loss: 0.0951
===> Epoch[59](1900/2500): Loss: 0.0960
===> Epoch[59](2000/2500): Loss: 0.0954
===> Epoch[59](2100/2500): Loss: 0.0961
===> Epoch[59](2200/2500): Loss: 0.0946
===> Epoch[59](2300/2500): Loss: 0.0952
===> Epoch[59](2400/2500): Loss: 0.0958
===> Epoch[59](2500/2500): Loss: 0.0956
===> Epoch 59 Complete: Avg. Loss: 0.0960
===> Timestamp: [2025-07-29 20:11:34]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.1014
===> Epoch[59](200/2500): Loss: 0.0961
===> Epoch[59](300/2500): Loss: 0.0949
===> Epoch[59](400/2500): Loss: 0.0953
===> Epoch[59](500/2500): Loss: 0.0956
===> Epoch[59](600/2500): Loss: 0.0960
===> Epoch[59](700/2500): Loss: 0.0961
===> Epoch[59](800/2500): Loss: 0.0962
===> Epoch[59](900/2500): Loss: 0.0959
===> Epoch[59](1000/2500): Loss: 0.0954
===> Epoch[59](1100/2500): Loss: 0.0959
===> Epoch[59](1200/2500): Loss: 0.0953
===> Epoch[59](1300/2500): Loss: 0.0956
===> Epoch[59](1400/2500): Loss: 0.0961
===> Epoch[59](1500/2500): Loss: 0.0960
===> Epoch[59](1600/2500): Loss: 0.0958
===> Epoch[59](1700/2500): Loss: 0.0957
===> Epoch[59](1800/2500): Loss: 0.0951
===> Epoch[59](1900/2500): Loss: 0.0960
===> Epoch[59](2000/2500): Loss: 0.0954
===> Epoch[59](2100/2500): Loss: 0.0961
===> Epoch[59](2200/2500): Loss: 0.0946
===> Epoch[59](2300/2500): Loss: 0.0952
===> Epoch[59](2400/2500): Loss: 0.0958
===> Epoch[59](2500/2500): Loss: 0.0956
===> Epoch 59 Complete: Avg. Loss: 0.0960
===> Timestamp: [2025-07-29 20:11:34]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.1014
===> Epoch[59](200/2500): Loss: 0.0961
===> Epoch[59](300/2500): Loss: 0.0949
===> Epoch[59](400/2500): Loss: 0.0953
===> Epoch[59](500/2500): Loss: 0.0956
===> Epoch[59](600/2500): Loss: 0.0960
===> Epoch[59](700/2500): Loss: 0.0961
===> Epoch[59](800/2500): Loss: 0.0962
===> Epoch[59](900/2500): Loss: 0.0959
===> Epoch[59](1000/2500): Loss: 0.0954
===> Epoch[59](1100/2500): Loss: 0.0959
===> Epoch[59](1200/2500): Loss: 0.0953
===> Epoch[59](1300/2500): Loss: 0.0956
===> Epoch[59](1400/2500): Loss: 0.0961
===> Epoch[59](1500/2500): Loss: 0.0960
===> Epoch[59](1600/2500): Loss: 0.0958
===> Epoch[59](1700/2500): Loss: 0.0957
===> Epoch[59](1800/2500): Loss: 0.0951
===> Epoch[59](1900/2500): Loss: 0.0960
===> Epoch[59](2000/2500): Loss: 0.0954
===> Epoch[59](2100/2500): Loss: 0.0961
===> Epoch[59](2200/2500): Loss: 0.0946
===> Epoch[59](2300/2500): Loss: 0.0952
===> Epoch[59](2400/2500): Loss: 0.0958
===> Epoch[59](2500/2500): Loss: 0.0956
===> Epoch 59 Complete: Avg. Loss: 0.0960
===> Timestamp: [2025-07-29 20:11:34]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.1014
===> Epoch[59](200/2500): Loss: 0.0961
===> Epoch[59](300/2500): Loss: 0.0949
===> Epoch[59](400/2500): Loss: 0.0953
===> Epoch[59](500/2500): Loss: 0.0956
===> Epoch[59](600/2500): Loss: 0.0960
===> Epoch[59](700/2500): Loss: 0.0961
===> Epoch[59](800/2500): Loss: 0.0962
===> Epoch[59](900/2500): Loss: 0.0959
===> Epoch[59](1000/2500): Loss: 0.0954
===> Epoch[59](1100/2500): Loss: 0.0959
===> Epoch[59](1200/2500): Loss: 0.0953
===> Epoch[59](1300/2500): Loss: 0.0956
===> Epoch[59](1400/2500): Loss: 0.0961
===> Epoch[59](1500/2500): Loss: 0.0960
===> Epoch[59](1600/2500): Loss: 0.0958
===> Epoch[59](1700/2500): Loss: 0.0957
===> Epoch[59](1800/2500): Loss: 0.0951
===> Epoch[59](1900/2500): Loss: 0.0960
===> Epoch[59](2000/2500): Loss: 0.0954
===> Epoch[59](2100/2500): Loss: 0.0961
===> Epoch[59](2200/2500): Loss: 0.0946
===> Epoch[59](2300/2500): Loss: 0.0952
===> Epoch[59](2400/2500): Loss: 0.0958
===> Epoch[59](2500/2500): Loss: 0.0956
===> Epoch 59 Complete: Avg. Loss: 0.0960
===> Timestamp: [2025-07-29 20:11:34]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.1014
===> Epoch[59](200/2500): Loss: 0.0961
===> Epoch[59](300/2500): Loss: 0.0949
===> Epoch[59](400/2500): Loss: 0.0953
===> Epoch[59](500/2500): Loss: 0.0956
===> Epoch[59](600/2500): Loss: 0.0960
===> Epoch[59](700/2500): Loss: 0.0961
===> Epoch[59](800/2500): Loss: 0.0962
===> Epoch[59](900/2500): Loss: 0.0959
===> Epoch[59](1000/2500): Loss: 0.0954
===> Epoch[59](1100/2500): Loss: 0.0959
===> Epoch[59](1200/2500): Loss: 0.0953
===> Epoch[59](1300/2500): Loss: 0.0956
===> Epoch[59](1400/2500): Loss: 0.0961
===> Epoch[59](1500/2500): Loss: 0.0960
===> Epoch[59](1600/2500): Loss: 0.0958
===> Epoch[59](1700/2500): Loss: 0.0957
===> Epoch[59](1800/2500): Loss: 0.0951
===> Epoch[59](1900/2500): Loss: 0.0960
===> Epoch[59](2000/2500): Loss: 0.0954
===> Epoch[59](2100/2500): Loss: 0.0961
===> Epoch[59](2200/2500): Loss: 0.0946
===> Epoch[59](2300/2500): Loss: 0.0952
===> Epoch[59](2400/2500): Loss: 0.0958
===> Epoch[59](2500/2500): Loss: 0.0956
===> Epoch 59 Complete: Avg. Loss: 0.0960
===> Timestamp: [2025-07-29 20:11:34]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.1014
===> Epoch[59](200/2500): Loss: 0.0961
===> Epoch[59](300/2500): Loss: 0.0949
===> Epoch[59](400/2500): Loss: 0.0953
===> Epoch[59](500/2500): Loss: 0.0956
===> Epoch[59](600/2500): Loss: 0.0960
===> Epoch[59](700/2500): Loss: 0.0961
===> Epoch[59](800/2500): Loss: 0.0962
===> Epoch[59](900/2500): Loss: 0.0959
===> Epoch[59](1000/2500): Loss: 0.0954
===> Epoch[59](1100/2500): Loss: 0.0959
===> Epoch[59](1200/2500): Loss: 0.0953
===> Epoch[59](1300/2500): Loss: 0.0956
===> Epoch[59](1400/2500): Loss: 0.0961
===> Epoch[59](1500/2500): Loss: 0.0960
===> Epoch[59](1600/2500): Loss: 0.0958
===> Epoch[59](1700/2500): Loss: 0.0957
===> Epoch[59](1800/2500): Loss: 0.0951
===> Epoch[59](1900/2500): Loss: 0.0960
===> Epoch[59](2000/2500): Loss: 0.0954
===> Epoch[59](2100/2500): Loss: 0.0961
===> Epoch[59](2200/2500): Loss: 0.0946
===> Epoch[59](2300/2500): Loss: 0.0952
===> Epoch[59](2400/2500): Loss: 0.0958
===> Epoch[59](2500/2500): Loss: 0.0956
===> Epoch 59 Complete: Avg. Loss: 0.0960
===> Timestamp: [2025-07-29 20:11:34]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.1014
===> Epoch[59](200/2500): Loss: 0.0961
===> Epoch[59](300/2500): Loss: 0.0949
===> Epoch[59](400/2500): Loss: 0.0953
===> Epoch[59](500/2500): Loss: 0.0956
===> Epoch[59](600/2500): Loss: 0.0960
===> Epoch[59](700/2500): Loss: 0.0961
===> Epoch[59](800/2500): Loss: 0.0962
===> Epoch[59](900/2500): Loss: 0.0959
===> Epoch[59](1000/2500): Loss: 0.0954
===> Epoch[59](1100/2500): Loss: 0.0959
===> Epoch[59](1200/2500): Loss: 0.0953
===> Epoch[59](1300/2500): Loss: 0.0956
===> Epoch[59](1400/2500): Loss: 0.0961
===> Epoch[59](1500/2500): Loss: 0.0960
===> Epoch[59](1600/2500): Loss: 0.0958
===> Epoch[59](1700/2500): Loss: 0.0957
===> Epoch[59](1800/2500): Loss: 0.0951
===> Epoch[59](1900/2500): Loss: 0.0960
===> Epoch[59](2000/2500): Loss: 0.0954
===> Epoch[59](2100/2500): Loss: 0.0961
===> Epoch[59](2200/2500): Loss: 0.0946
===> Epoch[59](2300/2500): Loss: 0.0952
===> Epoch[59](2400/2500): Loss: 0.0958
===> Epoch[59](2500/2500): Loss: 0.0956
===> Epoch 59 Complete: Avg. Loss: 0.0960
===> Timestamp: [2025-07-29 20:11:34]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.1014
===> Epoch[59](200/2500): Loss: 0.0961
===> Epoch[59](300/2500): Loss: 0.0949
===> Epoch[59](400/2500): Loss: 0.0953
===> Epoch[59](500/2500): Loss: 0.0956
===> Epoch[59](600/2500): Loss: 0.0960
===> Epoch[59](700/2500): Loss: 0.0961
===> Epoch[59](800/2500): Loss: 0.0962
===> Epoch[59](900/2500): Loss: 0.0959
===> Epoch[59](1000/2500): Loss: 0.0954
===> Epoch[59](1100/2500): Loss: 0.0959
===> Epoch[59](1200/2500): Loss: 0.0953
===> Epoch[59](1300/2500): Loss: 0.0956
===> Epoch[59](1400/2500): Loss: 0.0961
===> Epoch[59](1500/2500): Loss: 0.0960
===> Epoch[59](1600/2500): Loss: 0.0958
===> Epoch[59](1700/2500): Loss: 0.0957
===> Epoch[59](1800/2500): Loss: 0.0951
===> Epoch[59](1900/2500): Loss: 0.0960
===> Epoch[59](2000/2500): Loss: 0.0954
===> Epoch[59](2100/2500): Loss: 0.0961
===> Epoch[59](2200/2500): Loss: 0.0946
===> Epoch[59](2300/2500): Loss: 0.0952
===> Epoch[59](2400/2500): Loss: 0.0958
===> Epoch[59](2500/2500): Loss: 0.0956
===> Epoch 59 Complete: Avg. Loss: 0.0960
===> Timestamp: [2025-07-29 20:11:34]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.1014
===> Epoch[59](200/2500): Loss: 0.0961
===> Epoch[59](300/2500): Loss: 0.0949
===> Epoch[59](400/2500): Loss: 0.0953
===> Epoch[59](500/2500): Loss: 0.0956
===> Epoch[59](600/2500): Loss: 0.0960
===> Epoch[59](700/2500): Loss: 0.0961
===> Epoch[59](800/2500): Loss: 0.0962
===> Epoch[59](900/2500): Loss: 0.0959
===> Epoch[59](1000/2500): Loss: 0.0954
===> Epoch[59](1100/2500): Loss: 0.0959
===> Epoch[59](1200/2500): Loss: 0.0953
===> Epoch[59](1300/2500): Loss: 0.0956
===> Epoch[59](1400/2500): Loss: 0.0961
===> Epoch[59](1500/2500): Loss: 0.0960
===> Epoch[59](1600/2500): Loss: 0.0958
===> Epoch[59](1700/2500): Loss: 0.0957
===> Epoch[59](1800/2500): Loss: 0.0951
===> Epoch[59](1900/2500): Loss: 0.0960
===> Epoch[59](2000/2500): Loss: 0.0954
===> Epoch[59](2100/2500): Loss: 0.0961
===> Epoch[59](2200/2500): Loss: 0.0946
===> Epoch[59](2300/2500): Loss: 0.0952
===> Epoch[59](2400/2500): Loss: 0.0958
===> Epoch[59](2500/2500): Loss: 0.0956
===> Epoch 59 Complete: Avg. Loss: 0.0960
===> Timestamp: [2025-07-29 20:11:34]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.1014
===> Epoch[59](200/2500): Loss: 0.0961
===> Epoch[59](300/2500): Loss: 0.0949
===> Epoch[59](400/2500): Loss: 0.0953
===> Epoch[59](500/2500): Loss: 0.0956
===> Epoch[59](600/2500): Loss: 0.0960
===> Epoch[59](700/2500): Loss: 0.0961
===> Epoch[59](800/2500): Loss: 0.0962
===> Epoch[59](900/2500): Loss: 0.0959
===> Epoch[59](1000/2500): Loss: 0.0954
===> Epoch[59](1100/2500): Loss: 0.0959
===> Epoch[59](1200/2500): Loss: 0.0953
===> Epoch[59](1300/2500): Loss: 0.0956
===> Epoch[59](1400/2500): Loss: 0.0961
===> Epoch[59](1500/2500): Loss: 0.0960
===> Epoch[59](1600/2500): Loss: 0.0958
===> Epoch[59](1700/2500): Loss: 0.0957
===> Epoch[59](1800/2500): Loss: 0.0951
===> Epoch[59](1900/2500): Loss: 0.0960
===> Epoch[59](2000/2500): Loss: 0.0954
===> Epoch[59](2100/2500): Loss: 0.0961
===> Epoch[59](2200/2500): Loss: 0.0946
===> Epoch[59](2300/2500): Loss: 0.0952
===> Epoch[59](2400/2500): Loss: 0.0958
===> Epoch[59](2500/2500): Loss: 0.0956
===> Epoch 59 Complete: Avg. Loss: 0.0960
===> Timestamp: [2025-07-29 20:11:34]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.1014
===> Epoch[59](200/2500): Loss: 0.0961
===> Epoch[59](300/2500): Loss: 0.0949
===> Epoch[59](400/2500): Loss: 0.0953
===> Epoch[59](500/2500): Loss: 0.0956
===> Epoch[59](600/2500): Loss: 0.0960
===> Epoch[59](700/2500): Loss: 0.0961
===> Epoch[59](800/2500): Loss: 0.0962
===> Epoch[59](900/2500): Loss: 0.0959
===> Epoch[59](1000/2500): Loss: 0.0954
===> Epoch[59](1100/2500): Loss: 0.0959
===> Epoch[59](1200/2500): Loss: 0.0953
===> Epoch[59](1300/2500): Loss: 0.0956
===> Epoch[59](1400/2500): Loss: 0.0961
===> Epoch[59](1500/2500): Loss: 0.0960
===> Epoch[59](1600/2500): Loss: 0.0958
===> Epoch[59](1700/2500): Loss: 0.0957
===> Epoch[59](1800/2500): Loss: 0.0951
===> Epoch[59](1900/2500): Loss: 0.0960
===> Epoch[59](2000/2500): Loss: 0.0954
===> Epoch[59](2100/2500): Loss: 0.0961
===> Epoch[59](2200/2500): Loss: 0.0946
===> Epoch[59](2300/2500): Loss: 0.0952
===> Epoch[59](2400/2500): Loss: 0.0958
===> Epoch[59](2500/2500): Loss: 0.0956
===> Epoch 59 Complete: Avg. Loss: 0.0960
===> Timestamp: [2025-07-29 20:11:34]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.1014
===> Epoch[59](200/2500): Loss: 0.0961
===> Epoch[59](300/2500): Loss: 0.0949
===> Epoch[59](400/2500): Loss: 0.0953
===> Epoch[59](500/2500): Loss: 0.0956
===> Epoch[59](600/2500): Loss: 0.0960
===> Epoch[59](700/2500): Loss: 0.0961
===> Epoch[59](800/2500): Loss: 0.0962
===> Epoch[59](900/2500): Loss: 0.0959
===> Epoch[59](1000/2500): Loss: 0.0954
===> Epoch[59](1100/2500): Loss: 0.0959
===> Epoch[59](1200/2500): Loss: 0.0953
===> Epoch[59](1300/2500): Loss: 0.0956
===> Epoch[59](1400/2500): Loss: 0.0961
===> Epoch[59](1500/2500): Loss: 0.0960
===> Epoch[59](1600/2500): Loss: 0.0958
===> Epoch[59](1700/2500): Loss: 0.0957
===> Epoch[59](1800/2500): Loss: 0.0951
===> Epoch[59](1900/2500): Loss: 0.0960
===> Epoch[59](2000/2500): Loss: 0.0954
===> Epoch[59](2100/2500): Loss: 0.0961
===> Epoch[59](2200/2500): Loss: 0.0946
===> Epoch[59](2300/2500): Loss: 0.0952
===> Epoch[59](2400/2500): Loss: 0.0958
===> Epoch[59](2500/2500): Loss: 0.0956
===> Epoch 59 Complete: Avg. Loss: 0.0960
===> Timestamp: [2025-07-29 20:11:34]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.1014
===> Epoch[59](200/2500): Loss: 0.0961
===> Epoch[59](300/2500): Loss: 0.0949
===> Epoch[59](400/2500): Loss: 0.0953
===> Epoch[59](500/2500): Loss: 0.0956
===> Epoch[59](600/2500): Loss: 0.0960
===> Epoch[59](700/2500): Loss: 0.0961
===> Epoch[59](800/2500): Loss: 0.0962
===> Epoch[59](900/2500): Loss: 0.0959
===> Epoch[59](1000/2500): Loss: 0.0954
===> Epoch[59](1100/2500): Loss: 0.0959
===> Epoch[59](1200/2500): Loss: 0.0953
===> Epoch[59](1300/2500): Loss: 0.0956
===> Epoch[59](1400/2500): Loss: 0.0961
===> Epoch[59](1500/2500): Loss: 0.0960
===> Epoch[59](1600/2500): Loss: 0.0958
===> Epoch[59](1700/2500): Loss: 0.0957
===> Epoch[59](1800/2500): Loss: 0.0951
===> Epoch[59](1900/2500): Loss: 0.0960
===> Epoch[59](2000/2500): Loss: 0.0954
===> Epoch[59](2100/2500): Loss: 0.0961
===> Epoch[59](2200/2500): Loss: 0.0946
===> Epoch[59](2300/2500): Loss: 0.0952
===> Epoch[59](2400/2500): Loss: 0.0958
===> Epoch[59](2500/2500): Loss: 0.0956
===> Epoch 59 Complete: Avg. Loss: 0.0960
===> Timestamp: [2025-07-29 20:11:34]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.1014
===> Epoch[59](200/2500): Loss: 0.0961
===> Epoch[59](300/2500): Loss: 0.0949
===> Epoch[59](400/2500): Loss: 0.0953
===> Epoch[59](500/2500): Loss: 0.0956
===> Epoch[59](600/2500): Loss: 0.0960
===> Epoch[59](700/2500): Loss: 0.0961
===> Epoch[59](800/2500): Loss: 0.0962
===> Epoch[59](900/2500): Loss: 0.0959
===> Epoch[59](1000/2500): Loss: 0.0954
===> Epoch[59](1100/2500): Loss: 0.0959
===> Epoch[59](1200/2500): Loss: 0.0953
===> Epoch[59](1300/2500): Loss: 0.0956
===> Epoch[59](1400/2500): Loss: 0.0961
===> Epoch[59](1500/2500): Loss: 0.0960
===> Epoch[59](1600/2500): Loss: 0.0958
===> Epoch[59](1700/2500): Loss: 0.0957
===> Epoch[59](1800/2500): Loss: 0.0951
===> Epoch[59](1900/2500): Loss: 0.0960
===> Epoch[59](2000/2500): Loss: 0.0954
===> Epoch[59](2100/2500): Loss: 0.0961
===> Epoch[59](2200/2500): Loss: 0.0946
===> Epoch[59](2300/2500): Loss: 0.0952
===> Epoch[59](2400/2500): Loss: 0.0958
===> Epoch[59](2500/2500): Loss: 0.0956
===> Epoch 59 Complete: Avg. Loss: 0.0960
===> Timestamp: [2025-07-29 20:11:34]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.1014
===> Epoch[59](200/2500): Loss: 0.0961
===> Epoch[59](300/2500): Loss: 0.0949
===> Epoch[59](400/2500): Loss: 0.0953
===> Epoch[59](500/2500): Loss: 0.0956
===> Epoch[59](600/2500): Loss: 0.0960
===> Epoch[59](700/2500): Loss: 0.0961
===> Epoch[59](800/2500): Loss: 0.0962
===> Epoch[59](900/2500): Loss: 0.0959
===> Epoch[59](1000/2500): Loss: 0.0954
===> Epoch[59](1100/2500): Loss: 0.0959
===> Epoch[59](1200/2500): Loss: 0.0953
===> Epoch[59](1300/2500): Loss: 0.0956
===> Epoch[59](1400/2500): Loss: 0.0961
===> Epoch[59](1500/2500): Loss: 0.0960
===> Epoch[59](1600/2500): Loss: 0.0958
===> Epoch[59](1700/2500): Loss: 0.0957
===> Epoch[59](1800/2500): Loss: 0.0951
===> Epoch[59](1900/2500): Loss: 0.0960
===> Epoch[59](2000/2500): Loss: 0.0954
===> Epoch[59](2100/2500): Loss: 0.0961
===> Epoch[59](2200/2500): Loss: 0.0946
===> Epoch[59](2300/2500): Loss: 0.0952
===> Epoch[59](2400/2500): Loss: 0.0958
===> Epoch[59](2500/2500): Loss: 0.0956
===> Epoch 59 Complete: Avg. Loss: 0.0960
===> Timestamp: [2025-07-29 20:11:34]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.1014
===> Epoch[59](200/2500): Loss: 0.0961
===> Epoch[59](300/2500): Loss: 0.0949
===> Epoch[59](400/2500): Loss: 0.0953
===> Epoch[59](500/2500): Loss: 0.0956
===> Epoch[59](600/2500): Loss: 0.0960
===> Epoch[59](700/2500): Loss: 0.0961
===> Epoch[59](800/2500): Loss: 0.0962
===> Epoch[59](900/2500): Loss: 0.0959
===> Epoch[59](1000/2500): Loss: 0.0954
===> Epoch[59](1100/2500): Loss: 0.0959
===> Epoch[59](1200/2500): Loss: 0.0953
===> Epoch[59](1300/2500): Loss: 0.0956
===> Epoch[59](1400/2500): Loss: 0.0961
===> Epoch[59](1500/2500): Loss: 0.0960
===> Epoch[59](1600/2500): Loss: 0.0958
===> Epoch[59](1700/2500): Loss: 0.0957
===> Epoch[59](1800/2500): Loss: 0.0951
===> Epoch[59](1900/2500): Loss: 0.0960
===> Epoch[59](2000/2500): Loss: 0.0954
===> Epoch[59](2100/2500): Loss: 0.0961
===> Epoch[59](2200/2500): Loss: 0.0946
===> Epoch[59](2300/2500): Loss: 0.0952
===> Epoch[59](2400/2500): Loss: 0.0958
===> Epoch[59](2500/2500): Loss: 0.0956
===> Epoch 59 Complete: Avg. Loss: 0.0960
===> Timestamp: [2025-07-29 20:11:34]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.1014
===> Epoch[59](200/2500): Loss: 0.0961
===> Epoch[59](300/2500): Loss: 0.0949
===> Epoch[59](400/2500): Loss: 0.0953
===> Epoch[59](500/2500): Loss: 0.0956
===> Epoch[59](600/2500): Loss: 0.0960
===> Epoch[59](700/2500): Loss: 0.0961
===> Epoch[59](800/2500): Loss: 0.0962
===> Epoch[59](900/2500): Loss: 0.0959
===> Epoch[59](1000/2500): Loss: 0.0954
===> Epoch[59](1100/2500): Loss: 0.0959
===> Epoch[59](1200/2500): Loss: 0.0953
===> Epoch[59](1300/2500): Loss: 0.0956
===> Epoch[59](1400/2500): Loss: 0.0961
===> Epoch[59](1500/2500): Loss: 0.0960
===> Epoch[59](1600/2500): Loss: 0.0958
===> Epoch[59](1700/2500): Loss: 0.0957
===> Epoch[59](1800/2500): Loss: 0.0951
===> Epoch[59](1900/2500): Loss: 0.0960
===> Epoch[59](2000/2500): Loss: 0.0954
===> Epoch[59](2100/2500): Loss: 0.0961
===> Epoch[59](2200/2500): Loss: 0.0946
===> Epoch[59](2300/2500): Loss: 0.0952
===> Epoch[59](2400/2500): Loss: 0.0958
===> Epoch[59](2500/2500): Loss: 0.0956
===> Epoch 59 Complete: Avg. Loss: 0.0960
===> Timestamp: [2025-07-29 20:11:34]
===> Loading train datasets
===> Epoch[59](100/2500): Loss: 0.1014
===> Epoch[59](200/2500): Loss: 0.0961
===> Epoch[59](300/2500): Loss: 0.0949
===> Epoch[59](400/2500): Loss: 0.0953
===> Epoch[59](500/2500): Loss: 0.0956
===> Epoch[59](600/2500): Loss: 0.0960
===> Epoch[59](700/2500): Loss: 0.0961
===> Epoch[59](800/2500): Loss: 0.0962
===> Epoch[59](900/2500): Loss: 0.0959
===> Epoch[59](1000/2500): Loss: 0.0954
===> Epoch[59](1100/2500): Loss: 0.0959
===> Epoch[59](1200/2500): Loss: 0.0953
===> Epoch[59](1300/2500): Loss: 0.0956
===> Epoch[59](1400/2500): Loss: 0.0961
===> Epoch[59](1500/2500): Loss: 0.0960
===> Epoch[59](1600/2500): Loss: 0.0958
===> Epoch[59](1700/2500): Loss: 0.0957
===> Epoch[59](1800/2500): Loss: 0.0951
===> Epoch[59](1900/2500): Loss: 0.0960
===> Epoch[59](2000/2500): Loss: 0.0954
===> Epoch[59](2100/2500): Loss: 0.0961
===> Epoch[59](2200/2500): Loss: 0.0946
===> Epoch[59](2300/2500): Loss: 0.0952
===> Epoch[59](2400/2500): Loss: 0.0958
===> Epoch[59](2500/2500): Loss: 0.0956
===> Epoch 59 Complete: Avg. Loss: 0.0960
===> Timestamp: [2025-07-29 20:11:34]
===> Loading train datasets
===> Loading train datasets
===> Epoch[60](100/2500): Loss: 0.0955
===> Epoch[60](200/2500): Loss: 0.0948
===> Epoch[60](300/2500): Loss: 0.0960
===> Epoch[60](400/2500): Loss: 0.0952
===> Epoch[60](500/2500): Loss: 0.0953
===> Epoch[60](600/2500): Loss: 0.0950
===> Epoch[60](700/2500): Loss: 0.0951
===> Epoch[60](800/2500): Loss: 0.0961
===> Epoch[60](900/2500): Loss: 0.1032
===> Epoch[60](1000/2500): Loss: 0.0958
===> Epoch[60](1100/2500): Loss: 0.0955
===> Epoch[60](1200/2500): Loss: 0.0955
===> Epoch[60](1300/2500): Loss: 0.0948
===> Epoch[60](1400/2500): Loss: 0.0954
===> Epoch[60](1500/2500): Loss: 0.0951
===> Epoch[60](1600/2500): Loss: 0.0955
===> Epoch[60](1700/2500): Loss: 0.0954
===> Epoch[60](1800/2500): Loss: 0.0953
===> Epoch[60](1900/2500): Loss: 0.0955
===> Epoch[60](2000/2500): Loss: 0.0946
===> Epoch[60](2100/2500): Loss: 0.0956
===> Epoch[60](2200/2500): Loss: 0.0952
===> Epoch[60](2300/2500): Loss: 0.0954
===> Epoch[60](2400/2500): Loss: 0.0947
===> Epoch[60](2500/2500): Loss: 0.0951
===> Epoch 60 Complete: Avg. Loss: 0.0958
===> Timestamp: [2025-07-29 20:16:40]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.0955
===> Epoch[60](200/2500): Loss: 0.0948
===> Epoch[60](300/2500): Loss: 0.0960
===> Epoch[60](400/2500): Loss: 0.0952
===> Epoch[60](500/2500): Loss: 0.0953
===> Epoch[60](600/2500): Loss: 0.0950
===> Epoch[60](700/2500): Loss: 0.0951
===> Epoch[60](800/2500): Loss: 0.0961
===> Epoch[60](900/2500): Loss: 0.1032
===> Epoch[60](1000/2500): Loss: 0.0958
===> Epoch[60](1100/2500): Loss: 0.0955
===> Epoch[60](1200/2500): Loss: 0.0955
===> Epoch[60](1300/2500): Loss: 0.0948
===> Epoch[60](1400/2500): Loss: 0.0954
===> Epoch[60](1500/2500): Loss: 0.0951
===> Epoch[60](1600/2500): Loss: 0.0955
===> Epoch[60](1700/2500): Loss: 0.0954
===> Epoch[60](1800/2500): Loss: 0.0953
===> Epoch[60](1900/2500): Loss: 0.0955
===> Epoch[60](2000/2500): Loss: 0.0946
===> Epoch[60](2100/2500): Loss: 0.0956
===> Epoch[60](2200/2500): Loss: 0.0952
===> Epoch[60](2300/2500): Loss: 0.0954
===> Epoch[60](2400/2500): Loss: 0.0947
===> Epoch[60](2500/2500): Loss: 0.0951
===> Epoch 60 Complete: Avg. Loss: 0.0958
===> Timestamp: [2025-07-29 20:16:40]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.0955
===> Epoch[60](200/2500): Loss: 0.0948
===> Epoch[60](300/2500): Loss: 0.0960
===> Epoch[60](400/2500): Loss: 0.0952
===> Epoch[60](500/2500): Loss: 0.0953
===> Epoch[60](600/2500): Loss: 0.0950
===> Epoch[60](700/2500): Loss: 0.0951
===> Epoch[60](800/2500): Loss: 0.0961
===> Epoch[60](900/2500): Loss: 0.1032
===> Epoch[60](1000/2500): Loss: 0.0958
===> Epoch[60](1100/2500): Loss: 0.0955
===> Epoch[60](1200/2500): Loss: 0.0955
===> Epoch[60](1300/2500): Loss: 0.0948
===> Epoch[60](1400/2500): Loss: 0.0954
===> Epoch[60](1500/2500): Loss: 0.0951
===> Epoch[60](1600/2500): Loss: 0.0955
===> Epoch[60](1700/2500): Loss: 0.0954
===> Epoch[60](1800/2500): Loss: 0.0953
===> Epoch[60](1900/2500): Loss: 0.0955
===> Epoch[60](2000/2500): Loss: 0.0946
===> Epoch[60](2100/2500): Loss: 0.0956
===> Epoch[60](2200/2500): Loss: 0.0952
===> Epoch[60](2300/2500): Loss: 0.0954
===> Epoch[60](2400/2500): Loss: 0.0947
===> Epoch[60](2500/2500): Loss: 0.0951
===> Epoch 60 Complete: Avg. Loss: 0.0958
===> Timestamp: [2025-07-29 20:16:40]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.0955
===> Epoch[60](200/2500): Loss: 0.0948
===> Epoch[60](300/2500): Loss: 0.0960
===> Epoch[60](400/2500): Loss: 0.0952
===> Epoch[60](500/2500): Loss: 0.0953
===> Epoch[60](600/2500): Loss: 0.0950
===> Epoch[60](700/2500): Loss: 0.0951
===> Epoch[60](800/2500): Loss: 0.0961
===> Epoch[60](900/2500): Loss: 0.1032
===> Epoch[60](1000/2500): Loss: 0.0958
===> Epoch[60](1100/2500): Loss: 0.0955
===> Epoch[60](1200/2500): Loss: 0.0955
===> Epoch[60](1300/2500): Loss: 0.0948
===> Epoch[60](1400/2500): Loss: 0.0954
===> Epoch[60](1500/2500): Loss: 0.0951
===> Epoch[60](1600/2500): Loss: 0.0955
===> Epoch[60](1700/2500): Loss: 0.0954
===> Epoch[60](1800/2500): Loss: 0.0953
===> Epoch[60](1900/2500): Loss: 0.0955
===> Epoch[60](2000/2500): Loss: 0.0946
===> Epoch[60](2100/2500): Loss: 0.0956
===> Epoch[60](2200/2500): Loss: 0.0952
===> Epoch[60](2300/2500): Loss: 0.0954
===> Epoch[60](2400/2500): Loss: 0.0947
===> Epoch[60](2500/2500): Loss: 0.0951
===> Epoch 60 Complete: Avg. Loss: 0.0958
===> Timestamp: [2025-07-29 20:16:40]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.0955
===> Epoch[60](200/2500): Loss: 0.0948
===> Epoch[60](300/2500): Loss: 0.0960
===> Epoch[60](400/2500): Loss: 0.0952
===> Epoch[60](500/2500): Loss: 0.0953
===> Epoch[60](600/2500): Loss: 0.0950
===> Epoch[60](700/2500): Loss: 0.0951
===> Epoch[60](800/2500): Loss: 0.0961
===> Epoch[60](900/2500): Loss: 0.1032
===> Epoch[60](1000/2500): Loss: 0.0958
===> Epoch[60](1100/2500): Loss: 0.0955
===> Epoch[60](1200/2500): Loss: 0.0955
===> Epoch[60](1300/2500): Loss: 0.0948
===> Epoch[60](1400/2500): Loss: 0.0954
===> Epoch[60](1500/2500): Loss: 0.0951
===> Epoch[60](1600/2500): Loss: 0.0955
===> Epoch[60](1700/2500): Loss: 0.0954
===> Epoch[60](1800/2500): Loss: 0.0953
===> Epoch[60](1900/2500): Loss: 0.0955
===> Epoch[60](2000/2500): Loss: 0.0946
===> Epoch[60](2100/2500): Loss: 0.0956
===> Epoch[60](2200/2500): Loss: 0.0952
===> Epoch[60](2300/2500): Loss: 0.0954
===> Epoch[60](2400/2500): Loss: 0.0947
===> Epoch[60](2500/2500): Loss: 0.0951
===> Epoch 60 Complete: Avg. Loss: 0.0958
===> Timestamp: [2025-07-29 20:16:40]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.0955
===> Epoch[60](200/2500): Loss: 0.0948
===> Epoch[60](300/2500): Loss: 0.0960
===> Epoch[60](400/2500): Loss: 0.0952
===> Epoch[60](500/2500): Loss: 0.0953
===> Epoch[60](600/2500): Loss: 0.0950
===> Epoch[60](700/2500): Loss: 0.0951
===> Epoch[60](800/2500): Loss: 0.0961
===> Epoch[60](900/2500): Loss: 0.1032
===> Epoch[60](1000/2500): Loss: 0.0958
===> Epoch[60](1100/2500): Loss: 0.0955
===> Epoch[60](1200/2500): Loss: 0.0955
===> Epoch[60](1300/2500): Loss: 0.0948
===> Epoch[60](1400/2500): Loss: 0.0954
===> Epoch[60](1500/2500): Loss: 0.0951
===> Epoch[60](1600/2500): Loss: 0.0955
===> Epoch[60](1700/2500): Loss: 0.0954
===> Epoch[60](1800/2500): Loss: 0.0953
===> Epoch[60](1900/2500): Loss: 0.0955
===> Epoch[60](2000/2500): Loss: 0.0946
===> Epoch[60](2100/2500): Loss: 0.0956
===> Epoch[60](2200/2500): Loss: 0.0952
===> Epoch[60](2300/2500): Loss: 0.0954
===> Epoch[60](2400/2500): Loss: 0.0947
===> Epoch[60](2500/2500): Loss: 0.0951
===> Epoch 60 Complete: Avg. Loss: 0.0958
===> Timestamp: [2025-07-29 20:16:40]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.0955
===> Epoch[60](200/2500): Loss: 0.0948
===> Epoch[60](300/2500): Loss: 0.0960
===> Epoch[60](400/2500): Loss: 0.0952
===> Epoch[60](500/2500): Loss: 0.0953
===> Epoch[60](600/2500): Loss: 0.0950
===> Epoch[60](700/2500): Loss: 0.0951
===> Epoch[60](800/2500): Loss: 0.0961
===> Epoch[60](900/2500): Loss: 0.1032
===> Epoch[60](1000/2500): Loss: 0.0958
===> Epoch[60](1100/2500): Loss: 0.0955
===> Epoch[60](1200/2500): Loss: 0.0955
===> Epoch[60](1300/2500): Loss: 0.0948
===> Epoch[60](1400/2500): Loss: 0.0954
===> Epoch[60](1500/2500): Loss: 0.0951
===> Epoch[60](1600/2500): Loss: 0.0955
===> Epoch[60](1700/2500): Loss: 0.0954
===> Epoch[60](1800/2500): Loss: 0.0953
===> Epoch[60](1900/2500): Loss: 0.0955
===> Epoch[60](2000/2500): Loss: 0.0946
===> Epoch[60](2100/2500): Loss: 0.0956
===> Epoch[60](2200/2500): Loss: 0.0952
===> Epoch[60](2300/2500): Loss: 0.0954
===> Epoch[60](2400/2500): Loss: 0.0947
===> Epoch[60](2500/2500): Loss: 0.0951
===> Epoch 60 Complete: Avg. Loss: 0.0958
===> Timestamp: [2025-07-29 20:16:40]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.0955
===> Epoch[60](200/2500): Loss: 0.0948
===> Epoch[60](300/2500): Loss: 0.0960
===> Epoch[60](400/2500): Loss: 0.0952
===> Epoch[60](500/2500): Loss: 0.0953
===> Epoch[60](600/2500): Loss: 0.0950
===> Epoch[60](700/2500): Loss: 0.0951
===> Epoch[60](800/2500): Loss: 0.0961
===> Epoch[60](900/2500): Loss: 0.1032
===> Epoch[60](1000/2500): Loss: 0.0958
===> Epoch[60](1100/2500): Loss: 0.0955
===> Epoch[60](1200/2500): Loss: 0.0955
===> Epoch[60](1300/2500): Loss: 0.0948
===> Epoch[60](1400/2500): Loss: 0.0954
===> Epoch[60](1500/2500): Loss: 0.0951
===> Epoch[60](1600/2500): Loss: 0.0955
===> Epoch[60](1700/2500): Loss: 0.0954
===> Epoch[60](1800/2500): Loss: 0.0953
===> Epoch[60](1900/2500): Loss: 0.0955
===> Epoch[60](2000/2500): Loss: 0.0946
===> Epoch[60](2100/2500): Loss: 0.0956
===> Epoch[60](2200/2500): Loss: 0.0952
===> Epoch[60](2300/2500): Loss: 0.0954
===> Epoch[60](2400/2500): Loss: 0.0947
===> Epoch[60](2500/2500): Loss: 0.0951
===> Epoch 60 Complete: Avg. Loss: 0.0958
===> Timestamp: [2025-07-29 20:16:40]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.0955
===> Epoch[60](200/2500): Loss: 0.0948
===> Epoch[60](300/2500): Loss: 0.0960
===> Epoch[60](400/2500): Loss: 0.0952
===> Epoch[60](500/2500): Loss: 0.0953
===> Epoch[60](600/2500): Loss: 0.0950
===> Epoch[60](700/2500): Loss: 0.0951
===> Epoch[60](800/2500): Loss: 0.0961
===> Epoch[60](900/2500): Loss: 0.1032
===> Epoch[60](1000/2500): Loss: 0.0958
===> Epoch[60](1100/2500): Loss: 0.0955
===> Epoch[60](1200/2500): Loss: 0.0955
===> Epoch[60](1300/2500): Loss: 0.0948
===> Epoch[60](1400/2500): Loss: 0.0954
===> Epoch[60](1500/2500): Loss: 0.0951
===> Epoch[60](1600/2500): Loss: 0.0955
===> Epoch[60](1700/2500): Loss: 0.0954
===> Epoch[60](1800/2500): Loss: 0.0953
===> Epoch[60](1900/2500): Loss: 0.0955
===> Epoch[60](2000/2500): Loss: 0.0946
===> Epoch[60](2100/2500): Loss: 0.0956
===> Epoch[60](2200/2500): Loss: 0.0952
===> Epoch[60](2300/2500): Loss: 0.0954
===> Epoch[60](2400/2500): Loss: 0.0947
===> Epoch[60](2500/2500): Loss: 0.0951
===> Epoch 60 Complete: Avg. Loss: 0.0958
===> Timestamp: [2025-07-29 20:16:40]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.0955
===> Epoch[60](200/2500): Loss: 0.0948
===> Epoch[60](300/2500): Loss: 0.0960
===> Epoch[60](400/2500): Loss: 0.0952
===> Epoch[60](500/2500): Loss: 0.0953
===> Epoch[60](600/2500): Loss: 0.0950
===> Epoch[60](700/2500): Loss: 0.0951
===> Epoch[60](800/2500): Loss: 0.0961
===> Epoch[60](900/2500): Loss: 0.1032
===> Epoch[60](1000/2500): Loss: 0.0958
===> Epoch[60](1100/2500): Loss: 0.0955
===> Epoch[60](1200/2500): Loss: 0.0955
===> Epoch[60](1300/2500): Loss: 0.0948
===> Epoch[60](1400/2500): Loss: 0.0954
===> Epoch[60](1500/2500): Loss: 0.0951
===> Epoch[60](1600/2500): Loss: 0.0955
===> Epoch[60](1700/2500): Loss: 0.0954
===> Epoch[60](1800/2500): Loss: 0.0953
===> Epoch[60](1900/2500): Loss: 0.0955
===> Epoch[60](2000/2500): Loss: 0.0946
===> Epoch[60](2100/2500): Loss: 0.0956
===> Epoch[60](2200/2500): Loss: 0.0952
===> Epoch[60](2300/2500): Loss: 0.0954
===> Epoch[60](2400/2500): Loss: 0.0947
===> Epoch[60](2500/2500): Loss: 0.0951
===> Epoch 60 Complete: Avg. Loss: 0.0958
===> Timestamp: [2025-07-29 20:16:40]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.0955
===> Epoch[60](200/2500): Loss: 0.0948
===> Epoch[60](300/2500): Loss: 0.0960
===> Epoch[60](400/2500): Loss: 0.0952
===> Epoch[60](500/2500): Loss: 0.0953
===> Epoch[60](600/2500): Loss: 0.0950
===> Epoch[60](700/2500): Loss: 0.0951
===> Epoch[60](800/2500): Loss: 0.0961
===> Epoch[60](900/2500): Loss: 0.1032
===> Epoch[60](1000/2500): Loss: 0.0958
===> Epoch[60](1100/2500): Loss: 0.0955
===> Epoch[60](1200/2500): Loss: 0.0955
===> Epoch[60](1300/2500): Loss: 0.0948
===> Epoch[60](1400/2500): Loss: 0.0954
===> Epoch[60](1500/2500): Loss: 0.0951
===> Epoch[60](1600/2500): Loss: 0.0955
===> Epoch[60](1700/2500): Loss: 0.0954
===> Epoch[60](1800/2500): Loss: 0.0953
===> Epoch[60](1900/2500): Loss: 0.0955
===> Epoch[60](2000/2500): Loss: 0.0946
===> Epoch[60](2100/2500): Loss: 0.0956
===> Epoch[60](2200/2500): Loss: 0.0952
===> Epoch[60](2300/2500): Loss: 0.0954
===> Epoch[60](2400/2500): Loss: 0.0947
===> Epoch[60](2500/2500): Loss: 0.0951
===> Epoch 60 Complete: Avg. Loss: 0.0958
===> Timestamp: [2025-07-29 20:16:40]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.0955
===> Epoch[60](200/2500): Loss: 0.0948
===> Epoch[60](300/2500): Loss: 0.0960
===> Epoch[60](400/2500): Loss: 0.0952
===> Epoch[60](500/2500): Loss: 0.0953
===> Epoch[60](600/2500): Loss: 0.0950
===> Epoch[60](700/2500): Loss: 0.0951
===> Epoch[60](800/2500): Loss: 0.0961
===> Epoch[60](900/2500): Loss: 0.1032
===> Epoch[60](1000/2500): Loss: 0.0958
===> Epoch[60](1100/2500): Loss: 0.0955
===> Epoch[60](1200/2500): Loss: 0.0955
===> Epoch[60](1300/2500): Loss: 0.0948
===> Epoch[60](1400/2500): Loss: 0.0954
===> Epoch[60](1500/2500): Loss: 0.0951
===> Epoch[60](1600/2500): Loss: 0.0955
===> Epoch[60](1700/2500): Loss: 0.0954
===> Epoch[60](1800/2500): Loss: 0.0953
===> Epoch[60](1900/2500): Loss: 0.0955
===> Epoch[60](2000/2500): Loss: 0.0946
===> Epoch[60](2100/2500): Loss: 0.0956
===> Epoch[60](2200/2500): Loss: 0.0952
===> Epoch[60](2300/2500): Loss: 0.0954
===> Epoch[60](2400/2500): Loss: 0.0947
===> Epoch[60](2500/2500): Loss: 0.0951
===> Epoch 60 Complete: Avg. Loss: 0.0958
===> Timestamp: [2025-07-29 20:16:40]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.0955
===> Epoch[60](200/2500): Loss: 0.0948
===> Epoch[60](300/2500): Loss: 0.0960
===> Epoch[60](400/2500): Loss: 0.0952
===> Epoch[60](500/2500): Loss: 0.0953
===> Epoch[60](600/2500): Loss: 0.0950
===> Epoch[60](700/2500): Loss: 0.0951
===> Epoch[60](800/2500): Loss: 0.0961
===> Epoch[60](900/2500): Loss: 0.1032
===> Epoch[60](1000/2500): Loss: 0.0958
===> Epoch[60](1100/2500): Loss: 0.0955
===> Epoch[60](1200/2500): Loss: 0.0955
===> Epoch[60](1300/2500): Loss: 0.0948
===> Epoch[60](1400/2500): Loss: 0.0954
===> Epoch[60](1500/2500): Loss: 0.0951
===> Epoch[60](1600/2500): Loss: 0.0955
===> Epoch[60](1700/2500): Loss: 0.0954
===> Epoch[60](1800/2500): Loss: 0.0953
===> Epoch[60](1900/2500): Loss: 0.0955
===> Epoch[60](2000/2500): Loss: 0.0946
===> Epoch[60](2100/2500): Loss: 0.0956
===> Epoch[60](2200/2500): Loss: 0.0952
===> Epoch[60](2300/2500): Loss: 0.0954
===> Epoch[60](2400/2500): Loss: 0.0947
===> Epoch[60](2500/2500): Loss: 0.0951
===> Epoch 60 Complete: Avg. Loss: 0.0958
===> Timestamp: [2025-07-29 20:16:40]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.0955
===> Epoch[60](200/2500): Loss: 0.0948
===> Epoch[60](300/2500): Loss: 0.0960
===> Epoch[60](400/2500): Loss: 0.0952
===> Epoch[60](500/2500): Loss: 0.0953
===> Epoch[60](600/2500): Loss: 0.0950
===> Epoch[60](700/2500): Loss: 0.0951
===> Epoch[60](800/2500): Loss: 0.0961
===> Epoch[60](900/2500): Loss: 0.1032
===> Epoch[60](1000/2500): Loss: 0.0958
===> Epoch[60](1100/2500): Loss: 0.0955
===> Epoch[60](1200/2500): Loss: 0.0955
===> Epoch[60](1300/2500): Loss: 0.0948
===> Epoch[60](1400/2500): Loss: 0.0954
===> Epoch[60](1500/2500): Loss: 0.0951
===> Epoch[60](1600/2500): Loss: 0.0955
===> Epoch[60](1700/2500): Loss: 0.0954
===> Epoch[60](1800/2500): Loss: 0.0953
===> Epoch[60](1900/2500): Loss: 0.0955
===> Epoch[60](2000/2500): Loss: 0.0946
===> Epoch[60](2100/2500): Loss: 0.0956
===> Epoch[60](2200/2500): Loss: 0.0952
===> Epoch[60](2300/2500): Loss: 0.0954
===> Epoch[60](2400/2500): Loss: 0.0947
===> Epoch[60](2500/2500): Loss: 0.0951
===> Epoch 60 Complete: Avg. Loss: 0.0958
===> Timestamp: [2025-07-29 20:16:40]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.0955
===> Epoch[60](200/2500): Loss: 0.0948
===> Epoch[60](300/2500): Loss: 0.0960
===> Epoch[60](400/2500): Loss: 0.0952
===> Epoch[60](500/2500): Loss: 0.0953
===> Epoch[60](600/2500): Loss: 0.0950
===> Epoch[60](700/2500): Loss: 0.0951
===> Epoch[60](800/2500): Loss: 0.0961
===> Epoch[60](900/2500): Loss: 0.1032
===> Epoch[60](1000/2500): Loss: 0.0958
===> Epoch[60](1100/2500): Loss: 0.0955
===> Epoch[60](1200/2500): Loss: 0.0955
===> Epoch[60](1300/2500): Loss: 0.0948
===> Epoch[60](1400/2500): Loss: 0.0954
===> Epoch[60](1500/2500): Loss: 0.0951
===> Epoch[60](1600/2500): Loss: 0.0955
===> Epoch[60](1700/2500): Loss: 0.0954
===> Epoch[60](1800/2500): Loss: 0.0953
===> Epoch[60](1900/2500): Loss: 0.0955
===> Epoch[60](2000/2500): Loss: 0.0946
===> Epoch[60](2100/2500): Loss: 0.0956
===> Epoch[60](2200/2500): Loss: 0.0952
===> Epoch[60](2300/2500): Loss: 0.0954
===> Epoch[60](2400/2500): Loss: 0.0947
===> Epoch[60](2500/2500): Loss: 0.0951
===> Epoch 60 Complete: Avg. Loss: 0.0958
===> Timestamp: [2025-07-29 20:16:40]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.0955
===> Epoch[60](200/2500): Loss: 0.0948
===> Epoch[60](300/2500): Loss: 0.0960
===> Epoch[60](400/2500): Loss: 0.0952
===> Epoch[60](500/2500): Loss: 0.0953
===> Epoch[60](600/2500): Loss: 0.0950
===> Epoch[60](700/2500): Loss: 0.0951
===> Epoch[60](800/2500): Loss: 0.0961
===> Epoch[60](900/2500): Loss: 0.1032
===> Epoch[60](1000/2500): Loss: 0.0958
===> Epoch[60](1100/2500): Loss: 0.0955
===> Epoch[60](1200/2500): Loss: 0.0955
===> Epoch[60](1300/2500): Loss: 0.0948
===> Epoch[60](1400/2500): Loss: 0.0954
===> Epoch[60](1500/2500): Loss: 0.0951
===> Epoch[60](1600/2500): Loss: 0.0955
===> Epoch[60](1700/2500): Loss: 0.0954
===> Epoch[60](1800/2500): Loss: 0.0953
===> Epoch[60](1900/2500): Loss: 0.0955
===> Epoch[60](2000/2500): Loss: 0.0946
===> Epoch[60](2100/2500): Loss: 0.0956
===> Epoch[60](2200/2500): Loss: 0.0952
===> Epoch[60](2300/2500): Loss: 0.0954
===> Epoch[60](2400/2500): Loss: 0.0947
===> Epoch[60](2500/2500): Loss: 0.0951
===> Epoch 60 Complete: Avg. Loss: 0.0958
===> Timestamp: [2025-07-29 20:16:40]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.0955
===> Epoch[60](200/2500): Loss: 0.0948
===> Epoch[60](300/2500): Loss: 0.0960
===> Epoch[60](400/2500): Loss: 0.0952
===> Epoch[60](500/2500): Loss: 0.0953
===> Epoch[60](600/2500): Loss: 0.0950
===> Epoch[60](700/2500): Loss: 0.0951
===> Epoch[60](800/2500): Loss: 0.0961
===> Epoch[60](900/2500): Loss: 0.1032
===> Epoch[60](1000/2500): Loss: 0.0958
===> Epoch[60](1100/2500): Loss: 0.0955
===> Epoch[60](1200/2500): Loss: 0.0955
===> Epoch[60](1300/2500): Loss: 0.0948
===> Epoch[60](1400/2500): Loss: 0.0954
===> Epoch[60](1500/2500): Loss: 0.0951
===> Epoch[60](1600/2500): Loss: 0.0955
===> Epoch[60](1700/2500): Loss: 0.0954
===> Epoch[60](1800/2500): Loss: 0.0953
===> Epoch[60](1900/2500): Loss: 0.0955
===> Epoch[60](2000/2500): Loss: 0.0946
===> Epoch[60](2100/2500): Loss: 0.0956
===> Epoch[60](2200/2500): Loss: 0.0952
===> Epoch[60](2300/2500): Loss: 0.0954
===> Epoch[60](2400/2500): Loss: 0.0947
===> Epoch[60](2500/2500): Loss: 0.0951
===> Epoch 60 Complete: Avg. Loss: 0.0958
===> Timestamp: [2025-07-29 20:16:40]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.0955
===> Epoch[60](200/2500): Loss: 0.0948
===> Epoch[60](300/2500): Loss: 0.0960
===> Epoch[60](400/2500): Loss: 0.0952
===> Epoch[60](500/2500): Loss: 0.0953
===> Epoch[60](600/2500): Loss: 0.0950
===> Epoch[60](700/2500): Loss: 0.0951
===> Epoch[60](800/2500): Loss: 0.0961
===> Epoch[60](900/2500): Loss: 0.1032
===> Epoch[60](1000/2500): Loss: 0.0958
===> Epoch[60](1100/2500): Loss: 0.0955
===> Epoch[60](1200/2500): Loss: 0.0955
===> Epoch[60](1300/2500): Loss: 0.0948
===> Epoch[60](1400/2500): Loss: 0.0954
===> Epoch[60](1500/2500): Loss: 0.0951
===> Epoch[60](1600/2500): Loss: 0.0955
===> Epoch[60](1700/2500): Loss: 0.0954
===> Epoch[60](1800/2500): Loss: 0.0953
===> Epoch[60](1900/2500): Loss: 0.0955
===> Epoch[60](2000/2500): Loss: 0.0946
===> Epoch[60](2100/2500): Loss: 0.0956
===> Epoch[60](2200/2500): Loss: 0.0952
===> Epoch[60](2300/2500): Loss: 0.0954
===> Epoch[60](2400/2500): Loss: 0.0947
===> Epoch[60](2500/2500): Loss: 0.0951
===> Epoch 60 Complete: Avg. Loss: 0.0958
===> Timestamp: [2025-07-29 20:16:40]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.0955
===> Epoch[60](200/2500): Loss: 0.0948
===> Epoch[60](300/2500): Loss: 0.0960
===> Epoch[60](400/2500): Loss: 0.0952
===> Epoch[60](500/2500): Loss: 0.0953
===> Epoch[60](600/2500): Loss: 0.0950
===> Epoch[60](700/2500): Loss: 0.0951
===> Epoch[60](800/2500): Loss: 0.0961
===> Epoch[60](900/2500): Loss: 0.1032
===> Epoch[60](1000/2500): Loss: 0.0958
===> Epoch[60](1100/2500): Loss: 0.0955
===> Epoch[60](1200/2500): Loss: 0.0955
===> Epoch[60](1300/2500): Loss: 0.0948
===> Epoch[60](1400/2500): Loss: 0.0954
===> Epoch[60](1500/2500): Loss: 0.0951
===> Epoch[60](1600/2500): Loss: 0.0955
===> Epoch[60](1700/2500): Loss: 0.0954
===> Epoch[60](1800/2500): Loss: 0.0953
===> Epoch[60](1900/2500): Loss: 0.0955
===> Epoch[60](2000/2500): Loss: 0.0946
===> Epoch[60](2100/2500): Loss: 0.0956
===> Epoch[60](2200/2500): Loss: 0.0952
===> Epoch[60](2300/2500): Loss: 0.0954
===> Epoch[60](2400/2500): Loss: 0.0947
===> Epoch[60](2500/2500): Loss: 0.0951
===> Epoch 60 Complete: Avg. Loss: 0.0958
===> Timestamp: [2025-07-29 20:16:40]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.0955
===> Epoch[60](200/2500): Loss: 0.0948
===> Epoch[60](300/2500): Loss: 0.0960
===> Epoch[60](400/2500): Loss: 0.0952
===> Epoch[60](500/2500): Loss: 0.0953
===> Epoch[60](600/2500): Loss: 0.0950
===> Epoch[60](700/2500): Loss: 0.0951
===> Epoch[60](800/2500): Loss: 0.0961
===> Epoch[60](900/2500): Loss: 0.1032
===> Epoch[60](1000/2500): Loss: 0.0958
===> Epoch[60](1100/2500): Loss: 0.0955
===> Epoch[60](1200/2500): Loss: 0.0955
===> Epoch[60](1300/2500): Loss: 0.0948
===> Epoch[60](1400/2500): Loss: 0.0954
===> Epoch[60](1500/2500): Loss: 0.0951
===> Epoch[60](1600/2500): Loss: 0.0955
===> Epoch[60](1700/2500): Loss: 0.0954
===> Epoch[60](1800/2500): Loss: 0.0953
===> Epoch[60](1900/2500): Loss: 0.0955
===> Epoch[60](2000/2500): Loss: 0.0946
===> Epoch[60](2100/2500): Loss: 0.0956
===> Epoch[60](2200/2500): Loss: 0.0952
===> Epoch[60](2300/2500): Loss: 0.0954
===> Epoch[60](2400/2500): Loss: 0.0947
===> Epoch[60](2500/2500): Loss: 0.0951
===> Epoch 60 Complete: Avg. Loss: 0.0958
===> Timestamp: [2025-07-29 20:16:40]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.0955
===> Epoch[60](200/2500): Loss: 0.0948
===> Epoch[60](300/2500): Loss: 0.0960
===> Epoch[60](400/2500): Loss: 0.0952
===> Epoch[60](500/2500): Loss: 0.0953
===> Epoch[60](600/2500): Loss: 0.0950
===> Epoch[60](700/2500): Loss: 0.0951
===> Epoch[60](800/2500): Loss: 0.0961
===> Epoch[60](900/2500): Loss: 0.1032
===> Epoch[60](1000/2500): Loss: 0.0958
===> Epoch[60](1100/2500): Loss: 0.0955
===> Epoch[60](1200/2500): Loss: 0.0955
===> Epoch[60](1300/2500): Loss: 0.0948
===> Epoch[60](1400/2500): Loss: 0.0954
===> Epoch[60](1500/2500): Loss: 0.0951
===> Epoch[60](1600/2500): Loss: 0.0955
===> Epoch[60](1700/2500): Loss: 0.0954
===> Epoch[60](1800/2500): Loss: 0.0953
===> Epoch[60](1900/2500): Loss: 0.0955
===> Epoch[60](2000/2500): Loss: 0.0946
===> Epoch[60](2100/2500): Loss: 0.0956
===> Epoch[60](2200/2500): Loss: 0.0952
===> Epoch[60](2300/2500): Loss: 0.0954
===> Epoch[60](2400/2500): Loss: 0.0947
===> Epoch[60](2500/2500): Loss: 0.0951
===> Epoch 60 Complete: Avg. Loss: 0.0958
===> Timestamp: [2025-07-29 20:16:40]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.0955
===> Epoch[60](200/2500): Loss: 0.0948
===> Epoch[60](300/2500): Loss: 0.0960
===> Epoch[60](400/2500): Loss: 0.0952
===> Epoch[60](500/2500): Loss: 0.0953
===> Epoch[60](600/2500): Loss: 0.0950
===> Epoch[60](700/2500): Loss: 0.0951
===> Epoch[60](800/2500): Loss: 0.0961
===> Epoch[60](900/2500): Loss: 0.1032
===> Epoch[60](1000/2500): Loss: 0.0958
===> Epoch[60](1100/2500): Loss: 0.0955
===> Epoch[60](1200/2500): Loss: 0.0955
===> Epoch[60](1300/2500): Loss: 0.0948
===> Epoch[60](1400/2500): Loss: 0.0954
===> Epoch[60](1500/2500): Loss: 0.0951
===> Epoch[60](1600/2500): Loss: 0.0955
===> Epoch[60](1700/2500): Loss: 0.0954
===> Epoch[60](1800/2500): Loss: 0.0953
===> Epoch[60](1900/2500): Loss: 0.0955
===> Epoch[60](2000/2500): Loss: 0.0946
===> Epoch[60](2100/2500): Loss: 0.0956
===> Epoch[60](2200/2500): Loss: 0.0952
===> Epoch[60](2300/2500): Loss: 0.0954
===> Epoch[60](2400/2500): Loss: 0.0947
===> Epoch[60](2500/2500): Loss: 0.0951
===> Epoch 60 Complete: Avg. Loss: 0.0958
===> Timestamp: [2025-07-29 20:16:40]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.0955
===> Epoch[60](200/2500): Loss: 0.0948
===> Epoch[60](300/2500): Loss: 0.0960
===> Epoch[60](400/2500): Loss: 0.0952
===> Epoch[60](500/2500): Loss: 0.0953
===> Epoch[60](600/2500): Loss: 0.0950
===> Epoch[60](700/2500): Loss: 0.0951
===> Epoch[60](800/2500): Loss: 0.0961
===> Epoch[60](900/2500): Loss: 0.1032
===> Epoch[60](1000/2500): Loss: 0.0958
===> Epoch[60](1100/2500): Loss: 0.0955
===> Epoch[60](1200/2500): Loss: 0.0955
===> Epoch[60](1300/2500): Loss: 0.0948
===> Epoch[60](1400/2500): Loss: 0.0954
===> Epoch[60](1500/2500): Loss: 0.0951
===> Epoch[60](1600/2500): Loss: 0.0955
===> Epoch[60](1700/2500): Loss: 0.0954
===> Epoch[60](1800/2500): Loss: 0.0953
===> Epoch[60](1900/2500): Loss: 0.0955
===> Epoch[60](2000/2500): Loss: 0.0946
===> Epoch[60](2100/2500): Loss: 0.0956
===> Epoch[60](2200/2500): Loss: 0.0952
===> Epoch[60](2300/2500): Loss: 0.0954
===> Epoch[60](2400/2500): Loss: 0.0947
===> Epoch[60](2500/2500): Loss: 0.0951
===> Epoch 60 Complete: Avg. Loss: 0.0958
===> Timestamp: [2025-07-29 20:16:40]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.0955
===> Epoch[60](200/2500): Loss: 0.0948
===> Epoch[60](300/2500): Loss: 0.0960
===> Epoch[60](400/2500): Loss: 0.0952
===> Epoch[60](500/2500): Loss: 0.0953
===> Epoch[60](600/2500): Loss: 0.0950
===> Epoch[60](700/2500): Loss: 0.0951
===> Epoch[60](800/2500): Loss: 0.0961
===> Epoch[60](900/2500): Loss: 0.1032
===> Epoch[60](1000/2500): Loss: 0.0958
===> Epoch[60](1100/2500): Loss: 0.0955
===> Epoch[60](1200/2500): Loss: 0.0955
===> Epoch[60](1300/2500): Loss: 0.0948
===> Epoch[60](1400/2500): Loss: 0.0954
===> Epoch[60](1500/2500): Loss: 0.0951
===> Epoch[60](1600/2500): Loss: 0.0955
===> Epoch[60](1700/2500): Loss: 0.0954
===> Epoch[60](1800/2500): Loss: 0.0953
===> Epoch[60](1900/2500): Loss: 0.0955
===> Epoch[60](2000/2500): Loss: 0.0946
===> Epoch[60](2100/2500): Loss: 0.0956
===> Epoch[60](2200/2500): Loss: 0.0952
===> Epoch[60](2300/2500): Loss: 0.0954
===> Epoch[60](2400/2500): Loss: 0.0947
===> Epoch[60](2500/2500): Loss: 0.0951
===> Epoch 60 Complete: Avg. Loss: 0.0958
===> Timestamp: [2025-07-29 20:16:40]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.0955
===> Epoch[60](200/2500): Loss: 0.0948
===> Epoch[60](300/2500): Loss: 0.0960
===> Epoch[60](400/2500): Loss: 0.0952
===> Epoch[60](500/2500): Loss: 0.0953
===> Epoch[60](600/2500): Loss: 0.0950
===> Epoch[60](700/2500): Loss: 0.0951
===> Epoch[60](800/2500): Loss: 0.0961
===> Epoch[60](900/2500): Loss: 0.1032
===> Epoch[60](1000/2500): Loss: 0.0958
===> Epoch[60](1100/2500): Loss: 0.0955
===> Epoch[60](1200/2500): Loss: 0.0955
===> Epoch[60](1300/2500): Loss: 0.0948
===> Epoch[60](1400/2500): Loss: 0.0954
===> Epoch[60](1500/2500): Loss: 0.0951
===> Epoch[60](1600/2500): Loss: 0.0955
===> Epoch[60](1700/2500): Loss: 0.0954
===> Epoch[60](1800/2500): Loss: 0.0953
===> Epoch[60](1900/2500): Loss: 0.0955
===> Epoch[60](2000/2500): Loss: 0.0946
===> Epoch[60](2100/2500): Loss: 0.0956
===> Epoch[60](2200/2500): Loss: 0.0952
===> Epoch[60](2300/2500): Loss: 0.0954
===> Epoch[60](2400/2500): Loss: 0.0947
===> Epoch[60](2500/2500): Loss: 0.0951
===> Epoch 60 Complete: Avg. Loss: 0.0958
===> Timestamp: [2025-07-29 20:16:40]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.0955
===> Epoch[60](200/2500): Loss: 0.0948
===> Epoch[60](300/2500): Loss: 0.0960
===> Epoch[60](400/2500): Loss: 0.0952
===> Epoch[60](500/2500): Loss: 0.0953
===> Epoch[60](600/2500): Loss: 0.0950
===> Epoch[60](700/2500): Loss: 0.0951
===> Epoch[60](800/2500): Loss: 0.0961
===> Epoch[60](900/2500): Loss: 0.1032
===> Epoch[60](1000/2500): Loss: 0.0958
===> Epoch[60](1100/2500): Loss: 0.0955
===> Epoch[60](1200/2500): Loss: 0.0955
===> Epoch[60](1300/2500): Loss: 0.0948
===> Epoch[60](1400/2500): Loss: 0.0954
===> Epoch[60](1500/2500): Loss: 0.0951
===> Epoch[60](1600/2500): Loss: 0.0955
===> Epoch[60](1700/2500): Loss: 0.0954
===> Epoch[60](1800/2500): Loss: 0.0953
===> Epoch[60](1900/2500): Loss: 0.0955
===> Epoch[60](2000/2500): Loss: 0.0946
===> Epoch[60](2100/2500): Loss: 0.0956
===> Epoch[60](2200/2500): Loss: 0.0952
===> Epoch[60](2300/2500): Loss: 0.0954
===> Epoch[60](2400/2500): Loss: 0.0947
===> Epoch[60](2500/2500): Loss: 0.0951
===> Epoch 60 Complete: Avg. Loss: 0.0958
===> Timestamp: [2025-07-29 20:16:40]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.0955
===> Epoch[60](200/2500): Loss: 0.0948
===> Epoch[60](300/2500): Loss: 0.0960
===> Epoch[60](400/2500): Loss: 0.0952
===> Epoch[60](500/2500): Loss: 0.0953
===> Epoch[60](600/2500): Loss: 0.0950
===> Epoch[60](700/2500): Loss: 0.0951
===> Epoch[60](800/2500): Loss: 0.0961
===> Epoch[60](900/2500): Loss: 0.1032
===> Epoch[60](1000/2500): Loss: 0.0958
===> Epoch[60](1100/2500): Loss: 0.0955
===> Epoch[60](1200/2500): Loss: 0.0955
===> Epoch[60](1300/2500): Loss: 0.0948
===> Epoch[60](1400/2500): Loss: 0.0954
===> Epoch[60](1500/2500): Loss: 0.0951
===> Epoch[60](1600/2500): Loss: 0.0955
===> Epoch[60](1700/2500): Loss: 0.0954
===> Epoch[60](1800/2500): Loss: 0.0953
===> Epoch[60](1900/2500): Loss: 0.0955
===> Epoch[60](2000/2500): Loss: 0.0946
===> Epoch[60](2100/2500): Loss: 0.0956
===> Epoch[60](2200/2500): Loss: 0.0952
===> Epoch[60](2300/2500): Loss: 0.0954
===> Epoch[60](2400/2500): Loss: 0.0947
===> Epoch[60](2500/2500): Loss: 0.0951
===> Epoch 60 Complete: Avg. Loss: 0.0958
===> Timestamp: [2025-07-29 20:16:40]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.0955
===> Epoch[60](200/2500): Loss: 0.0948
===> Epoch[60](300/2500): Loss: 0.0960
===> Epoch[60](400/2500): Loss: 0.0952
===> Epoch[60](500/2500): Loss: 0.0953
===> Epoch[60](600/2500): Loss: 0.0950
===> Epoch[60](700/2500): Loss: 0.0951
===> Epoch[60](800/2500): Loss: 0.0961
===> Epoch[60](900/2500): Loss: 0.1032
===> Epoch[60](1000/2500): Loss: 0.0958
===> Epoch[60](1100/2500): Loss: 0.0955
===> Epoch[60](1200/2500): Loss: 0.0955
===> Epoch[60](1300/2500): Loss: 0.0948
===> Epoch[60](1400/2500): Loss: 0.0954
===> Epoch[60](1500/2500): Loss: 0.0951
===> Epoch[60](1600/2500): Loss: 0.0955
===> Epoch[60](1700/2500): Loss: 0.0954
===> Epoch[60](1800/2500): Loss: 0.0953
===> Epoch[60](1900/2500): Loss: 0.0955
===> Epoch[60](2000/2500): Loss: 0.0946
===> Epoch[60](2100/2500): Loss: 0.0956
===> Epoch[60](2200/2500): Loss: 0.0952
===> Epoch[60](2300/2500): Loss: 0.0954
===> Epoch[60](2400/2500): Loss: 0.0947
===> Epoch[60](2500/2500): Loss: 0.0951
===> Epoch 60 Complete: Avg. Loss: 0.0958
===> Timestamp: [2025-07-29 20:16:40]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.0955
===> Epoch[60](200/2500): Loss: 0.0948
===> Epoch[60](300/2500): Loss: 0.0960
===> Epoch[60](400/2500): Loss: 0.0952
===> Epoch[60](500/2500): Loss: 0.0953
===> Epoch[60](600/2500): Loss: 0.0950
===> Epoch[60](700/2500): Loss: 0.0951
===> Epoch[60](800/2500): Loss: 0.0961
===> Epoch[60](900/2500): Loss: 0.1032
===> Epoch[60](1000/2500): Loss: 0.0958
===> Epoch[60](1100/2500): Loss: 0.0955
===> Epoch[60](1200/2500): Loss: 0.0955
===> Epoch[60](1300/2500): Loss: 0.0948
===> Epoch[60](1400/2500): Loss: 0.0954
===> Epoch[60](1500/2500): Loss: 0.0951
===> Epoch[60](1600/2500): Loss: 0.0955
===> Epoch[60](1700/2500): Loss: 0.0954
===> Epoch[60](1800/2500): Loss: 0.0953
===> Epoch[60](1900/2500): Loss: 0.0955
===> Epoch[60](2000/2500): Loss: 0.0946
===> Epoch[60](2100/2500): Loss: 0.0956
===> Epoch[60](2200/2500): Loss: 0.0952
===> Epoch[60](2300/2500): Loss: 0.0954
===> Epoch[60](2400/2500): Loss: 0.0947
===> Epoch[60](2500/2500): Loss: 0.0951
===> Epoch 60 Complete: Avg. Loss: 0.0958
===> Timestamp: [2025-07-29 20:16:40]
Checkpoint saved to TrainedNet/_epoch_60.pth
===> Epoch[60](100/2500): Loss: 0.0955
===> Epoch[60](200/2500): Loss: 0.0948
===> Epoch[60](300/2500): Loss: 0.0960
===> Epoch[60](400/2500): Loss: 0.0952
===> Epoch[60](500/2500): Loss: 0.0953
===> Epoch[60](600/2500): Loss: 0.0950
===> Epoch[60](700/2500): Loss: 0.0951
===> Epoch[60](800/2500): Loss: 0.0961
===> Epoch[60](900/2500): Loss: 0.1032
===> Epoch[60](1000/2500): Loss: 0.0958
===> Epoch[60](1100/2500): Loss: 0.0955
===> Epoch[60](1200/2500): Loss: 0.0955
===> Epoch[60](1300/2500): Loss: 0.0948
===> Epoch[60](1400/2500): Loss: 0.0954
===> Epoch[60](1500/2500): Loss: 0.0951
===> Epoch[60](1600/2500): Loss: 0.0955
===> Epoch[60](1700/2500): Loss: 0.0954
===> Epoch[60](1800/2500): Loss: 0.0953
===> Epoch[60](1900/2500): Loss: 0.0955
===> Epoch[60](2000/2500): Loss: 0.0946
===> Epoch[60](2100/2500): Loss: 0.0956
===> Epoch[60](2200/2500): Loss: 0.0952
===> Epoch[60](2300/2500): Loss: 0.0954
===> Epoch[60](2400/2500): Loss: 0.0947
===> Epoch[60](2500/2500): Loss: 0.0951
===> Epoch 60 Complete: Avg. Loss: 0.0958
===> Timestamp: [2025-07-29 20:16:40]
Checkpoint saved to TrainedNet/_epoch_60.pth
